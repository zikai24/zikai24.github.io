<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>SwinTransformer</title>
    <link href="/2023/03/27/SwinTransformer/"/>
    <url>/2023/03/27/SwinTransformer/</url>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br><span class="line">556</span><br><span class="line">557</span><br><span class="line">558</span><br><span class="line">559</span><br><span class="line">560</span><br><span class="line">561</span><br><span class="line">562</span><br><span class="line">563</span><br><span class="line">564</span><br><span class="line">565</span><br><span class="line">566</span><br><span class="line">567</span><br><span class="line">568</span><br><span class="line">569</span><br><span class="line">570</span><br><span class="line">571</span><br><span class="line">572</span><br><span class="line">573</span><br><span class="line">574</span><br><span class="line">575</span><br><span class="line">576</span><br><span class="line">577</span><br><span class="line">578</span><br><span class="line">579</span><br><span class="line">580</span><br><span class="line">581</span><br><span class="line">582</span><br><span class="line">583</span><br><span class="line">584</span><br><span class="line">585</span><br><span class="line">586</span><br><span class="line">587</span><br><span class="line">588</span><br><span class="line">589</span><br><span class="line">590</span><br><span class="line">591</span><br><span class="line">592</span><br><span class="line">593</span><br><span class="line">594</span><br><span class="line">595</span><br><span class="line">596</span><br><span class="line">597</span><br><span class="line">598</span><br><span class="line">599</span><br><span class="line">600</span><br><span class="line">601</span><br><span class="line">602</span><br><span class="line">603</span><br><span class="line">604</span><br><span class="line">605</span><br><span class="line">606</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># --------------------------------------------------------</span><br><span class="hljs-comment"># Swin Transformer</span><br><span class="hljs-comment"># Copyright (c) 2021 Microsoft</span><br><span class="hljs-comment"># Licensed under The MIT License [see LICENSE for details]</span><br><span class="hljs-comment"># Written by Ze Liu</span><br><span class="hljs-comment"># --------------------------------------------------------</span><br><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.utils.checkpoint <span class="hljs-keyword">as</span> checkpoint<br><span class="hljs-keyword">from</span> timm.models.layers <span class="hljs-keyword">import</span> DropPath, to_2tuple, trunc_normal_<br><br><span class="hljs-keyword">try</span>:<br>    <span class="hljs-keyword">import</span> os, sys<br><br>    kernel_path = os.path.abspath(os.path.join(<span class="hljs-string">&#x27;..&#x27;</span>))<br>    sys.path.append(kernel_path)<br>    <span class="hljs-keyword">from</span> kernels.window_process.window_process <span class="hljs-keyword">import</span> WindowProcess, WindowProcessReverse<br><br><span class="hljs-keyword">except</span>:<br>    WindowProcess = <span class="hljs-literal">None</span><br>    WindowProcessReverse = <span class="hljs-literal">None</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;[Warning] Fused window process have not been installed. Please refer to get_started.md for installation.&quot;</span>)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Mlp</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, in_features, hidden_features=<span class="hljs-literal">None</span>, out_features=<span class="hljs-literal">None</span>, act_layer=nn.GELU, drop=<span class="hljs-number">0.</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        out_features = out_features <span class="hljs-keyword">or</span> in_features<br>        hidden_features = hidden_features <span class="hljs-keyword">or</span> in_features<br>        self.fc1 = nn.Linear(in_features, hidden_features)<br>        self.act = act_layer()<br>        self.fc2 = nn.Linear(hidden_features, out_features)<br>        self.drop = nn.Dropout(drop)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.fc1(x)<br>        x = self.act(x)<br>        x = self.drop(x)<br>        x = self.fc2(x)<br>        x = self.drop(x)<br>        <span class="hljs-keyword">return</span> x<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">window_partition</span>(<span class="hljs-params">x, window_size</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        x: (B, H, W, C)</span><br><span class="hljs-string">        window_size (int): window size</span><br><span class="hljs-string">    Returns:</span><br><span class="hljs-string">        windows: (num_windows*B, window_size, window_size, C)</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    B, H, W, C = x.shape<br>    x = x.view(B, H // window_size, window_size, W // window_size, window_size, C)<br>    windows = x.permute(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>).contiguous().view(-<span class="hljs-number">1</span>, window_size, window_size, C)<br>    <span class="hljs-keyword">return</span> windows<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">window_reverse</span>(<span class="hljs-params">windows, window_size, H, W</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        windows: (num_windows*B, window_size, window_size, C)</span><br><span class="hljs-string">        window_size (int): Window size</span><br><span class="hljs-string">        H (int): Height of image</span><br><span class="hljs-string">        W (int): Width of image</span><br><span class="hljs-string">    Returns:</span><br><span class="hljs-string">        x: (B, H, W, C)</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    B = <span class="hljs-built_in">int</span>(windows.shape[<span class="hljs-number">0</span>] / (H * W / window_size / window_size))<br>    x = windows.view(B, H // window_size, W // window_size, window_size, window_size, -<span class="hljs-number">1</span>)<br>    x = x.permute(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>).contiguous().view(B, H, W, -<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> x<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">WindowAttention</span>(nn.Module):<br>    <span class="hljs-string">r&quot;&quot;&quot; Window based multi-head self attention (W-MSA) module with relative position bias.</span><br><span class="hljs-string">    It supports both of shifted and non-shifted window.</span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        dim (int): Number of input channels.</span><br><span class="hljs-string">        window_size (tuple[int]): The height and width of the window.</span><br><span class="hljs-string">        num_heads (int): Number of attention heads.</span><br><span class="hljs-string">        qkv_bias (bool, optional):  If True, add a learnable bias to query, key, value. Default: True</span><br><span class="hljs-string">        qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set</span><br><span class="hljs-string">        attn_drop (float, optional): Dropout ratio of attention weight. Default: 0.0</span><br><span class="hljs-string">        proj_drop (float, optional): Dropout ratio of output. Default: 0.0</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, dim, window_size, num_heads, qkv_bias=<span class="hljs-literal">True</span>, qk_scale=<span class="hljs-literal">None</span>, attn_drop=<span class="hljs-number">0.</span>, proj_drop=<span class="hljs-number">0.</span></span>):<br><br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.dim = dim<br>        self.window_size = window_size  <span class="hljs-comment"># Wh, Ww</span><br>        self.num_heads = num_heads<br>        head_dim = dim // num_heads<br>        self.scale = qk_scale <span class="hljs-keyword">or</span> head_dim ** -<span class="hljs-number">0.5</span><br><br>        <span class="hljs-comment"># define a parameter table of relative position bias</span><br>        self.relative_position_bias_table = nn.Parameter(<br>            torch.zeros((<span class="hljs-number">2</span> * window_size[<span class="hljs-number">0</span>] - <span class="hljs-number">1</span>) * (<span class="hljs-number">2</span> * window_size[<span class="hljs-number">1</span>] - <span class="hljs-number">1</span>), num_heads))  <span class="hljs-comment"># 2*Wh-1 * 2*Ww-1, nH</span><br><br>        <span class="hljs-comment"># get pair-wise relative position index for each token inside the window</span><br>        coords_h = torch.arange(self.window_size[<span class="hljs-number">0</span>])<br>        coords_w = torch.arange(self.window_size[<span class="hljs-number">1</span>])<br>        coords = torch.stack(torch.meshgrid([coords_h, coords_w]))  <span class="hljs-comment"># 2, Wh, Ww</span><br>        coords_flatten = torch.flatten(coords, <span class="hljs-number">1</span>)  <span class="hljs-comment"># 2, Wh*Ww</span><br>        relative_coords = coords_flatten[:, :, <span class="hljs-literal">None</span>] - coords_flatten[:, <span class="hljs-literal">None</span>, :]  <span class="hljs-comment"># 2, Wh*Ww, Wh*Ww</span><br>        relative_coords = relative_coords.permute(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>).contiguous()  <span class="hljs-comment"># Wh*Ww, Wh*Ww, 2</span><br>        relative_coords[:, :, <span class="hljs-number">0</span>] += self.window_size[<span class="hljs-number">0</span>] - <span class="hljs-number">1</span>  <span class="hljs-comment"># shift to start from 0</span><br>        relative_coords[:, :, <span class="hljs-number">1</span>] += self.window_size[<span class="hljs-number">1</span>] - <span class="hljs-number">1</span><br>        relative_coords[:, :, <span class="hljs-number">0</span>] *= <span class="hljs-number">2</span> * self.window_size[<span class="hljs-number">1</span>] - <span class="hljs-number">1</span><br>        relative_position_index = relative_coords.<span class="hljs-built_in">sum</span>(-<span class="hljs-number">1</span>)  <span class="hljs-comment"># Wh*Ww, Wh*Ww</span><br>        self.register_buffer(<span class="hljs-string">&quot;relative_position_index&quot;</span>, relative_position_index)<br><br>        self.qkv = nn.Linear(dim, dim * <span class="hljs-number">3</span>, bias=qkv_bias)<br>        self.attn_drop = nn.Dropout(attn_drop)<br>        self.proj = nn.Linear(dim, dim)<br>        self.proj_drop = nn.Dropout(proj_drop)<br><br>        trunc_normal_(self.relative_position_bias_table, std=<span class="hljs-number">.02</span>)<br>        self.softmax = nn.Softmax(dim=-<span class="hljs-number">1</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, mask=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            x: input features with shape of (num_windows*B, N, C)</span><br><span class="hljs-string">            mask: (0/-inf) mask with shape of (num_windows, Wh*Ww, Wh*Ww) or None</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        B_, N, C = x.shape<br>        qkv = self.qkv(x).reshape(B_, N, <span class="hljs-number">3</span>, self.num_heads, C // self.num_heads).permute(<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">4</span>)<br>        q, k, v = qkv[<span class="hljs-number">0</span>], qkv[<span class="hljs-number">1</span>], qkv[<span class="hljs-number">2</span>]  <span class="hljs-comment"># make torchscript happy (cannot use tensor as tuple)</span><br><br>        q = q * self.scale<br>        attn = (q @ k.transpose(-<span class="hljs-number">2</span>, -<span class="hljs-number">1</span>))<br><br>        relative_position_bias = self.relative_position_bias_table[self.relative_position_index.view(-<span class="hljs-number">1</span>)].view(<br>            self.window_size[<span class="hljs-number">0</span>] * self.window_size[<span class="hljs-number">1</span>], self.window_size[<span class="hljs-number">0</span>] * self.window_size[<span class="hljs-number">1</span>], -<span class="hljs-number">1</span>)  <span class="hljs-comment"># Wh*Ww,Wh*Ww,nH</span><br>        relative_position_bias = relative_position_bias.permute(<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>).contiguous()  <span class="hljs-comment"># nH, Wh*Ww, Wh*Ww</span><br>        attn = attn + relative_position_bias.unsqueeze(<span class="hljs-number">0</span>)<br><br>        <span class="hljs-keyword">if</span> mask <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            nW = mask.shape[<span class="hljs-number">0</span>]<br>            attn = attn.view(B_ // nW, nW, self.num_heads, N, N) + mask.unsqueeze(<span class="hljs-number">1</span>).unsqueeze(<span class="hljs-number">0</span>)<br>            attn = attn.view(-<span class="hljs-number">1</span>, self.num_heads, N, N)<br>            attn = self.softmax(attn)<br>        <span class="hljs-keyword">else</span>:<br>            attn = self.softmax(attn)<br><br>        attn = self.attn_drop(attn)<br><br>        x = (attn @ v).transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>).reshape(B_, N, C)<br>        x = self.proj(x)<br>        x = self.proj_drop(x)<br>        <span class="hljs-keyword">return</span> x<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">extra_repr</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-built_in">str</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">f&#x27;dim=<span class="hljs-subst">&#123;self.dim&#125;</span>, window_size=<span class="hljs-subst">&#123;self.window_size&#125;</span>, num_heads=<span class="hljs-subst">&#123;self.num_heads&#125;</span>&#x27;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">flops</span>(<span class="hljs-params">self, N</span>):<br>        <span class="hljs-comment"># calculate flops for 1 window with token length of N</span><br>        flops = <span class="hljs-number">0</span><br>        <span class="hljs-comment"># qkv = self.qkv(x)</span><br>        flops += N * self.dim * <span class="hljs-number">3</span> * self.dim<br>        <span class="hljs-comment"># attn = (q @ k.transpose(-2, -1))</span><br>        flops += self.num_heads * N * (self.dim // self.num_heads) * N<br>        <span class="hljs-comment">#  x = (attn @ v)</span><br>        flops += self.num_heads * N * N * (self.dim // self.num_heads)<br>        <span class="hljs-comment"># x = self.proj(x)</span><br>        flops += N * self.dim * self.dim<br>        <span class="hljs-keyword">return</span> flops<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SwinTransformerBlock</span>(nn.Module):<br>    <span class="hljs-string">r&quot;&quot;&quot; Swin Transformer Block.</span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        dim (int): Number of input channels.</span><br><span class="hljs-string">        input_resolution (tuple[int]): Input resulotion.</span><br><span class="hljs-string">        num_heads (int): Number of attention heads.</span><br><span class="hljs-string">        window_size (int): Window size.</span><br><span class="hljs-string">        shift_size (int): Shift size for SW-MSA.</span><br><span class="hljs-string">        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.</span><br><span class="hljs-string">        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True</span><br><span class="hljs-string">        qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set.</span><br><span class="hljs-string">        drop (float, optional): Dropout rate. Default: 0.0</span><br><span class="hljs-string">        attn_drop (float, optional): Attention dropout rate. Default: 0.0</span><br><span class="hljs-string">        drop_path (float, optional): Stochastic depth rate. Default: 0.0</span><br><span class="hljs-string">        act_layer (nn.Module, optional): Activation layer. Default: nn.GELU</span><br><span class="hljs-string">        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm</span><br><span class="hljs-string">        fused_window_process (bool, optional): If True, use one kernel to fused window shift &amp; window partition for acceleration, similar for the reversed part. Default: False</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, dim, input_resolution, num_heads, window_size=<span class="hljs-number">7</span>, shift_size=<span class="hljs-number">0</span>,</span><br><span class="hljs-params">                 mlp_ratio=<span class="hljs-number">4.</span>, qkv_bias=<span class="hljs-literal">True</span>, qk_scale=<span class="hljs-literal">None</span>, drop=<span class="hljs-number">0.</span>, attn_drop=<span class="hljs-number">0.</span>, drop_path=<span class="hljs-number">0.</span>,</span><br><span class="hljs-params">                 act_layer=nn.GELU, norm_layer=nn.LayerNorm,</span><br><span class="hljs-params">                 fused_window_process=<span class="hljs-literal">False</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.dim = dim<br>        self.input_resolution = input_resolution<br>        self.num_heads = num_heads<br>        self.window_size = window_size<br>        self.shift_size = shift_size<br>        self.mlp_ratio = mlp_ratio<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">min</span>(self.input_resolution) &lt;= self.window_size:<br>            <span class="hljs-comment"># if window size is larger than input resolution, we don&#x27;t partition windows</span><br>            self.shift_size = <span class="hljs-number">0</span><br>            self.window_size = <span class="hljs-built_in">min</span>(self.input_resolution)<br>        <span class="hljs-keyword">assert</span> <span class="hljs-number">0</span> &lt;= self.shift_size &lt; self.window_size, <span class="hljs-string">&quot;shift_size must in 0-window_size&quot;</span><br><br>        self.norm1 = norm_layer(dim)<br>        self.attn = WindowAttention(<br>            dim, window_size=to_2tuple(self.window_size), num_heads=num_heads,<br>            qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)<br><br>        self.drop_path = DropPath(drop_path) <span class="hljs-keyword">if</span> drop_path &gt; <span class="hljs-number">0.</span> <span class="hljs-keyword">else</span> nn.Identity()<br>        self.norm2 = norm_layer(dim)<br>        mlp_hidden_dim = <span class="hljs-built_in">int</span>(dim * mlp_ratio)<br>        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)<br><br>        <span class="hljs-keyword">if</span> self.shift_size &gt; <span class="hljs-number">0</span>:<br>            <span class="hljs-comment"># calculate attention mask for SW-MSA</span><br>            H, W = self.input_resolution<br>            img_mask = torch.zeros((<span class="hljs-number">1</span>, H, W, <span class="hljs-number">1</span>))  <span class="hljs-comment"># 1 H W 1</span><br>            h_slices = (<span class="hljs-built_in">slice</span>(<span class="hljs-number">0</span>, -self.window_size),<br>                        <span class="hljs-built_in">slice</span>(-self.window_size, -self.shift_size),<br>                        <span class="hljs-built_in">slice</span>(-self.shift_size, <span class="hljs-literal">None</span>))<br>            w_slices = (<span class="hljs-built_in">slice</span>(<span class="hljs-number">0</span>, -self.window_size),<br>                        <span class="hljs-built_in">slice</span>(-self.window_size, -self.shift_size),<br>                        <span class="hljs-built_in">slice</span>(-self.shift_size, <span class="hljs-literal">None</span>))<br>            cnt = <span class="hljs-number">0</span><br>            <span class="hljs-keyword">for</span> h <span class="hljs-keyword">in</span> h_slices:<br>                <span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> w_slices:<br>                    img_mask[:, h, w, :] = cnt<br>                    cnt += <span class="hljs-number">1</span><br><br>            mask_windows = window_partition(img_mask, self.window_size)  <span class="hljs-comment"># nW, window_size, window_size, 1</span><br>            mask_windows = mask_windows.view(-<span class="hljs-number">1</span>, self.window_size * self.window_size)<br>            attn_mask = mask_windows.unsqueeze(<span class="hljs-number">1</span>) - mask_windows.unsqueeze(<span class="hljs-number">2</span>)<br>            attn_mask = attn_mask.masked_fill(attn_mask != <span class="hljs-number">0</span>, <span class="hljs-built_in">float</span>(-<span class="hljs-number">100.0</span>)).masked_fill(attn_mask == <span class="hljs-number">0</span>, <span class="hljs-built_in">float</span>(<span class="hljs-number">0.0</span>))<br>        <span class="hljs-keyword">else</span>:<br>            attn_mask = <span class="hljs-literal">None</span><br><br>        self.register_buffer(<span class="hljs-string">&quot;attn_mask&quot;</span>, attn_mask)<br>        self.fused_window_process = fused_window_process<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        H, W = self.input_resolution<br>        B, L, C = x.shape<br>        <span class="hljs-keyword">assert</span> L == H * W, <span class="hljs-string">&quot;input feature has wrong size&quot;</span><br><br>        shortcut = x<br>        x = self.norm1(x)<br>        x = x.view(B, H, W, C)<br><br>        <span class="hljs-comment"># cyclic shift</span><br>        <span class="hljs-keyword">if</span> self.shift_size &gt; <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> self.fused_window_process:<br>                shifted_x = torch.roll(x, shifts=(-self.shift_size, -self.shift_size), dims=(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>))<br>                <span class="hljs-comment"># partition windows</span><br>                x_windows = window_partition(shifted_x, self.window_size)  <span class="hljs-comment"># nW*B, window_size, window_size, C</span><br>            <span class="hljs-keyword">else</span>:<br>                x_windows = WindowProcess.apply(x, B, H, W, C, -self.shift_size, self.window_size)<br>        <span class="hljs-keyword">else</span>:<br>            shifted_x = x<br>            <span class="hljs-comment"># partition windows</span><br>            x_windows = window_partition(shifted_x, self.window_size)  <span class="hljs-comment"># nW*B, window_size, window_size, C</span><br><br>        x_windows = x_windows.view(-<span class="hljs-number">1</span>, self.window_size * self.window_size, C)  <span class="hljs-comment"># nW*B, window_size*window_size, C</span><br><br>        <span class="hljs-comment"># W-MSA/SW-MSA</span><br>        attn_windows = self.attn(x_windows, mask=self.attn_mask)  <span class="hljs-comment"># nW*B, window_size*window_size, C</span><br><br>        <span class="hljs-comment"># merge windows</span><br>        attn_windows = attn_windows.view(-<span class="hljs-number">1</span>, self.window_size, self.window_size, C)<br><br>        <span class="hljs-comment"># reverse cyclic shift</span><br>        <span class="hljs-keyword">if</span> self.shift_size &gt; <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> self.fused_window_process:<br>                shifted_x = window_reverse(attn_windows, self.window_size, H, W)  <span class="hljs-comment"># B H&#x27; W&#x27; C</span><br>                x = torch.roll(shifted_x, shifts=(self.shift_size, self.shift_size), dims=(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>))<br>            <span class="hljs-keyword">else</span>:<br>                x = WindowProcessReverse.apply(attn_windows, B, H, W, C, self.shift_size, self.window_size)<br>        <span class="hljs-keyword">else</span>:<br>            shifted_x = window_reverse(attn_windows, self.window_size, H, W)  <span class="hljs-comment"># B H&#x27; W&#x27; C</span><br>            x = shifted_x<br>        x = x.view(B, H * W, C)<br>        x = shortcut + self.drop_path(x)<br><br>        <span class="hljs-comment"># FFN</span><br>        x = x + self.drop_path(self.mlp(self.norm2(x)))<br><br>        <span class="hljs-keyword">return</span> x<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">extra_repr</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-built_in">str</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">f&quot;dim=<span class="hljs-subst">&#123;self.dim&#125;</span>, input_resolution=<span class="hljs-subst">&#123;self.input_resolution&#125;</span>, num_heads=<span class="hljs-subst">&#123;self.num_heads&#125;</span>, &quot;</span> \<br>               <span class="hljs-string">f&quot;window_size=<span class="hljs-subst">&#123;self.window_size&#125;</span>, shift_size=<span class="hljs-subst">&#123;self.shift_size&#125;</span>, mlp_ratio=<span class="hljs-subst">&#123;self.mlp_ratio&#125;</span>&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">flops</span>(<span class="hljs-params">self</span>):<br>        flops = <span class="hljs-number">0</span><br>        H, W = self.input_resolution<br>        <span class="hljs-comment"># norm1</span><br>        flops += self.dim * H * W<br>        <span class="hljs-comment"># W-MSA/SW-MSA</span><br>        nW = H * W / self.window_size / self.window_size<br>        flops += nW * self.attn.flops(self.window_size * self.window_size)<br>        <span class="hljs-comment"># mlp</span><br>        flops += <span class="hljs-number">2</span> * H * W * self.dim * self.dim * self.mlp_ratio<br>        <span class="hljs-comment"># norm2</span><br>        flops += self.dim * H * W<br>        <span class="hljs-keyword">return</span> flops<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">PatchMerging</span>(nn.Module):<br>    <span class="hljs-string">r&quot;&quot;&quot; Patch Merging Layer.</span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        input_resolution (tuple[int]): Resolution of input feature.</span><br><span class="hljs-string">        dim (int): Number of input channels.</span><br><span class="hljs-string">        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_resolution, dim, norm_layer=nn.LayerNorm</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.input_resolution = input_resolution<br>        self.dim = dim<br>        self.reduction = nn.Linear(<span class="hljs-number">4</span> * dim, <span class="hljs-number">2</span> * dim, bias=<span class="hljs-literal">False</span>)<br>        self.norm = norm_layer(<span class="hljs-number">4</span> * dim)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        x: B, H*W, C</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        H, W = self.input_resolution<br>        B, L, C = x.shape<br>        <span class="hljs-keyword">assert</span> L == H * W, <span class="hljs-string">&quot;input feature has wrong size&quot;</span><br>        <span class="hljs-keyword">assert</span> H % <span class="hljs-number">2</span> == <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> W % <span class="hljs-number">2</span> == <span class="hljs-number">0</span>, <span class="hljs-string">f&quot;x size (<span class="hljs-subst">&#123;H&#125;</span>*<span class="hljs-subst">&#123;W&#125;</span>) are not even.&quot;</span><br><br>        x = x.view(B, H, W, C)<br><br>        x0 = x[:, <span class="hljs-number">0</span>::<span class="hljs-number">2</span>, <span class="hljs-number">0</span>::<span class="hljs-number">2</span>, :]  <span class="hljs-comment"># B H/2 W/2 C</span><br>        x1 = x[:, <span class="hljs-number">1</span>::<span class="hljs-number">2</span>, <span class="hljs-number">0</span>::<span class="hljs-number">2</span>, :]  <span class="hljs-comment"># B H/2 W/2 C</span><br>        x2 = x[:, <span class="hljs-number">0</span>::<span class="hljs-number">2</span>, <span class="hljs-number">1</span>::<span class="hljs-number">2</span>, :]  <span class="hljs-comment"># B H/2 W/2 C</span><br>        x3 = x[:, <span class="hljs-number">1</span>::<span class="hljs-number">2</span>, <span class="hljs-number">1</span>::<span class="hljs-number">2</span>, :]  <span class="hljs-comment"># B H/2 W/2 C</span><br>        x = torch.cat([x0, x1, x2, x3], -<span class="hljs-number">1</span>)  <span class="hljs-comment"># B H/2 W/2 4*C</span><br>        x = x.view(B, -<span class="hljs-number">1</span>, <span class="hljs-number">4</span> * C)  <span class="hljs-comment"># B H/2*W/2 4*C</span><br><br>        x = self.norm(x)<br>        x = self.reduction(x)<br><br>        <span class="hljs-keyword">return</span> x<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">extra_repr</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-built_in">str</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">f&quot;input_resolution=<span class="hljs-subst">&#123;self.input_resolution&#125;</span>, dim=<span class="hljs-subst">&#123;self.dim&#125;</span>&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">flops</span>(<span class="hljs-params">self</span>):<br>        H, W = self.input_resolution<br>        flops = H * W * self.dim<br>        flops += (H // <span class="hljs-number">2</span>) * (W // <span class="hljs-number">2</span>) * <span class="hljs-number">4</span> * self.dim * <span class="hljs-number">2</span> * self.dim<br>        <span class="hljs-keyword">return</span> flops<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">BasicLayer</span>(nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot; A basic Swin Transformer layer for one stage.</span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        dim (int): Number of input channels.</span><br><span class="hljs-string">        input_resolution (tuple[int]): Input resolution.</span><br><span class="hljs-string">        depth (int): Number of blocks.</span><br><span class="hljs-string">        num_heads (int): Number of attention heads.</span><br><span class="hljs-string">        window_size (int): Local window size.</span><br><span class="hljs-string">        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim.</span><br><span class="hljs-string">        qkv_bias (bool, optional): If True, add a learnable bias to query, key, value. Default: True</span><br><span class="hljs-string">        qk_scale (float | None, optional): Override default qk scale of head_dim ** -0.5 if set.</span><br><span class="hljs-string">        drop (float, optional): Dropout rate. Default: 0.0</span><br><span class="hljs-string">        attn_drop (float, optional): Attention dropout rate. Default: 0.0</span><br><span class="hljs-string">        drop_path (float | tuple[float], optional): Stochastic depth rate. Default: 0.0</span><br><span class="hljs-string">        norm_layer (nn.Module, optional): Normalization layer. Default: nn.LayerNorm</span><br><span class="hljs-string">        downsample (nn.Module | None, optional): Downsample layer at the end of the layer. Default: None</span><br><span class="hljs-string">        use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False.</span><br><span class="hljs-string">        fused_window_process (bool, optional): If True, use one kernel to fused window shift &amp; window partition for acceleration, similar for the reversed part. Default: False</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, dim, input_resolution, depth, num_heads, window_size,</span><br><span class="hljs-params">                 mlp_ratio=<span class="hljs-number">4.</span>, qkv_bias=<span class="hljs-literal">True</span>, qk_scale=<span class="hljs-literal">None</span>, drop=<span class="hljs-number">0.</span>, attn_drop=<span class="hljs-number">0.</span>,</span><br><span class="hljs-params">                 drop_path=<span class="hljs-number">0.</span>, norm_layer=nn.LayerNorm, downsample=<span class="hljs-literal">None</span>, use_checkpoint=<span class="hljs-literal">False</span>,</span><br><span class="hljs-params">                 fused_window_process=<span class="hljs-literal">False</span></span>):<br><br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.dim = dim<br>        self.input_resolution = input_resolution<br>        self.depth = depth<br>        self.use_checkpoint = use_checkpoint<br><br>        <span class="hljs-comment"># build blocks</span><br>        self.blocks = nn.ModuleList([<br>            SwinTransformerBlock(dim=dim, input_resolution=input_resolution,<br>                                 num_heads=num_heads, window_size=window_size,<br>                                 shift_size=<span class="hljs-number">0</span> <span class="hljs-keyword">if</span> (i % <span class="hljs-number">2</span> == <span class="hljs-number">0</span>) <span class="hljs-keyword">else</span> window_size // <span class="hljs-number">2</span>,<br>                                 mlp_ratio=mlp_ratio,<br>                                 qkv_bias=qkv_bias, qk_scale=qk_scale,<br>                                 drop=drop, attn_drop=attn_drop,<br>                                 drop_path=drop_path[i] <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(drop_path, <span class="hljs-built_in">list</span>) <span class="hljs-keyword">else</span> drop_path,<br>                                 norm_layer=norm_layer,<br>                                 fused_window_process=fused_window_process)<br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(depth)])<br><br>        <span class="hljs-comment"># patch merging layer</span><br>        <span class="hljs-keyword">if</span> downsample <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            self.downsample = downsample(input_resolution, dim=dim, norm_layer=norm_layer)<br>        <span class="hljs-keyword">else</span>:<br>            self.downsample = <span class="hljs-literal">None</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">for</span> blk <span class="hljs-keyword">in</span> self.blocks:<br>            <span class="hljs-keyword">if</span> self.use_checkpoint:<br>                x = checkpoint.checkpoint(blk, x)<br>            <span class="hljs-keyword">else</span>:<br>                x = blk(x)<br>        <span class="hljs-keyword">if</span> self.downsample <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            x = self.downsample(x)<br>        <span class="hljs-keyword">return</span> x<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">extra_repr</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-built_in">str</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">f&quot;dim=<span class="hljs-subst">&#123;self.dim&#125;</span>, input_resolution=<span class="hljs-subst">&#123;self.input_resolution&#125;</span>, depth=<span class="hljs-subst">&#123;self.depth&#125;</span>&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">flops</span>(<span class="hljs-params">self</span>):<br>        flops = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> blk <span class="hljs-keyword">in</span> self.blocks:<br>            flops += blk.flops()<br>        <span class="hljs-keyword">if</span> self.downsample <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            flops += self.downsample.flops()<br>        <span class="hljs-keyword">return</span> flops<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">PatchEmbed</span>(nn.Module):<br>    <span class="hljs-string">r&quot;&quot;&quot; Image to Patch Embedding</span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        img_size (int): Image size.  Default: 224.</span><br><span class="hljs-string">        patch_size (int): Patch token size. Default: 4.</span><br><span class="hljs-string">        in_chans (int): Number of input image channels. Default: 3.</span><br><span class="hljs-string">        embed_dim (int): Number of linear projection output channels. Default: 96.</span><br><span class="hljs-string">        norm_layer (nn.Module, optional): Normalization layer. Default: None</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, img_size=<span class="hljs-number">224</span>, patch_size=<span class="hljs-number">4</span>, in_chans=<span class="hljs-number">3</span>, embed_dim=<span class="hljs-number">96</span>, norm_layer=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        img_size = to_2tuple(img_size)<br>        patch_size = to_2tuple(patch_size)<br>        patches_resolution = [img_size[<span class="hljs-number">0</span>] // patch_size[<span class="hljs-number">0</span>], img_size[<span class="hljs-number">1</span>] // patch_size[<span class="hljs-number">1</span>]]<br>        self.img_size = img_size<br>        self.patch_size = patch_size<br>        self.patches_resolution = patches_resolution<br>        self.num_patches = patches_resolution[<span class="hljs-number">0</span>] * patches_resolution[<span class="hljs-number">1</span>]<br><br>        self.in_chans = in_chans<br>        self.embed_dim = embed_dim<br><br>        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)<br>        <span class="hljs-keyword">if</span> norm_layer <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            self.norm = norm_layer(embed_dim)<br>        <span class="hljs-keyword">else</span>:<br>            self.norm = <span class="hljs-literal">None</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        B, C, H, W = x.shape<br>        <span class="hljs-comment"># FIXME look at relaxing size constraints</span><br>        <span class="hljs-keyword">assert</span> H == self.img_size[<span class="hljs-number">0</span>] <span class="hljs-keyword">and</span> W == self.img_size[<span class="hljs-number">1</span>], \<br>            <span class="hljs-string">f&quot;Input image size (<span class="hljs-subst">&#123;H&#125;</span>*<span class="hljs-subst">&#123;W&#125;</span>) doesn&#x27;t match model (<span class="hljs-subst">&#123;self.img_size[<span class="hljs-number">0</span>]&#125;</span>*<span class="hljs-subst">&#123;self.img_size[<span class="hljs-number">1</span>]&#125;</span>).&quot;</span><br>        x = self.proj(x).flatten(<span class="hljs-number">2</span>).transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)  <span class="hljs-comment"># B Ph*Pw C</span><br>        <span class="hljs-keyword">if</span> self.norm <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            x = self.norm(x)<br>        <span class="hljs-keyword">return</span> x<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">flops</span>(<span class="hljs-params">self</span>):<br>        Ho, Wo = self.patches_resolution<br>        flops = Ho * Wo * self.embed_dim * self.in_chans * (self.patch_size[<span class="hljs-number">0</span>] * self.patch_size[<span class="hljs-number">1</span>])<br>        <span class="hljs-keyword">if</span> self.norm <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            flops += Ho * Wo * self.embed_dim<br>        <span class="hljs-keyword">return</span> flops<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SwinTransformer</span>(nn.Module):<br>    <span class="hljs-string">r&quot;&quot;&quot; Swin Transformer</span><br><span class="hljs-string">        A PyTorch impl of : `Swin Transformer: Hierarchical Vision Transformer using Shifted Windows`  -</span><br><span class="hljs-string">          https://arxiv.org/pdf/2103.14030</span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        img_size (int | tuple(int)): Input image size. Default 224</span><br><span class="hljs-string">        patch_size (int | tuple(int)): Patch size. Default: 4</span><br><span class="hljs-string">        in_chans (int): Number of input image channels. Default: 3</span><br><span class="hljs-string">        num_classes (int): Number of classes for classification head. Default: 1000</span><br><span class="hljs-string">        embed_dim (int): Patch embedding dimension. Default: 96</span><br><span class="hljs-string">        depths (tuple(int)): Depth of each Swin Transformer layer.</span><br><span class="hljs-string">        num_heads (tuple(int)): Number of attention heads in different layers.</span><br><span class="hljs-string">        window_size (int): Window size. Default: 7</span><br><span class="hljs-string">        mlp_ratio (float): Ratio of mlp hidden dim to embedding dim. Default: 4</span><br><span class="hljs-string">        qkv_bias (bool): If True, add a learnable bias to query, key, value. Default: True</span><br><span class="hljs-string">        qk_scale (float): Override default qk scale of head_dim ** -0.5 if set. Default: None</span><br><span class="hljs-string">        drop_rate (float): Dropout rate. Default: 0</span><br><span class="hljs-string">        attn_drop_rate (float): Attention dropout rate. Default: 0</span><br><span class="hljs-string">        drop_path_rate (float): Stochastic depth rate. Default: 0.1</span><br><span class="hljs-string">        norm_layer (nn.Module): Normalization layer. Default: nn.LayerNorm.</span><br><span class="hljs-string">        ape (bool): If True, add absolute position embedding to the patch embedding. Default: False</span><br><span class="hljs-string">        patch_norm (bool): If True, add normalization after patch embedding. Default: True</span><br><span class="hljs-string">        use_checkpoint (bool): Whether to use checkpointing to save memory. Default: False</span><br><span class="hljs-string">        fused_window_process (bool, optional): If True, use one kernel to fused window shift &amp; window partition for acceleration, similar for the reversed part. Default: False</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, img_size=<span class="hljs-number">224</span>, patch_size=<span class="hljs-number">4</span>, in_chans=<span class="hljs-number">3</span>, num_classes=<span class="hljs-number">1000</span>,</span><br><span class="hljs-params">                 embed_dim=<span class="hljs-number">96</span>, depths=[<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">6</span>, <span class="hljs-number">2</span>], num_heads=[<span class="hljs-number">3</span>, <span class="hljs-number">6</span>, <span class="hljs-number">12</span>, <span class="hljs-number">24</span>],</span><br><span class="hljs-params">                 window_size=<span class="hljs-number">7</span>, mlp_ratio=<span class="hljs-number">4.</span>, qkv_bias=<span class="hljs-literal">True</span>, qk_scale=<span class="hljs-literal">None</span>,</span><br><span class="hljs-params">                 drop_rate=<span class="hljs-number">0.</span>, attn_drop_rate=<span class="hljs-number">0.</span>, drop_path_rate=<span class="hljs-number">0.1</span>,</span><br><span class="hljs-params">                 norm_layer=nn.LayerNorm, ape=<span class="hljs-literal">False</span>, patch_norm=<span class="hljs-literal">True</span>,</span><br><span class="hljs-params">                 use_checkpoint=<span class="hljs-literal">False</span>, fused_window_process=<span class="hljs-literal">False</span>, **kwargs</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br><br>        self.num_classes = num_classes<br>        self.num_layers = <span class="hljs-built_in">len</span>(depths)<br>        self.embed_dim = embed_dim<br>        self.ape = ape<br>        self.patch_norm = patch_norm<br>        self.num_features = <span class="hljs-built_in">int</span>(embed_dim * <span class="hljs-number">2</span> ** (self.num_layers - <span class="hljs-number">1</span>))<br>        self.mlp_ratio = mlp_ratio<br><br>        <span class="hljs-comment"># split image into non-overlapping patches</span><br>        self.patch_embed = PatchEmbed(<br>            img_size=img_size, patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim,<br>            norm_layer=norm_layer <span class="hljs-keyword">if</span> self.patch_norm <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>)<br>        num_patches = self.patch_embed.num_patches<br>        patches_resolution = self.patch_embed.patches_resolution<br>        self.patches_resolution = patches_resolution<br><br>        <span class="hljs-comment"># absolute position embedding</span><br>        <span class="hljs-keyword">if</span> self.ape:<br>            self.absolute_pos_embed = nn.Parameter(torch.zeros(<span class="hljs-number">1</span>, num_patches, embed_dim))<br>            trunc_normal_(self.absolute_pos_embed, std=<span class="hljs-number">.02</span>)<br><br>        self.pos_drop = nn.Dropout(p=drop_rate)<br><br>        <span class="hljs-comment"># stochastic depth</span><br>        dpr = [x.item() <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> torch.linspace(<span class="hljs-number">0</span>, drop_path_rate, <span class="hljs-built_in">sum</span>(depths))]  <span class="hljs-comment"># stochastic depth decay rule</span><br><br>        <span class="hljs-comment"># build layers</span><br>        self.layers = nn.ModuleList()<br>        <span class="hljs-keyword">for</span> i_layer <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.num_layers):<br>            layer = BasicLayer(dim=<span class="hljs-built_in">int</span>(embed_dim * <span class="hljs-number">2</span> ** i_layer),<br>                               input_resolution=(patches_resolution[<span class="hljs-number">0</span>] // (<span class="hljs-number">2</span> ** i_layer),<br>                                                 patches_resolution[<span class="hljs-number">1</span>] // (<span class="hljs-number">2</span> ** i_layer)),<br>                               depth=depths[i_layer],<br>                               num_heads=num_heads[i_layer],<br>                               window_size=window_size,<br>                               mlp_ratio=self.mlp_ratio,<br>                               qkv_bias=qkv_bias, qk_scale=qk_scale,<br>                               drop=drop_rate, attn_drop=attn_drop_rate,<br>                               drop_path=dpr[<span class="hljs-built_in">sum</span>(depths[:i_layer]):<span class="hljs-built_in">sum</span>(depths[:i_layer + <span class="hljs-number">1</span>])],<br>                               norm_layer=norm_layer,<br>                               downsample=PatchMerging <span class="hljs-keyword">if</span> (i_layer &lt; self.num_layers - <span class="hljs-number">1</span>) <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>,<br>                               use_checkpoint=use_checkpoint,<br>                               fused_window_process=fused_window_process)<br>            self.layers.append(layer)<br><br>        self.norm = norm_layer(self.num_features)<br>        self.avgpool = nn.AdaptiveAvgPool1d(<span class="hljs-number">1</span>)<br>        self.head = nn.Linear(self.num_features, num_classes) <span class="hljs-keyword">if</span> num_classes &gt; <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> nn.Identity()<br><br>        self.apply(self._init_weights)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_init_weights</span>(<span class="hljs-params">self, m</span>):<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m, nn.Linear):<br>            trunc_normal_(m.weight, std=<span class="hljs-number">.02</span>)<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m, nn.Linear) <span class="hljs-keyword">and</span> m.bias <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                nn.init.constant_(m.bias, <span class="hljs-number">0</span>)<br>        <span class="hljs-keyword">elif</span> <span class="hljs-built_in">isinstance</span>(m, nn.LayerNorm):<br>            nn.init.constant_(m.bias, <span class="hljs-number">0</span>)<br>            nn.init.constant_(m.weight, <span class="hljs-number">1.0</span>)<br><br><span class="hljs-meta">    @torch.jit.ignore</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">no_weight_decay</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;absolute_pos_embed&#x27;</span>&#125;<br><br><span class="hljs-meta">    @torch.jit.ignore</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">no_weight_decay_keywords</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> &#123;<span class="hljs-string">&#x27;relative_position_bias_table&#x27;</span>&#125;<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward_features</span>(<span class="hljs-params">self, x</span>):<br>        x = self.patch_embed(x)<br>        <span class="hljs-keyword">if</span> self.ape:<br>            x = x + self.absolute_pos_embed<br>        x = self.pos_drop(x)<br><br>        <span class="hljs-keyword">for</span> layer <span class="hljs-keyword">in</span> self.layers:<br>            x = layer(x)<br><br>        x = self.norm(x)  <span class="hljs-comment"># B L C</span><br>        x = self.avgpool(x.transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>))  <span class="hljs-comment"># B C 1</span><br>        x = torch.flatten(x, <span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> x<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.forward_features(x)<br>        x = self.head(x)<br>        <span class="hljs-keyword">return</span> x<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">flops</span>(<span class="hljs-params">self</span>):<br>        flops = <span class="hljs-number">0</span><br>        flops += self.patch_embed.flops()<br>        <span class="hljs-keyword">for</span> i, layer <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(self.layers):<br>            flops += layer.flops()<br>        flops += self.num_features * self.patches_resolution[<span class="hljs-number">0</span>] * self.patches_resolution[<span class="hljs-number">1</span>] // (<span class="hljs-number">2</span> ** self.num_layers)<br>        flops += self.num_features * self.num_classes<br>        <span class="hljs-keyword">return</span> flops<br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>cv</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>SIoU</title>
    <link href="/2023/03/20/SIoU/"/>
    <url>/2023/03/20/SIoU/</url>
    
    <content type="html"><![CDATA[<p>SIoU Loss: More Powerful Learning for Bounding BoxRegression</p><p><img src="/img/cv/image-20230320150334407.png" /></p><h1 id="methods">Methods</h1><p>SIoU</p><ul><li>Angle cost</li><li>Distance cost</li><li>Shape cost</li><li>IoU cost</li></ul><h2 id="angle-cost">Angle cost</h2><p>""XY()<span class="math inline">\(\alpha \le \frac{\pi}{4}\)</span> <span class="math inline">\(\alpha\)</span> <span class="math inline">\(\beta = \frac{\pi}{2} - \alpha\)</span></p><p> <spanclass="math display">\[\Lambda=1-2 * \sin ^{2}\left(\arcsin (x)-\frac{\pi}{4}\right) \ \ \ \where \ \ \ x=\frac{c_{h}}{\sigma}=\sin (\alpha)\]</span></p><p><span class="math display">\[\begin{array}{c}\sigma=\sqrt{\left(b_{c_{x}}^{gt}-b_{c_{x}}\right)^{2}+\left(b_{c_{y}}^{g t}-b_{c_{y}}\right)^{2}} \\c_{h}=\max \left(b_{c_{y}}^{g t}, b_{c_{y}}\right)-\min\left(b_{c_{y}}^{g t}, b_{c_{y}}\right)\end{array}\]</span></p><p><img src="/img/cv/image-20230320151915779.png" /></p><h2 id="distance-cost">Distance cost</h2><p> <spanclass="math display">\[\Delta=\sum_{t=x, y}\left(1-e^{-\gamma \rho_{t}}\right)\]</span> where <span class="math display">\[\rho_{x}=\left(\frac{b_{c_{x}}^{g t}-b_{c_{x}}}{c_{w}}\right)^{2},\rho_{y}=\left(\frac{b_{c_{y}}^{g t}-b_{c_{y}}}{c_{h}}\right)^{2},\gamma=2-\Lambda\]</span> 0 <spanclass="math inline">\(\frac{\pi}{4}\)</span><spanclass="math inline">\(\gamma\)</span>0</p><h2 id="shape-cost">Shape cost</h2><p>Shape cost <span class="math display">\[\Omega=\sum_{t=w, h}\left(1-e^{-\omega_{t}}\right)^{\theta}\]</span> where <span class="math display">\[\omega_{w}=\frac{\left|w-w^{g t}\right|}{\max \left(w, w^{g t}\right)},\omega_{h}=\frac{\left|h-h^{g t}\right|}{\max \left(h, h^{g t}\right)}\]</span>1 426</p><p><img src="/img/cv/image-20230320163652268.png" /></p><p>; <span class="math display">\[L_{b o x}=1-I o U+\frac{\Delta+\Omega}{2}\]</span></p><p><span class="math display">\[I o U=\frac{\left|B \cap B^{G T}\right|}{\left|B \cup B^{G T}\right|}\]</span></p>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>cv</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>SimAM</title>
    <link href="/2023/03/06/SimAM/"/>
    <url>/2023/03/06/SimAM/</url>
    
    <content type="html"><![CDATA[<p>SimAM: A Simple, Parameter-Free Attention Module forConvolutional Neural Networks</p><p><img src="/img/cv/image-20230306101414478.png" /></p><h1 id="method">method</h1><p>,</p><ol type="1"><li><p>1D</p></li><li><p>2D</p><p><img src="/img/cv/image-20230306101627185.png" /></p></li></ol><p>BAMCBAM<span class="math display">\[e_{t}\left(w_{t}, b_{t}, \mathbf{y},x_{i}\right)=\left(y_{t}-\hat{t}\right)^{2}+\frac{1}{M-1}\sum_{i=1}^{M-1}\left(y_{o}-\hat{x}_{i}\right)^{2}\ \ \ \ \ (1)\]</span>  <span class="math inline">\(\hat{t}=w_{t}t+b_{t}\)</span>  <span class="math inline">\(\hat{x} = w_tx_i +b_t\)</span>  <span class="math inline">\(t\)</span>  <spanclass="math inline">\(x_i\)</span>  <spanclass="math inline">\(t\)</span>  <spanclass="math inline">\(x_i\)</span>  <spanclass="math inline">\(\mathbf{X} \in \mathbb{R}^{C \times H \timesW}\)</span> <spanclass="math inline">\(i\)</span> <spanclass="math inline">\(M = H \times W\)</span><span class="math inline">\(w_t\)</span> <span class="math inline">\(b_t\)</span> ( 1) <span class="math inline">\(\hat{t} =y_t\)</span> ( 1 ) <spanclass="math inline">\(x_i\)</span>  <spanclass="math inline">\(y_0\)</span>  <spanclass="math inline">\(y_t\)</span>  <spanclass="math inline">\(y_0\)</span>( 1 ) <spanclass="math inline">\(t\)</span> <spanclass="math inline">\(y_t\)</span>  <spanclass="math inline">\(y_0\)</span> (1-1)( 1 ) <spanclass="math display">\[\begin{aligned}e_{t}\left(w_{t}, b_{t}, \mathbf{y}, x_{i}\right) &amp; =\frac{1}{M-1}\sum_{i=1}^{M-1}\left(-1-\left(w_{t} x_{i}+b_{t}\right)\right)^{2}+\left(1-\left(w_{t} t+b_{t}\right)\right)^{2}+\lambda w_{t}^{2}\end{aligned}\ \ \ \ (2)\]</span>MSGD(2 ) <span class="math inline">\(w_t\)</span>  <spanclass="math inline">\(b_t\)</span> <span class="math display">\[w_{t}=-\frac{2\left(t-\mu_{t}\right)}{\left(t-\mu_{t}\right)^{2}+2\sigma_{t}^{2}+2 \lambda}\ \ \ \ \ \ \ \ \ \ (3)\]</span></p><p><span class="math display">\[b_{t}=-\frac{1}{2}\left(t+\mu_{t}\right) w_{t}\ \ \ \ \ \ \ \ \ \ \ \(4)\]</span></p><p><span class="math inline">\(\mu_{t}=\frac{1}{M-1} \sum_{i=1}^{M-1}x_{i}\)</span>  <spanclass="math inline">\(\hat{\sigma}^{2}=\frac{1}{M}\sum_{i=1}^{M}\left(x_{i}-\hat{\mu}\right)^{2}\)</span> <span class="math inline">\(t\)</span>( 3 )( 4)(Hariharanet al.,2012)   <spanclass="math display">\[e_{t}^{*}=\frac{4\left(\hat{\sigma}^{2}+\lambda\right)}{(t-\hat{\mu})^{2}+2\hat{\sigma}^{2}+2 \lambda}\]</span>  <span class="math inline">\(\hat{\mu}=\frac{1}{M}\sum_{i=1}^{M} x_{i}\)</span>  <spanclass="math inline">\(\hat{\sigma}^{2}=\frac{1}{M}\sum_{i=1}^{M}\left(x_{i}-\hat{\mu}\right)^{2}\)</span> </p><p>(,1998)(,)<span class="math display">\[\widetilde{\mathbf{X}}=\operatorname{sigmoid}\left(\frac{1}{\mathbf{E}}\right)\odot \mathbf{X}\]</span> E <spanclass="math inline">\(e^t_*\)</span>sigmoidEsigmoid</p><h1 id=""></h1><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">simam_module</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, channels = <span class="hljs-literal">None</span>, e_lambda = <span class="hljs-number">1e-4</span></span>):<br>        <span class="hljs-built_in">super</span>(simam_module, self).__init__()<br><br>        self.activation = nn.Sigmoid()<br>        self.e_lambda = e_lambda<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__repr__</span>(<span class="hljs-params">self</span>):<br>        s = self.__class__.__name__ + <span class="hljs-string">&#x27;(&#x27;</span><br>        s += (<span class="hljs-string">&#x27;lambda=%f)&#x27;</span> % self.e_lambda)<br>        <span class="hljs-keyword">return</span> s<br><br><span class="hljs-meta">    @staticmethod</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_module_name</span>():<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;simam&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br><br>        b, c, h, w = x.size()<br>        <br>        n = w * h - <span class="hljs-number">1</span><br><br>        x_minus_mu_square = (x - x.mean(dim=[<span class="hljs-number">2</span>,<span class="hljs-number">3</span>], keepdim=<span class="hljs-literal">True</span>)).<span class="hljs-built_in">pow</span>(<span class="hljs-number">2</span>)<br>        y = x_minus_mu_square / (<span class="hljs-number">4</span> * (x_minus_mu_square.<span class="hljs-built_in">sum</span>(dim=[<span class="hljs-number">2</span>,<span class="hljs-number">3</span>], keepdim=<span class="hljs-literal">True</span>) / n + self.e_lambda)) + <span class="hljs-number">0.5</span><br><br>        <span class="hljs-keyword">return</span> x * self.activation(y)<br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>cv</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>ASPP</title>
    <link href="/2023/03/05/ASPP/"/>
    <url>/2023/03/05/ASPP/</url>
    
    <content type="html"><![CDATA[<p>ASPPAtrous Spatial PyramidPoolingASPP</p><p><img src="/img/cv/image-20230305100613533.png" /></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># </span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ASPPConv</span>(nn.Sequential):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, in_channels, out_channels, dilation</span>):<br>        modules = [<br>            nn.Conv2d(in_channels, out_channels, <span class="hljs-number">3</span>, padding=dilation, dilation=dilation, bias=<span class="hljs-literal">False</span>),<br>            nn.BatchNorm2d(out_channels),<br>            nn.ReLU()<br>        ]<br>        <span class="hljs-built_in">super</span>(ASPPConv, self).__init__(*modules)<br><br><span class="hljs-comment">#  -&gt; 1*1  -&gt; </span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ASPPPooling</span>(nn.Sequential):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, in_channels, out_channels</span>):<br>        <span class="hljs-built_in">super</span>(ASPPPooling, self).__init__(<br>            nn.AdaptiveAvgPool2d(<span class="hljs-number">1</span>),  <span class="hljs-comment"># </span><br>            nn.Conv2d(in_channels, out_channels, <span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>),<br>            nn.BatchNorm2d(out_channels),<br>            nn.ReLU())<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        size = x.shape[-<span class="hljs-number">2</span>:]<br>        <span class="hljs-keyword">for</span> mod <span class="hljs-keyword">in</span> self:<br>            x = mod(x)<br>        <span class="hljs-comment"># </span><br>        <span class="hljs-keyword">return</span> F.interpolate(x, size=size, mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>, align_corners=<span class="hljs-literal">False</span>)  <br><br><span class="hljs-comment">#  ASPP </span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ASPP</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, in_channels, atrous_rates, out_channels=<span class="hljs-number">256</span></span>):<br>        <span class="hljs-built_in">super</span>(ASPP, self).__init__()<br>        modules = []<br>        <span class="hljs-comment"># 1*1 </span><br>        modules.append(nn.Sequential(<br>            nn.Conv2d(in_channels, out_channels, <span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>),<br>            nn.BatchNorm2d(out_channels),<br>            nn.ReLU()))<br><br>        <span class="hljs-comment"># </span><br>        rates = <span class="hljs-built_in">tuple</span>(atrous_rates)<br>        <span class="hljs-keyword">for</span> rate <span class="hljs-keyword">in</span> rates:<br>            modules.append(ASPPConv(in_channels, out_channels, rate))<br><br>        <span class="hljs-comment"># </span><br>        modules.append(ASPPPooling(in_channels, out_channels))<br><br>        self.convs = nn.ModuleList(modules)<br>        <br>        <span class="hljs-comment"># </span><br>        self.project = nn.Sequential(<br>            nn.Conv2d(<span class="hljs-built_in">len</span>(self.convs) * out_channels, out_channels, <span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>),<br>            nn.BatchNorm2d(out_channels),<br>            nn.ReLU(),<br>            nn.Dropout(<span class="hljs-number">0.5</span>))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        res = []<br>        <span class="hljs-keyword">for</span> conv <span class="hljs-keyword">in</span> self.convs:<br>            res.append(conv(x))<br>        res = torch.cat(res, dim=<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> self.project(res)<br><br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>cv</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>ACmix</title>
    <link href="/2023/02/22/ACmix/"/>
    <url>/2023/02/22/ACmix/</url>
    
    <content type="html"><![CDATA[<ul><li>On the Integration of Self-Attention and Convolution</li></ul><p><img src="/img/cv/image-20230222112700129.png" /></p><h1 id=""></h1><p><img src="/img/cv/image-20230222112746676.png" /></p><p></p><ul><li><p></p><ul><li>( p ,q)1  1</li></ul></li></ul><p><span class="math display">\[\text { Stage I: } \tilde{g}_{i j}^{(p, q)}=K_{p, q} f_{i j} \text {, }\]</span></p><ul><li></li></ul><p><span class="math display">\[\begin{array}{c}\text { Stage II: } g_{i j}^{(p,q)}=\operatorname{Shift}\left(\tilde{g}_{i j}^{(p, q)}, p-\lfloor k /2\rfloor, q-\lfloor k / 2\rfloor\right) \\g_{i j}=\sum_{p, q} g_{i j}^{(p, q)}\end{array}\]</span></p><ul><li> <span class="math display">\[Stage I:  q_{i j}^{(l)}=W_{q}^{(l)} f_{i j}, k_{i j}^{(l)}=W_{k}^{(l)}f_{i j}, v_{i j}^{(l)}=W_{v}^{(l)} f_{i j}\]</span> <span class="math display">\[Stage II:  g_{i j}=\|_{l=1}^{N}\left(\sum_{a, b \in \mathcal{N}_{k}(i,j)} \mathrm{A}\left(q_{i j}^{(l)}, k_{a b}^{(l)}\right) v_{ab}^{(l)}\right) .\]</span></li></ul><p><span class="math display">\[F_{\text {out }}=\alpha F_{\mathrm{att}}+\beta F_{\mathrm{conv}}\]</span></p><h1 id=""></h1><p><img src="/img/cv/image-20230222114239381.png" /></p><p><img src="/img/cv/image-20230222114341767.png" /></p><p><img src="/img/cv/image-20230222114402505.png" /></p><h1 id=""></h1><p>ACmixResNet</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">import</span> time<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">position</span>(<span class="hljs-params">H, W, is_cuda=<span class="hljs-literal">True</span></span>):<br>    <span class="hljs-keyword">if</span> is_cuda:<br>        loc_w = torch.linspace(-<span class="hljs-number">1.0</span>, <span class="hljs-number">1.0</span>, W).cuda().unsqueeze(<span class="hljs-number">0</span>).repeat(H, <span class="hljs-number">1</span>)<br>        loc_h = torch.linspace(-<span class="hljs-number">1.0</span>, <span class="hljs-number">1.0</span>, H).cuda().unsqueeze(<span class="hljs-number">1</span>).repeat(<span class="hljs-number">1</span>, W)<br>    <span class="hljs-keyword">else</span>:<br>        loc_w = torch.linspace(-<span class="hljs-number">1.0</span>, <span class="hljs-number">1.0</span>, W).unsqueeze(<span class="hljs-number">0</span>).repeat(H, <span class="hljs-number">1</span>)<br>        loc_h = torch.linspace(-<span class="hljs-number">1.0</span>, <span class="hljs-number">1.0</span>, H).unsqueeze(<span class="hljs-number">1</span>).repeat(<span class="hljs-number">1</span>, W)<br>    loc = torch.cat([loc_w.unsqueeze(<span class="hljs-number">0</span>), loc_h.unsqueeze(<span class="hljs-number">0</span>)], <span class="hljs-number">0</span>).unsqueeze(<span class="hljs-number">0</span>)<br>    <span class="hljs-keyword">return</span> loc<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">stride</span>(<span class="hljs-params">x, stride</span>):<br>    b, c, h, w = x.shape<br>    <span class="hljs-keyword">return</span> x[:, :, ::stride, ::stride]<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_rate_half</span>(<span class="hljs-params">tensor</span>):<br>    <span class="hljs-keyword">if</span> tensor <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        tensor.data.fill_(<span class="hljs-number">0.5</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_rate_0</span>(<span class="hljs-params">tensor</span>):<br>    <span class="hljs-keyword">if</span> tensor <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        tensor.data.fill_(<span class="hljs-number">0.</span>)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ACmix</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, in_planes, out_planes, kernel_att=<span class="hljs-number">7</span>, head=<span class="hljs-number">4</span>, kernel_conv=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, dilation=<span class="hljs-number">1</span></span>):<br>        <span class="hljs-built_in">super</span>(ACmix, self).__init__()<br>        self.in_planes = in_planes<br>        self.out_planes = out_planes<br>        self.head = head<br>        self.kernel_att = kernel_att<br>        self.kernel_conv = kernel_conv<br>        self.stride = stride<br>        self.dilation = dilation<br>        self.rate1 = torch.nn.Parameter(torch.Tensor(<span class="hljs-number">1</span>))<br>        self.rate2 = torch.nn.Parameter(torch.Tensor(<span class="hljs-number">1</span>))<br>        self.head_dim = self.out_planes // self.head<br><br>        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=<span class="hljs-number">1</span>)<br>        self.conv2 = nn.Conv2d(in_planes, out_planes, kernel_size=<span class="hljs-number">1</span>)<br>        self.conv3 = nn.Conv2d(in_planes, out_planes, kernel_size=<span class="hljs-number">1</span>)<br>        self.conv_p = nn.Conv2d(<span class="hljs-number">2</span>, self.head_dim, kernel_size=<span class="hljs-number">1</span>)<br><br>        self.padding_att = (self.dilation * (self.kernel_att - <span class="hljs-number">1</span>) + <span class="hljs-number">1</span>) // <span class="hljs-number">2</span><br>        <span class="hljs-comment"># nn.ReflectionPad2d()padding</span><br>        self.pad_att = torch.nn.ReflectionPad2d(self.padding_att)<br>        <span class="hljs-comment"># nn.Unfold()patch</span><br>        self.unfold = nn.Unfold(kernel_size=self.kernel_att, padding=<span class="hljs-number">0</span>, stride=self.stride)<br>        self.softmax = torch.nn.Softmax(dim=<span class="hljs-number">1</span>)<br><br>        self.fc = nn.Conv2d(<span class="hljs-number">3</span>*self.head, self.kernel_conv * self.kernel_conv, kernel_size=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>)<br>        self.dep_conv = nn.Conv2d(self.kernel_conv * self.kernel_conv * self.head_dim, out_planes, kernel_size=self.kernel_conv, bias=<span class="hljs-literal">True</span>, groups=self.head_dim, padding=<span class="hljs-number">1</span>, stride=stride)<br><br>        self.reset_parameters()<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">reset_parameters</span>(<span class="hljs-params">self</span>):<br>        init_rate_half(self.rate1)<br>        init_rate_half(self.rate2)<br>        kernel = torch.zeros(self.kernel_conv * self.kernel_conv, self.kernel_conv, self.kernel_conv)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.kernel_conv * self.kernel_conv):<br>            kernel[i, i//self.kernel_conv, i % self.kernel_conv] = <span class="hljs-number">1.</span><br>        kernel = kernel.squeeze(<span class="hljs-number">0</span>).repeat(self.out_planes, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>        self.dep_conv.weight = nn.Parameter(data=kernel, requires_grad=<span class="hljs-literal">True</span>)<br>        self.dep_conv.bias = init_rate_0(self.dep_conv.bias)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        q, k, v = self.conv1(x), self.conv2(x), self.conv3(x)<br>        scaling = <span class="hljs-built_in">float</span>(self.head_dim) ** -<span class="hljs-number">0.5</span><br>        b, c, h, w = q.shape<br>        h_out, w_out = h//self.stride, w//self.stride<br><br><br>    <span class="hljs-comment"># att</span><br>        <span class="hljs-comment"># positional encoding</span><br>        pe = self.conv_p(position(h, w, x.is_cuda))<br><br>        q_att = q.view(b*self.head, self.head_dim, h, w) * scaling<br>        k_att = k.view(b*self.head, self.head_dim, h, w)<br>        v_att = v.view(b*self.head, self.head_dim, h, w)<br><br>        <span class="hljs-comment"># </span><br>        <span class="hljs-keyword">if</span> self.stride &gt; <span class="hljs-number">1</span>:<br>            q_att = stride(q_att, self.stride)<br>            q_pe = stride(pe, self.stride)<br>        <span class="hljs-keyword">else</span>:<br>            q_pe = pe<br><br>        unfold_k = self.unfold(self.pad_att(k_att)).view(b*self.head, self.head_dim, self.kernel_att*self.kernel_att, h_out, w_out) <span class="hljs-comment"># b*head, head_dim, k_att^2, h_out, w_out</span><br>        unfold_rpe = self.unfold(self.pad_att(pe)).view(<span class="hljs-number">1</span>, self.head_dim, self.kernel_att*self.kernel_att, h_out, w_out) <span class="hljs-comment"># 1, head_dim, k_att^2, h_out, w_out</span><br>        <br>        att = (q_att.unsqueeze(<span class="hljs-number">2</span>)*(unfold_k + q_pe.unsqueeze(<span class="hljs-number">2</span>) - unfold_rpe)).<span class="hljs-built_in">sum</span>(<span class="hljs-number">1</span>) <span class="hljs-comment"># (b*head, head_dim, 1, h_out, w_out) * (b*head, head_dim, k_att^2, h_out, w_out) -&gt; (b*head, k_att^2, h_out, w_out)</span><br>        att = self.softmax(att)<br><br>        out_att = self.unfold(self.pad_att(v_att)).view(b*self.head, self.head_dim, self.kernel_att*self.kernel_att, h_out, w_out)<br>        out_att = (att.unsqueeze(<span class="hljs-number">1</span>) * out_att).<span class="hljs-built_in">sum</span>(<span class="hljs-number">2</span>).view(b, self.out_planes, h_out, w_out)<br><br>        <span class="hljs-comment"># conv</span><br>        f_all = self.fc(torch.cat([q.view(b, self.head, self.head_dim, h*w), k.view(b, self.head, self.head_dim, h*w), v.view(b, self.head, self.head_dim, h*w)], <span class="hljs-number">1</span>))<br>        f_conv = f_all.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>).reshape(x.shape[<span class="hljs-number">0</span>], -<span class="hljs-number">1</span>, x.shape[-<span class="hljs-number">2</span>], x.shape[-<span class="hljs-number">1</span>])<br>        <br>        out_conv = self.dep_conv(f_conv)<br><br>        <span class="hljs-keyword">return</span> self.rate1 * out_att + self.rate2 * out_conv<br></code></pre></div></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">from</span> torch.hub <span class="hljs-keyword">import</span> load_state_dict_from_url<br><span class="hljs-keyword">from</span> test_bottleneck <span class="hljs-keyword">import</span> ACmix<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">conv3x3</span>(<span class="hljs-params">in_planes, out_planes, stride=<span class="hljs-number">1</span>, groups=<span class="hljs-number">1</span>, dilation=<span class="hljs-number">1</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;3x3 convolution with padding&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> nn.Conv2d(in_planes, out_planes, kernel_size=<span class="hljs-number">3</span>, stride=stride,<br>                     padding=dilation, groups=groups, bias=<span class="hljs-literal">False</span>, dilation=dilation)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">conv1x1</span>(<span class="hljs-params">in_planes, out_planes, stride=<span class="hljs-number">1</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;1x1 convolution&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> nn.Conv2d(in_planes, out_planes, kernel_size=<span class="hljs-number">1</span>, stride=stride, bias=<span class="hljs-literal">False</span>)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Bottleneck</span>(nn.Module):<br>    <span class="hljs-comment"># Bottleneck in torchvision places the stride for downsampling at 3x3 convolution(self.conv2)</span><br>    <span class="hljs-comment"># while original implementation places the stride at the first 1x1 convolution(self.conv1)</span><br>    <span class="hljs-comment"># according to &quot;Deep residual learning for image recognition&quot;https://arxiv.org/abs/1512.03385.</span><br>    <span class="hljs-comment"># This variant is also known as ResNet V1.5 and improves accuracy according to</span><br>    <span class="hljs-comment"># https://ngc.nvidia.com/catalog/model-scripts/nvidia:resnet_50_v1_5_for_pytorch.</span><br><br>    expansion = <span class="hljs-number">4</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, inplanes, planes, k_att, head, k_conv, stride=<span class="hljs-number">1</span>, downsample=<span class="hljs-literal">None</span>, groups=<span class="hljs-number">1</span>,</span><br><span class="hljs-params">                 base_width=<span class="hljs-number">64</span>, dilation=<span class="hljs-number">1</span>, norm_layer=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-built_in">super</span>(Bottleneck, self).__init__()<br>        <span class="hljs-keyword">if</span> norm_layer <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            norm_layer = nn.BatchNorm2d<br>        width = <span class="hljs-built_in">int</span>(planes * (base_width / <span class="hljs-number">64.</span>)) * groups<br>        <span class="hljs-comment"># Both self.conv2 and self.downsample layers downsample the input when stride != 1</span><br>        self.conv1 = conv1x1(inplanes, width)<br>        self.bn1 = norm_layer(width)<br>        self.conv2 = ACmix(width, width, k_att, head, k_conv, stride=stride, dilation=dilation)<br>        self.bn2 = norm_layer(width)<br>        self.conv3 = conv1x1(width, planes * self.expansion)<br>        self.bn3 = norm_layer(planes * self.expansion)<br>        self.relu = nn.ReLU(inplace=<span class="hljs-literal">True</span>)<br>        self.downsample = downsample<br>        self.stride = stride<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        identity = x<br><br>        out = self.conv1(x)<br>        out = self.bn1(out)<br>        out = self.relu(out)<br><br>        out = self.conv2(out)<br>        out = self.bn2(out)<br>        out = self.relu(out)<br><br>        out = self.conv3(out)<br>        out = self.bn3(out)<br><br>        <span class="hljs-keyword">if</span> self.downsample <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            identity = self.downsample(x)<br><br>        out += identity<br>        out = self.relu(out)<br><br>        <span class="hljs-keyword">return</span> out<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ResNet</span>(nn.Module):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, block, layers, k_att=<span class="hljs-number">7</span>, head=<span class="hljs-number">4</span>, k_conv=<span class="hljs-number">3</span>, num_classes=<span class="hljs-number">1000</span>, zero_init_residual=<span class="hljs-literal">False</span>,</span><br><span class="hljs-params">                 groups=<span class="hljs-number">1</span>, width_per_group=<span class="hljs-number">64</span>, replace_stride_with_dilation=<span class="hljs-literal">None</span>,</span><br><span class="hljs-params">                 norm_layer=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-built_in">super</span>(ResNet, self).__init__()<br>        <span class="hljs-keyword">if</span> norm_layer <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            norm_layer = nn.BatchNorm2d<br>        self._norm_layer = norm_layer<br><br>        self.inplanes = <span class="hljs-number">64</span><br>        self.dilation = <span class="hljs-number">1</span><br>        <span class="hljs-keyword">if</span> replace_stride_with_dilation <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:<br>            <span class="hljs-comment"># each element in the tuple indicates if we should replace</span><br>            <span class="hljs-comment"># the 2x2 stride with a dilated convolution instead</span><br>            replace_stride_with_dilation = [<span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>]<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(replace_stride_with_dilation) != <span class="hljs-number">3</span>:<br>            <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&quot;replace_stride_with_dilation should be None &quot;</span><br>                             <span class="hljs-string">&quot;or a 3-element tuple, got &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(replace_stride_with_dilation))<br>        self.groups = groups<br>        self.base_width = width_per_group<br>        self.conv1 = nn.Conv2d(<span class="hljs-number">3</span>, self.inplanes, kernel_size=<span class="hljs-number">7</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">3</span>,<br>                               bias=<span class="hljs-literal">False</span>)<br>        self.bn1 = norm_layer(self.inplanes)<br>        self.relu = nn.ReLU(inplace=<span class="hljs-literal">True</span>)<br>        self.maxpool = nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>)<br>        self.layer1 = self._make_layer(block, <span class="hljs-number">64</span>, layers[<span class="hljs-number">0</span>], k_att, head, k_conv)<br>        self.layer2 = self._make_layer(block, <span class="hljs-number">128</span>, layers[<span class="hljs-number">1</span>], k_att, head, k_conv, stride=<span class="hljs-number">2</span>,<br>                                       dilate=replace_stride_with_dilation[<span class="hljs-number">0</span>])<br>        self.layer3 = self._make_layer(block, <span class="hljs-number">256</span>, layers[<span class="hljs-number">2</span>], k_att, head, k_conv, stride=<span class="hljs-number">2</span>,<br>                                       dilate=replace_stride_with_dilation[<span class="hljs-number">1</span>])<br>        self.layer4 = self._make_layer(block, <span class="hljs-number">512</span>, layers[<span class="hljs-number">3</span>], k_att, head, k_conv, stride=<span class="hljs-number">2</span>,<br>                                       dilate=replace_stride_with_dilation[<span class="hljs-number">2</span>])<br>        self.avgpool = nn.AdaptiveAvgPool2d((<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>        self.fc = nn.Linear(<span class="hljs-number">512</span> * block.expansion, num_classes)<br><br>        <span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> self.modules():<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m, nn.Conv2d):<br>                nn.init.kaiming_normal_(m.weight, mode=<span class="hljs-string">&#x27;fan_out&#x27;</span>, nonlinearity=<span class="hljs-string">&#x27;relu&#x27;</span>)<br>            <span class="hljs-keyword">elif</span> <span class="hljs-built_in">isinstance</span>(m, (nn.BatchNorm2d, nn.GroupNorm)):<br>                nn.init.constant_(m.weight, <span class="hljs-number">1</span>)<br>                nn.init.constant_(m.bias, <span class="hljs-number">0</span>)<br><br>        <span class="hljs-comment"># Zero-initialize the last BN in each residual branch,</span><br>        <span class="hljs-comment"># so that the residual branch starts with zeros, and each residual block behaves like an identity.</span><br>        <span class="hljs-comment"># This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677</span><br>        <span class="hljs-keyword">if</span> zero_init_residual:<br>            <span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> self.modules():<br>                <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m, Bottleneck):<br>                    nn.init.constant_(m.bn3.weight, <span class="hljs-number">0</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_make_layer</span>(<span class="hljs-params">self, block, planes, blocks, rate, k, head, stride=<span class="hljs-number">1</span>, dilate=<span class="hljs-literal">False</span></span>):<br>        norm_layer = self._norm_layer<br>        downsample = <span class="hljs-literal">None</span><br>        previous_dilation = self.dilation<br>        <span class="hljs-keyword">if</span> dilate:<br>            self.dilation *= stride<br>            stride = <span class="hljs-number">1</span><br>        <span class="hljs-keyword">if</span> stride != <span class="hljs-number">1</span> <span class="hljs-keyword">or</span> self.inplanes != planes * block.expansion:<br>            downsample = nn.Sequential(<br>                conv1x1(self.inplanes, planes * block.expansion, stride),<br>                norm_layer(planes * block.expansion),<br>            )<br><br>        layers = []<br>        layers.append(block(self.inplanes, planes, rate, k, head, stride, downsample, self.groups,<br>                            self.base_width, previous_dilation, norm_layer))<br>        self.inplanes = planes * block.expansion<br>        <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, blocks):<br>            layers.append(block(self.inplanes, planes, rate, k, head, groups=self.groups,<br>                                base_width=self.base_width, dilation=self.dilation,<br>                                norm_layer=norm_layer))<br><br>        <span class="hljs-keyword">return</span> nn.Sequential(*layers)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_forward_impl</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># See note [TorchScript super()]</span><br>        x = self.conv1(x)<br>        x = self.bn1(x)<br>        x = self.relu(x)<br>        x = self.maxpool(x)<br><br>        x = self.layer1(x)<br>        x = self.layer2(x)<br>        x = self.layer3(x)<br>        x = self.layer4(x)<br><br>        x = self.avgpool(x)<br>        x = torch.flatten(x, <span class="hljs-number">1</span>)<br>        x = self.fc(x)<br><br>        <span class="hljs-keyword">return</span> x<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> self._forward_impl(x)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">_resnet</span>(<span class="hljs-params">block, layers, **kwargs</span>):<br>    model = ResNet(block, layers, **kwargs)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">ACmix_ResNet</span>(<span class="hljs-params">layers=[<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">6</span>,<span class="hljs-number">3</span>], **kwargs</span>):<br>    <span class="hljs-keyword">return</span> _resnet(Bottleneck, layers, **kwargs)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    model = ACmix_ResNet().cuda()<br>    <span class="hljs-built_in">input</span> = torch.randn([<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">224</span>,<span class="hljs-number">224</span>]).cuda()<br>    total_params = <span class="hljs-built_in">sum</span>(p.numel() <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> model.parameters())<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;total_params:,&#125;</span> total parameters.&#x27;</span>)<br>    total_trainable_params = <span class="hljs-built_in">sum</span>(p.numel() <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> model.parameters() <span class="hljs-keyword">if</span> p.requires_grad)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;total_trainable_params:,&#125;</span> training parameters.&#x27;</span>)<br>    <span class="hljs-built_in">print</span>(model(<span class="hljs-built_in">input</span>).shape)<br>    <span class="hljs-comment"># print(summary(model, torch.zeros((1, 3, 224, 224)).cuda()))</span><br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>cv</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2022/11/30/%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95/"/>
    <url>/2022/11/30/%E6%90%9C%E7%B4%A2%E7%AE%97%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h1 id="">695</h1><p><img src="/img/LeetCode/image-20221130155605866.png" /></p><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">maxAreaOfIsland</span>(<span class="hljs-params">self, grid: <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]]</span>) -&gt; <span class="hljs-built_in">int</span>:<br>        maxArea = <span class="hljs-number">0</span><br>        m, n = <span class="hljs-built_in">len</span>(grid), <span class="hljs-built_in">len</span>(grid[<span class="hljs-number">0</span>])<br><br>        <span class="hljs-keyword">for</span> i, l <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(grid):<br>            <span class="hljs-keyword">for</span> j, s <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(l):<br>                <span class="hljs-keyword">if</span> grid[i][j]:<br>                    maxArea = <span class="hljs-built_in">max</span>(self.dfs(grid, i, j), maxArea)<br>        <span class="hljs-keyword">return</span> maxArea<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">dfs</span>(<span class="hljs-params">self, grid, m, n</span>):<br>        <span class="hljs-keyword">if</span> grid[m][n] == <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>        area = <span class="hljs-number">1</span><br>        grid[m][n] = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> i, j <span class="hljs-keyword">in</span> [[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>], [<span class="hljs-number">0</span>, -<span class="hljs-number">1</span>], [-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>]]:<br>            a = m + i<br>            b = n + j<br>            <span class="hljs-keyword">if</span> a &gt;= <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> b &gt;= <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> a &lt; <span class="hljs-built_in">len</span>(grid) <span class="hljs-keyword">and</span> b &lt; <span class="hljs-built_in">len</span>(grid[<span class="hljs-number">0</span>]):<br>                area += self.dfs(grid, a, b)<br>        <span class="hljs-keyword">return</span> area<br></code></pre></div></td></tr></table></figure><h1 id="">547</h1><p><img src="/img/LeetCode/image-20221130162958180.png" /></p><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">findCircleNum</span>(<span class="hljs-params">self, isConnected: <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]]</span>) -&gt; <span class="hljs-built_in">int</span>:<br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">dfs</span>(<span class="hljs-params">x</span>):<br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(isConnected)):<br>                <span class="hljs-keyword">if</span> isConnected[x][i] == <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> i <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> visited:<br>                    visited.add(i)<br>                    dfs(i)<br><br>        n = <span class="hljs-built_in">len</span>(isConnected)<br>        visited = <span class="hljs-built_in">set</span>()<br>        ans = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>            <span class="hljs-keyword">if</span> i <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> visited:<br>                dfs(i)<br>                ans += <span class="hljs-number">1</span><br><br>        <span class="hljs-keyword">return</span> ans<br></code></pre></div></td></tr></table></figure><h1 id="">417</h1><p><img src="/img/LeetCode/image-20221130173426471.png" /></p><p></p><p></p><p></p><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">pacificAtlantic</span>(<span class="hljs-params">self, heights: <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]]</span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]]:<br>        m, n = <span class="hljs-built_in">len</span>(heights), <span class="hljs-built_in">len</span>(heights[<span class="hljs-number">0</span>])<br><br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">search</span>(<span class="hljs-params">ocean</span>):<br>            res = <span class="hljs-built_in">set</span>()<br><br>            <span class="hljs-keyword">def</span> <span class="hljs-title function_">dfs</span>(<span class="hljs-params">x, y</span>):<br>                <span class="hljs-keyword">if</span> (x, y) <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> res:<br>                    res.add((x, y))<br>                    <span class="hljs-keyword">for</span> i, j <span class="hljs-keyword">in</span> [[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>], [<span class="hljs-number">0</span>, -<span class="hljs-number">1</span>], [-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>]]:<br>                        a = x + i<br>                        b = y + j<br>                        <span class="hljs-keyword">if</span> a &gt;= <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> b &gt;= <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> a &lt; m <span class="hljs-keyword">and</span> b &lt; n <span class="hljs-keyword">and</span> heights[a][b] &gt;= heights[x][y]:<br>                            dfs(a, b)<br><br>            <span class="hljs-keyword">for</span> (i, j) <span class="hljs-keyword">in</span> ocean:<br>                dfs(i, j)<br>            <span class="hljs-keyword">return</span> res<br>            <br><br>        pacificOcean = [(<span class="hljs-number">0</span>, i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n)] + [(i, <span class="hljs-number">0</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(m)]<br>        atlanticOcean = [(i, n - <span class="hljs-number">1</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(m)] + [(m - <span class="hljs-number">1</span>, i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n)]<br>        <br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-built_in">list</span>, search(pacificOcean) &amp; search(atlanticOcean)))<br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>LeetCode</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2022/11/29/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/"/>
    <url>/2022/11/29/%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE/</url>
    
    <content type="html"><![CDATA[<h1 id="x">69x</h1><p><img src="/img/LeetCode/image-20221129170111904.png" /></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">mySqrt</span>(<span class="hljs-params">self, x: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:<br>        <span class="hljs-keyword">if</span> x == <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>        left, right, ans = <span class="hljs-number">0</span>, x, -<span class="hljs-number">1</span><br>        <span class="hljs-keyword">while</span> left &lt;= right:<br>            mid = (right + left) // <span class="hljs-number">2</span><br>            <span class="hljs-keyword">if</span> mid * mid &lt;= x:<br>                ans = mid<br>                left = mid + <span class="hljs-number">1</span><br>            <span class="hljs-keyword">else</span>:<br>                right = mid - <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> ans<br></code></pre></div></td></tr></table></figure><h1 id="">81</h1><p><img src="/img/LeetCode/image-20221130152347305.png" /></p><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">search</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], target: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">bool</span>:<br>        n = <span class="hljs-built_in">len</span>(nums)<br>        left, right = <span class="hljs-number">0</span>, n - <span class="hljs-number">1</span><br>        <span class="hljs-keyword">while</span> left &lt;= right:<br>            mid = (left + right) // <span class="hljs-number">2</span><br>            <span class="hljs-keyword">if</span> nums[mid] == target:<br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span><br>            <span class="hljs-keyword">if</span> nums[mid] &lt; nums[right]:<br>                <span class="hljs-keyword">if</span> nums[mid] &lt; target <span class="hljs-keyword">and</span> target &lt;= nums[right]:<br>                    left = mid + <span class="hljs-number">1</span><br>                <span class="hljs-keyword">else</span>:<br>                    right = mid - <span class="hljs-number">1</span><br>            <span class="hljs-keyword">elif</span> nums[mid] &gt; nums[right]:<br>                <span class="hljs-keyword">if</span> nums[mid] &gt; target <span class="hljs-keyword">and</span> target &gt;= nums[left]:<br>                    right = mid - <span class="hljs-number">1</span><br>                <span class="hljs-keyword">else</span>:<br>                    left = mid + <span class="hljs-number">1</span><br>            <span class="hljs-keyword">elif</span> nums[mid] == nums[left]:<br>                left += <span class="hljs-number">1</span><br>            <span class="hljs-keyword">elif</span> nums[mid] == nums[right]:<br>                right -= <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>LeetCode</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2022/11/22/%E8%B4%AA%E5%BF%83/"/>
    <url>/2022/11/22/%E8%B4%AA%E5%BF%83/</url>
    
    <content type="html"><![CDATA[<h1 id="">455</h1><p><img src="/img/LeetCode/image-20221122172521839.png" /></p><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">findContentChildren</span>(<span class="hljs-params">self, g: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], s: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">int</span>:<br>        g.sort()<br>        s.sort()<br>        i , j = <span class="hljs-number">0</span>, <span class="hljs-number">0</span><br>        <span class="hljs-keyword">while</span> i &lt; <span class="hljs-built_in">len</span>(g) <span class="hljs-keyword">and</span> j &lt; <span class="hljs-built_in">len</span>(s):<br>            <span class="hljs-keyword">if</span> s[j] &gt;= g[i]:<br>                i += <span class="hljs-number">1</span><br>                j += <span class="hljs-number">1</span><br>            <span class="hljs-keyword">else</span>:<br>                j += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> i<br></code></pre></div></td></tr></table></figure><h1 id="">135</h1><p><img src="/img/LeetCode/image-20221122172932167.png" /></p><p>455111</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">candy</span>(<span class="hljs-params">self, ratings: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">int</span>:<br>        n = <span class="hljs-built_in">len</span>(ratings)<br>        <span class="hljs-keyword">if</span> n &lt; <span class="hljs-number">2</span>:<br>            <span class="hljs-keyword">return</span> n<br>        res = [<span class="hljs-number">1</span>]<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, n):<br>            <span class="hljs-keyword">if</span> ratings[i] &gt; ratings[i - <span class="hljs-number">1</span>]:<br>                res.append(res[i - <span class="hljs-number">1</span>] + <span class="hljs-number">1</span>)<br>            <span class="hljs-keyword">else</span>:<br>                res.append(<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n - <span class="hljs-number">2</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>):<br>            <span class="hljs-keyword">if</span> ratings[i] &gt; ratings[i + <span class="hljs-number">1</span>] <span class="hljs-keyword">and</span> res[i] &lt;= res[i + <span class="hljs-number">1</span>]:<br>                res[i] = res[i + <span class="hljs-number">1</span>] + <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">sum</span>(res)<br></code></pre></div></td></tr></table></figure><h1 id="">435</h1><p><img src="/img/LeetCode/image-20221123102842444.png" /></p><p></p><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">eraseOverlapIntervals</span>(<span class="hljs-params">self, intervals: <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]]</span>) -&gt; <span class="hljs-built_in">int</span>:<br>        n = <span class="hljs-built_in">len</span>(intervals)<br>        <span class="hljs-keyword">if</span> n == <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">sortKey</span>(<span class="hljs-params">x</span>):<br>            <span class="hljs-keyword">return</span> x[<span class="hljs-number">1</span>]<br>        intervals.sort(key=sortKey)<br>        res = [intervals[<span class="hljs-number">0</span>]]<br>        prev = res[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>]<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, n):<br>            <span class="hljs-keyword">if</span> intervals[i][<span class="hljs-number">0</span>] &gt;= prev:<br>                prev = intervals[i][<span class="hljs-number">1</span>]<br>                res.append(intervals[i])<br>        n2 = <span class="hljs-built_in">len</span>(res)<br>        <span class="hljs-keyword">return</span> n - n2<br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>LeetCode</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MaxViT</title>
    <link href="/2022/11/16/MaxViT/"/>
    <url>/2022/11/16/MaxViT/</url>
    
    <content type="html"><![CDATA[<ul><li><p>MaxViT: Multi-Axis Vision Transformer</p></li><li><p>ECCV 2022</p></li></ul><p><img src="/img/cv/image-20221116155126807.png" /></p><h1 id="motivation">Motivation</h1><p>ViTTransformer<strong><ahref="https://www.zhihu.com/question/264264203"></a></strong><strong></strong>TwinsLocalViTSwinTransformerSwinTransformer<strong>ViT</strong>ImageNet-21KJFT</p><p><strong></strong><strong></strong></p><p>BackboneTransformer(MaxViT)Max-SA</p><ul><li><strong>MaxViT</strong>Transformer<strong></strong><strong></strong></li><li><strong>Max-SA</strong><strong>BlockattentionGridattention</strong><strong></strong></li><li><strong><ahref="https://zhuanlan.zhihu.com/p/463033740">MBConv</a></strong><strong></strong></li></ul><h1 id="method">Method</h1><p>(multi-axis self-attention,MaxSA)<strong>BlockattentionGridattention</strong>Max-SAMax-SAMBConvMaxViTBackbone</p><p><img src="/img/cv/image-20221116155246646.png" /></p><h2 id="attention">Attention</h2><p>MaxViT</p><h2 id="multi-axis-attention">Multi-axis Attention</h2><p><strong>blockattentiongridattention</strong></p><p><img src="/img/cv/image-20221116155449655.png" /></p><h3 id="block-attention">block attention</h3><p><span class="math display">\[\text { Block }:(H, W, C) \rightarrow\left(\frac{H}{P} \times P,\frac{W}{P} \times P, C\right) \rightarrow\left(\frac{H W}{P^{2}},P^{2}, C\right)\]</span></p><h3 id="grid-attention">grid attention</h3><p><span class="math display">\[\text { Grid : }(H, W, C) \rightarrow\left(G \times \frac{H}{G}, G\times \frac{W}{G}, C\right) \rightarrow \underbrace{\left(G^{2},\frac{H W}{G^{2}}, C\right) \rightarrow\left(\frac{H W}{G^{2}}, G^{2},C\right)}_{\text {swapaxes(axis1 } 1=-2, \text { axis } 2=-3)}\]</span></p><p>Swin Transformer P=G=7Max-SASwinFLOPsmasking, padding, orcyclic-shifting</p><h2 id="maxvit-block">MaxViT block</h2><p>( SE)MBConvMBConvMBConv(Conditional Position CodingCPE)</p><h1 id=""></h1><ul><li>MaxViT-Tdim_conv_stem = 64, depth = (2, 2, 5, 2),dim = 64</li></ul><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">from</span> functools <span class="hljs-keyword">import</span> partial<br><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn, einsum<br><br><span class="hljs-keyword">from</span> einops <span class="hljs-keyword">import</span> rearrange, repeat<br><span class="hljs-keyword">from</span> einops.layers.torch <span class="hljs-keyword">import</span> Rearrange, Reduce<br><br><br><span class="hljs-comment"># helpers</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">exists</span>(<span class="hljs-params">val</span>):<br>    <span class="hljs-keyword">return</span> val <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span><br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">default</span>(<span class="hljs-params">val, d</span>):<br>    <span class="hljs-keyword">return</span> val <span class="hljs-keyword">if</span> exists(val) <span class="hljs-keyword">else</span> d<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">cast_tuple</span>(<span class="hljs-params">val, length = <span class="hljs-number">1</span></span>):<br>    <span class="hljs-keyword">return</span> val <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(val, <span class="hljs-built_in">tuple</span>) <span class="hljs-keyword">else</span> ((val,) * length)<br><br><br><span class="hljs-comment"># helper classes</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">PreNormResidual</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, dim, fn</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.norm = nn.LayerNorm(dim)<br>        self.fn = fn<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> self.fn(self.norm(x)) + x<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">FeedForward</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, dim, mult = <span class="hljs-number">4</span>, dropout = <span class="hljs-number">0.</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        inner_dim = <span class="hljs-built_in">int</span>(dim * mult)<br>        self.net = nn.Sequential(<br>            nn.Linear(dim, inner_dim),<br>            nn.GELU(),<br>            nn.Dropout(dropout),<br>            nn.Linear(inner_dim, dim),<br>            nn.Dropout(dropout)<br>        )<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> self.net(x)<br><br><br><span class="hljs-comment"># MBConv</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SqueezeExcitation</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, dim, shrinkage_rate = <span class="hljs-number">0.25</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        hidden_dim = <span class="hljs-built_in">int</span>(dim * shrinkage_rate)<br><br>        self.gate = nn.Sequential(<br>            Reduce(<span class="hljs-string">&#x27;b c h w -&gt; b c&#x27;</span>, <span class="hljs-string">&#x27;mean&#x27;</span>),<br>            nn.Linear(dim, hidden_dim, bias = <span class="hljs-literal">False</span>),<br>            nn.SiLU(),<br>            nn.Linear(hidden_dim, dim, bias = <span class="hljs-literal">False</span>),<br>            nn.Sigmoid(),<br>            Rearrange(<span class="hljs-string">&#x27;b c -&gt; b c 1 1&#x27;</span>)<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> x * self.gate(x)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MBConvResidual</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, fn, dropout = <span class="hljs-number">0.</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.fn = fn<br>        self.dropsample = Dropsample(dropout)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        out = self.fn(x)<br>        out = self.dropsample(out)<br>        <span class="hljs-keyword">return</span> out + x<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Dropsample</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, prob = <span class="hljs-number">0</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.prob = prob<br>  <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        device = x.device<br><br>        <span class="hljs-keyword">if</span> self.prob == <span class="hljs-number">0.</span> <span class="hljs-keyword">or</span> (<span class="hljs-keyword">not</span> self.training):<br>            <span class="hljs-keyword">return</span> x<br><br>        keep_mask = torch.FloatTensor((x.shape[<span class="hljs-number">0</span>], <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>), device = device).uniform_() &gt; self.prob<br>        <span class="hljs-keyword">return</span> x * keep_mask / (<span class="hljs-number">1</span> - self.prob)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">MBConv</span>(<span class="hljs-params"></span><br><span class="hljs-params">    dim_in,</span><br><span class="hljs-params">    dim_out,</span><br><span class="hljs-params">    *,</span><br><span class="hljs-params">    downsample,</span><br><span class="hljs-params">    expansion_rate = <span class="hljs-number">4</span>,</span><br><span class="hljs-params">    shrinkage_rate = <span class="hljs-number">0.25</span>,</span><br><span class="hljs-params">    dropout = <span class="hljs-number">0.</span></span><br><span class="hljs-params"></span>):<br>    hidden_dim = <span class="hljs-built_in">int</span>(expansion_rate * dim_out)<br>    stride = <span class="hljs-number">2</span> <span class="hljs-keyword">if</span> downsample <span class="hljs-keyword">else</span> <span class="hljs-number">1</span><br><br>    net = nn.Sequential(<br>        <span class="hljs-comment"># [dim_in, n, n] -&gt; [hidden_dim, n, n]</span><br>        nn.Conv2d(dim_in, hidden_dim, <span class="hljs-number">1</span>),<br>        nn.BatchNorm2d(hidden_dim),<br>        nn.GELU(),<br>        <span class="hljs-comment"># if stride == 2, [hidden_dim, n, n] -&gt; [hidden_dim, n / 2, n / 2]</span><br>        <span class="hljs-comment"># if stride == 1, [hidden_dim, n / 2, n / 2] -&gt; [hidden_dim, n / 2, n / 2]</span><br>        nn.Conv2d(hidden_dim, hidden_dim, <span class="hljs-number">3</span>, stride = stride, padding = <span class="hljs-number">1</span>, groups = hidden_dim),<br>        nn.BatchNorm2d(hidden_dim),<br>        nn.GELU(),<br>        <span class="hljs-comment"># [hidden_dim, n / 2, n / 2] -&gt; [hidden_dim, n / 2, n / 2]</span><br>        SqueezeExcitation(hidden_dim, shrinkage_rate = shrinkage_rate),<br>        <span class="hljs-comment"># [hidden_dim, n / 2, n / 2] -&gt; [dim_out, n / 2, n / 2]</span><br>        nn.Conv2d(hidden_dim, dim_out, <span class="hljs-number">1</span>),<br>        nn.BatchNorm2d(dim_out)<br>    )<br><br>    <span class="hljs-comment"># </span><br>    <span class="hljs-keyword">if</span> dim_in == dim_out <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> downsample:<br>        net = MBConvResidual(net, dropout = dropout)<br><br>    <span class="hljs-keyword">return</span> net<br><br><br><span class="hljs-comment"># attention related classes</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Attention</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self,</span><br><span class="hljs-params">        dim,</span><br><span class="hljs-params">        dim_head=<span class="hljs-number">32</span>,</span><br><span class="hljs-params">        dropout=<span class="hljs-number">0.</span>,</span><br><span class="hljs-params">        window_size=<span class="hljs-number">7</span></span><br><span class="hljs-params">    </span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-keyword">assert</span> (dim % dim_head) == <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;dimension should be divisible by dimension per head&#x27;</span><br><br>        self.heads = dim // dim_head<br>        self.scale = dim_head ** -<span class="hljs-number">0.5</span><br><br>        self.to_qkv = nn.Linear(dim, dim * <span class="hljs-number">3</span>, bias = <span class="hljs-literal">False</span>)<br><br>        self.attend = nn.Sequential(<br>            nn.Softmax(dim=-<span class="hljs-number">1</span>),<br>            nn.Dropout(dropout)<br>        )<br><br>        self.to_out = nn.Sequential(<br>            nn.Linear(dim, dim, bias = <span class="hljs-literal">False</span>),<br>            nn.Dropout(dropout)<br>        )<br><br>        <span class="hljs-comment"># relative positional bias</span><br>        self.rel_pos_bias = nn.Embedding((<span class="hljs-number">2</span> * window_size - <span class="hljs-number">1</span>) ** <span class="hljs-number">2</span>, self.heads)<br><br>        pos = torch.arange(window_size)<br>        grid = torch.stack(torch.meshgrid(pos, pos, indexing=<span class="hljs-string">&#x27;ij&#x27;</span>))<br>        grid = rearrange(grid, <span class="hljs-string">&#x27;c i j -&gt; (i j) c&#x27;</span>)<br>        rel_pos = rearrange(grid, <span class="hljs-string">&#x27;i ... -&gt; i 1 ...&#x27;</span>) - rearrange(grid, <span class="hljs-string">&#x27;j ... -&gt; 1 j ...&#x27;</span>)<br>        rel_pos += window_size - <span class="hljs-number">1</span><br>        rel_pos_indices = (rel_pos * torch.tensor([<span class="hljs-number">2</span> * window_size - <span class="hljs-number">1</span>, <span class="hljs-number">1</span>])).<span class="hljs-built_in">sum</span>(dim=-<span class="hljs-number">1</span>)<br><br>        self.register_buffer(<span class="hljs-string">&#x27;rel_pos_indices&#x27;</span>, rel_pos_indices, persistent=<span class="hljs-literal">False</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        batch, height, width, window_height, window_width, _, device, h = *x.shape, x.device, self.heads<br><br>        <span class="hljs-comment"># flatten</span><br>        x = rearrange(x, <span class="hljs-string">&#x27;b x y w1 w2 d -&gt; (b x y) (w1 w2) d&#x27;</span>)<br><br>        <span class="hljs-comment"># project for queries, keys, values</span><br>        q, k, v = self.to_qkv(x).chunk(<span class="hljs-number">3</span>, dim=-<span class="hljs-number">1</span>)<br>        <br>        <span class="hljs-comment"># split heads</span><br>        q, k, v = <span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> t: rearrange(t, <span class="hljs-string">&#x27;b n (h d ) -&gt; b h n d&#x27;</span>, h=h), (q, k, v))<br><br>        <span class="hljs-comment"># scale</span><br>        q = q * self.scale<br><br>        <span class="hljs-comment"># sim</span><br>        sim = einsum(<span class="hljs-string">&#x27;b h i d, b h j d -&gt; b h i j&#x27;</span>, q, k)<br><br>        <span class="hljs-comment"># add positional bias</span><br>        bias = self.rel_pos_bias(self.rel_pos_indices)<br>        sim = sim + rearrange(bias, <span class="hljs-string">&#x27;i j h -&gt; h i j&#x27;</span>)<br><br>        <span class="hljs-comment"># attention</span><br>        attn = self.attend(sim)<br><br>        <span class="hljs-comment"># aggregate</span><br>        out = einsum(<span class="hljs-string">&#x27;b h i j, b h j d -&gt; b h i d&#x27;</span>, attn, v)<br><br>        <span class="hljs-comment"># merge heads</span><br>        out = rearrange(out, <span class="hljs-string">&#x27;b h (w1 w2) d -&gt; b w1 w2 (h d)&#x27;</span>, w1=window_height, w2=window_width)<br><br>        <span class="hljs-comment"># combine heads out</span><br>        out = self.to_out(out)<br>        <span class="hljs-keyword">return</span> rearrange(out, <span class="hljs-string">&#x27;(b x y) ... -&gt; b x y ...&#x27;</span>, x=height, y=width)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MaxViT</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self,</span><br><span class="hljs-params">        *,</span><br><span class="hljs-params">        num_classes,</span><br><span class="hljs-params">        dim,</span><br><span class="hljs-params">        depth,</span><br><span class="hljs-params">        dim_head=<span class="hljs-number">32</span>,</span><br><span class="hljs-params">        dim_conv_stem=<span class="hljs-literal">None</span>,</span><br><span class="hljs-params">        window_size=<span class="hljs-number">7</span>,</span><br><span class="hljs-params">        mbconv_expansion_rate=<span class="hljs-number">4</span>,</span><br><span class="hljs-params">        mbconv_shrinkage_rate=<span class="hljs-number">0.25</span>,</span><br><span class="hljs-params">        dropout=<span class="hljs-number">0.1</span>,</span><br><span class="hljs-params">        channels=<span class="hljs-number">3</span></span><br><span class="hljs-params">    </span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-keyword">assert</span> <span class="hljs-built_in">isinstance</span>(depth, <span class="hljs-built_in">tuple</span>), <span class="hljs-string">&#x27;depth needs to be tuple if integers indicating number of transformer blocks at that stage&#x27;</span><br><br>        <span class="hljs-comment"># convolutional stem</span><br>        dim_conv_stem = default(dim_conv_stem, dim)<br><br>        self.conv_stem = nn.Sequential(<br>            <span class="hljs-comment"># [-1, 3, 224, 224] -&gt; [-1, 64, 112, 112]</span><br>            nn.Conv2d(channels, dim_conv_stem, <span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>),<br>            <span class="hljs-comment"># [-1, 64, 112, 112] -&gt; [-1, 64, 112, 112]</span><br>            nn.Conv2d(dim_conv_stem, dim_conv_stem, <span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>)<br>        )<br><br>        <span class="hljs-comment"># variables, depth = (2, 2, 5, 2)</span><br>        num_stages = <span class="hljs-built_in">len</span>(depth)<br><br>        <span class="hljs-comment"># dims = (64, 128, 256, 512) </span><br>        dims = <span class="hljs-built_in">tuple</span>(<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> i: (<span class="hljs-number">2</span> ** i) * dim, <span class="hljs-built_in">range</span>(num_stages)))<br>        <span class="hljs-comment"># dims = (64, 64, 128, 256, 512) </span><br>        dims = (dim_conv_stem, *dims)<br>        <span class="hljs-comment"># dim_pairs = ((64, 64), (64, 128), (128, 256), (256, 512))</span><br>        dim_pairs = <span class="hljs-built_in">tuple</span>(<span class="hljs-built_in">zip</span>(dims[:-<span class="hljs-number">1</span>], dims[<span class="hljs-number">1</span>:]))<br><br>        self.layers = nn.ModuleList([])<br><br>        <span class="hljs-comment"># shorthand for window size for efficient block - grid like attention</span><br>        <span class="hljs-comment"># window_size = 7</span><br>        w = window_size<br><br>        <span class="hljs-comment"># iterate through stages</span><br>        <span class="hljs-comment"># (((64, 64), 2),</span><br>        <span class="hljs-comment">#  ((64, 128), 2),</span><br>        <span class="hljs-comment">#  ((128, 256), 5),</span><br>        <span class="hljs-comment">#  ((256, 512), 2))</span><br>        <span class="hljs-keyword">for</span> ind, ((layer_dim_in, layer_dim), layer_depth) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(<span class="hljs-built_in">zip</span>(dim_pairs, depth)):<br>            <span class="hljs-keyword">for</span> stage_ind <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(layer_depth):<br>                is_first = stage_ind == <span class="hljs-number">0</span><br>                stage_dim_in = layer_dim_in <span class="hljs-keyword">if</span> is_first <span class="hljs-keyword">else</span> layer_dim<br><br>                block = nn.Sequential(<br>                    <span class="hljs-comment"># [-1, stage_dim_in, n, n] -&gt; [-1, layer_dim, n / 2, n / 2] if is_first</span><br>                    <span class="hljs-comment"># [-1, layer_dim, n / 2, n / 2] -&gt; [-1, layer_dim, n / 2, n / 2] if not is_first</span><br>                    MBConv(<br>                        stage_dim_in,<br>                        layer_dim,<br>                        downsample=is_first,<br>                        expansion_rate=mbconv_expansion_rate,<br>                        shrinkage_rate=mbconv_shrinkage_rate<br>                    ),<br>                    Rearrange(<span class="hljs-string">&#x27;b d (x w1) (y w2) -&gt; b x y w1 w2 d&#x27;</span>, w1=w, w2=w),  <span class="hljs-comment"># block-like attention</span><br>                    PreNormResidual(layer_dim, Attention(dim=layer_dim, dim_head=dim_head, dropout=dropout, window_size=w)),<br>                    PreNormResidual(layer_dim, FeedForward(dim=layer_dim, dropout=dropout)),<br>                    Rearrange(<span class="hljs-string">&#x27;b x y w1 w2 d -&gt; b d (x w1) (y w2)&#x27;</span>),<br><br>                    Rearrange(<span class="hljs-string">&#x27;b d (w1 x) (w2 y) -&gt; b x y w1 w2 d&#x27;</span>, w1=w, w2=w),  <span class="hljs-comment"># grid-like attention</span><br>                    PreNormResidual(layer_dim, Attention(dim=layer_dim, dim_head=dim_head, dropout=dropout, window_size=w)),<br>                    PreNormResidual(layer_dim, FeedForward(dim=layer_dim, dropout=dropout)),<br>                    Rearrange(<span class="hljs-string">&#x27;b x y w1 w2 d -&gt; b d (w1 x) (w2 y)&#x27;</span>),<br>                )<br><br>                self.layers.append(block)<br><br>        <span class="hljs-comment"># mlp head out</span><br><br>        self.mlp_head = nn.Sequential(<br>            Reduce(<span class="hljs-string">&#x27;b d h w -&gt; b d&#x27;</span>, <span class="hljs-string">&#x27;mean&#x27;</span>),<br>            nn.LayerNorm(dims[-<span class="hljs-number">1</span>]),<br>            nn.Linear(dims[-<span class="hljs-number">1</span>], num_classes)<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.conv_stem(x)<br><br>        <span class="hljs-keyword">for</span> stage <span class="hljs-keyword">in</span> self.layers:<br>            x = stage(x)<br><br>        <span class="hljs-keyword">return</span> self.mlp_head(x)<br><br><br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>cv</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>MAXIM</title>
    <link href="/2022/11/14/MAXIM/"/>
    <url>/2022/11/14/MAXIM/</url>
    
    <content type="html"><![CDATA[<ul><li>MAXIM: Multi-Axis MLP for Image Processing</li></ul><p><img src="/img/cv/image-20221114195010981.png" /></p><h1 id=""></h1><p>MLPMAXIMMAXIMU-netMAXIMMLP<strong>MLPmulti-axisgatedMLP</strong>/<strong>cross-gatingblock</strong>MAXIM<strong>/</strong><strong></strong>5()10<strong>SOTA</strong></p><h1 id="contribution">Contribution</h1><ul><li>MAXIM10SOTA</li><li>MLPMulti-axis gated MLPblock<strong></strong><strong></strong><strong></strong></li><li>Cross-GatingblockEncoderDecoderskipconnection<strong></strong><strong></strong></li></ul><h1 id=""></h1><h2 id=""></h2><p><img src="/img/cv/image-20221114164926504.png" /></p><h2 id="mlpmulti-axis-gated-mlp-block">MLPMulti-AxisGated MLP Block</h2><p><img src="/img/cv/image-20221114165825735.png" /></p><p>LayerNorm-Dense-GELU/</p><p>Local Branch<strong></strong> <spanclass="math inline">\(b \times b\)</span> blcok <spanclass="math inline">\([H,W,C]\)</span>  <spanclass="math inline">\(\left[\frac{H}{b} \times \frac{W}{b}, b \times b,C\right]\)</span>gMLPunblock<span class="math inline">\([H,W,C]\)</span> GlobalBranch<strong></strong>GlobalBranchgMLP</p><p>Local BranchGlobalBranchConcatDense</p><p>blockgridMLP<strong></strong><span class="math display">\[\Omega(\mathrm{MAB})=\underbrace{d^{2} H W C}_{\text {Global gMLP}}+\underbrace{b^{2} H W C}_{\text {Local gMLP }}+\underbrace{10 H WC^{2}}_{\text {Dense layers }}\ \ \ \ \ \ \ (1)\]</span></p><h2 id="cross-gated-mlp-block">Cross Gated MLPBlock</h2><p><img src="/img/cv/image-20221114170902221.png" /></p><p>U-netskipconnection</p><p>XYDense <spanclass="math inline">\(X_1\)</span>  <spanclass="math inline">\(Y_1\)</span> </p><p>LN-Dense-GELU <span class="math inline">\(X_2\)</span> <span class="math inline">\(Y_2\)</span> </p><p><span class="math display">\[\mathbf{X}_{2}=\sigma\left(\mathbf{W}_{1}\mathrm{LN}\left(\mathbf{X}_{1}\right)\right), \quad\mathbf{Y}_{2}=\sigma\left(\mathbf{W}_{2}\mathrm{LN}\left(\mathbf{Y}_{1}\right)\right)\ \ \ \ \ \ \ (2)\]</span>  <spanclass="math inline">\(\hat{X}\)</span>  <spanclass="math inline">\(\hat{Y}\)</span></p><p><span class="math display">\[\hat{\mathbf{X}}=\mathbf{X}_{2} \odot\mathrm{G}\left(\mathbf{Y}_{2}\right), \quad\hat{\mathbf{Y}}=\mathbf{Y}_{2} \odot\mathrm{G}\left(\mathbf{X}_{2}\right)\ \ \ \ \ \ \ (3)\]</span>  <span class="math inline">\(\odot\)</span>element-wisemultiplicationG2MLP <spanclass="math display">\[\mathrm{G}(\mathbf{x})=\mathbf{W}_{5}\left(\left[\mathbf{W}_{3}\operatorname{Block}_{b}\left(\mathbf{z}_{1}\right), \mathbf{W}_{4}\operatorname{Grid}_{d}\left(\mathbf{z}_{\mathbf{2}}\right)\right]\right)\\ \ \ \ \ \ (4)\]</span>  <span class="math inline">\([\cdot, \cdot]\)</span>concatenate <span class="math inline">\((z_1, z_2)\)</span> <span class="math inline">\(z\)</span>channelhead <span class="math display">\[\left[\mathbf{z}_{1},\mathbf{z}_{2}\right]=\mathbf{z}=\sigma\left(\mathbf{W}_{6} \mathbf{LN}(\mathbf{x})\right)\ \ \ \ \ \ \ (5)\]</span>  <spanclass="math inline">\(X_3\)</span>  <spanclass="math inline">\(Y_3\)</span>  <span class="math display">\[\mathbf{X}_{3}=\mathbf{X}_{1}+\mathbf{W}_{7} \hat{\mathbf{X}}, \quad\mathbf{Y}_{3}=\mathbf{Y}_{1}+\mathbf{W}_{8} \hat{\mathbf{Y}}\ \ \ \ \ \\ (6)\]</span>/</p><h2 id=""></h2><p><img src="/img/cv/image-20221114172412249.png" /></p><p><strong></strong></p><p>CharbonnierL1<span class="math display">\[\mathcal{L}=\sum_{s=1}^{S} \sum_{n=1}^{N}\left[\mathcal{L}_{c h ar}\left(\mathbf{R}_{s, n}, \mathbf{T}_{n}\right)+\lambda \mathcal{L}_{fr e q}\left(\mathbf{R}_{s, n}, \mathbf{T}_{n}\right)\right]\ \ \ \ \ \ \(7)\]</span>  <span class="math inline">\(T_n\)</span>()<spanclass="math inline">\(\mathcal{L}_{c h a r}\)</span> Charbonnierloss <span class="math display">\[\mathcal{L}_{c h a r}(\mathbf{R},\mathbf{T})=\sqrt{\|\mathbf{R}-\mathbf{T}\|^{2}+\epsilon^{2}}\ \ \ \ \ \\ (8)\]</span>  <span class="math inline">\(\epsilon\)</span> <span class="math inline">\(10^{-3}\)</span> <spanclass="math inline">\(\mathcal{L}_{f r e q}\)</span> <span class="math display">\[\mathcal{L}_{\text {freq }}(\mathbf{R},\mathbf{T})=\|\mathcal{F}(\mathbf{R})-\mathcal{F}(\mathbf{T})\|_{1}\ \ \\ \ \ \ (9)\]</span>  <span class="math inline">\(\mathcal{F}\)</span>2D <spanclass="math inline">\(\lambda = 0.1\)</span> </p>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>cv</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>gMLP</title>
    <link href="/2022/11/11/gMLP/"/>
    <url>/2022/11/11/gMLP/</url>
    
    <content type="html"><![CDATA[<ul><li>Pay Attention to MLPs</li></ul><p><img src="/img/cv/image-20221114213308452.png" /></p><h1 id=""></h1><p>TransformergMLPbasedon MLPs withgatingTransformervisionTransformergMLPBERTgMLPTransformerNLPgMLPgMLPTransformergMLPTransformers</p><h1 id="introduction">Introduction</h1><p>MLPTransformerwithmultiplicativegating1gMLPMLPwithgatinggMLPImageNetgMLPDeiT66%gMLPMLP-mixer3%Transformer</p><h1 id="model">Model</h1><h2 id=""></h2><p><img src="/img/cv/image-20221111113705112.png" /></p><h2 id="spatial-gating-unit">Spatial Gating Unit</h2><p>tokens() <spanclass="math display">\[f_{W, b}(Z)=W Z+b\]</span>  <span class="math inline">\(W \in \mathbb{R}^{n \timesn}\)</span> self-attention W  Zgating <spanclass="math display">\[s(Z)=Z \odot f_{W, b}(Z)\]</span>  W  b  0  1 <spanclass="math inline">\(f_{W,b}1s(Z)Z\)</span>gMLPFFNtoken</p><p> Z  <spanclass="math inline">\((Z_1,Z_2)\)</span>gating <span class="math display">\[s(Z)=Z_{1} \odot f_{W, b}\left(Z_{2}\right)\]</span>  <spanclass="math inline">\(f_{W,b}\)</span>NLP</p><h2 id=""></h2><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">from</span> torchsummary <span class="hljs-keyword">import</span> summary<br><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">spatial_gating_unit</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, d_ffn, seq_len</span>):<br>        <span class="hljs-built_in">super</span>(spatial_gating_unit, self).__init__()<br>        self.norm = nn.LayerNorm(d_ffn)<br>        self.spatial_proj = nn.Conv1d(seq_len, seq_len, <span class="hljs-number">1</span>)<br>        nn.init.zeros_(self.norm.weight)<br>        nn.init.ones_(self.norm.bias)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># [-1, 256, 1024] -&gt; [-1, 256, 512]</span><br>        res, gate = torch.chunk(x, <span class="hljs-number">2</span>, -<span class="hljs-number">1</span>)<br>        <span class="hljs-comment"># [-1, 256, 512]</span><br>        gate = self.norm(gate)<br>        <span class="hljs-comment"># [-1, 256, 512]</span><br>        gate = self.spatial_proj(gate)<br>        <span class="hljs-keyword">return</span> res * gate<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">gMLPBlock</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, d_model, d_ffn, seq_len</span>):<br>        <span class="hljs-built_in">super</span>(gMLPBlock, self).__init__()<br>        self.norm = nn.LayerNorm(d_model)<br>        self.channel_proj1 = nn.Linear(d_model, d_ffn * <span class="hljs-number">2</span>)  <span class="hljs-comment"># [-1, 256, 1024]</span><br>        self.sgu = spatial_gating_unit(d_ffn, seq_len)<br>        self.channel_proj2 = nn.Linear(d_ffn, d_model)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        residual = x<br>        <span class="hljs-comment"># [-1, 256, 256]</span><br>        x = self.norm(x)<br>        <span class="hljs-comment"># [-1, 256, 256] -&gt; [-1, 256, 1024]</span><br>        x = self.channel_proj1(x)<br>        <span class="hljs-comment"># [-1, 256, 256] -&gt; [-1, 256, 1024]</span><br>        x = F.gelu(x)<br>        <span class="hljs-comment"># [-1, 256, 1024] -&gt; [-1, 256, 512]</span><br>        x = self.sgu(x)<br>        <span class="hljs-comment"># [-1, 256, 512] -&gt; [-1, 256, 256]</span><br>        x = self.channel_proj2(x)<br>        <span class="hljs-keyword">return</span> residual + x<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">gMLP</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, d_model=<span class="hljs-number">256</span>, d_ffn=<span class="hljs-number">512</span>, seq_len=<span class="hljs-number">256</span>, num_layers=<span class="hljs-number">6</span></span>):<br>        <span class="hljs-built_in">super</span>(gMLP, self).__init__()<br>        self.model = nn.Sequential(<br>            *[gMLPBlock(d_model, d_ffn, seq_len) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_layers)]<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> self.model(x)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">gMLPForImageClassification</span>(<span class="hljs-title class_ inherited__">gMLP</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,</span><br><span class="hljs-params">                 image_size=<span class="hljs-number">256</span>,</span><br><span class="hljs-params">                 patch_size=<span class="hljs-number">16</span>,</span><br><span class="hljs-params">                 in_channels=<span class="hljs-number">3</span>,</span><br><span class="hljs-params">                 num_classes=<span class="hljs-number">1000</span>,</span><br><span class="hljs-params">                 d_model=<span class="hljs-number">256</span>,</span><br><span class="hljs-params">                 d_ffn=<span class="hljs-number">512</span>,</span><br><span class="hljs-params">                 seq_len=<span class="hljs-number">256</span>,</span><br><span class="hljs-params">                 num_layers=<span class="hljs-number">6</span></span>):<br><br>        num_patches = (image_size / patch_size) ** <span class="hljs-number">2</span>    <span class="hljs-comment"># 256</span><br>        <span class="hljs-built_in">super</span>().__init__(d_model, d_ffn, seq_len, num_layers)<br>        self.patcher = nn.Conv2d(<br>            in_channels, d_model, kernel_size=patch_size, stride=patch_size<br>        )   <span class="hljs-comment"># [2, 3, 256, 256] -&gt; [2, 256, 16, 16]</span><br>        self.classifier = nn.Linear(d_model, num_classes)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># [2, 3, 256, 256] -&gt; [2, 256, 16, 16]</span><br>        patches = self.patcher(x)<br>        batch_size, num_channels, _, _ = patches.shape<br>        patches = patches.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>)   <span class="hljs-comment"># [2, 256, 16, 16] -&gt; [2, 16, 16, 256]</span><br>        patches = patches.view(batch_size, -<span class="hljs-number">1</span>, num_channels)    <span class="hljs-comment"># [2, 256, 256]</span><br>        <span class="hljs-comment"># [2, 256, 256]</span><br>        embedding = self.model(patches)<br>        <span class="hljs-comment"># [2, 256, 256] -&gt; [2, 256]</span><br>        embedding = embedding.mean(dim=<span class="hljs-number">1</span>)<br>        <span class="hljs-comment"># [2, 256] -&gt; [2, 1000]</span><br>        out = self.classifier(embedding)<br>        <span class="hljs-keyword">return</span> out<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    device = torch.device(<span class="hljs-string">&quot;cuda:0&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br>    model = gMLPForImageClassification(image_size=<span class="hljs-number">256</span>, patch_size=<span class="hljs-number">16</span>, in_channels=<span class="hljs-number">3</span>, num_classes=<span class="hljs-number">1000</span>, d_model=<span class="hljs-number">256</span>, d_ffn=<span class="hljs-number">512</span>, seq_len=<span class="hljs-number">256</span>, num_layers=<span class="hljs-number">6</span>).to(device)<br>    summary(model, (<span class="hljs-number">3</span>, <span class="hljs-number">256</span>, <span class="hljs-number">256</span>))<br><br>    inputs = torch.Tensor(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">256</span>, <span class="hljs-number">256</span>)<br>    inputs = inputs.to(device)<br>    <span class="hljs-built_in">print</span>(inputs.shape)<br><br>    <span class="hljs-comment"># modelgraph</span><br>    <span class="hljs-keyword">with</span> SummaryWriter(log_dir=<span class="hljs-string">&#x27;logs&#x27;</span>, comment=<span class="hljs-string">&#x27;model&#x27;</span>) <span class="hljs-keyword">as</span> w:<br>        w.add_graph(model, (inputs,))<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;success&#x27;</span>)<br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>cv</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>RepMLP</title>
    <link href="/2022/11/10/RepMLP/"/>
    <url>/2022/11/10/RepMLP/</url>
    
    <content type="html"><![CDATA[<ul><li>RepMLPNet: Hierarchical Vision MLP with Re-parameterizedLocality</li><li></li><li></li></ul><h1 id=""></h1><p><img src="/img/cv/image-20221110101258348.png" /></p><p><img src="/img/cv/image-20221110155613883.png" /></p><h1 id=""></h1><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.utils.checkpoint <span class="hljs-keyword">as</span> checkpoint<br><span class="hljs-keyword">import</span> torch<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">conv_bn</span>(<span class="hljs-params">in_channels, out_channels, kernel_size, stride, padding, groups=<span class="hljs-number">1</span></span>):<br>    result = nn.Sequential()<br>    result.add_module(<span class="hljs-string">&#x27;conv&#x27;</span>, nn.Conv2d(in_channels=in_channels, out_channels=out_channels,<br>                                                  kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=<span class="hljs-literal">False</span>))<br>    result.add_module(<span class="hljs-string">&#x27;bn&#x27;</span>, nn.BatchNorm2d(num_features=out_channels))<br>    <span class="hljs-keyword">return</span> result<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">conv_bn_relu</span>(<span class="hljs-params">in_channels, out_channels, kernel_size, stride, padding, groups=<span class="hljs-number">1</span></span>):<br>    result = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups)<br>    result.add_module(<span class="hljs-string">&#x27;relu&#x27;</span>, nn.ReLU())<br>    <span class="hljs-keyword">return</span> result<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">fuse_bn</span>(<span class="hljs-params">conv_or_fc, bn</span>):<br>    std = (bn.running_var + bn.eps).sqrt()<br>    t = bn.weight / std<br>    t = t.reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(t) == conv_or_fc.weight.size(<span class="hljs-number">0</span>):<br>        <span class="hljs-keyword">return</span> conv_or_fc.weight * t, bn.bias - bn.running_mean * bn.weight / std<br>    <span class="hljs-keyword">else</span>:<br>        repeat_times = conv_or_fc.weight.size(<span class="hljs-number">0</span>) // <span class="hljs-built_in">len</span>(t)<br>        repeated = t.repeat_interleave(repeat_times, <span class="hljs-number">0</span>)<br>        <span class="hljs-keyword">return</span> conv_or_fc.weight * repeated, (bn.bias - bn.running_mean * bn.weight / std).repeat_interleave(<br>            repeat_times, <span class="hljs-number">0</span>)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">GlobalPerceptron</span>(nn.Module):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, input_channels, internal_neurons</span>):<br>        <span class="hljs-built_in">super</span>(GlobalPerceptron, self).__init__()<br>        self.fc1 = nn.Conv2d(in_channels=input_channels, out_channels=internal_neurons, kernel_size=<span class="hljs-number">1</span>, stride=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>)<br>        self.fc2 = nn.Conv2d(in_channels=internal_neurons, out_channels=input_channels, kernel_size=<span class="hljs-number">1</span>, stride=<span class="hljs-number">1</span>, bias=<span class="hljs-literal">True</span>)<br>        self.input_channels = input_channels<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, inputs</span>):<br>        x = F.adaptive_avg_pool2d(inputs, output_size=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>        x = self.fc1(x)<br>        x = F.relu(x, inplace=<span class="hljs-literal">True</span>)<br>        x = self.fc2(x)<br>        x = F.sigmoid(x)<br>        x = x.view(-<span class="hljs-number">1</span>, self.input_channels, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> x<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">RepMLPBlock</span>(nn.Module):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, in_channels, out_channels,</span><br><span class="hljs-params">                 h, w,</span><br><span class="hljs-params">                 reparam_conv_k=<span class="hljs-literal">None</span>,</span><br><span class="hljs-params">                 globalperceptron_reduce=<span class="hljs-number">4</span>,</span><br><span class="hljs-params">                 num_sharesets=<span class="hljs-number">1</span>,</span><br><span class="hljs-params">                 deploy=<span class="hljs-literal">False</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br><br>        self.C = in_channels<br>        self.O = out_channels<br>        self.S = num_sharesets<br><br>        self.h, self.w = h, w<br><br>        self.deploy = deploy<br><br>        <span class="hljs-keyword">assert</span> in_channels == out_channels<br>        self.gp = GlobalPerceptron(input_channels=in_channels, internal_neurons=in_channels // globalperceptron_reduce)<br><br>        self.fc3 = nn.Conv2d(self.h * self.w * num_sharesets, self.h * self.w * num_sharesets, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, bias=deploy, groups=num_sharesets)<br>        <span class="hljs-keyword">if</span> deploy:<br>            self.fc3_bn = nn.Identity()<br>        <span class="hljs-keyword">else</span>:<br>            self.fc3_bn = nn.BatchNorm2d(num_sharesets)<br><br>        self.reparam_conv_k = reparam_conv_k<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> deploy <span class="hljs-keyword">and</span> reparam_conv_k <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> reparam_conv_k:<br>                conv_branch = conv_bn(num_sharesets, num_sharesets, kernel_size=k, stride=<span class="hljs-number">1</span>, padding=k//<span class="hljs-number">2</span>, groups=num_sharesets)<br>                self.__setattr__(<span class="hljs-string">&#x27;repconv&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(k), conv_branch)<br><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">partition</span>(<span class="hljs-params">self, x, h_parts, w_parts</span>):<br>        x = x.reshape(-<span class="hljs-number">1</span>, self.C, h_parts, self.h, w_parts, self.w)<br>        x = x.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5</span>)<br>        <span class="hljs-keyword">return</span> x<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">partition_affine</span>(<span class="hljs-params">self, x, h_parts, w_parts</span>):<br>        fc_inputs = x.reshape(-<span class="hljs-number">1</span>, self.S * self.h * self.w, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>        out = self.fc3(fc_inputs)<br>        out = out.reshape(-<span class="hljs-number">1</span>, self.S, self.h, self.w)<br>        out = self.fc3_bn(out)<br>        out = out.reshape(-<span class="hljs-number">1</span>, h_parts, w_parts, self.S, self.h, self.w)<br>        <span class="hljs-keyword">return</span> out<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, inputs</span>):<br>        <span class="hljs-comment">#   Global Perceptron</span><br>        global_vec = self.gp(inputs)<br><br>        origin_shape = inputs.size()<br>        h_parts = origin_shape[<span class="hljs-number">2</span>] // self.h<br>        w_parts = origin_shape[<span class="hljs-number">3</span>] // self.w<br><br>        partitions = self.partition(inputs, h_parts, w_parts)<br><br>        <span class="hljs-comment">#   Channel Perceptron</span><br>        fc3_out = self.partition_affine(partitions, h_parts, w_parts)<br><br>        <span class="hljs-comment">#   Local Perceptron</span><br>        <span class="hljs-keyword">if</span> self.reparam_conv_k <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> self.deploy:<br>            conv_inputs = partitions.reshape(-<span class="hljs-number">1</span>, self.S, self.h, self.w)<br>            conv_out = <span class="hljs-number">0</span><br>            <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> self.reparam_conv_k:<br>                conv_branch = self.__getattr__(<span class="hljs-string">&#x27;repconv&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(k))<br>                conv_out += conv_branch(conv_inputs)<br>            conv_out = conv_out.reshape(-<span class="hljs-number">1</span>, h_parts, w_parts, self.S, self.h, self.w)<br>            fc3_out += conv_out<br><br>        fc3_out = fc3_out.permute(<span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">2</span>, <span class="hljs-number">5</span>)  <span class="hljs-comment"># N, O, h_parts, out_h, w_parts, out_w</span><br>        out = fc3_out.reshape(*origin_shape)<br>        out = out * global_vec<br>        <span class="hljs-keyword">return</span> out<br><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_equivalent_fc3</span>(<span class="hljs-params">self</span>):<br>        fc_weight, fc_bias = fuse_bn(self.fc3, self.fc3_bn)<br>        <span class="hljs-keyword">if</span> self.reparam_conv_k <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            largest_k = <span class="hljs-built_in">max</span>(self.reparam_conv_k)<br>            largest_branch = self.__getattr__(<span class="hljs-string">&#x27;repconv&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(largest_k))<br>            total_kernel, total_bias = fuse_bn(largest_branch.conv, largest_branch.bn)<br>            <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> self.reparam_conv_k:<br>                <span class="hljs-keyword">if</span> k != largest_k:<br>                    k_branch = self.__getattr__(<span class="hljs-string">&#x27;repconv&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(k))<br>                    kernel, bias = fuse_bn(k_branch.conv, k_branch.bn)<br>                    total_kernel += F.pad(kernel, [(largest_k - k) // <span class="hljs-number">2</span>] * <span class="hljs-number">4</span>)<br>                    total_bias += bias<br>            rep_weight, rep_bias = self._convert_conv_to_fc(total_kernel, total_bias)<br>            final_fc3_weight = rep_weight.reshape_as(fc_weight) + fc_weight<br>            final_fc3_bias = rep_bias + fc_bias<br>        <span class="hljs-keyword">else</span>:<br>            final_fc3_weight = fc_weight<br>            final_fc3_bias = fc_bias<br>        <span class="hljs-keyword">return</span> final_fc3_weight, final_fc3_bias<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">local_inject</span>(<span class="hljs-params">self</span>):<br>        self.deploy = <span class="hljs-literal">True</span><br>        <span class="hljs-comment">#   Locality Injection</span><br>        fc3_weight, fc3_bias = self.get_equivalent_fc3()<br>        <span class="hljs-comment">#   Remove Local Perceptron</span><br>        <span class="hljs-keyword">if</span> self.reparam_conv_k <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> self.reparam_conv_k:<br>                self.__delattr__(<span class="hljs-string">&#x27;repconv&#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(k))<br>        self.__delattr__(<span class="hljs-string">&#x27;fc3&#x27;</span>)<br>        self.__delattr__(<span class="hljs-string">&#x27;fc3_bn&#x27;</span>)<br>        self.fc3 = nn.Conv2d(self.S * self.h * self.w, self.S * self.h * self.w, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, bias=<span class="hljs-literal">True</span>, groups=self.S)<br>        self.fc3_bn = nn.Identity()<br>        self.fc3.weight.data = fc3_weight<br>        self.fc3.bias.data = fc3_bias<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_convert_conv_to_fc</span>(<span class="hljs-params">self, conv_kernel, conv_bias</span>):<br>        I = torch.eye(self.h * self.w).repeat(<span class="hljs-number">1</span>, self.S).reshape(self.h * self.w, self.S, self.h, self.w).to(conv_kernel.device)<br>        fc_k = F.conv2d(I, conv_kernel, padding=(conv_kernel.size(<span class="hljs-number">2</span>)//<span class="hljs-number">2</span>,conv_kernel.size(<span class="hljs-number">3</span>)//<span class="hljs-number">2</span>), groups=self.S)<br>        fc_k = fc_k.reshape(self.h * self.w, self.S * self.h * self.w).t()<br>        fc_bias = conv_bias.repeat_interleave(self.h * self.w)<br>        <span class="hljs-keyword">return</span> fc_k, fc_bias<br><br><br><span class="hljs-comment">#   The common FFN Block used in many Transformer and MLP models.</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">FFNBlock</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, in_channels, hidden_channels=<span class="hljs-literal">None</span>, out_channels=<span class="hljs-literal">None</span>, act_layer=nn.GELU</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        out_features = out_channels <span class="hljs-keyword">or</span> in_channels<br>        hidden_features = hidden_channels <span class="hljs-keyword">or</span> in_channels<br>        self.ffn_fc1 = conv_bn(in_channels, hidden_features, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>)<br>        self.ffn_fc2 = conv_bn(hidden_features, out_features, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>)<br>        self.act = act_layer()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.ffn_fc1(x)<br>        x = self.act(x)<br>        x = self.ffn_fc2(x)<br>        <span class="hljs-keyword">return</span> x<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">RepMLPNetUnit</span>(nn.Module):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, channels, h, w, reparam_conv_k, globalperceptron_reduce, ffn_expand=<span class="hljs-number">4</span>,</span><br><span class="hljs-params">                 num_sharesets=<span class="hljs-number">1</span>, deploy=<span class="hljs-literal">False</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.repmlp_block = RepMLPBlock(in_channels=channels, out_channels=channels, h=h, w=w,<br>                                        reparam_conv_k=reparam_conv_k, globalperceptron_reduce=globalperceptron_reduce,<br>                                        num_sharesets=num_sharesets, deploy=deploy)<br>        self.ffn_block = FFNBlock(channels, channels * ffn_expand)<br>        self.prebn1 = nn.BatchNorm2d(channels)<br>        self.prebn2 = nn.BatchNorm2d(channels)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        y = x + self.repmlp_block(self.prebn1(x))  <span class="hljs-comment"># TODO use droppath?</span><br>        z = y + self.ffn_block(self.prebn2(y))<br>        <span class="hljs-keyword">return</span> z<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">RepMLPNet</span>(nn.Module):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,</span><br><span class="hljs-params">                 in_channels=<span class="hljs-number">3</span>, num_class=<span class="hljs-number">1000</span>,</span><br><span class="hljs-params">                 patch_size=(<span class="hljs-params"><span class="hljs-number">4</span>, <span class="hljs-number">4</span></span>),</span><br><span class="hljs-params">                 num_blocks=(<span class="hljs-params"><span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">6</span>,<span class="hljs-number">2</span></span>), channels=(<span class="hljs-params"><span class="hljs-number">192</span>,<span class="hljs-number">384</span>,<span class="hljs-number">768</span>,<span class="hljs-number">1536</span></span>),</span><br><span class="hljs-params">                 hs=(<span class="hljs-params"><span class="hljs-number">64</span>,<span class="hljs-number">32</span>,<span class="hljs-number">16</span>,<span class="hljs-number">8</span></span>), ws=(<span class="hljs-params"><span class="hljs-number">64</span>,<span class="hljs-number">32</span>,<span class="hljs-number">16</span>,<span class="hljs-number">8</span></span>),</span><br><span class="hljs-params">                 sharesets_nums=(<span class="hljs-params"><span class="hljs-number">4</span>,<span class="hljs-number">8</span>,<span class="hljs-number">16</span>,<span class="hljs-number">32</span></span>),</span><br><span class="hljs-params">                 reparam_conv_k=(<span class="hljs-params"><span class="hljs-number">3</span>,</span>),</span><br><span class="hljs-params">                 globalperceptron_reduce=<span class="hljs-number">4</span>, use_checkpoint=<span class="hljs-literal">False</span>,</span><br><span class="hljs-params">                 deploy=<span class="hljs-literal">False</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        num_stages = <span class="hljs-built_in">len</span>(num_blocks)<br>        <span class="hljs-keyword">assert</span> num_stages == <span class="hljs-built_in">len</span>(channels)<br>        <span class="hljs-keyword">assert</span> num_stages == <span class="hljs-built_in">len</span>(hs)<br>        <span class="hljs-keyword">assert</span> num_stages == <span class="hljs-built_in">len</span>(ws)<br>        <span class="hljs-keyword">assert</span> num_stages == <span class="hljs-built_in">len</span>(sharesets_nums)<br><br>        self.conv_embedding = conv_bn_relu(in_channels, channels[<span class="hljs-number">0</span>], kernel_size=patch_size, stride=patch_size, padding=<span class="hljs-number">0</span>)<br><br>        stages = []<br>        embeds = []<br>        <span class="hljs-keyword">for</span> stage_idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_stages):<br>            stage_blocks = [RepMLPNetUnit(channels=channels[stage_idx], h=hs[stage_idx], w=ws[stage_idx], reparam_conv_k=reparam_conv_k,<br>                                            globalperceptron_reduce=globalperceptron_reduce, ffn_expand=<span class="hljs-number">4</span>, num_sharesets=sharesets_nums[stage_idx],<br>                                            deploy=deploy) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_blocks[stage_idx])]<br>            stages.append(nn.ModuleList(stage_blocks))<br>            <span class="hljs-keyword">if</span> stage_idx &lt; num_stages - <span class="hljs-number">1</span>:<br>                embeds.append(conv_bn_relu(in_channels=channels[stage_idx], out_channels=channels[stage_idx + <span class="hljs-number">1</span>], kernel_size=<span class="hljs-number">2</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">0</span>))<br><br>        self.stages = nn.ModuleList(stages)<br>        self.embeds = nn.ModuleList(embeds)<br>        self.head_norm = nn.BatchNorm2d(channels[-<span class="hljs-number">1</span>])<br>        self.head = nn.Linear(channels[-<span class="hljs-number">1</span>], num_class)<br><br>        self.use_checkpoint = use_checkpoint<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.conv_embedding(x)<br>        <span class="hljs-keyword">for</span> i, stage <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(self.stages):<br>            <span class="hljs-keyword">for</span> block <span class="hljs-keyword">in</span> stage:<br>                <span class="hljs-keyword">if</span> self.use_checkpoint:<br>                    x = checkpoint.checkpoint(block, x)<br>                <span class="hljs-keyword">else</span>:<br>                    x = block(x)<br>            <span class="hljs-keyword">if</span> i &lt; <span class="hljs-built_in">len</span>(self.stages) - <span class="hljs-number">1</span>:<br>                embed = self.embeds[i]<br>                <span class="hljs-keyword">if</span> self.use_checkpoint:<br>                    x = checkpoint.checkpoint(embed, x)<br>                <span class="hljs-keyword">else</span>:<br>                    x = embed(x)<br>        x = self.head_norm(x)<br>        x = F.adaptive_avg_pool2d(x, <span class="hljs-number">1</span>)<br>        x = x.view(x.size(<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>)<br>        x = self.head(x)<br>        <span class="hljs-keyword">return</span> x<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">locality_injection</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> self.modules():<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(m, <span class="hljs-string">&#x27;local_inject&#x27;</span>):<br>                m.local_inject()<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">create_RepMLPNet_T224</span>(<span class="hljs-params">deploy=<span class="hljs-literal">False</span></span>):<br>    <span class="hljs-keyword">return</span> RepMLPNet(channels=(<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">256</span>, <span class="hljs-number">512</span>), hs=(<span class="hljs-number">56</span>,<span class="hljs-number">28</span>,<span class="hljs-number">14</span>,<span class="hljs-number">7</span>), ws=(<span class="hljs-number">56</span>,<span class="hljs-number">28</span>,<span class="hljs-number">14</span>,<span class="hljs-number">7</span>),<br>                      num_blocks=(<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">6</span>,<span class="hljs-number">2</span>), reparam_conv_k=(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>), sharesets_nums=(<span class="hljs-number">1</span>,<span class="hljs-number">4</span>,<span class="hljs-number">16</span>,<span class="hljs-number">128</span>),<br>                     deploy=deploy)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">create_RepMLPNet_T256</span>(<span class="hljs-params">deploy=<span class="hljs-literal">False</span></span>):<br>    <span class="hljs-keyword">return</span> RepMLPNet(channels=(<span class="hljs-number">64</span>, <span class="hljs-number">128</span>, <span class="hljs-number">256</span>, <span class="hljs-number">512</span>), hs=(<span class="hljs-number">64</span>,<span class="hljs-number">32</span>,<span class="hljs-number">16</span>,<span class="hljs-number">8</span>), ws=(<span class="hljs-number">64</span>,<span class="hljs-number">32</span>,<span class="hljs-number">16</span>,<span class="hljs-number">8</span>),<br>                      num_blocks=(<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">6</span>,<span class="hljs-number">2</span>), reparam_conv_k=(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>), sharesets_nums=(<span class="hljs-number">1</span>,<span class="hljs-number">4</span>,<span class="hljs-number">16</span>,<span class="hljs-number">128</span>),<br>                     deploy=deploy)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">create_RepMLPNet_B224</span>(<span class="hljs-params">deploy=<span class="hljs-literal">False</span></span>):<br>    <span class="hljs-keyword">return</span> RepMLPNet(channels=(<span class="hljs-number">96</span>, <span class="hljs-number">192</span>, <span class="hljs-number">384</span>, <span class="hljs-number">768</span>), hs=(<span class="hljs-number">56</span>,<span class="hljs-number">28</span>,<span class="hljs-number">14</span>,<span class="hljs-number">7</span>), ws=(<span class="hljs-number">56</span>,<span class="hljs-number">28</span>,<span class="hljs-number">14</span>,<span class="hljs-number">7</span>),<br>                      num_blocks=(<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">12</span>,<span class="hljs-number">2</span>), reparam_conv_k=(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>), sharesets_nums=(<span class="hljs-number">1</span>,<span class="hljs-number">4</span>,<span class="hljs-number">32</span>,<span class="hljs-number">128</span>),<br>                     deploy=deploy)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">create_RepMLPNet_B256</span>(<span class="hljs-params">deploy=<span class="hljs-literal">False</span></span>):<br>    <span class="hljs-keyword">return</span> RepMLPNet(channels=(<span class="hljs-number">96</span>, <span class="hljs-number">192</span>, <span class="hljs-number">384</span>, <span class="hljs-number">768</span>), hs=(<span class="hljs-number">64</span>,<span class="hljs-number">32</span>,<span class="hljs-number">16</span>,<span class="hljs-number">8</span>), ws=(<span class="hljs-number">64</span>,<span class="hljs-number">32</span>,<span class="hljs-number">16</span>,<span class="hljs-number">8</span>),<br>                      num_blocks=(<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">12</span>,<span class="hljs-number">2</span>), reparam_conv_k=(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>), sharesets_nums=(<span class="hljs-number">1</span>,<span class="hljs-number">4</span>,<span class="hljs-number">32</span>,<span class="hljs-number">128</span>),<br>                     deploy=deploy)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">create_RepMLPNet_D256</span>(<span class="hljs-params">deploy=<span class="hljs-literal">False</span></span>):<br>    <span class="hljs-keyword">return</span> RepMLPNet(channels=(<span class="hljs-number">80</span>, <span class="hljs-number">160</span>, <span class="hljs-number">320</span>, <span class="hljs-number">640</span>), hs=(<span class="hljs-number">64</span>,<span class="hljs-number">32</span>,<span class="hljs-number">16</span>,<span class="hljs-number">8</span>), ws=(<span class="hljs-number">64</span>,<span class="hljs-number">32</span>,<span class="hljs-number">16</span>,<span class="hljs-number">8</span>),<br>                      num_blocks=(<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">18</span>,<span class="hljs-number">2</span>), reparam_conv_k=(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>), sharesets_nums=(<span class="hljs-number">1</span>,<span class="hljs-number">4</span>,<span class="hljs-number">16</span>,<span class="hljs-number">128</span>),<br>                     deploy=deploy)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">create_RepMLPNet_L256</span>(<span class="hljs-params">deploy=<span class="hljs-literal">False</span></span>):<br>    <span class="hljs-keyword">return</span> RepMLPNet(channels=(<span class="hljs-number">96</span>, <span class="hljs-number">192</span>, <span class="hljs-number">384</span>, <span class="hljs-number">768</span>), hs=(<span class="hljs-number">64</span>,<span class="hljs-number">32</span>,<span class="hljs-number">16</span>,<span class="hljs-number">8</span>), ws=(<span class="hljs-number">64</span>,<span class="hljs-number">32</span>,<span class="hljs-number">16</span>,<span class="hljs-number">8</span>),<br>                      num_blocks=(<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">18</span>,<span class="hljs-number">2</span>), reparam_conv_k=(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>), sharesets_nums=(<span class="hljs-number">1</span>,<span class="hljs-number">4</span>,<span class="hljs-number">32</span>,<span class="hljs-number">256</span>),<br>                     deploy=deploy)<br><br>model_map = &#123;<br>    <span class="hljs-string">&#x27;RepMLPNet-T256&#x27;</span>: create_RepMLPNet_T256,<br>    <span class="hljs-string">&#x27;RepMLPNet-T224&#x27;</span>: create_RepMLPNet_T224,<br>    <span class="hljs-string">&#x27;RepMLPNet-B224&#x27;</span>: create_RepMLPNet_B224,<br>    <span class="hljs-string">&#x27;RepMLPNet-B256&#x27;</span>: create_RepMLPNet_B256,<br>    <span class="hljs-string">&#x27;RepMLPNet-D256&#x27;</span>: create_RepMLPNet_D256,<br>    <span class="hljs-string">&#x27;RepMLPNet-L256&#x27;</span>: create_RepMLPNet_L256,<br>&#125;<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_RepMLPNet_model</span>(<span class="hljs-params">name, deploy=<span class="hljs-literal">False</span></span>):<br>    <span class="hljs-keyword">if</span> name <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> model_map:<br>        <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&#x27;Not yet supported. You may add some code to create the model here.&#x27;</span>)<br>    model = model_map[name](deploy=deploy)<br>    <span class="hljs-keyword">return</span> model<br><br><br><span class="hljs-comment">#   Verify the equivalency</span><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    model = create_RepMLPNet_B224()<br>    model.<span class="hljs-built_in">eval</span>()<br><br>    x = torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>)<br>    origin_y = model(x)<br><br>    model.locality_injection()<br><br>    <span class="hljs-built_in">print</span>(model)<br>    new_y = model(x)<br>    <span class="hljs-built_in">print</span>((new_y - origin_y).<span class="hljs-built_in">abs</span>().<span class="hljs-built_in">sum</span>())<br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>cv</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Mlp-mixer</title>
    <link href="/2022/11/07/Mlp-mixer/"/>
    <url>/2022/11/07/Mlp-mixer/</url>
    
    <content type="html"><![CDATA[<ul><li>MLP-Mixer: An all-MLP Architecture for Vision</li></ul><p><img src="/img/cv/image-20221115163816919.png" /></p><h1 id="mixer-architecture">Mixer Architecture</h1><p>MLP-MixerPer-patch Fully-connectedMixerLayer</p><p>GAP+ FC+ Softmax</p><h2 id="per-patch-fully-connected">Per-patch Fully-connected</h2><p>FCConvMLP-MixerPer-patchFully-connected2DTable</p><p>MLP-Mixer<strong></strong>SPatch<strong>PatchMLP</strong>CPatchS*C2DTable<strong>PatchMLP</strong></p><p>Per-patchFully-connected<strong>WHC</strong><strong>SC</strong></p><p>240<em>240</em>3Patch16<em>16240</em>240/16<em>16=225PatchPatch16</em>16<em>3 =768768FlattenMLPMLP128Patch128225</em>128TableMLP-MixerPatchMLP</p><h2 id="mixer-layer">Mixer Layer</h2><p>Per-patchFully-connectedTableTable<strong>TableTable</strong></p><p><ahref="https://so.csdn.net/so/search?q=CNN&amp;spm=1001.2101.3001.7020">CNN</a>1*1Conv</p><p><ahref="https://so.csdn.net/so/search?q=Transformer&amp;spm=1001.2101.3001.7020">Transformer</a>Self-AttentionMLP</p><p>MLP-MixerMixerLayerMLP<strong>MixerLayer</strong>XceptionMobileNet</p><h2 id=""></h2><p>MLP-MixerMLPConvSelf-AttentionMLPCV</p><h1 id=""></h1><p><img src="/img/cv/image-20221107220710150.png" /></p><h1 id=""></h1><h2 id="mlp">Mlp</h2><p><img src="/img/cv/image-20221107221903063.png" /></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">from</span> torchsummary <span class="hljs-keyword">import</span> summary<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> Conv2d<br><span class="hljs-keyword">from</span> einops.layers.torch <span class="hljs-keyword">import</span> Rearrange, Reduce<br><span class="hljs-keyword">from</span> tensorboardX <span class="hljs-keyword">import</span> SummaryWriter<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">FeedForward</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,dim,hidden_dim,dropout=<span class="hljs-number">0.</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.net=nn.Sequential(<br>            <span class="hljs-comment"># FeedForward </span><br>            nn.Linear(dim,hidden_dim),<br>            <span class="hljs-comment">#</span><br>            nn.GELU(),<br>            <span class="hljs-comment">#</span><br>            nn.Dropout(dropout),<br>            <span class="hljs-comment">#</span><br>            nn.Linear(hidden_dim,dim),<br>            nn.Dropout(dropout)<br>        )<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,x</span>):<br>        x=self.net(x)<br>        <span class="hljs-keyword">return</span> x<br></code></pre></div></td></tr></table></figure><h2 id="mixer-layer-1">Mixer-Layer</h2><p><img src="/img/cv/image-20221107221936346.png" /></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MixerBlock</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,dim,num_patch,token_dim,channel_dim,dropout=<span class="hljs-number">0.</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.token_mixer=nn.Sequential(<br>            nn.LayerNorm(dim),<br>            Rearrange(<span class="hljs-string">&#x27;b n d -&gt; b d n&#x27;</span>),<br>            FeedForward(num_patch,token_dim,dropout),<br>            Rearrange(<span class="hljs-string">&#x27;b d n -&gt; b n d&#x27;</span>)<br><br>         )<br>        self.channel_mixer=nn.Sequential(<br>            nn.LayerNorm(dim),<br>            FeedForward(dim,channel_dim,dropout)<br>        )<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,x</span>):<br>        x = x+self.token_mixer(x)<br>        x = x+self.channel_mixer(x)<br>        <span class="hljs-keyword">return</span> x<br></code></pre></div></td></tr></table></figure><h2 id="mlp-mixer">Mlp-Mixer</h2><p><img src="/img/cv/image-20221107222216487.png" /></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MLPMixer</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,in_channels,dim,num_classes,patch_size,image_size,depth,token_dim,channel_dim,dropout=<span class="hljs-number">0.</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-keyword">assert</span> image_size%patch_size==<span class="hljs-number">0</span><br>        self.num_patches=(image_size//patch_size)**<span class="hljs-number">2</span>   <span class="hljs-comment"># 224/16**2=196</span><br>        <span class="hljs-comment"># embedding </span><br>        <span class="hljs-comment"># embedding3*224*224Channel*Patches=512*196Rearrange196*512</span><br>        self.to_embedding=nn.Sequential(Conv2d(in_channels=in_channels,out_channels=dim,kernel_size=patch_size,stride=patch_size),<br>            Rearrange(<span class="hljs-string">&#x27;b c h w -&gt; b (h w) c&#x27;</span>)<br>        )<br><br>        <span class="hljs-comment"># 196*512table</span><br>        <span class="hljs-comment"># token-mixing MLPsMLP1channel-mixing MLPsMLP2</span><br>        self.mixer_blocks=nn.ModuleList([])<br>        <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(depth):<br>            self.mixer_blocks.append(MixerBlock(dim,self.num_patches,token_dim,channel_dim,dropout))<br><br>        <span class="hljs-comment">#</span><br>        self.layer_normal=nn.LayerNorm(dim)<br><br>        <span class="hljs-comment">#</span><br>        self.mlp_head=nn.Sequential(<br>            nn.Linear(dim,num_classes)<br>        )<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,x</span>):<br>        x = self.to_embedding(x)<br>        <span class="hljs-keyword">for</span> mixer_block <span class="hljs-keyword">in</span> self.mixer_blocks:<br>            x = mixer_block(x)<br>        x = self.layer_normal(x)<br>        x = x.mean(dim=<span class="hljs-number">1</span>)<br><br>        x = self.mlp_head(x)<br>        <span class="hljs-keyword">return</span> x<br></code></pre></div></td></tr></table></figure><h2 id=""></h2><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    device = torch.device(<span class="hljs-string">&quot;cuda:0&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br>    model = MLPMixer(in_channels=<span class="hljs-number">3</span>, dim=<span class="hljs-number">512</span>, num_classes=<span class="hljs-number">1000</span>, patch_size=<span class="hljs-number">16</span>, image_size=<span class="hljs-number">224</span>, depth=<span class="hljs-number">1</span>, token_dim=<span class="hljs-number">256</span>,<br>                     channel_dim=<span class="hljs-number">2048</span>).to(device)<br>    summary(model,(<span class="hljs-number">3</span>,<span class="hljs-number">224</span>,<span class="hljs-number">224</span>))<br><br>    <span class="hljs-comment"># torch.Tensor([1, 2, 3, 4, 5, 6])</span><br>    inputs = torch.Tensor(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">224</span>, <span class="hljs-number">224</span>)<br>    inputs = inputs.to(device)<br>    <span class="hljs-built_in">print</span>(inputs.shape)<br><br>    <span class="hljs-comment"># modelgraph</span><br>    <span class="hljs-keyword">with</span> SummaryWriter(log_dir=<span class="hljs-string">&#x27;logs&#x27;</span>, comment=<span class="hljs-string">&#x27;model&#x27;</span>) <span class="hljs-keyword">as</span> w:<br>        w.add_graph(model, (inputs,))<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;success&quot;</span>)<br></code></pre></div></td></tr></table></figure><h2 id=""></h2><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">----------------------------------------------------------------<br>        Layer (type)               Output Shape         Param #<br>================================================================<br>            Conv2d-1          [-1, 512, 14, 14]         393,728<br>         Rearrange-2             [-1, 196, 512]               0<br>         LayerNorm-3             [-1, 196, 512]           1,024<br>         Rearrange-4             [-1, 512, 196]               0<br>            Linear-5             [-1, 512, 256]          50,432<br>              GELU-6             [-1, 512, 256]               0<br>           Dropout-7             [-1, 512, 256]               0<br>            Linear-8             [-1, 512, 196]          50,372<br>           Dropout-9             [-1, 512, 196]               0<br>      FeedForward-10             [-1, 512, 196]               0<br>        Rearrange-11             [-1, 196, 512]               0<br>        LayerNorm-12             [-1, 196, 512]           1,024<br>           Linear-13            [-1, 196, 2048]       1,050,624<br>             GELU-14            [-1, 196, 2048]               0<br>          Dropout-15            [-1, 196, 2048]               0<br>           Linear-16             [-1, 196, 512]       1,049,088<br>          Dropout-17             [-1, 196, 512]               0<br>      FeedForward-18             [-1, 196, 512]               0<br>       MixerBlock-19             [-1, 196, 512]               0<br>        LayerNorm-20             [-1, 196, 512]           1,024<br>           Linear-21                 [-1, 1000]         513,000<br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>cv</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>CoAtNet</title>
    <link href="/2022/11/06/CoAtNet/"/>
    <url>/2022/11/06/CoAtNet/</url>
    
    <content type="html"><![CDATA[<ul><li>CoAtNet: Marrying Convolution and Attention for All DataSizes</li></ul><p><img src="/img/cv/image-20221114204217704.png" /></p><h1 id=""></h1><h2id="convolutionself-attention">convolutionself-attention</h2><p> MBConv   Transformer  MBConv  FFN(invertedbottleneck) 4  4 </p><p> <spanclass="math display">\[y_{i}=\sum_{j \in \mathcal{L}(i)} w_{i-j} \odot x_{j} \  (depthwise \convolution), \ \ \ (1)\]</span> <span class="math inline">\(x_{i}, y_{i} \in\mathbb{R}^{D}\)</span> <span class="math inline">\(i\)</span><span class="math inline">\(\mathcal{L}(i)\)</span><span class="math inline">\(i\)</span> <span class="math inline">\(i\)</span>  3x3 </p><p>self-attention <spanclass="math inline">\((x_i,x_j)\)</span>(re-normalized pairwisesimilarity) <span class="math display">\[y_{i}=\sum_{j \in \mathcal{G}} \underbrace{\frac{\exp \left(x_{i}^{\top}x_{j}\right)}{\sum_{k \in \mathcal{G}} \exp \left(x_{i}^{\top}x_{k}\right)}}_{A_{i, j}} x_{j}\ \ \ \ (self-attention),\ \ \ (2)\]</span>  <span class="math inline">\(\mathcal{G}\)</span></p><ul><li><p>depthwise  <spanclass="math inline">\(w_{i-j}\)</span> <spanclass="math inline">\(A_{i,j}\)</span></p></li><li><p>(i; j) <spanclass="math inline">\(w_{i-j}\)</span> <span class="math inline">\(i -j\)</span>  <spanclass="math inline">\(i\)</span>  <spanclass="math inline">\(j\)</span>Transformer (ViT)ConvNets Transformers </p></li><li><p>w.r.t.</p></li></ul><p><img src="/img/cv/image-20221106160427620.png" /></p><p> 1  3 Softmax  <span class="math display">\[y_{i}^{\text {post }}=\sum_{j \in \mathcal{G}}\left(\frac{\exp\left(x_{i}^{\top} x_{j}\right)}{\sum_{k \in \mathcal{G}} \exp\left(x_{i}^{\top} x_{k}\right)}+w_{i-j}\right) x_{j} \text  { or }y_{i}^{\text {pre }}=\sum_{j \in \mathcal{G}} \frac{\exp\left(x_{i}^{\top} x_{j}+w_{i-j}\right)}{\sum_{k \in \mathcal{G}} \exp\left(x_{i}^{\top} x_{k}+w_{i-k}\right)} x_{j} .\ \ \ (3)\]</span>  <spanclass="math inline">\(y^{pre}\)</span> <spanclass="math inline">\(A_{i,j}\)</span>  <spanclass="math inline">\(w_{i-j}\)</span>  <spanclass="math inline">\(x_{i}^{\top} x_{j}\)</span><span class="math inline">\(w_{i-j}\)</span> ( <spanclass="math inline">\(w \in \mathbb{R}^{O(|\mathcal{G}|)}\)</span>)Eqn(1)<span class="math inline">\(w\)</span><spanclass="math inline">\((i,j)\)</span> <spanclass="math inline">\(w_{i-j}\)</span>(A.1)Eqn(3)TransformerCoAt Net</p><h2 id="vertical-layout-design">Vertical Layout Design</h2><p></p><p>Eqn(3)</p><ul><li><p><strong>A</strong></p></li><li><p>B  <spanclass="math inline">\(\mathcal{G}\)</span>  <spanclass="math inline">\(\mathcal{L}\)</span> </p></li><li><p>CSoftmax</p></li></ul><p>( C )( B)(TPU)<strong>(A )</strong></p><p>( A )( 1 )ViT(,16x16)( 2)5</p><ul><li><p>ViT Stem <spanclass="math inline">\(L\)</span> Transformer <spanclass="math inline">\(ViT_{REL}\)</span></p></li><li><p>5(S0S1S2S3S4)S0S4<strong>2</strong>(,A.1)</p><p>S02StemS1squeeze-excitation(SE)MBConvS2S4MBConvTransformerTransformer<strong></strong>4TransformerC- C - C - CC - C - C - TC - C - T - TC - T - T -TCTConvolutionTransformer</p></li></ul><p>5</p><p>ImageNet - 1K ( 1.3M )JFT (&gt; 300M)3003epoch1</p><figure><img src="/img/cv/image-20221106164733104.png" alt="1" /><figcaption aria-hidden="true">1</figcaption></figure><ul><li>ImageNet -1K(,)</li></ul><p><span class="math display">\[\mathrm{C}-\mathrm{C}-\mathrm{C}-\mathrm{C} \approx\mathrm{C}-\mathrm{C}-\mathrm{C}-\mathrm{T} \geq\mathrm{C}-\mathrm{C}-\mathrm{T}-\mathrm{T}&gt;\mathrm{C}-\mathrm{T}-\mathrm{T}-\mathrm{T}\gg \mathrm{VIT}_{\mathrm{REL}}\]</span></p><p><spanclass="math inline">\(ViT_{REL}\)</span>Stem</p><ul><li>JFT</li></ul><p><span class="math display">\[\mathrm{C}-\mathrm{C}-\mathrm{T}-\mathrm{T} \approx\mathrm{C}-\mathrm{T}-\mathrm{T}-\mathrm{T}&gt;\mathrm{VIT}_{\mathrm{REL}}&gt;\mathrm{C}-\mathrm{C}-\mathrm{C}-\mathrm{T}&gt;\mathrm{C}-\mathrm{C}-\mathrm{C}-\mathrm{C}\]</span></p><p><strong>Transformer</strong><spanclass="math inline">\(ViT_{REL}\)</span>MBConvTransformerC- C - T - TC - T - T - T<spanclass="math inline">\(ViT_{REL}\)</span> <strong>ViTStem</strong>C-C-T-TC-T-T-T</p><p>C - C - T - TC - T - T -T3 - -ImageNet -1KJFT30epoch2C-C-T-TC-T-T-T</p><p><img src="/img/cv/image-20221106164712746.png" /></p><p><strong>C- C - T - T</strong>A.1</p><p><img src="/img/cv/image-20221106165751331.png" /></p><h1 id=""></h1><h2 id="a.1-">A.1 </h2><p>CoAtNet</p><p><img src="/img/cv/image-20221106164949720.png" /></p><p><img src="/img/cv/image-20221106165319538.png" /></p><p><img src="/img/cv/image-20221106165448391.png" /></p><p><img src="/img/cv/image-20221106165504183.png" /></p><p><img src="/img/cv/image-20221106165537550.png" /></p><p><img src="/img/cv/image-20221106165549351.png" /></p><h2 id="a.2-">A.2 </h2><p><img src="/img/cv/image-20221106165643160.png" /></p><h1 id=""></h1><h2 id="s0-stage">s0-stage</h2><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">conv_3x3_bn</span>(<span class="hljs-params">in_c, out_c, image_size, downsample=<span class="hljs-literal">False</span></span>):<br><span class="hljs-comment"># out_c = 64, imagesize = (112, 112)</span><br>    stride = <span class="hljs-number">2</span> <span class="hljs-keyword">if</span> downsample <span class="hljs-keyword">else</span> <span class="hljs-number">1</span><br>    layer = nn.Sequential(<br>        nn.Conv2d(in_c, out_c, <span class="hljs-number">3</span>, stride, <span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>),<br>        nn.BatchNorm2d(out_c),<br>        nn.GELU()<br>    )<br>    <span class="hljs-keyword">return</span> layer<br></code></pre></div></td></tr></table></figure><h2 id="s1-mbconv">s1-MBConv</h2><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MBConv</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,</span><br><span class="hljs-params">                 in_c,</span><br><span class="hljs-params">                 out_c,</span><br><span class="hljs-params">                 image_size,</span><br><span class="hljs-params">                 downsample=<span class="hljs-literal">False</span>,</span><br><span class="hljs-params">                 expansion=<span class="hljs-number">4</span></span>):<br>        <span class="hljs-built_in">super</span>(MBConv, self).__init__()<br>        self.downsample = downsample<br>        stride = <span class="hljs-number">2</span> <span class="hljs-keyword">if</span> downsample <span class="hljs-keyword">else</span> <span class="hljs-number">1</span><br>        hidden_dim = <span class="hljs-built_in">int</span>(in_c * expansion)<br><br>        <span class="hljs-keyword">if</span> self.downsample:<br>            <span class="hljs-comment"># </span><br>            <span class="hljs-comment"># self.pool = nn.MaxPool2d(kernel_size=2,stride=2)</span><br>            <span class="hljs-comment"># self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)</span><br>            <span class="hljs-comment"># self.proj = nn.Conv2d(in_c, out_c, 1, 1, 0, bias=False)</span><br><br>            self.downsample_layer = nn.Sequential(<br>                nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>),<br>                nn.Conv2d(in_c, out_c, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, bias=<span class="hljs-literal">False</span>)<br>            )<br><br>        layers = OrderedDict()<br>        <span class="hljs-comment"># expand</span><br>        expand_conv = nn.Sequential(<br>            nn.Conv2d(in_c, hidden_dim, <span class="hljs-number">1</span>, stride, <span class="hljs-number">0</span>, bias=<span class="hljs-literal">False</span>),<br>            nn.BatchNorm2d(hidden_dim),<br>            nn.GELU(),<br>        )<br>        layers.update(&#123;<span class="hljs-string">&quot;expand_conv&quot;</span>: expand_conv&#125;)<br><br>        <span class="hljs-comment"># Depwise Conv</span><br>        dw_conv = nn.Sequential(<br>            nn.Conv2d(hidden_dim, hidden_dim, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, groups=hidden_dim, bias=<span class="hljs-literal">False</span>),<br>            nn.BatchNorm2d(hidden_dim),<br>            nn.GELU(),<br>        )<br>        layers.update(&#123;<span class="hljs-string">&quot;dw_conv&quot;</span>: dw_conv&#125;)<br><br>        <span class="hljs-comment"># se</span><br>        layers.update(&#123;<span class="hljs-string">&quot;se&quot;</span>: SE(in_c, hidden_dim)&#125;)<br><br>        <span class="hljs-comment"># project</span><br>        pro_conv = nn.Sequential(<br>            nn.Conv2d(hidden_dim, out_c, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, bias=<span class="hljs-literal">False</span>),<br>            nn.BatchNorm2d(out_c)<br>        )<br>        layers.update(&#123;<span class="hljs-string">&quot;pro_conv&quot;</span>: pro_conv&#125;)<br>        self.block = nn.Sequential(layers)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">if</span> self.downsample:<br>            <span class="hljs-keyword">return</span> self.downsample_layer(x) + self.block(x)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">return</span> x + self.block(x)<br></code></pre></div></td></tr></table></figure><p>Se</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">SE</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, in_c, out_c, expansion=<span class="hljs-number">0.25</span></span>):<br>        <span class="hljs-built_in">super</span>(SE, self).__init__()<br>        self.avg_pool = nn.AdaptiveAvgPool2d(<span class="hljs-number">1</span>)<br>        self.fc = nn.Sequential(<br>            nn.Linear(out_c, <span class="hljs-built_in">int</span>(in_c * expansion), bias=<span class="hljs-literal">False</span>),<br>            nn.GELU(),<br>            nn.Linear(<span class="hljs-built_in">int</span>(in_c * expansion), out_c, bias=<span class="hljs-literal">False</span>),<br>            nn.Sigmoid()<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        b, c, _, _ = x.size()<br>        y = self.avg_pool(x).view(b, c)<br>        y = self.fc(y).view(b, c, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> x * y<br></code></pre></div></td></tr></table></figure><h2 id="s3-tfm_rel">s3-TFM_rel</h2><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Transformer</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,</span><br><span class="hljs-params">                 in_c,</span><br><span class="hljs-params">                 out_c,</span><br><span class="hljs-params">                 image_size,</span><br><span class="hljs-params">                 heads=<span class="hljs-number">8</span>,</span><br><span class="hljs-params">                 dim_head=<span class="hljs-number">32</span>,</span><br><span class="hljs-params">                 downsample=<span class="hljs-literal">False</span>,</span><br><span class="hljs-params">                 dropout=<span class="hljs-number">0.</span>,</span><br><span class="hljs-params">                 expansion=<span class="hljs-number">4</span>,</span><br><span class="hljs-params">                 norm_layer=nn.LayerNorm</span>):<br>        <span class="hljs-built_in">super</span>(Transformer, self).__init__()<br>        self.downsample = downsample<br>        hidden_dim = <span class="hljs-built_in">int</span>(in_c * expansion)<br>        self.ih, self.iw = image_size<br><br>        <span class="hljs-keyword">if</span> self.downsample:<br>            <span class="hljs-comment"># </span><br>            self.pool1 = nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>)<br>            self.pool2 = nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>)<br>            self.proj = nn.Conv2d(in_c, out_c, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, bias=<span class="hljs-literal">False</span>)<br><br>        self.attn = Attention(in_c, out_c, image_size, heads, dim_head, dropout)<br>        self.ffn = FFN(out_c, hidden_dim)<br>        self.norm1 = norm_layer(in_c)<br>        self.norm2 = norm_layer(out_c)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x1 = self.pool1(x) <span class="hljs-keyword">if</span> self.downsample <span class="hljs-keyword">else</span> x<br>        x1 = rearrange(x1, <span class="hljs-string">&#x27;b c h w -&gt; b (h w) c&#x27;</span>)<br>        x1 = self.attn(self.norm1(x1))<br>        x1 = rearrange(x1, <span class="hljs-string">&#x27;b (h w) c -&gt; b c h w&#x27;</span>, h=self.ih, w=self.iw)<br>        x2 = self.proj((self.pool2(x))) <span class="hljs-keyword">if</span> self.downsample <span class="hljs-keyword">else</span> x<br><br>        x3 = x1 + x2<br>        x4 = rearrange(x3, <span class="hljs-string">&#x27;b c h w -&gt; b (h w) c&#x27;</span>)<br>        x4 = self.ffn(self.norm2(x4))<br>        x4 = rearrange(x4, <span class="hljs-string">&#x27;b (h w) c -&gt; b c h w&#x27;</span>, h=self.ih, w=self.iw)<br>        out = x3 + x4<br>        <span class="hljs-keyword">return</span> out<br></code></pre></div></td></tr></table></figure><h2 id="attention">attention()</h2><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Attention</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,</span><br><span class="hljs-params">                 in_c,</span><br><span class="hljs-params">                 out_c,</span><br><span class="hljs-params">                 image_size,</span><br><span class="hljs-params">                 heads=<span class="hljs-number">8</span>,</span><br><span class="hljs-params">                 dim_head=<span class="hljs-number">32</span>,</span><br><span class="hljs-params">                 dropout=<span class="hljs-number">0.</span></span>):<br>        <span class="hljs-built_in">super</span>(Attention, self).__init__()<br>        inner_dim = dim_head * heads<br>        project_out = <span class="hljs-keyword">not</span> (heads == <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> dim_head == in_c)<br><br>        self.ih, self.iw = image_size <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(image_size) == <span class="hljs-number">2</span> <span class="hljs-keyword">else</span> (image_size, image_size)<br><br>        self.heads = heads<br>        self.scale = dim_head ** -<span class="hljs-number">0.5</span><br><br>        <span class="hljs-comment"># parameter table of relative position bias</span><br>        self.relative_bias_table = nn.Parameter(<br>            torch.zeros((<span class="hljs-number">2</span> * self.ih - <span class="hljs-number">1</span>) * (<span class="hljs-number">2</span> * self.iw - <span class="hljs-number">1</span>), heads)<br>        )<br><br>        coords = torch.meshgrid((torch.arange(self.ih), torch.arange(self.iw)))<br>        coords = torch.flatten(torch.stack(coords), <span class="hljs-number">1</span>)<br>        relative_coords = coords[:, :, <span class="hljs-literal">None</span>] - coords[:, <span class="hljs-literal">None</span>, :]<br><br>        relative_coords[<span class="hljs-number">0</span>] += self.ih - <span class="hljs-number">1</span><br>        relative_coords[<span class="hljs-number">1</span>] += self.iw - <span class="hljs-number">1</span><br>        relative_coords[<span class="hljs-number">0</span>] *= <span class="hljs-number">2</span> * self.iw - <span class="hljs-number">1</span><br>        relative_coords = rearrange(relative_coords, <span class="hljs-string">&#x27;c h w -&gt; h w c&#x27;</span>)<br>        relative_index = relative_coords.<span class="hljs-built_in">sum</span>(-<span class="hljs-number">1</span>).flatten().unsqueeze(<span class="hljs-number">1</span>)<br><br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        PyTorchself.register_buffer(&#x27;name&#x27;, Tensor)</span><br><span class="hljs-string">        </span><br><span class="hljs-string">         optimizer.step() </span><br><span class="hljs-string">        </span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        self.register_buffer(<span class="hljs-string">&quot;relative_index&quot;</span>, relative_index)<br><br>        self.attend = nn.Softmax(dim=-<span class="hljs-number">1</span>)<br>        self.qkv = nn.Linear(in_c, inner_dim * <span class="hljs-number">3</span>, bias=<span class="hljs-literal">False</span>)<br>        self.proj = nn.Sequential(<br>            nn.Linear(inner_dim, out_c),<br>            nn.Dropout(dropout)<br>        ) <span class="hljs-keyword">if</span> project_out <span class="hljs-keyword">else</span> nn.Identity()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># [q,k,v]</span><br>        qkv = self.qkv(x).chunk(<span class="hljs-number">3</span>, dim=-<span class="hljs-number">1</span>)<br>        <span class="hljs-comment"># q,k,v:[batch_size, num_heads, num_patches, head_dim]</span><br>        q, k, v = <span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> t: rearrange(<br>            t, <span class="hljs-string">&#x27;b n (h d) -&gt; b h n d&#x27;</span>, h=self.heads), qkv)<br><br>        <span class="hljs-comment"># [batch_size, num_heads, ih*iw, ih*iw]</span><br>        <span class="hljs-comment"># O()</span><br>        dots = torch.matmul(q, k.transpose(-<span class="hljs-number">1</span>, -<span class="hljs-number">2</span>)) * self.scale<br><br>        <span class="hljs-comment"># Use &quot;gather&quot; for more efficiency on GPUs</span><br>        relative_bias = self.relative_bias_table.gather(<br>            <span class="hljs-number">0</span>, self.relative_index.repeat(<span class="hljs-number">1</span>, self.heads)<br>        )<br>        relative_bias = rearrange(<br>            relative_bias, <span class="hljs-string">&#x27;(h w) c -&gt; 1 c h w&#x27;</span>, h=self.ih * self.iw, w=self.ih * self.iw<br>        )<br>        dots = dots + relative_bias<br><br>        attn = self.attend(dots)<br>        out = torch.matmul(attn, v)<br>        out = rearrange(out, <span class="hljs-string">&#x27;b h n d -&gt; b n (h d)&#x27;</span>)<br>        out = self.proj(out)<br>        <span class="hljs-keyword">return</span> out<br></code></pre></div></td></tr></table></figure><h2 id="ffnmlp">FFNMLP</h2><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">FFN</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, dim, hidden_dim, dropout=<span class="hljs-number">0.</span></span>):<br>        <span class="hljs-built_in">super</span>(FFN, self).__init__()<br>        self.ffn = nn.Sequential(<br>            nn.Linear(dim, hidden_dim),<br>            nn.GELU(),<br>            nn.Dropout(dropout),<br>            nn.Linear(hidden_dim, dim),<br>            nn.Dropout(dropout)<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> self.ffn(x)<br></code></pre></div></td></tr></table></figure><h2 id="coatnet">CoAtNet</h2><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">CoAtNet</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,</span><br><span class="hljs-params">                 image_size=(<span class="hljs-params"><span class="hljs-number">224</span>, <span class="hljs-number">224</span></span>),</span><br><span class="hljs-params">                 in_channels: <span class="hljs-built_in">int</span> = <span class="hljs-number">3</span>,</span><br><span class="hljs-params">                 num_blocks: <span class="hljs-built_in">list</span> = [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5</span>, <span class="hljs-number">2</span>],  <span class="hljs-comment"># L</span></span><br><span class="hljs-params">                 channels: <span class="hljs-built_in">list</span> = [<span class="hljs-number">64</span>, <span class="hljs-number">96</span>, <span class="hljs-number">192</span>, <span class="hljs-number">384</span>, <span class="hljs-number">768</span>],  <span class="hljs-comment"># D</span></span><br><span class="hljs-params">                 num_classes: <span class="hljs-built_in">int</span> = <span class="hljs-number">1000</span>,</span><br><span class="hljs-params">                 block_types=[<span class="hljs-string">&#x27;C&#x27;</span>, <span class="hljs-string">&#x27;C&#x27;</span>, <span class="hljs-string">&#x27;T&#x27;</span>, <span class="hljs-string">&#x27;T&#x27;</span>]</span>):<br>        <span class="hljs-built_in">super</span>(CoAtNet, self).__init__()<br><br>        <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(image_size) == <span class="hljs-number">2</span>, <span class="hljs-string">&quot;image size must be: &#123;H,W&#125;&quot;</span><br>        <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(channels) == <span class="hljs-number">5</span><br>        <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(block_types) == <span class="hljs-number">4</span><br><br>        ih, iw = image_size<br>        block = &#123;<span class="hljs-string">&#x27;C&#x27;</span>: MBConv, <span class="hljs-string">&#x27;T&#x27;</span>: Transformer&#125;<br><br>        self.s0 = self._make_layer(<br>            conv_3x3_bn, in_channels, channels[<span class="hljs-number">0</span>], num_blocks[<span class="hljs-number">0</span>], (ih // <span class="hljs-number">2</span>, iw // <span class="hljs-number">2</span>)<br>        )<br>        self.s1 = self._make_layer(<br>            block[block_types[<span class="hljs-number">0</span>]], channels[<span class="hljs-number">0</span>], channels[<span class="hljs-number">1</span>], num_blocks[<span class="hljs-number">1</span>], (ih // <span class="hljs-number">4</span>, iw // <span class="hljs-number">4</span>)<br>        )<br>        self.s2 = self._make_layer(<br>            block[block_types[<span class="hljs-number">1</span>]], channels[<span class="hljs-number">1</span>], channels[<span class="hljs-number">2</span>], num_blocks[<span class="hljs-number">2</span>], (ih // <span class="hljs-number">8</span>, iw // <span class="hljs-number">8</span>)<br>        )<br>        self.s3 = self._make_layer(<br>            block[block_types[<span class="hljs-number">2</span>]], channels[<span class="hljs-number">2</span>], channels[<span class="hljs-number">3</span>], num_blocks[<span class="hljs-number">3</span>], (ih // <span class="hljs-number">16</span>, iw // <span class="hljs-number">16</span>)<br>        )<br>        self.s4 = self._make_layer(<br>            block[block_types[<span class="hljs-number">3</span>]], channels[<span class="hljs-number">3</span>], channels[<span class="hljs-number">4</span>], num_blocks[<span class="hljs-number">4</span>], (ih // <span class="hljs-number">32</span>, iw // <span class="hljs-number">32</span>)<br>        )<br><br>        <span class="hljs-comment"># 32 2^5=32</span><br>        self.pool = nn.AvgPool2d(ih // <span class="hljs-number">32</span>, <span class="hljs-number">1</span>)<br>        self.fc = nn.Linear(channels[-<span class="hljs-number">1</span>], num_classes, bias=<span class="hljs-literal">False</span>)<br><br>        <span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> self.modules():<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m, nn.Conv2d):<br>                nn.init.kaiming_normal_(m.weight, mode=<span class="hljs-string">&#x27;fan_out&#x27;</span>, nonlinearity=<span class="hljs-string">&#x27;relu&#x27;</span>)<br>            <span class="hljs-keyword">elif</span> <span class="hljs-built_in">isinstance</span>(m, (nn.BatchNorm2d, nn.GroupNorm, nn.LayerNorm)):<br>                nn.init.constant_(m.weight, <span class="hljs-number">1</span>)<br>                nn.init.constant_(m.bias, <span class="hljs-number">0</span>)<br><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.s0(x)<br>        x = self.s1(x)<br>        x = self.s2(x)<br>        x = self.s3(x)<br>        x = self.s4(x)<br><br>        x = self.pool(x)<br>        x = torch.flatten(x, <span class="hljs-number">1</span>)<br>        x = self.fc(x)<br>        <span class="hljs-keyword">return</span> x<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_make_layer</span>(<span class="hljs-params">self, block, in_c, out_c, depth, image_size</span>):<br>        layers = nn.ModuleList([])<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(depth):<br>            <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span>:<br>                layers.append(block(in_c, out_c, image_size, downsample=<span class="hljs-literal">True</span>))<br>            <span class="hljs-keyword">else</span>:<br>                layers.append(block(out_c, out_c, image_size, downsample=<span class="hljs-literal">False</span>))<br>        <span class="hljs-keyword">return</span> nn.Sequential(*layers)<br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>cv</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Masked_Autoencoder(MAE)</title>
    <link href="/2022/11/05/Masked-Autoencoder-MAE/"/>
    <url>/2022/11/05/Masked-Autoencoder-MAE/</url>
    
    <content type="html"><![CDATA[<ul><li>Masked Autoencoders Are Scalable Vision Learners</li></ul><h1 id=""></h1><p><img src="/img/cv/image-20221105154549102.png" /></p><h1 id="approach">Approach</h1><h2 id="masking">Masking</h2><p>MAEViT75%</p><h2 id="mae-encoder">MAE encoder</h2><p>encodeViTmaskpatchencoder</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MAE_Encoder</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,</span><br><span class="hljs-params">                 image_size=<span class="hljs-number">32</span>,</span><br><span class="hljs-params">                 patch_size=<span class="hljs-number">2</span>,</span><br><span class="hljs-params">                 emb_dim=<span class="hljs-number">192</span>,</span><br><span class="hljs-params">                 num_layer=<span class="hljs-number">12</span>,</span><br><span class="hljs-params">                 num_head=<span class="hljs-number">3</span>,</span><br><span class="hljs-params">                 mask_ratio=<span class="hljs-number">0.75</span>,</span><br><span class="hljs-params">                 </span>) -&gt; <span class="hljs-literal">None</span>:<br>        <span class="hljs-built_in">super</span>().__init__()<br><br>        self.cls_token = torch.nn.Parameter(torch.zeros(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, emb_dim)) <br>        self.pos_embedding = torch.nn.Parameter(torch.zeros((image_size // patch_size) ** <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, emb_dim))<br>        <br>        <span class="hljs-comment"># patchshuffle  mask</span><br>        self.shuffle = PatchShuffle(mask_ratio)<br>        <br>        <span class="hljs-comment">#  (3, dim, patch, patch)</span><br>        self.patchify = torch.nn.Conv2d(<span class="hljs-number">3</span>, emb_dim, patch_size, patch_size)<br><br>        self.transformer = torch.nn.Sequential(*[Block(emb_dim, num_head) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_layer)])<br>        <br>        <span class="hljs-comment"># ViTlaynorm</span><br>        self.layer_norm = torch.nn.LayerNorm(emb_dim)<br><br>        self.init_weight()<br>    <span class="hljs-comment"># </span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">init_weight</span>(<span class="hljs-params">self</span>):<br>        trunc_normal_(self.cls_token, std=<span class="hljs-number">.02</span>)<br>        trunc_normal_(self.pos_embedding, std=<span class="hljs-number">.02</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, img</span>):<br>        patches = self.patchify(img)<br>        patches = rearrange(patches, <span class="hljs-string">&#x27;b c h w -&gt; (h w) b c&#x27;</span>)<br>        patches = patches + self.pos_embedding<br><br>        patches, forward_indexes, backward_indexes = self.shuffle(patches)<br><br>        patches = torch.cat([self.cls_token.expand(-<span class="hljs-number">1</span>, patches.shape[<span class="hljs-number">1</span>], -<span class="hljs-number">1</span>), patches], dim=<span class="hljs-number">0</span>)<br>        patches = rearrange(patches, <span class="hljs-string">&#x27;t b c -&gt; b t c&#x27;</span>)<br>        features = self.layer_norm(self.transformer(patches))<br>        features = rearrange(features, <span class="hljs-string">&#x27;b t c -&gt; t b c&#x27;</span>)<br><br>        <span class="hljs-keyword">return</span> features, backward_indexes<br></code></pre></div></td></tr></table></figure><h2 id="mae-decoder">MAE decoder</h2><p>decoder  tokens </p><ul><li> patches</li><li>mask tokens</li></ul><p> mask token patchembedding  tokens  ; masktokens </p><p>Transformer</p><p>decoder decoder encoder  decoder encoder decoder  token  encoder 10%</p><p> token  decoder encoder tokens</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MAE_Decoder</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,</span><br><span class="hljs-params">                 image_size=<span class="hljs-number">32</span>,</span><br><span class="hljs-params">                 patch_size=<span class="hljs-number">2</span>,</span><br><span class="hljs-params">                 emb_dim=<span class="hljs-number">192</span>,</span><br><span class="hljs-params">                 num_layer=<span class="hljs-number">4</span>,</span><br><span class="hljs-params">                 num_head=<span class="hljs-number">3</span>,</span><br><span class="hljs-params">                 </span>) -&gt; <span class="hljs-literal">None</span>:<br>        <span class="hljs-built_in">super</span>().__init__()<br><br>        self.mask_token = torch.nn.Parameter(torch.zeros(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, emb_dim))<br>        self.pos_embedding = torch.nn.Parameter(torch.zeros((image_size // patch_size) ** <span class="hljs-number">2</span> + <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, emb_dim))<br><br>        self.transformer = torch.nn.Sequential(*[Block(emb_dim, num_head) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_layer)])<br><br>        self.head = torch.nn.Linear(emb_dim, <span class="hljs-number">3</span> * patch_size ** <span class="hljs-number">2</span>)<br>        self.patch2img = Rearrange(<span class="hljs-string">&#x27;(h w) b (c p1 p2) -&gt; b c (h p1) (w p2)&#x27;</span>, p1=patch_size, p2=patch_size, h=image_size//patch_size)<br><br>        self.init_weight()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">init_weight</span>(<span class="hljs-params">self</span>):<br>        trunc_normal_(self.mask_token, std=<span class="hljs-number">.02</span>)<br>        trunc_normal_(self.pos_embedding, std=<span class="hljs-number">.02</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, features, backward_indexes</span>):<br>        T = features.shape[<span class="hljs-number">0</span>]<br>        backward_indexes = torch.cat([torch.zeros(<span class="hljs-number">1</span>, backward_indexes.shape[<span class="hljs-number">1</span>]).to(backward_indexes), backward_indexes + <span class="hljs-number">1</span>], dim=<span class="hljs-number">0</span>)<br>        features = torch.cat([features, self.mask_token.expand(backward_indexes.shape[<span class="hljs-number">0</span>] - features.shape[<span class="hljs-number">0</span>], features.shape[<span class="hljs-number">1</span>], -<span class="hljs-number">1</span>)], dim=<span class="hljs-number">0</span>)<br>        features = take_indexes(features, backward_indexes)<br>        features = features + self.pos_embedding <span class="hljs-comment"># </span><br><br>        features = rearrange(features, <span class="hljs-string">&#x27;t b c -&gt; b t c&#x27;</span>)<br>        features = self.transformer(features)<br>        features = rearrange(features, <span class="hljs-string">&#x27;b t c -&gt; t b c&#x27;</span>) <br>        features = features[<span class="hljs-number">1</span>:] <span class="hljs-comment"># remove global feature </span><br><br>        patches = self.head(features) <span class="hljs-comment"># headpatchs</span><br>        mask = torch.zeros_like(patches) <br>        mask[T:] = <span class="hljs-number">1</span>  <span class="hljs-comment"># mask 1</span><br>        mask = take_indexes(mask, backward_indexes[<span class="hljs-number">1</span>:] - <span class="hljs-number">1</span>)<br>        img = self.patch2img(patches) <span class="hljs-comment">#   img</span><br>        mask = self.patch2img(mask)<br><br>        <span class="hljs-keyword">return</span> img, mask<br></code></pre></div></td></tr></table></figure><h2 id="reconstruction-target">Reconstruction target</h2><p> MAE  masked patch decoder  patchdecoder  linearprojection patch decoder reshape </p><p> loss function MSE masked patches  loss BEiT </p><p> masked patchpatchpatch</p><h2 id="simple-implementation">Simple implementation</h2><p>MAE</p><p>input patch token LinearProjection embedding</p><p> tokens list listencodertokens patches </p><p> encoding  encoded patch list  mask tokenslistlisttokenstragets</p><p>decoder  list  embedding</p><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MAE_ViT</span>(torch.nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,</span><br><span class="hljs-params">                 image_size=<span class="hljs-number">32</span>,</span><br><span class="hljs-params">                 patch_size=<span class="hljs-number">2</span>,</span><br><span class="hljs-params">                 emb_dim=<span class="hljs-number">192</span>,</span><br><span class="hljs-params">                 encoder_layer=<span class="hljs-number">12</span>,</span><br><span class="hljs-params">                 encoder_head=<span class="hljs-number">3</span>,</span><br><span class="hljs-params">                 decoder_layer=<span class="hljs-number">4</span>,</span><br><span class="hljs-params">                 decoder_head=<span class="hljs-number">3</span>,</span><br><span class="hljs-params">                 mask_ratio=<span class="hljs-number">0.75</span>,</span><br><span class="hljs-params">                 </span>) -&gt; <span class="hljs-literal">None</span>:<br>        <span class="hljs-built_in">super</span>().__init__()<br><br>        self.encoder = MAE_Encoder(image_size, patch_size, emb_dim, encoder_layer, encoder_head, mask_ratio)<br>        self.decoder = MAE_Decoder(image_size, patch_size, emb_dim, decoder_layer, decoder_head)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, img</span>):<br>        features, backward_indexes = self.encoder(img)<br>        predicted_img, mask = self.decoder(features,  backward_indexes)<br>        <span class="hljs-keyword">return</span> predicted_img, mask<br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>cv</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Vision_Transformer</title>
    <link href="/2022/11/05/Vision-Transformer/"/>
    <url>/2022/11/05/Vision-Transformer/</url>
    
    <content type="html"><![CDATA[<ul><li>AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGERECOGNITION AT SCALE</li></ul><h1 id=""></h1><p><strong>Transformer</strong></p><p></p><p><img src="/img/cv/image-20221105101612727.png" /></p><h2 id=""></h2><p>2D<span class="math inline">\(\mathbf{x} \in\mathbb{R}^{H \times W \timesC}\)</span>2D<spanclass="math inline">\(\mathbf{x}_{p} \in \mathbb{R}^{N \times\left(P^{2}\cdot C\right)}\)</span><span class="math inline">\((W,H)\)</span><spanclass="math inline">\(C\)</span><spanclass="math inline">\((P,P)\)</span><spanclass="math inline">\(N=H W /P^{2}\)</span>Transformer</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">x = rearrange(img, <span class="hljs-string">&#x27;b c (h p1) (w p2) -&gt; b (h w) (p1 p2 c)&#x27;</span>, p1=p, p2=p)<br></code></pre></div></td></tr></table></figure><p>einops</p><h2 id="patch-embedding">Patch Embedding</h2><p><strong></strong>DPatch Embedding</p><p>dim</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">self.patch_to_embedding = nn.Linear(patch_dim, dim)<br><br><span class="hljs-comment"># forward</span><br>x = rearrange(img, <span class="hljs-string">&#x27;b c (h p1) (w p2) -&gt; b (h w) (p1 p2 c)&#x27;</span>, p1=p, p2=p)<br>x = self.patch_to_embedding(x)<br></code></pre></div></td></tr></table></figure><h2 id="position-embedding">Position Embedding</h2><p><strong>Transformer Positional encoding</strong>pos_embedding<strong></strong></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">self.pos_embedding = nn.Parameter(torch.randn(<span class="hljs-number">1</span>, num_patches + <span class="hljs-number">1</span>, dim))<br></code></pre></div></td></tr></table></figure><p><img src="/img/cv/image-20221105102549504.png" /></p><h2 id="class-token">class token</h2><p>Transformerseq2seq</p><p>ViTEncoder<ahref="https://so.csdn.net/so/search?q=&amp;spm=1001.2101.3001.7020"></a><strong>9</strong><strong></strong></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># dim=128shape(1, 1, 128)</span><br>self.cls_token = nn.Parameter(torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, dim))<br><br><span class="hljs-comment"># forward</span><br><span class="hljs-comment"># batchsize=10shape(10, 1, 128)</span><br>cls_tokens = repeat(self.cls_token, <span class="hljs-string">&#x27;() n d -&gt; b n d&#x27;</span>, b=b)<br><span class="hljs-comment"># x1064 128concat</span><br><span class="hljs-comment"># 10 65 128</span><br>x = torch.cat((cls_tokens, x), dim=<span class="hljs-number">1</span>)<br></code></pre></div></td></tr></table></figure><p>pos_embedding1pos_embeddingx</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">x += self.pos_embedding[:, :(n + <span class="hljs-number">1</span>)]<br></code></pre></div></td></tr></table></figure><h2 id=""></h2><p>LayerNormGELU</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">self.mlp_head = nn.Sequential(<br>            nn.LayerNorm(dim),<br>            nn.Linear(dim, mlp_dim),<br>            nn.GELU(),<br>            nn.Dropout(dropout),<br>            nn.Linear(mlp_dim, num_classes)<br>        )<br></code></pre></div></td></tr></table></figure><p>token</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">self.to_cls_token = nn.Identity()<br><span class="hljs-comment"># forward</span><br>x = self.transformer(x, mask)<br>x = self.to_cls_token(x[:, <span class="hljs-number">0</span>])<br><span class="hljs-keyword">return</span> self.mlp_head(x)<br></code></pre></div></td></tr></table></figure><h2 id=""></h2><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ViT</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, channels=<span class="hljs-number">3</span>, dropout=<span class="hljs-number">0.</span>,</span><br><span class="hljs-params">                 emb_dropout=<span class="hljs-number">0.</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-keyword">assert</span> image_size % patch_size == <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;Image dimensions must be divisible by the patch size.&#x27;</span><br>        num_patches = (image_size // patch_size) ** <span class="hljs-number">2</span><br>        patch_dim = channels * patch_size ** <span class="hljs-number">2</span><br>        <span class="hljs-keyword">assert</span> num_patches &gt; MIN_NUM_PATCHES, <span class="hljs-string">f&#x27;your number of patches (<span class="hljs-subst">&#123;num_patches&#125;</span>) is way too small for attention to be effective (at least 16). Try decreasing your patch size&#x27;</span><br><br>        self.patch_size = patch_size<br><br>        self.pos_embedding = nn.Parameter(torch.randn(<span class="hljs-number">1</span>, num_patches + <span class="hljs-number">1</span>, dim))<br>        self.patch_to_embedding = nn.Linear(patch_dim, dim)<br>        self.cls_token = nn.Parameter(torch.randn(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, dim))<br>        self.dropout = nn.Dropout(emb_dropout)<br><br>        self.transformer = Transformer(dim, depth, heads, mlp_dim, dropout)<br><br>        self.to_cls_token = nn.Identity()<br><br>        self.mlp_head = nn.Sequential(<br>            nn.LayerNorm(dim),<br>            nn.Linear(dim, mlp_dim),<br>            nn.GELU(),<br>            nn.Dropout(dropout),<br>            nn.Linear(mlp_dim, num_classes)<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, img, mask=<span class="hljs-literal">None</span></span>):<br>        p = self.patch_size<br><br>        x = self.patch_to_embedding(x)<br>        b, n, _ = x.shape<br><br>        cls_tokens = repeat(self.cls_token, <span class="hljs-string">&#x27;() n d -&gt; b n d&#x27;</span>, b=b)<br>        x = torch.cat((cls_tokens, x), dim=<span class="hljs-number">1</span>)<br>        x += self.pos_embedding[:, :(n + <span class="hljs-number">1</span>)]<br>        x = self.dropout(x)<br><br>        x = self.transformer(x, mask)<br><br>        x = self.to_cls_token(x[:, <span class="hljs-number">0</span>])<br>        <span class="hljs-keyword">return</span> self.mlp_head(x)<br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>cv</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>yolov5</title>
    <link href="/2022/10/21/yolov5%E6%BA%90%E7%A0%81%E8%AF%A6%E8%A7%A3/"/>
    <url>/2022/10/21/yolov5%E6%BA%90%E7%A0%81%E8%AF%A6%E8%A7%A3/</url>
    
    <content type="html"><![CDATA[<h1 id="yolo.yaml">yolo.yaml</h1><ul><li>yolov5s.yaml</li></ul><figure class="highlight yaml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yaml"><span class="hljs-comment"># YOLOv5  by Ultralytics, GPL-3.0 license</span><br><br><span class="hljs-comment"># Parameters</span><br><span class="hljs-attr">nc:</span> <span class="hljs-number">80</span>  <span class="hljs-comment"># number of classes</span><br><span class="hljs-attr">depth_multiple:</span> <span class="hljs-number">0.33</span>  <span class="hljs-comment"># model depth multiple</span><br><span class="hljs-attr">width_multiple:</span> <span class="hljs-number">0.50</span>  <span class="hljs-comment"># layer channel multiple</span><br><span class="hljs-attr">anchors:</span><br>  <span class="hljs-bullet">-</span> [<span class="hljs-number">10</span>,<span class="hljs-number">13</span>, <span class="hljs-number">16</span>,<span class="hljs-number">30</span>, <span class="hljs-number">33</span>,<span class="hljs-number">23</span>]  <span class="hljs-comment"># P3/8</span><br>  <span class="hljs-bullet">-</span> [<span class="hljs-number">30</span>,<span class="hljs-number">61</span>, <span class="hljs-number">62</span>,<span class="hljs-number">45</span>, <span class="hljs-number">59</span>,<span class="hljs-number">119</span>]  <span class="hljs-comment"># P4/16</span><br>  <span class="hljs-bullet">-</span> [<span class="hljs-number">116</span>,<span class="hljs-number">90</span>, <span class="hljs-number">156</span>,<span class="hljs-number">198</span>, <span class="hljs-number">373</span>,<span class="hljs-number">326</span>]  <span class="hljs-comment"># P5/32</span><br><br><span class="hljs-comment"># YOLOv5 v6.0 backbone</span><br><span class="hljs-attr">backbone:</span><br>  <span class="hljs-comment"># [from, number, module, args]</span><br>  [[<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">Conv</span>, [<span class="hljs-number">64</span>, <span class="hljs-number">6</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>]],  <span class="hljs-comment"># 0-P1/2</span><br>   [<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">Conv</span>, [<span class="hljs-number">128</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>]],  <span class="hljs-comment"># 1-P2/4</span><br>   [<span class="hljs-number">-1</span>, <span class="hljs-number">3</span>, <span class="hljs-string">C3</span>, [<span class="hljs-number">128</span>]],<br>   [<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">Conv</span>, [<span class="hljs-number">256</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>]],  <span class="hljs-comment"># 3-P3/8</span><br>   [<span class="hljs-number">-1</span>, <span class="hljs-number">6</span>, <span class="hljs-string">C3</span>, [<span class="hljs-number">256</span>]],<br>   [<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">Conv</span>, [<span class="hljs-number">512</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>]],  <span class="hljs-comment"># 5-P4/16</span><br>   [<span class="hljs-number">-1</span>, <span class="hljs-number">9</span>, <span class="hljs-string">C3</span>, [<span class="hljs-number">512</span>]],<br>   [<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">Conv</span>, [<span class="hljs-number">1024</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>]],  <span class="hljs-comment"># 7-P5/32</span><br>   [<span class="hljs-number">-1</span>, <span class="hljs-number">3</span>, <span class="hljs-string">C3</span>, [<span class="hljs-number">1024</span>]],<br>   [<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">SPPF</span>, [<span class="hljs-number">1024</span>, <span class="hljs-number">5</span>]],  <span class="hljs-comment"># 9</span><br>  ]<br><br><span class="hljs-comment"># YOLOv5 v6.0 head</span><br><span class="hljs-attr">head:</span><br>  [[<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">Conv</span>, [<span class="hljs-number">512</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]],<br>   [<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">nn.Upsample</span>, [<span class="hljs-string">None</span>, <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;nearest&#x27;</span>]],<br>   [[<span class="hljs-number">-1</span>, <span class="hljs-number">6</span>], <span class="hljs-number">1</span>, <span class="hljs-string">Concat</span>, [<span class="hljs-number">1</span>]],  <span class="hljs-comment"># cat backbone P4</span><br>   [<span class="hljs-number">-1</span>, <span class="hljs-number">3</span>, <span class="hljs-string">C3</span>, [<span class="hljs-number">512</span>, <span class="hljs-literal">False</span>]],  <span class="hljs-comment"># 13</span><br><br>   [<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">Conv</span>, [<span class="hljs-number">256</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]],<br>   [<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">nn.Upsample</span>, [<span class="hljs-string">None</span>, <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;nearest&#x27;</span>]],<br>   [[<span class="hljs-number">-1</span>, <span class="hljs-number">4</span>], <span class="hljs-number">1</span>, <span class="hljs-string">Concat</span>, [<span class="hljs-number">1</span>]],  <span class="hljs-comment"># cat backbone P3</span><br>   [<span class="hljs-number">-1</span>, <span class="hljs-number">3</span>, <span class="hljs-string">C3</span>, [<span class="hljs-number">256</span>, <span class="hljs-literal">False</span>]],  <span class="hljs-comment"># 17 (P3/8-small)</span><br><br>   [<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">Conv</span>, [<span class="hljs-number">256</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>]],<br>   [[<span class="hljs-number">-1</span>, <span class="hljs-number">14</span>], <span class="hljs-number">1</span>, <span class="hljs-string">Concat</span>, [<span class="hljs-number">1</span>]],  <span class="hljs-comment"># cat head P4</span><br>   [<span class="hljs-number">-1</span>, <span class="hljs-number">3</span>, <span class="hljs-string">C3</span>, [<span class="hljs-number">512</span>, <span class="hljs-literal">False</span>]],  <span class="hljs-comment"># 20 (P4/16-medium)</span><br><br>   [<span class="hljs-number">-1</span>, <span class="hljs-number">1</span>, <span class="hljs-string">Conv</span>, [<span class="hljs-number">512</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>]],<br>   [[<span class="hljs-number">-1</span>, <span class="hljs-number">10</span>], <span class="hljs-number">1</span>, <span class="hljs-string">Concat</span>, [<span class="hljs-number">1</span>]],  <span class="hljs-comment"># cat head P5</span><br>   [<span class="hljs-number">-1</span>, <span class="hljs-number">3</span>, <span class="hljs-string">C3</span>, [<span class="hljs-number">1024</span>, <span class="hljs-literal">False</span>]],  <span class="hljs-comment"># 23 (P5/32-large)</span><br><br>   [[<span class="hljs-number">17</span>, <span class="hljs-number">20</span>, <span class="hljs-number">23</span>], <span class="hljs-number">1</span>, <span class="hljs-string">Detect</span>, [<span class="hljs-string">nc</span>, <span class="hljs-string">anchors</span>]],  <span class="hljs-comment"># Detect(P3, P4, P5)</span><br>  ]<br><br></code></pre></div></td></tr></table></figure><h1 id="yolo.py">yolo.py</h1><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># </span><br>FILE = Path(__file__).resolve()<br>ROOT = FILE.parents[<span class="hljs-number">1</span>]  <span class="hljs-comment"># YOLOv5 root directory</span><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">str</span>(ROOT) <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> sys.path:<br>    sys.path.append(<span class="hljs-built_in">str</span>(ROOT))  <span class="hljs-comment"># add ROOT to PATH</span><br><span class="hljs-keyword">if</span> platform.system() != <span class="hljs-string">&#x27;Windows&#x27;</span>:<br>    ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  <span class="hljs-comment"># relative</span><br>    <br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Detect</span>(nn.Module):<br>    stride = <span class="hljs-literal">None</span>  <span class="hljs-comment"># strides computed during build</span><br>    onnx_dynamic = <span class="hljs-literal">False</span>  <span class="hljs-comment"># ONNX export parameter</span><br>    export = <span class="hljs-literal">False</span>  <span class="hljs-comment"># export mode</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, nc=<span class="hljs-number">80</span>, anchors=(<span class="hljs-params"></span>), ch=(<span class="hljs-params"></span>), inplace=<span class="hljs-literal">True</span></span>):  <span class="hljs-comment"># detection layer</span><br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.nc = nc  <span class="hljs-comment"># number of classes</span><br>        self.no = nc + <span class="hljs-number">5</span>  <span class="hljs-comment"># number of outputs per anchor</span><br>        self.nl = <span class="hljs-built_in">len</span>(anchors)  <span class="hljs-comment"># number of detection layers</span><br>        self.na = <span class="hljs-built_in">len</span>(anchors[<span class="hljs-number">0</span>]) // <span class="hljs-number">2</span>  <span class="hljs-comment"># number of anchors</span><br>        self.grid = [torch.zeros(<span class="hljs-number">1</span>)] * self.nl  <span class="hljs-comment"># init grid</span><br>        self.anchor_grid = [torch.zeros(<span class="hljs-number">1</span>)] * self.nl  <span class="hljs-comment"># init anchor grid</span><br>        self.register_buffer(<span class="hljs-string">&#x27;anchors&#x27;</span>, torch.tensor(anchors).<span class="hljs-built_in">float</span>().view(self.nl, -<span class="hljs-number">1</span>, <span class="hljs-number">2</span>))  <span class="hljs-comment"># shape(nl,na,2)</span><br>        self.m = nn.ModuleList(nn.Conv2d(x, self.no * self.na, <span class="hljs-number">1</span>) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> ch)  <span class="hljs-comment"># output conv</span><br>        self.inplace = inplace  <span class="hljs-comment"># use in-place ops (e.g. slice assignment)</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        z = []  <span class="hljs-comment"># inference output</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.nl):<br>            x[i] = self.m[i](x[i])  <span class="hljs-comment"># conv</span><br>            bs, _, ny, nx = x[i].shape  <span class="hljs-comment"># x(bs,255,20,20) to x(bs,3,20,20,85)</span><br>            <span class="hljs-comment"># permute()tensor</span><br>            <span class="hljs-comment"># contiguous()</span><br>            x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">2</span>).contiguous()<br><br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> self.training:  <span class="hljs-comment"># inference</span><br>                <span class="hljs-keyword">if</span> self.onnx_dynamic <span class="hljs-keyword">or</span> self.grid[i].shape[<span class="hljs-number">2</span>:<span class="hljs-number">4</span>] != x[i].shape[<span class="hljs-number">2</span>:<span class="hljs-number">4</span>]:<br>                    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)<br><br>                y = x[i].sigmoid()<br>                <span class="hljs-keyword">if</span> self.inplace:<br>                    y[..., <span class="hljs-number">0</span>:<span class="hljs-number">2</span>] = (y[..., <span class="hljs-number">0</span>:<span class="hljs-number">2</span>] * <span class="hljs-number">2</span> + self.grid[i]) * self.stride[i]  <span class="hljs-comment"># xy</span><br>                    y[..., <span class="hljs-number">2</span>:<span class="hljs-number">4</span>] = (y[..., <span class="hljs-number">2</span>:<span class="hljs-number">4</span>] * <span class="hljs-number">2</span>) ** <span class="hljs-number">2</span> * self.anchor_grid[i]  <span class="hljs-comment"># wh</span><br>                <span class="hljs-keyword">else</span>:  <span class="hljs-comment"># for YOLOv5 on AWS Inferentia https://github.com/ultralytics/yolov5/pull/2953</span><br>                    xy, wh, conf = y.split((<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, self.nc + <span class="hljs-number">1</span>), <span class="hljs-number">4</span>)  <span class="hljs-comment"># y.tensor_split((2, 4, 5), 4)  # torch 1.8.0</span><br>                    xy = (xy * <span class="hljs-number">2</span> + self.grid[i]) * self.stride[i]  <span class="hljs-comment"># xy</span><br>                    wh = (wh * <span class="hljs-number">2</span>) ** <span class="hljs-number">2</span> * self.anchor_grid[i]  <span class="hljs-comment"># wh</span><br>                    y = torch.cat((xy, wh, conf), <span class="hljs-number">4</span>)<br>                z.append(y.view(bs, -<span class="hljs-number">1</span>, self.no))<br><br>        <span class="hljs-keyword">return</span> x <span class="hljs-keyword">if</span> self.training <span class="hljs-keyword">else</span> (torch.cat(z, <span class="hljs-number">1</span>),) <span class="hljs-keyword">if</span> self.export <span class="hljs-keyword">else</span> (torch.cat(z, <span class="hljs-number">1</span>), x)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_make_grid</span>(<span class="hljs-params">self, nx=<span class="hljs-number">20</span>, ny=<span class="hljs-number">20</span>, i=<span class="hljs-number">0</span></span>):<br>        d = self.anchors[i].device<br>        t = self.anchors[i].dtype<br>        shape = <span class="hljs-number">1</span>, self.na, ny, nx, <span class="hljs-number">2</span>  <span class="hljs-comment"># grid shape</span><br>        <span class="hljs-comment"># arange()</span><br>        y, x = torch.arange(ny, device=d, dtype=t), torch.arange(nx, device=d, dtype=t)<br>        <span class="hljs-keyword">if</span> check_version(torch.__version__, <span class="hljs-string">&#x27;1.10.0&#x27;</span>):  <span class="hljs-comment"># torch&gt;=1.10.0 meshgrid workaround for torch&gt;=0.7 compatibility</span><br>            <span class="hljs-comment"># meshgrid()</span><br>            <span class="hljs-comment"># yv: ny * nx, xv: ny * nx</span><br>            <span class="hljs-comment"># example: y = tensor([1, 2, 3, 4]), x = tensor([5, 6, 7])</span><br>            <span class="hljs-comment"># yv = [[1, 1, 1], </span><br>            <span class="hljs-comment">#       [2, 2, 2], </span><br>            <span class="hljs-comment">#       [3, 3, 3], </span><br>            <span class="hljs-comment">#       [4, 4, 4]]</span><br>            <span class="hljs-comment"># xv = [[5, 6, 7], </span><br>            <span class="hljs-comment">#       [5, 6, 7], </span><br>            <span class="hljs-comment">#       [5, 6, 7], </span><br>            <span class="hljs-comment">#       [5, 6, 7]]</span><br>            yv, xv = torch.meshgrid(y, x, indexing=<span class="hljs-string">&#x27;ij&#x27;</span>)<br>        <span class="hljs-keyword">else</span>:<br>            yv, xv = torch.meshgrid(y, x)<br>        <span class="hljs-comment"># stack()</span><br>        <span class="hljs-comment"># expand()</span><br>        grid = torch.stack((xv, yv), <span class="hljs-number">2</span>).expand(shape) - <span class="hljs-number">0.5</span>  <span class="hljs-comment"># add grid offset, i.e. y = 2.0 * x - 0.5</span><br>        anchor_grid = (self.anchors[i] * self.stride[i]).view((<span class="hljs-number">1</span>, self.na, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>)).expand(shape)<br>        <span class="hljs-keyword">return</span> grid, anchor_grid<br>    <br>    <br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Model</span>(nn.Module):<br>    <span class="hljs-comment"># YOLOv5 model</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, cfg=<span class="hljs-string">&#x27;yolov5s.yaml&#x27;</span>, ch=<span class="hljs-number">3</span>, nc=<span class="hljs-literal">None</span>, anchors=<span class="hljs-literal">None</span></span>):  <span class="hljs-comment"># model, input channels, number of classes</span><br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(cfg, <span class="hljs-built_in">dict</span>):<br>            self.yaml = cfg  <span class="hljs-comment"># model dict</span><br>        <span class="hljs-keyword">else</span>:  <span class="hljs-comment"># is *.yaml</span><br>            <span class="hljs-keyword">import</span> yaml  <span class="hljs-comment"># for torch hub</span><br>            self.yaml_file = Path(cfg).name<br>            <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(cfg, encoding=<span class="hljs-string">&#x27;ascii&#x27;</span>, errors=<span class="hljs-string">&#x27;ignore&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>                self.yaml = yaml.safe_load(f)  <span class="hljs-comment"># model dict</span><br><br>        <span class="hljs-comment"># Define model</span><br>        ch = self.yaml[<span class="hljs-string">&#x27;ch&#x27;</span>] = self.yaml.get(<span class="hljs-string">&#x27;ch&#x27;</span>, ch)  <span class="hljs-comment"># input channelsyamlch</span><br>        <span class="hljs-keyword">if</span> nc <span class="hljs-keyword">and</span> nc != self.yaml[<span class="hljs-string">&#x27;nc&#x27;</span>]:<br>            LOGGER.info(<span class="hljs-string">f&quot;Overriding model.yaml nc=<span class="hljs-subst">&#123;self.yaml[<span class="hljs-string">&#x27;nc&#x27;</span>]&#125;</span> with nc=<span class="hljs-subst">&#123;nc&#125;</span>&quot;</span>)<br>            self.yaml[<span class="hljs-string">&#x27;nc&#x27;</span>] = nc  <span class="hljs-comment"># override yaml value</span><br>        <span class="hljs-keyword">if</span> anchors:<br>            LOGGER.info(<span class="hljs-string">f&#x27;Overriding model.yaml anchors with anchors=<span class="hljs-subst">&#123;anchors&#125;</span>&#x27;</span>)<br>            self.yaml[<span class="hljs-string">&#x27;anchors&#x27;</span>] = <span class="hljs-built_in">round</span>(anchors)  <span class="hljs-comment"># override yaml valueround()</span><br>        self.model, self.save = parse_model(deepcopy(self.yaml), ch=[ch])  <span class="hljs-comment"># model, savelist</span><br>        self.names = [<span class="hljs-built_in">str</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.yaml[<span class="hljs-string">&#x27;nc&#x27;</span>])]  <span class="hljs-comment"># default names</span><br>        self.inplace = self.yaml.get(<span class="hljs-string">&#x27;inplace&#x27;</span>, <span class="hljs-literal">True</span>)<br><br>        <span class="hljs-comment"># Build strides, anchors</span><br>        m = self.model[-<span class="hljs-number">1</span>]  <span class="hljs-comment"># Detect()</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m, Detect):<br>            s = <span class="hljs-number">256</span>  <span class="hljs-comment"># 2x min stride</span><br>            m.inplace = self.inplace<br>            <span class="hljs-comment"># [8, 16, 32]</span><br>            m.stride = torch.tensor([s / x.shape[-<span class="hljs-number">2</span>] <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> self.forward(torch.zeros(<span class="hljs-number">1</span>, ch, s, s))])  <span class="hljs-comment"># forward</span><br>            <span class="hljs-comment"># anchor</span><br>            check_anchor_order(m)  <span class="hljs-comment"># must be in pixel-space (not grid-space)</span><br>            <span class="hljs-comment"># anchor</span><br>            m.anchors /= m.stride.view(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>            self.stride = m.stride<br>            <span class="hljs-comment"># </span><br>            self._initialize_biases()  <span class="hljs-comment"># only run once</span><br><br>        <span class="hljs-comment"># Init weights, biases</span><br>        initialize_weights(self)<br>        self.info()<br>        LOGGER.info(<span class="hljs-string">&#x27;&#x27;</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, augment=<span class="hljs-literal">False</span>, profile=<span class="hljs-literal">False</span>, visualize=<span class="hljs-literal">False</span></span>):<br>        <span class="hljs-comment"># </span><br>        <span class="hljs-keyword">if</span> augment:<br>            <span class="hljs-keyword">return</span> self._forward_augment(x)  <span class="hljs-comment"># augmented inference, None</span><br>        <span class="hljs-keyword">return</span> self._forward_once(x, profile, visualize)  <span class="hljs-comment"># single-scale inference, train</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_forward_augment</span>(<span class="hljs-params">self, x</span>):<br>        img_size = x.shape[-<span class="hljs-number">2</span>:]  <span class="hljs-comment"># height, width</span><br>        s = [<span class="hljs-number">1</span>, <span class="hljs-number">0.83</span>, <span class="hljs-number">0.67</span>]  <span class="hljs-comment"># scales</span><br>        f = [<span class="hljs-literal">None</span>, <span class="hljs-number">3</span>, <span class="hljs-literal">None</span>]  <span class="hljs-comment"># flips (2-ud, 3-lr)</span><br>        y = []  <span class="hljs-comment"># outputs</span><br>        <span class="hljs-keyword">for</span> si, fi <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(s, f):<br>            xi = scale_img(x.flip(fi) <span class="hljs-keyword">if</span> fi <span class="hljs-keyword">else</span> x, si, gs=<span class="hljs-built_in">int</span>(self.stride.<span class="hljs-built_in">max</span>()))<br>            yi = self._forward_once(xi)[<span class="hljs-number">0</span>]  <span class="hljs-comment"># forward</span><br>            <span class="hljs-comment"># cv2.imwrite(f&#x27;img_&#123;si&#125;.jpg&#x27;, 255 * xi[0].cpu().numpy().transpose((1, 2, 0))[:, :, ::-1])  # save</span><br>            yi = self._descale_pred(yi, fi, si, img_size)<br>            y.append(yi)<br>        y = self._clip_augmented(y)  <span class="hljs-comment"># clip augmented tails</span><br>        <span class="hljs-keyword">return</span> torch.cat(y, <span class="hljs-number">1</span>), <span class="hljs-literal">None</span>  <span class="hljs-comment"># augmented inference, train</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_forward_once</span>(<span class="hljs-params">self, x, profile=<span class="hljs-literal">False</span>, visualize=<span class="hljs-literal">False</span></span>):<br>        y, dt = [], []  <span class="hljs-comment"># outputs</span><br>        <span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> self.model:<br>            <span class="hljs-keyword">if</span> m.f != -<span class="hljs-number">1</span>:  <span class="hljs-comment"># if not from previous layer</span><br>                x = y[m.f] <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m.f, <span class="hljs-built_in">int</span>) <span class="hljs-keyword">else</span> [x <span class="hljs-keyword">if</span> j == -<span class="hljs-number">1</span> <span class="hljs-keyword">else</span> y[j] <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> m.f]  <span class="hljs-comment"># from earlier layers</span><br>            <span class="hljs-keyword">if</span> profile:<br>                self._profile_one_layer(m, x, dt)<br>            x = m(x)  <span class="hljs-comment"># run</span><br>            y.append(x <span class="hljs-keyword">if</span> m.i <span class="hljs-keyword">in</span> self.save <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>)  <span class="hljs-comment"># save output</span><br>            <span class="hljs-keyword">if</span> visualize:<br>                feature_visualization(x, m.<span class="hljs-built_in">type</span>, m.i, save_dir=visualize)<br>        <span class="hljs-keyword">return</span> x<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_descale_pred</span>(<span class="hljs-params">self, p, flips, scale, img_size</span>):<br>        <span class="hljs-comment"># de-scale predictions following augmented inference (inverse operation)</span><br>        <span class="hljs-keyword">if</span> self.inplace:<br>            p[..., :<span class="hljs-number">4</span>] /= scale  <span class="hljs-comment"># de-scale</span><br>            <span class="hljs-keyword">if</span> flips == <span class="hljs-number">2</span>:<br>                p[..., <span class="hljs-number">1</span>] = img_size[<span class="hljs-number">0</span>] - p[..., <span class="hljs-number">1</span>]  <span class="hljs-comment"># de-flip ud</span><br>            <span class="hljs-keyword">elif</span> flips == <span class="hljs-number">3</span>:<br>                p[..., <span class="hljs-number">0</span>] = img_size[<span class="hljs-number">1</span>] - p[..., <span class="hljs-number">0</span>]  <span class="hljs-comment"># de-flip lr</span><br>        <span class="hljs-keyword">else</span>:<br>            x, y, wh = p[..., <span class="hljs-number">0</span>:<span class="hljs-number">1</span>] / scale, p[..., <span class="hljs-number">1</span>:<span class="hljs-number">2</span>] / scale, p[..., <span class="hljs-number">2</span>:<span class="hljs-number">4</span>] / scale  <span class="hljs-comment"># de-scale</span><br>            <span class="hljs-keyword">if</span> flips == <span class="hljs-number">2</span>:<br>                y = img_size[<span class="hljs-number">0</span>] - y  <span class="hljs-comment"># de-flip ud</span><br>            <span class="hljs-keyword">elif</span> flips == <span class="hljs-number">3</span>:<br>                x = img_size[<span class="hljs-number">1</span>] - x  <span class="hljs-comment"># de-flip lr</span><br>            p = torch.cat((x, y, wh, p[..., <span class="hljs-number">4</span>:]), -<span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> p<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_clip_augmented</span>(<span class="hljs-params">self, y</span>):<br>        <span class="hljs-comment"># Clip YOLOv5 augmented inference tails</span><br>        nl = self.model[-<span class="hljs-number">1</span>].nl  <span class="hljs-comment"># number of detection layers (P3-P5)</span><br>        g = <span class="hljs-built_in">sum</span>(<span class="hljs-number">4</span> ** x <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(nl))  <span class="hljs-comment"># grid points</span><br>        e = <span class="hljs-number">1</span>  <span class="hljs-comment"># exclude layer count</span><br>        i = (y[<span class="hljs-number">0</span>].shape[<span class="hljs-number">1</span>] // g) * <span class="hljs-built_in">sum</span>(<span class="hljs-number">4</span> ** x <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(e))  <span class="hljs-comment"># indices</span><br>        y[<span class="hljs-number">0</span>] = y[<span class="hljs-number">0</span>][:, :-i]  <span class="hljs-comment"># large</span><br>        i = (y[-<span class="hljs-number">1</span>].shape[<span class="hljs-number">1</span>] // g) * <span class="hljs-built_in">sum</span>(<span class="hljs-number">4</span> ** (nl - <span class="hljs-number">1</span> - x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(e))  <span class="hljs-comment"># indices</span><br>        y[-<span class="hljs-number">1</span>] = y[-<span class="hljs-number">1</span>][:, i:]  <span class="hljs-comment"># small</span><br>        <span class="hljs-keyword">return</span> y<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_profile_one_layer</span>(<span class="hljs-params">self, m, x, dt</span>):<br>        c = <span class="hljs-built_in">isinstance</span>(m, Detect)  <span class="hljs-comment"># is final layer, copy input as inplace fix</span><br>        o = thop.profile(m, inputs=(x.copy() <span class="hljs-keyword">if</span> c <span class="hljs-keyword">else</span> x,), verbose=<span class="hljs-literal">False</span>)[<span class="hljs-number">0</span>] / <span class="hljs-number">1E9</span> * <span class="hljs-number">2</span> <span class="hljs-keyword">if</span> thop <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>  <span class="hljs-comment"># FLOPs</span><br>        t = time_sync()<br>        <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>            m(x.copy() <span class="hljs-keyword">if</span> c <span class="hljs-keyword">else</span> x)<br>        dt.append((time_sync() - t) * <span class="hljs-number">100</span>)<br>        <span class="hljs-keyword">if</span> m == self.model[<span class="hljs-number">0</span>]:<br>            LOGGER.info(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;<span class="hljs-string">&#x27;time (ms)&#x27;</span>:&gt;10s&#125;</span> <span class="hljs-subst">&#123;<span class="hljs-string">&#x27;GFLOPs&#x27;</span>:&gt;10s&#125;</span> <span class="hljs-subst">&#123;<span class="hljs-string">&#x27;params&#x27;</span>:&gt;10s&#125;</span>  <span class="hljs-subst">&#123;<span class="hljs-string">&#x27;module&#x27;</span>&#125;</span>&quot;</span>)<br>        LOGGER.info(<span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;dt[-<span class="hljs-number">1</span>]:<span class="hljs-number">10.2</span>f&#125;</span> <span class="hljs-subst">&#123;o:<span class="hljs-number">10.2</span>f&#125;</span> <span class="hljs-subst">&#123;m.np:<span class="hljs-number">10.0</span>f&#125;</span>  <span class="hljs-subst">&#123;m.<span class="hljs-built_in">type</span>&#125;</span>&#x27;</span>)<br>        <span class="hljs-keyword">if</span> c:<br>            LOGGER.info(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;<span class="hljs-built_in">sum</span>(dt):<span class="hljs-number">10.2</span>f&#125;</span> <span class="hljs-subst">&#123;<span class="hljs-string">&#x27;-&#x27;</span>:&gt;10s&#125;</span> <span class="hljs-subst">&#123;<span class="hljs-string">&#x27;-&#x27;</span>:&gt;10s&#125;</span>  Total&quot;</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_initialize_biases</span>(<span class="hljs-params">self, cf=<span class="hljs-literal">None</span></span>):  <span class="hljs-comment"># initialize biases into Detect(), cf is class frequency</span><br>        <span class="hljs-comment"># https://arxiv.org/abs/1708.02002 section 3.3</span><br>        <span class="hljs-comment"># cf = torch.bincount(torch.tensor(np.concatenate(dataset.labels, 0)[:, 0]).long(), minlength=nc) + 1.</span><br>        m = self.model[-<span class="hljs-number">1</span>]  <span class="hljs-comment"># Detect() module</span><br>        <span class="hljs-keyword">for</span> mi, s <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(m.m, m.stride):  <span class="hljs-comment"># from</span><br>            b = mi.bias.view(m.na, -<span class="hljs-number">1</span>)  <span class="hljs-comment"># conv.bias(255) to (3,85)</span><br>            b.data[:, <span class="hljs-number">4</span>] += math.log(<span class="hljs-number">8</span> / (<span class="hljs-number">640</span> / s) ** <span class="hljs-number">2</span>)  <span class="hljs-comment"># obj (8 objects per 640 image)</span><br>            b.data[:, <span class="hljs-number">5</span>:] += math.log(<span class="hljs-number">0.6</span> / (m.nc - <span class="hljs-number">0.999999</span>)) <span class="hljs-keyword">if</span> cf <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">else</span> torch.log(cf / cf.<span class="hljs-built_in">sum</span>())  <span class="hljs-comment"># cls</span><br>            mi.bias = torch.nn.Parameter(b.view(-<span class="hljs-number">1</span>), requires_grad=<span class="hljs-literal">True</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_print_biases</span>(<span class="hljs-params">self</span>):<br>        m = self.model[-<span class="hljs-number">1</span>]  <span class="hljs-comment"># Detect() module</span><br>        <span class="hljs-keyword">for</span> mi <span class="hljs-keyword">in</span> m.m:  <span class="hljs-comment"># from</span><br>            b = mi.bias.detach().view(m.na, -<span class="hljs-number">1</span>).T  <span class="hljs-comment"># conv.bias(255) to (3,85)</span><br>            LOGGER.info(<br>                (<span class="hljs-string">&#x27;%6g Conv2d.bias:&#x27;</span> + <span class="hljs-string">&#x27;%10.3g&#x27;</span> * <span class="hljs-number">6</span>) % (mi.weight.shape[<span class="hljs-number">1</span>], *b[:<span class="hljs-number">5</span>].mean(<span class="hljs-number">1</span>).tolist(), b[<span class="hljs-number">5</span>:].mean()))<br><br>    <span class="hljs-comment"># def _print_weights(self):</span><br>    <span class="hljs-comment">#     for m in self.model.modules():</span><br>    <span class="hljs-comment">#         if type(m) is Bottleneck:</span><br>    <span class="hljs-comment">#             LOGGER.info(&#x27;%10.3g&#x27; % (m.w.detach().sigmoid() * 2))  # shortcut weights</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">fuse</span>(<span class="hljs-params">self</span>):  <span class="hljs-comment"># fuse model Conv2d() + BatchNorm2d() layers</span><br>        LOGGER.info(<span class="hljs-string">&#x27;Fusing layers... &#x27;</span>)<br>        <span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> self.model.modules():<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m, (Conv, DWConv)) <span class="hljs-keyword">and</span> <span class="hljs-built_in">hasattr</span>(m, <span class="hljs-string">&#x27;bn&#x27;</span>):<br>                m.conv = fuse_conv_and_bn(m.conv, m.bn)  <span class="hljs-comment"># update conv</span><br>                <span class="hljs-built_in">delattr</span>(m, <span class="hljs-string">&#x27;bn&#x27;</span>)  <span class="hljs-comment"># remove batchnorm</span><br>                m.forward = m.forward_fuse  <span class="hljs-comment"># update forward</span><br>        self.info()<br>        <span class="hljs-keyword">return</span> self<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">info</span>(<span class="hljs-params">self, verbose=<span class="hljs-literal">False</span>, img_size=<span class="hljs-number">640</span></span>):  <span class="hljs-comment"># print model information</span><br>        model_info(self, verbose, img_size)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_apply</span>(<span class="hljs-params">self, fn</span>):<br>        <span class="hljs-comment"># Apply to(), cpu(), cuda(), half() to model tensors that are not parameters or registered buffers</span><br>        self = <span class="hljs-built_in">super</span>()._apply(fn)<br>        m = self.model[-<span class="hljs-number">1</span>]  <span class="hljs-comment"># Detect()</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m, Detect):<br>            m.stride = fn(m.stride)<br>            m.grid = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(fn, m.grid))<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m.anchor_grid, <span class="hljs-built_in">list</span>):<br>                m.anchor_grid = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(fn, m.anchor_grid))<br>        <span class="hljs-keyword">return</span> self<br>    <br>    <br><span class="hljs-comment"># yamlsavelist</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">parse_model</span>(<span class="hljs-params">d, ch</span>):  <span class="hljs-comment"># model_dict, input_channels(3)</span><br>    LOGGER.info(<span class="hljs-string">f&quot;\n<span class="hljs-subst">&#123;<span class="hljs-string">&#x27;&#x27;</span>:&gt;<span class="hljs-number">3</span>&#125;</span><span class="hljs-subst">&#123;<span class="hljs-string">&#x27;from&#x27;</span>:&gt;<span class="hljs-number">18</span>&#125;</span><span class="hljs-subst">&#123;<span class="hljs-string">&#x27;n&#x27;</span>:&gt;<span class="hljs-number">3</span>&#125;</span><span class="hljs-subst">&#123;<span class="hljs-string">&#x27;params&#x27;</span>:&gt;<span class="hljs-number">10</span>&#125;</span>  <span class="hljs-subst">&#123;<span class="hljs-string">&#x27;module&#x27;</span>:&lt;<span class="hljs-number">40</span>&#125;</span><span class="hljs-subst">&#123;<span class="hljs-string">&#x27;arguments&#x27;</span>:&lt;<span class="hljs-number">30</span>&#125;</span>&quot;</span>)<br>    anchors, nc, gd, gw = d[<span class="hljs-string">&#x27;anchors&#x27;</span>], d[<span class="hljs-string">&#x27;nc&#x27;</span>], d[<span class="hljs-string">&#x27;depth_multiple&#x27;</span>], d[<span class="hljs-string">&#x27;width_multiple&#x27;</span>]<br>    na = (<span class="hljs-built_in">len</span>(anchors[<span class="hljs-number">0</span>]) // <span class="hljs-number">2</span>) <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(anchors, <span class="hljs-built_in">list</span>) <span class="hljs-keyword">else</span> anchors  <span class="hljs-comment"># number of anchors</span><br>    no = na * (nc + <span class="hljs-number">5</span>)  <span class="hljs-comment"># number of outputs = anchors * (classes + 5)</span><br><br>    layers, save, c2 = [], [], ch[-<span class="hljs-number">1</span>]  <span class="hljs-comment"># layers, savelist, ch out</span><br>    <span class="hljs-comment"># backbonehead</span><br>    <span class="hljs-keyword">for</span> i, (f, n, m, args) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(d[<span class="hljs-string">&#x27;backbone&#x27;</span>] + d[<span class="hljs-string">&#x27;head&#x27;</span>]):  <span class="hljs-comment"># from, number, module, args</span><br>        m = <span class="hljs-built_in">eval</span>(m) <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m, <span class="hljs-built_in">str</span>) <span class="hljs-keyword">else</span> m  <span class="hljs-comment"># eval strings</span><br>        <span class="hljs-keyword">for</span> j, a <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(args):<br>            <span class="hljs-keyword">try</span>:<br>                args[j] = <span class="hljs-built_in">eval</span>(a) <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(a, <span class="hljs-built_in">str</span>) <span class="hljs-keyword">else</span> a  <span class="hljs-comment"># eval strings</span><br>            <span class="hljs-keyword">except</span> NameError:<br>                <span class="hljs-keyword">pass</span><br><br>        n = n_ = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">round</span>(n * gd), <span class="hljs-number">1</span>) <span class="hljs-keyword">if</span> n &gt; <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> n  <span class="hljs-comment"># depth gainmoduledepth_multiple</span><br>        <span class="hljs-keyword">if</span> m <span class="hljs-keyword">in</span> (Conv, GhostConv, Bottleneck, GhostBottleneck, SPP, SPPF, DWConv, MixConv2d, Focus, CrossConv,<br>                 BottleneckCSP, C3, C3TR, C3SPP, C3Ghost):<br>            c1, c2 = ch[f], args[<span class="hljs-number">0</span>]<span class="hljs-comment"># c1c2</span><br>            <span class="hljs-keyword">if</span> c2 != no:  <span class="hljs-comment"># if not output</span><br>                <span class="hljs-comment"># make_divisiblemath.ceil(c2 * gw / 8) * 8</span><br>                <span class="hljs-comment"># 8</span><br>                c2 = make_divisible(c2 * gw, <span class="hljs-number">8</span>)<br><span class="hljs-comment"># args[yaml]</span><br>            args = [c1, c2, *args[<span class="hljs-number">1</span>:]]<br>            <span class="hljs-comment"># modulemodulen</span><br>            <span class="hljs-keyword">if</span> m <span class="hljs-keyword">in</span> [BottleneckCSP, C3, C3TR, C3Ghost]:<br>                args.insert(<span class="hljs-number">2</span>, n)  <span class="hljs-comment"># number of repeats</span><br>                n = <span class="hljs-number">1</span><br>        <span class="hljs-keyword">elif</span> m <span class="hljs-keyword">is</span> nn.BatchNorm2d:<br>            <span class="hljs-comment"># mBatchNorm2dmodule</span><br>            args = [ch[f]]<br>        <span class="hljs-keyword">elif</span> m <span class="hljs-keyword">is</span> Concat:<br>            <span class="hljs-comment"># mConcatc2module</span><br>            c2 = <span class="hljs-built_in">sum</span>(ch[x] <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> f)<br>        <span class="hljs-keyword">elif</span> m <span class="hljs-keyword">is</span> Detect:<br>            <span class="hljs-comment"># mDetectmodule</span><br>            args.append([ch[x] <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> f])<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(args[<span class="hljs-number">1</span>], <span class="hljs-built_in">int</span>):  <span class="hljs-comment"># number of anchors</span><br>                args[<span class="hljs-number">1</span>] = [<span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(args[<span class="hljs-number">1</span>] * <span class="hljs-number">2</span>))] * <span class="hljs-built_in">len</span>(f)<br>        <span class="hljs-keyword">elif</span> m <span class="hljs-keyword">is</span> Contract:<br>            c2 = ch[f] * args[<span class="hljs-number">0</span>] ** <span class="hljs-number">2</span><br>        <span class="hljs-keyword">elif</span> m <span class="hljs-keyword">is</span> Expand:<br>            c2 = ch[f] // args[<span class="hljs-number">0</span>] ** <span class="hljs-number">2</span><br>        <span class="hljs-keyword">else</span>:<br>            c2 = ch[f]<br><br>        <span class="hljs-comment"># yamlmodulenn.Sequential</span><br>        m_ = nn.Sequential(*(m(*args) <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n))) <span class="hljs-keyword">if</span> n &gt; <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> m(*args)  <span class="hljs-comment"># module</span><br>        t = <span class="hljs-built_in">str</span>(m)[<span class="hljs-number">8</span>:-<span class="hljs-number">2</span>].replace(<span class="hljs-string">&#x27;__main__.&#x27;</span>, <span class="hljs-string">&#x27;&#x27;</span>)  <span class="hljs-comment"># module type</span><br>        np = <span class="hljs-built_in">sum</span>(x.numel() <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> m_.parameters())  <span class="hljs-comment"># number params</span><br>        m_.i, m_.f, m_.<span class="hljs-built_in">type</span>, m_.np = i, f, t, np  <span class="hljs-comment"># attach index, &#x27;from&#x27; index, type, number params</span><br>        LOGGER.info(<span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;i:&gt;<span class="hljs-number">3</span>&#125;</span><span class="hljs-subst">&#123;<span class="hljs-built_in">str</span>(f):&gt;<span class="hljs-number">18</span>&#125;</span><span class="hljs-subst">&#123;n_:&gt;<span class="hljs-number">3</span>&#125;</span><span class="hljs-subst">&#123;np:<span class="hljs-number">10.0</span>f&#125;</span>  <span class="hljs-subst">&#123;t:&lt;<span class="hljs-number">40</span>&#125;</span><span class="hljs-subst">&#123;<span class="hljs-built_in">str</span>(args):&lt;<span class="hljs-number">30</span>&#125;</span>&#x27;</span>)  <span class="hljs-comment"># print</span><br>        save.extend(x % i <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> ([f] <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(f, <span class="hljs-built_in">int</span>) <span class="hljs-keyword">else</span> f) <span class="hljs-keyword">if</span> x != -<span class="hljs-number">1</span>)  <span class="hljs-comment"># append to savelist</span><br>        layers.append(m_)<span class="hljs-comment"># layermodule</span><br>        <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span>:<span class="hljs-comment"># modulech</span><br>            ch = []<br>        ch.append(c2)<span class="hljs-comment"># ch</span><br>    <span class="hljs-keyword">return</span> nn.Sequential(*layers), <span class="hljs-built_in">sorted</span>(save)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    parser = argparse.ArgumentParser()<br>    parser.add_argument(<span class="hljs-string">&#x27;--cfg&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=<span class="hljs-string">&#x27;yolov5s.yaml&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;model.yaml&#x27;</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--batch-size&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">1</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;total batch size for all GPUs&#x27;</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--device&#x27;</span>, default=<span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;cuda device, i.e. 0 or 0,1,2,3 or cpu&#x27;</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--profile&#x27;</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;profile model speed&#x27;</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--line-profile&#x27;</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;profile model speed layer by layer&#x27;</span>)<br>    parser.add_argument(<span class="hljs-string">&#x27;--test&#x27;</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;test all yolo*.yaml&#x27;</span>)<br>    opt = parser.parse_args()<br>    opt.cfg = check_yaml(opt.cfg)  <span class="hljs-comment"># check YAML</span><br>    print_args(<span class="hljs-built_in">vars</span>(opt))<br>    device = select_device(opt.device)<br><br>    <span class="hljs-comment"># Create model</span><br>    im = torch.rand(opt.batch_size, <span class="hljs-number">3</span>, <span class="hljs-number">640</span>, <span class="hljs-number">640</span>).to(device)<br>    model = Model(opt.cfg).to(device)<br><br>    <span class="hljs-comment"># Options</span><br>    <span class="hljs-keyword">if</span> opt.line_profile:  <span class="hljs-comment"># profile layer by layer</span><br>        _ = model(im, profile=<span class="hljs-literal">True</span>)<br><br>    <span class="hljs-keyword">elif</span> opt.profile:  <span class="hljs-comment"># profile forward-backward</span><br>        results = profile(<span class="hljs-built_in">input</span>=im, ops=[model], n=<span class="hljs-number">3</span>)<br><br>    <span class="hljs-keyword">elif</span> opt.test:  <span class="hljs-comment"># test all models</span><br>        <span class="hljs-keyword">for</span> cfg <span class="hljs-keyword">in</span> Path(ROOT / <span class="hljs-string">&#x27;models&#x27;</span>).rglob(<span class="hljs-string">&#x27;yolo*.yaml&#x27;</span>):<br>            <span class="hljs-keyword">try</span>:<br>                _ = Model(cfg)<br>            <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:<br>                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Error in <span class="hljs-subst">&#123;cfg&#125;</span>: <span class="hljs-subst">&#123;e&#125;</span>&#x27;</span>)<br></code></pre></div></td></tr></table></figure><h1 id="train.py">train.py</h1><ul><li><ul><li>run()</li><li>main()</li><li>parse_opt()</li><li>train()</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br><span class="line">556</span><br><span class="line">557</span><br><span class="line">558</span><br><span class="line">559</span><br><span class="line">560</span><br><span class="line">561</span><br><span class="line">562</span><br><span class="line">563</span><br><span class="line">564</span><br><span class="line">565</span><br><span class="line">566</span><br><span class="line">567</span><br><span class="line">568</span><br><span class="line">569</span><br><span class="line">570</span><br><span class="line">571</span><br><span class="line">572</span><br><span class="line">573</span><br><span class="line">574</span><br><span class="line">575</span><br><span class="line">576</span><br><span class="line">577</span><br><span class="line">578</span><br><span class="line">579</span><br><span class="line">580</span><br><span class="line">581</span><br><span class="line">582</span><br><span class="line">583</span><br><span class="line">584</span><br><span class="line">585</span><br><span class="line">586</span><br><span class="line">587</span><br><span class="line">588</span><br><span class="line">589</span><br><span class="line">590</span><br><span class="line">591</span><br><span class="line">592</span><br><span class="line">593</span><br><span class="line">594</span><br><span class="line">595</span><br><span class="line">596</span><br><span class="line">597</span><br><span class="line">598</span><br><span class="line">599</span><br><span class="line">600</span><br><span class="line">601</span><br><span class="line">602</span><br><span class="line">603</span><br><span class="line">604</span><br><span class="line">605</span><br><span class="line">606</span><br><span class="line">607</span><br><span class="line">608</span><br><span class="line">609</span><br><span class="line">610</span><br><span class="line">611</span><br><span class="line">612</span><br><span class="line">613</span><br><span class="line">614</span><br><span class="line">615</span><br><span class="line">616</span><br><span class="line">617</span><br><span class="line">618</span><br><span class="line">619</span><br><span class="line">620</span><br><span class="line">621</span><br><span class="line">622</span><br><span class="line">623</span><br><span class="line">624</span><br><span class="line">625</span><br><span class="line">626</span><br><span class="line">627</span><br><span class="line">628</span><br><span class="line">629</span><br><span class="line">630</span><br><span class="line">631</span><br><span class="line">632</span><br><span class="line">633</span><br><span class="line">634</span><br><span class="line">635</span><br><span class="line">636</span><br><span class="line">637</span><br><span class="line">638</span><br><span class="line">639</span><br><span class="line">640</span><br><span class="line">641</span><br><span class="line">642</span><br><span class="line">643</span><br><span class="line">644</span><br><span class="line">645</span><br><span class="line">646</span><br><span class="line">647</span><br><span class="line">648</span><br><span class="line">649</span><br><span class="line">650</span><br><span class="line">651</span><br><span class="line">652</span><br><span class="line">653</span><br><span class="line">654</span><br><span class="line">655</span><br><span class="line">656</span><br><span class="line">657</span><br><span class="line">658</span><br><span class="line">659</span><br><span class="line">660</span><br><span class="line">661</span><br><span class="line">662</span><br><span class="line">663</span><br><span class="line">664</span><br><span class="line">665</span><br><span class="line">666</span><br><span class="line">667</span><br><span class="line">668</span><br><span class="line">669</span><br><span class="line">670</span><br><span class="line">671</span><br><span class="line">672</span><br><span class="line">673</span><br><span class="line">674</span><br><span class="line">675</span><br><span class="line">676</span><br><span class="line">677</span><br><span class="line">678</span><br><span class="line">679</span><br><span class="line">680</span><br><span class="line">681</span><br><span class="line">682</span><br><span class="line">683</span><br><span class="line">684</span><br><span class="line">685</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># </span><br>FILE = Path(__file__).resolve()<br>ROOT = FILE.parents[<span class="hljs-number">0</span>]  <span class="hljs-comment"># YOLOv5 root directory</span><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">str</span>(ROOT) <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> sys.path:<br>    sys.path.append(<span class="hljs-built_in">str</span>(ROOT))  <span class="hljs-comment"># add ROOT to PATH</span><br>ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  <span class="hljs-comment"># relative</span><br><br><span class="hljs-comment"># GPU</span><br><span class="hljs-comment"># ranklocal_rankgpu</span><br>LOCAL_RANK = <span class="hljs-built_in">int</span>(os.getenv(<span class="hljs-string">&#x27;LOCAL_RANK&#x27;</span>, -<span class="hljs-number">1</span>))  <span class="hljs-comment"># https://pytorch.org/docs/stable/elastic/run.html</span><br>RANK = <span class="hljs-built_in">int</span>(os.getenv(<span class="hljs-string">&#x27;RANK&#x27;</span>, -<span class="hljs-number">1</span>))<br><span class="hljs-comment"># world_size</span><br>WORLD_SIZE = <span class="hljs-built_in">int</span>(os.getenv(<span class="hljs-string">&#x27;WORLD_SIZE&#x27;</span>, <span class="hljs-number">1</span>))<br><span class="hljs-comment"># LOCAL_RANK=-1, RANK=-1, WORLD_SIZE=1</span><br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">hyp, opt, device, callbacks</span>):  <span class="hljs-comment"># hyp is path/to/hyp.yaml or hyp dictionary</span><br>    save_dir, epochs, batch_size, weights, single_cls, evolve, data, cfg, resume, noval, nosave, workers, freeze = \<br>        Path(opt.save_dir), opt.epochs, opt.batch_size, opt.weights, opt.single_cls, opt.evolve, opt.data, opt.cfg, \<br>        opt.resume, opt.noval, opt.nosave, opt.workers, opt.freeze<br>    callbacks.run(<span class="hljs-string">&#x27;on_pretrain_routine_start&#x27;</span>)<br><br>    <span class="hljs-comment"># </span><br>    <span class="hljs-comment"># </span><br>    w = save_dir / <span class="hljs-string">&#x27;weights&#x27;</span>  <span class="hljs-comment"># weights dir</span><br>    (w.parent <span class="hljs-keyword">if</span> evolve <span class="hljs-keyword">else</span> w).mkdir(parents=<span class="hljs-literal">True</span>, exist_ok=<span class="hljs-literal">True</span>)  <span class="hljs-comment"># make dir</span><br>    last, best = w / <span class="hljs-string">&#x27;last.pt&#x27;</span>, w / <span class="hljs-string">&#x27;best.pt&#x27;</span><br><br>    <span class="hljs-comment"># </span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(hyp, <span class="hljs-built_in">str</span>):<br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(hyp, errors=<span class="hljs-string">&#x27;ignore&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>            hyp = yaml.safe_load(f)  <span class="hljs-comment"># load hyps dict</span><br>    LOGGER.info(colorstr(<span class="hljs-string">&#x27;hyperparameters: &#x27;</span>) + <span class="hljs-string">&#x27;, &#x27;</span>.join(<span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;k&#125;</span>=<span class="hljs-subst">&#123;v&#125;</span>&#x27;</span> <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> hyp.items()))<br><br>    <span class="hljs-comment"># </span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> evolve:<br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(save_dir / <span class="hljs-string">&#x27;hyp.yaml&#x27;</span>, <span class="hljs-string">&#x27;w&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>            yaml.safe_dump(hyp, f, sort_keys=<span class="hljs-literal">False</span>)<br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(save_dir / <span class="hljs-string">&#x27;opt.yaml&#x27;</span>, <span class="hljs-string">&#x27;w&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>            yaml.safe_dump(<span class="hljs-built_in">vars</span>(opt), f, sort_keys=<span class="hljs-literal">False</span>)<br><br>    <span class="hljs-comment"># </span><br>    data_dict = <span class="hljs-literal">None</span><br>    <span class="hljs-keyword">if</span> RANK <span class="hljs-keyword">in</span> [-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>]:<br>        loggers = Loggers(save_dir, weights, opt, hyp, LOGGER)  <span class="hljs-comment"># loggers instance</span><br>        <span class="hljs-keyword">if</span> loggers.wandb:<br>            <span class="hljs-comment"># </span><br>            data_dict = loggers.wandb.data_dict<br>            <span class="hljs-keyword">if</span> resume:<span class="hljs-comment"># </span><br>                weights, epochs, hyp, batch_size = opt.weights, opt.epochs, opt.hyp, opt.batch_size<br><br>        <span class="hljs-comment"># Register actions</span><br>        <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> methods(loggers):<br>            callbacks.register_action(k, callback=<span class="hljs-built_in">getattr</span>(loggers, k))<br><br>    <span class="hljs-comment"># </span><br>    plots = <span class="hljs-keyword">not</span> evolve <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> opt.noplots  <span class="hljs-comment"># create plots</span><br>    cuda = device.<span class="hljs-built_in">type</span> != <span class="hljs-string">&#x27;cpu&#x27;</span><span class="hljs-comment"># </span><br>    init_seeds(<span class="hljs-number">1</span> + RANK)<span class="hljs-comment"># </span><br>    <span class="hljs-comment"># </span><br>    <span class="hljs-keyword">with</span> torch_distributed_zero_first(LOCAL_RANK):<br>        data_dict = data_dict <span class="hljs-keyword">or</span> check_dataset(data)  <span class="hljs-comment"># check if None</span><br>    <br>    <span class="hljs-comment"># </span><br>    train_path, val_path = data_dict[<span class="hljs-string">&#x27;train&#x27;</span>], data_dict[<span class="hljs-string">&#x27;val&#x27;</span>]<br>    nc = <span class="hljs-number">1</span> <span class="hljs-keyword">if</span> single_cls <span class="hljs-keyword">else</span> <span class="hljs-built_in">int</span>(data_dict[<span class="hljs-string">&#x27;nc&#x27;</span>])  <span class="hljs-comment"># class</span><br>    names = [<span class="hljs-string">&#x27;item&#x27;</span>] <span class="hljs-keyword">if</span> single_cls <span class="hljs-keyword">and</span> <span class="hljs-built_in">len</span>(data_dict[<span class="hljs-string">&#x27;names&#x27;</span>]) != <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> data_dict[<span class="hljs-string">&#x27;names&#x27;</span>]  <span class="hljs-comment"># class</span><br>    <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(names) == nc, <span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(names)&#125;</span> names found for nc=<span class="hljs-subst">&#123;nc&#125;</span> dataset in <span class="hljs-subst">&#123;data&#125;</span>&#x27;</span>  <span class="hljs-comment"># check</span><br>    is_coco = <span class="hljs-built_in">isinstance</span>(val_path, <span class="hljs-built_in">str</span>) <span class="hljs-keyword">and</span> val_path.endswith(<span class="hljs-string">&#x27;coco/val2017.txt&#x27;</span>)  <span class="hljs-comment"># COCO</span><br><br>    <span class="hljs-comment"># </span><br>    check_suffix(weights, <span class="hljs-string">&#x27;.pt&#x27;</span>)  <span class="hljs-comment"># </span><br>    pretrained = weights.endswith(<span class="hljs-string">&#x27;.pt&#x27;</span>)<span class="hljs-comment"># .pt</span><br>    <span class="hljs-keyword">if</span> pretrained: <span class="hljs-comment"># </span><br>        <span class="hljs-keyword">with</span> torch_distributed_zero_first(LOCAL_RANK):<br>            weights = attempt_download(weights)  <span class="hljs-comment"># </span><br>        <span class="hljs-comment"># CPUCUDA</span><br>        ckpt = torch.load(weights, map_location=<span class="hljs-string">&#x27;cpu&#x27;</span>) <br>        <span class="hljs-comment"># </span><br>        model = Model(cfg <span class="hljs-keyword">or</span> ckpt[<span class="hljs-string">&#x27;model&#x27;</span>].yaml, ch=<span class="hljs-number">3</span>, nc=nc, anchors=hyp.get(<span class="hljs-string">&#x27;anchors&#x27;</span>)).to(device)<br>        exclude = [<span class="hljs-string">&#x27;anchor&#x27;</span>] <span class="hljs-keyword">if</span> (cfg <span class="hljs-keyword">or</span> hyp.get(<span class="hljs-string">&#x27;anchors&#x27;</span>)) <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> resume <span class="hljs-keyword">else</span> []  <span class="hljs-comment"># exclude keys</span><br>        csd = ckpt[<span class="hljs-string">&#x27;model&#x27;</span>].<span class="hljs-built_in">float</span>().state_dict()  <span class="hljs-comment"># checkpoint state_dict as FP32</span><br>        csd = intersect_dicts(csd, model.state_dict(), exclude=exclude)  <span class="hljs-comment"># intersect</span><br>        model.load_state_dict(csd, strict=<span class="hljs-literal">False</span>)  <span class="hljs-comment"># load</span><br>        LOGGER.info(<span class="hljs-string">f&#x27;Transferred <span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(csd)&#125;</span>/<span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(model.state_dict())&#125;</span> items from <span class="hljs-subst">&#123;weights&#125;</span>&#x27;</span>)  <span class="hljs-comment"># report</span><br>    <span class="hljs-keyword">else</span>: <span class="hljs-comment"># </span><br>        <span class="hljs-comment"># </span><br>        model = Model(cfg, ch=<span class="hljs-number">3</span>, nc=nc, anchors=hyp.get(<span class="hljs-string">&#x27;anchors&#x27;</span>)).to(device)<br><br>    <span class="hljs-comment"># </span><br>    freeze = [<span class="hljs-string">f&#x27;model.<span class="hljs-subst">&#123;x&#125;</span>.&#x27;</span> <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> (freeze <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(freeze) &gt; <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-built_in">range</span>(freeze[<span class="hljs-number">0</span>]))]  <span class="hljs-comment"># layers to freeze</span><br>    <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> model.named_parameters():<br>        v.requires_grad = <span class="hljs-literal">True</span>  <span class="hljs-comment"># train all layers</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">any</span>(x <span class="hljs-keyword">in</span> k <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> freeze):<span class="hljs-comment"># </span><br>            LOGGER.info(<span class="hljs-string">f&#x27;freezing <span class="hljs-subst">&#123;k&#125;</span>&#x27;</span>)<br>            v.requires_grad = <span class="hljs-literal">False</span><br><br>    <span class="hljs-comment"># </span><br>    gs = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">int</span>(model.stride.<span class="hljs-built_in">max</span>()), <span class="hljs-number">32</span>)  <span class="hljs-comment"># grid size (max stride)</span><br>    imgsz = check_img_size(opt.imgsz, gs, floor=gs * <span class="hljs-number">2</span>)  <span class="hljs-comment"># verify imgsz is gs-multiple</span><br><br>    <span class="hljs-comment"># Batch size</span><br>    <span class="hljs-keyword">if</span> RANK == -<span class="hljs-number">1</span> <span class="hljs-keyword">and</span> batch_size == -<span class="hljs-number">1</span>:  <span class="hljs-comment"># single-GPU only, estimate best batch size</span><br>        batch_size = check_train_batch_size(model, imgsz)<br>        loggers.on_params_update(&#123;<span class="hljs-string">&quot;batch_size&quot;</span>: batch_size&#125;)<br><br>    <span class="hljs-comment"># </span><br>    nbs = <span class="hljs-number">64</span>  <span class="hljs-comment"># nominal batch size</span><br>    accumulate = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">round</span>(nbs / batch_size), <span class="hljs-number">1</span>)  <span class="hljs-comment"># accumulate loss before optimizing</span><br>    hyp[<span class="hljs-string">&#x27;weight_decay&#x27;</span>] *= batch_size * accumulate / nbs  <span class="hljs-comment"># scale weight_decay</span><br>    LOGGER.info(<span class="hljs-string">f&quot;Scaled weight_decay = <span class="hljs-subst">&#123;hyp[<span class="hljs-string">&#x27;weight_decay&#x27;</span>]&#125;</span>&quot;</span>)<br><br>    g = [], [], []  <span class="hljs-comment"># optimizer parameter groups</span><br>    bn = <span class="hljs-built_in">tuple</span>(v <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> nn.__dict__.items() <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;Norm&#x27;</span> <span class="hljs-keyword">in</span> k)  <span class="hljs-comment"># normalization layers, i.e. BatchNorm2d()</span><br>    <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> model.modules():<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(v, <span class="hljs-string">&#x27;bias&#x27;</span>) <span class="hljs-keyword">and</span> <span class="hljs-built_in">isinstance</span>(v.bias, nn.Parameter):  <span class="hljs-comment"># bias</span><br>            g[<span class="hljs-number">2</span>].append(v.bias)<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(v, bn):  <span class="hljs-comment"># weight (no decay)</span><br>            g[<span class="hljs-number">1</span>].append(v.weight)<br>        <span class="hljs-keyword">elif</span> <span class="hljs-built_in">hasattr</span>(v, <span class="hljs-string">&#x27;weight&#x27;</span>) <span class="hljs-keyword">and</span> <span class="hljs-built_in">isinstance</span>(v.weight, nn.Parameter):  <span class="hljs-comment"># weight (with decay)</span><br>            g[<span class="hljs-number">0</span>].append(v.weight)<br><br>    <span class="hljs-keyword">if</span> opt.optimizer == <span class="hljs-string">&#x27;Adam&#x27;</span>:<br>        optimizer = Adam(g[<span class="hljs-number">2</span>], lr=hyp[<span class="hljs-string">&#x27;lr0&#x27;</span>], betas=(hyp[<span class="hljs-string">&#x27;momentum&#x27;</span>], <span class="hljs-number">0.999</span>))  <span class="hljs-comment"># adjust beta1 to momentum</span><br>    <span class="hljs-keyword">elif</span> opt.optimizer == <span class="hljs-string">&#x27;AdamW&#x27;</span>:<br>        optimizer = AdamW(g[<span class="hljs-number">2</span>], lr=hyp[<span class="hljs-string">&#x27;lr0&#x27;</span>], betas=(hyp[<span class="hljs-string">&#x27;momentum&#x27;</span>], <span class="hljs-number">0.999</span>))  <span class="hljs-comment"># adjust beta1 to momentum</span><br>    <span class="hljs-keyword">else</span>:<br>        optimizer = SGD(g[<span class="hljs-number">2</span>], lr=hyp[<span class="hljs-string">&#x27;lr0&#x27;</span>], momentum=hyp[<span class="hljs-string">&#x27;momentum&#x27;</span>], nesterov=<span class="hljs-literal">True</span>)<br><br>    optimizer.add_param_group(&#123;<span class="hljs-string">&#x27;params&#x27;</span>: g[<span class="hljs-number">0</span>], <span class="hljs-string">&#x27;weight_decay&#x27;</span>: hyp[<span class="hljs-string">&#x27;weight_decay&#x27;</span>]&#125;)  <span class="hljs-comment"># add g0 with weight_decay</span><br>    optimizer.add_param_group(&#123;<span class="hljs-string">&#x27;params&#x27;</span>: g[<span class="hljs-number">1</span>]&#125;)  <span class="hljs-comment"># add g1 (BatchNorm2d weights)</span><br>    LOGGER.info(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;colorstr(<span class="hljs-string">&#x27;optimizer:&#x27;</span>)&#125;</span> <span class="hljs-subst">&#123;<span class="hljs-built_in">type</span>(optimizer).__name__&#125;</span> with parameter groups &quot;</span><br>                <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(g[<span class="hljs-number">1</span>])&#125;</span> weight (no decay), <span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(g[<span class="hljs-number">0</span>])&#125;</span> weight, <span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(g[<span class="hljs-number">2</span>])&#125;</span> bias&quot;</span>)<br>    <span class="hljs-keyword">del</span> g<br><br>    <span class="hljs-comment"># </span><br>    <span class="hljs-keyword">if</span> opt.cos_lr:<br>        lf = one_cycle(<span class="hljs-number">1</span>, hyp[<span class="hljs-string">&#x27;lrf&#x27;</span>], epochs)  <span class="hljs-comment"># cosine 1-&gt;hyp[&#x27;lrf&#x27;]</span><br>    <span class="hljs-keyword">else</span>:<br>        lf = <span class="hljs-keyword">lambda</span> x: (<span class="hljs-number">1</span> - x / epochs) * (<span class="hljs-number">1.0</span> - hyp[<span class="hljs-string">&#x27;lrf&#x27;</span>]) + hyp[<span class="hljs-string">&#x27;lrf&#x27;</span>]  <span class="hljs-comment"># linear</span><br>    <span class="hljs-comment"># Deep Learningpytorch</span><br>    scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)  <span class="hljs-comment"># plot_lr_scheduler(optimizer, scheduler, epochs)</span><br><br>    <span class="hljs-comment"># EMAstate_dict</span><br>    ema = ModelEMA(model) <span class="hljs-keyword">if</span> RANK <span class="hljs-keyword">in</span> [-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>] <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span><br><br>    <span class="hljs-comment"># </span><br>    start_epoch, best_fitness = <span class="hljs-number">0</span>, <span class="hljs-number">0.0</span><br>    <span class="hljs-keyword">if</span> pretrained:<span class="hljs-comment"># </span><br>        <span class="hljs-comment"># Optimizer</span><br>        <span class="hljs-keyword">if</span> ckpt[<span class="hljs-string">&#x27;optimizer&#x27;</span>] <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            optimizer.load_state_dict(ckpt[<span class="hljs-string">&#x27;optimizer&#x27;</span>])<br>            best_fitness = ckpt[<span class="hljs-string">&#x27;best_fitness&#x27;</span>]<br><br>        <span class="hljs-comment"># EMA</span><br>        <span class="hljs-keyword">if</span> ema <span class="hljs-keyword">and</span> ckpt.get(<span class="hljs-string">&#x27;ema&#x27;</span>):<br>            ema.ema.load_state_dict(ckpt[<span class="hljs-string">&#x27;ema&#x27;</span>].<span class="hljs-built_in">float</span>().state_dict())<br>            ema.updates = ckpt[<span class="hljs-string">&#x27;updates&#x27;</span>]<br><br>        <span class="hljs-comment"># Epochs</span><br>        start_epoch = ckpt[<span class="hljs-string">&#x27;epoch&#x27;</span>] + <span class="hljs-number">1</span><br>        <span class="hljs-keyword">if</span> resume:<br>            <span class="hljs-keyword">assert</span> start_epoch &gt; <span class="hljs-number">0</span>, <span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;weights&#125;</span> training to <span class="hljs-subst">&#123;epochs&#125;</span> epochs is finished, nothing to resume.&#x27;</span><br>        <span class="hljs-keyword">if</span> epochs &lt; start_epoch:<br>            LOGGER.info(<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;weights&#125;</span> has been trained for <span class="hljs-subst">&#123;ckpt[<span class="hljs-string">&#x27;epoch&#x27;</span>]&#125;</span> epochs. Fine-tuning for <span class="hljs-subst">&#123;epochs&#125;</span> more epochs.&quot;</span>)<br>            epochs += ckpt[<span class="hljs-string">&#x27;epoch&#x27;</span>]  <span class="hljs-comment"># finetune additional epochs</span><br><br>        <span class="hljs-keyword">del</span> ckpt, csd<br><br>    <span class="hljs-comment"># </span><br>    <span class="hljs-keyword">if</span> cuda <span class="hljs-keyword">and</span> RANK == -<span class="hljs-number">1</span> <span class="hljs-keyword">and</span> torch.cuda.device_count() &gt; <span class="hljs-number">1</span>:<br>        LOGGER.warning(<span class="hljs-string">&#x27;WARNING: DP not recommended, use torch.distributed.run for best DDP Multi-GPU results.\n&#x27;</span><br>                       <span class="hljs-string">&#x27;See Multi-GPU Tutorial at https://github.com/ultralytics/yolov5/issues/475 to get started.&#x27;</span>)<br>        model = torch.nn.DataParallel(model)<br><br>    <span class="hljs-comment"># SyncBatchNorm</span><br>    <span class="hljs-keyword">if</span> opt.sync_bn <span class="hljs-keyword">and</span> cuda <span class="hljs-keyword">and</span> RANK != -<span class="hljs-number">1</span>:<br>        model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model).to(device)<br>        LOGGER.info(<span class="hljs-string">&#x27;Using SyncBatchNorm()&#x27;</span>)<br><br>    <span class="hljs-comment"># Trainloader</span><br>    train_loader, dataset = create_dataloader(train_path,<br>                                              imgsz,<br>                                              batch_size // WORLD_SIZE,<br>                                              gs,<br>                                              single_cls,<br>                                              hyp=hyp,<br>                                              augment=<span class="hljs-literal">True</span>,<br>                                              cache=<span class="hljs-literal">None</span> <span class="hljs-keyword">if</span> opt.cache == <span class="hljs-string">&#x27;val&#x27;</span> <span class="hljs-keyword">else</span> opt.cache,<br>                                              rect=opt.rect,<br>                                              rank=LOCAL_RANK,<br>                                              workers=workers,<br>                                              image_weights=opt.image_weights,<br>                                              quad=opt.quad,<br>                                              prefix=colorstr(<span class="hljs-string">&#x27;train: &#x27;</span>),<br>                                              shuffle=<span class="hljs-literal">True</span>)<br>    mlc = <span class="hljs-built_in">int</span>(np.concatenate(dataset.labels, <span class="hljs-number">0</span>)[:, <span class="hljs-number">0</span>].<span class="hljs-built_in">max</span>())  <span class="hljs-comment"># max label class</span><br>    nb = <span class="hljs-built_in">len</span>(train_loader)  <span class="hljs-comment"># number of batches</span><br>    <span class="hljs-keyword">assert</span> mlc &lt; nc, <span class="hljs-string">f&#x27;Label class <span class="hljs-subst">&#123;mlc&#125;</span> exceeds nc=<span class="hljs-subst">&#123;nc&#125;</span> in <span class="hljs-subst">&#123;data&#125;</span>. Possible class labels are 0-<span class="hljs-subst">&#123;nc - <span class="hljs-number">1</span>&#125;</span>&#x27;</span><br><br>    <span class="hljs-comment"># dataloader</span><br>    <span class="hljs-keyword">if</span> RANK <span class="hljs-keyword">in</span> [-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>]:<br>        val_loader = create_dataloader(val_path,<br>                                       imgsz,<br>                                       batch_size // WORLD_SIZE * <span class="hljs-number">2</span>,<br>                                       gs,<br>                                       single_cls,<br>                                       hyp=hyp,<br>                                       cache=<span class="hljs-literal">None</span> <span class="hljs-keyword">if</span> noval <span class="hljs-keyword">else</span> opt.cache,<br>                                       rect=<span class="hljs-literal">True</span>,<br>                                       rank=-<span class="hljs-number">1</span>,<br>                                       workers=workers * <span class="hljs-number">2</span>,<br>                                       pad=<span class="hljs-number">0.5</span>,<br>                                       prefix=colorstr(<span class="hljs-string">&#x27;val: &#x27;</span>))[<span class="hljs-number">0</span>]<br><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> resume:<br>            labels = np.concatenate(dataset.labels, <span class="hljs-number">0</span>)<br>            <span class="hljs-comment"># c = torch.tensor(labels[:, 0])  # classes</span><br>            <span class="hljs-comment"># cf = torch.bincount(c.long(), minlength=nc) + 1.  # frequency</span><br>            <span class="hljs-comment"># model._initialize_biases(cf.to(device))</span><br>            <span class="hljs-keyword">if</span> plots:<br>                plot_labels(labels, names, save_dir)<br><br>            <span class="hljs-comment"># Anchors</span><br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.noautoanchor:<br>                check_anchors(dataset, model=model, thr=hyp[<span class="hljs-string">&#x27;anchor_t&#x27;</span>], imgsz=imgsz)<br>            model.half().<span class="hljs-built_in">float</span>()  <span class="hljs-comment"># pre-reduce anchor precision</span><br><br>        callbacks.run(<span class="hljs-string">&#x27;on_pretrain_routine_end&#x27;</span>)<br><br>    <span class="hljs-comment"># </span><br>    <span class="hljs-keyword">if</span> cuda <span class="hljs-keyword">and</span> RANK != -<span class="hljs-number">1</span>:<br>        model = DDP(model, device_ids=[LOCAL_RANK], output_device=LOCAL_RANK)<br><br>    <span class="hljs-comment"># Model attributes</span><br>    nl = de_parallel(model).model[-<span class="hljs-number">1</span>].nl  <span class="hljs-comment"># number of detection layers (to scale hyps)</span><br>    hyp[<span class="hljs-string">&#x27;box&#x27;</span>] *= <span class="hljs-number">3</span> / nl  <span class="hljs-comment"># scale to layers</span><br>    hyp[<span class="hljs-string">&#x27;cls&#x27;</span>] *= nc / <span class="hljs-number">80</span> * <span class="hljs-number">3</span> / nl  <span class="hljs-comment"># scale to classes and layers</span><br>    hyp[<span class="hljs-string">&#x27;obj&#x27;</span>] *= (imgsz / <span class="hljs-number">640</span>) ** <span class="hljs-number">2</span> * <span class="hljs-number">3</span> / nl  <span class="hljs-comment"># scale to image size and layers</span><br>    hyp[<span class="hljs-string">&#x27;label_smoothing&#x27;</span>] = opt.label_smoothing<br>    model.nc = nc  <span class="hljs-comment"># attach number of classes to model</span><br>    model.hyp = hyp  <span class="hljs-comment"># attach hyperparameters to model</span><br>    model.class_weights = labels_to_class_weights(dataset.labels, nc).to(device) * nc  <span class="hljs-comment"># attach class weights</span><br>    model.names = names<br><br>    <span class="hljs-comment"># </span><br>    t0 = time.time()<span class="hljs-comment"># </span><br>    nw = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">round</span>(hyp[<span class="hljs-string">&#x27;warmup_epochs&#x27;</span>] * nb), <span class="hljs-number">100</span>)  <span class="hljs-comment"># number of warmup iterations, max(3 epochs, 100 iterations)</span><br>    <span class="hljs-comment"># nw = min(nw, (epochs - start_epoch) / 2 * nb)  # limit warmup to &lt; 1/2 of training</span><br>    last_opt_step = -<span class="hljs-number">1</span><br>    maps = np.zeros(nc)  <span class="hljs-comment"># mAP per class</span><br>    results = (<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>)  <span class="hljs-comment"># P, R, mAP@.5, mAP@.5-.95, val_loss(box, obj, cls)</span><br>    scheduler.last_epoch = start_epoch - <span class="hljs-number">1</span>  <span class="hljs-comment"># do not move</span><br>    scaler = amp.GradScaler(enabled=cuda)<span class="hljs-comment"># </span><br>    stopper = EarlyStopping(patience=opt.patience)<br>    compute_loss = ComputeLoss(model)  <span class="hljs-comment"># losslossutils/loss.py</span><br>    callbacks.run(<span class="hljs-string">&#x27;on_train_start&#x27;</span>)<br>    LOGGER.info(<span class="hljs-string">f&#x27;Image sizes <span class="hljs-subst">&#123;imgsz&#125;</span> train, <span class="hljs-subst">&#123;imgsz&#125;</span> val\n&#x27;</span><br>                <span class="hljs-string">f&#x27;Using <span class="hljs-subst">&#123;train_loader.num_workers * WORLD_SIZE&#125;</span> dataloader workers\n&#x27;</span><br>                <span class="hljs-string">f&quot;Logging results to <span class="hljs-subst">&#123;colorstr(<span class="hljs-string">&#x27;bold&#x27;</span>, save_dir)&#125;</span>\n&quot;</span><br>                <span class="hljs-string">f&#x27;Starting training for <span class="hljs-subst">&#123;epochs&#125;</span> epochs...&#x27;</span>)<br>    <span class="hljs-comment"># epoch</span><br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(start_epoch, epochs):  <span class="hljs-comment"># epoch ------------------------------------------------------------------</span><br>        callbacks.run(<span class="hljs-string">&#x27;on_train_epoch_start&#x27;</span>)<br>        model.train()<br><br>        <span class="hljs-comment"># Update image weights (optional, single-GPU only)</span><br>        <span class="hljs-keyword">if</span> opt.image_weights:<br>            cw = model.class_weights.cpu().numpy() * (<span class="hljs-number">1</span> - maps) ** <span class="hljs-number">2</span> / nc  <span class="hljs-comment"># class weights</span><br>            iw = labels_to_image_weights(dataset.labels, nc=nc, class_weights=cw)  <span class="hljs-comment"># image weights</span><br>            dataset.indices = random.choices(<span class="hljs-built_in">range</span>(dataset.n), weights=iw, k=dataset.n)  <span class="hljs-comment"># rand weighted idx</span><br><br>        <span class="hljs-comment"># Update mosaic border (optional)</span><br>        <span class="hljs-comment"># b = int(random.uniform(0.25 * imgsz, 0.75 * imgsz + gs) // gs * gs)</span><br>        <span class="hljs-comment"># dataset.mosaic_border = [b - imgsz, -b]  # height, width borders</span><br><br>        mloss = torch.zeros(<span class="hljs-number">3</span>, device=device)  <span class="hljs-comment"># mean losses</span><br>        <span class="hljs-keyword">if</span> RANK != -<span class="hljs-number">1</span>:<br>            train_loader.sampler.set_epoch(epoch)<br>        pbar = <span class="hljs-built_in">enumerate</span>(train_loader)<br>        LOGGER.info((<span class="hljs-string">&#x27;\n&#x27;</span> + <span class="hljs-string">&#x27;%10s&#x27;</span> * <span class="hljs-number">7</span>) % (<span class="hljs-string">&#x27;Epoch&#x27;</span>, <span class="hljs-string">&#x27;gpu_mem&#x27;</span>, <span class="hljs-string">&#x27;box&#x27;</span>, <span class="hljs-string">&#x27;obj&#x27;</span>, <span class="hljs-string">&#x27;cls&#x27;</span>, <span class="hljs-string">&#x27;labels&#x27;</span>, <span class="hljs-string">&#x27;img_size&#x27;</span>))<br>        <span class="hljs-keyword">if</span> RANK <span class="hljs-keyword">in</span> (-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>):<br>            pbar = tqdm(pbar, total=nb, bar_format=<span class="hljs-string">&#x27;&#123;l_bar&#125;&#123;bar:10&#125;&#123;r_bar&#125;&#123;bar:-10b&#125;&#x27;</span>)  <span class="hljs-comment"># </span><br>        optimizer.zero_grad()<span class="hljs-comment"># </span><br>        <span class="hljs-comment"># batch</span><br>        <span class="hljs-keyword">for</span> i, (imgs, targets, paths, _) <span class="hljs-keyword">in</span> pbar:  <span class="hljs-comment"># batch -------------------------------------------------------------</span><br>            callbacks.run(<span class="hljs-string">&#x27;on_train_batch_start&#x27;</span>)<br>            ni = i + nb * epoch  <span class="hljs-comment"># number integrated batches (since train start)</span><br>            imgs = imgs.to(device, non_blocking=<span class="hljs-literal">True</span>).<span class="hljs-built_in">float</span>() / <span class="hljs-number">255</span>  <span class="hljs-comment"># uint8 to float32, 0-255 to 0.0-1.0</span><br><br>            <span class="hljs-comment"># </span><br>            <span class="hljs-keyword">if</span> ni &lt;= nw:<br>                xi = [<span class="hljs-number">0</span>, nw]  <span class="hljs-comment"># x interp</span><br>                <span class="hljs-comment"># compute_loss.gr = np.interp(ni, xi, [0.0, 1.0])  # iou loss ratio (obj_loss = 1.0 or iou)</span><br>                accumulate = <span class="hljs-built_in">max</span>(<span class="hljs-number">1</span>, np.interp(ni, xi, [<span class="hljs-number">1</span>, nbs / batch_size]).<span class="hljs-built_in">round</span>())<br>                <span class="hljs-keyword">for</span> j, x <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(optimizer.param_groups):<br>                    <span class="hljs-comment"># bias lr falls from 0.1 to lr0, all other lrs rise from 0.0 to lr0</span><br>                    x[<span class="hljs-string">&#x27;lr&#x27;</span>] = np.interp(ni, xi, [hyp[<span class="hljs-string">&#x27;warmup_bias_lr&#x27;</span>] <span class="hljs-keyword">if</span> j == <span class="hljs-number">2</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0.0</span>, x[<span class="hljs-string">&#x27;initial_lr&#x27;</span>] * lf(epoch)])<br>                    <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;momentum&#x27;</span> <span class="hljs-keyword">in</span> x:<br>                        x[<span class="hljs-string">&#x27;momentum&#x27;</span>] = np.interp(ni, xi, [hyp[<span class="hljs-string">&#x27;warmup_momentum&#x27;</span>], hyp[<span class="hljs-string">&#x27;momentum&#x27;</span>]])<br><br>            <span class="hljs-comment"># </span><br>            <span class="hljs-keyword">if</span> opt.multi_scale:<br>                sz = random.randrange(imgsz * <span class="hljs-number">0.5</span>, imgsz * <span class="hljs-number">1.5</span> + gs) // gs * gs  <span class="hljs-comment"># size</span><br>                sf = sz / <span class="hljs-built_in">max</span>(imgs.shape[<span class="hljs-number">2</span>:])  <span class="hljs-comment"># scale factor</span><br>                <span class="hljs-keyword">if</span> sf != <span class="hljs-number">1</span>:<br>                    ns = [math.ceil(x * sf / gs) * gs <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> imgs.shape[<span class="hljs-number">2</span>:]]  <span class="hljs-comment"># new shape (stretched to gs-multiple)</span><br>                    imgs = nn.functional.interpolate(imgs, size=ns, mode=<span class="hljs-string">&#x27;bilinear&#x27;</span>, align_corners=<span class="hljs-literal">False</span>)<br><br>            <span class="hljs-comment"># loss</span><br>            <span class="hljs-keyword">with</span> amp.autocast(enabled=cuda):<br>                pred = model(imgs)  <span class="hljs-comment"># forward</span><br>                loss, loss_items = compute_loss(pred, targets.to(device))  <span class="hljs-comment"># loss scaled by batch_size</span><br>                <span class="hljs-keyword">if</span> RANK != -<span class="hljs-number">1</span>:<br>                    loss *= WORLD_SIZE  <span class="hljs-comment"># gradient averaged between devices in DDP mode</span><br>                <span class="hljs-keyword">if</span> opt.quad:<br>                    loss *= <span class="hljs-number">4.</span><br><br>            <span class="hljs-comment"># </span><br>            scaler.scale(loss).backward()<br><br>            <span class="hljs-comment"># </span><br>            <span class="hljs-keyword">if</span> ni - last_opt_step &gt;= accumulate:<br>                scaler.step(optimizer)  <span class="hljs-comment"># optimizer.step</span><br>                scaler.update()<br>                optimizer.zero_grad()<br>                <span class="hljs-keyword">if</span> ema:<br>                    ema.update(model)<br>                last_opt_step = ni<br><br>            <span class="hljs-comment"># </span><br>            <span class="hljs-keyword">if</span> RANK <span class="hljs-keyword">in</span> (-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>):<br>                mloss = (mloss * i + loss_items) / (i + <span class="hljs-number">1</span>)  <span class="hljs-comment"># update mean losses</span><br>                mem = <span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;torch.cuda.memory_reserved() / <span class="hljs-number">1E9</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>:<span class="hljs-number">.3</span>g&#125;</span>G&#x27;</span>  <span class="hljs-comment"># (GB)</span><br>                pbar.set_description((<span class="hljs-string">&#x27;%10s&#x27;</span> * <span class="hljs-number">2</span> + <span class="hljs-string">&#x27;%10.4g&#x27;</span> * <span class="hljs-number">5</span>) %<br>                                     (<span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;epoch&#125;</span>/<span class="hljs-subst">&#123;epochs - <span class="hljs-number">1</span>&#125;</span>&#x27;</span>, mem, *mloss, targets.shape[<span class="hljs-number">0</span>], imgs.shape[-<span class="hljs-number">1</span>]))<br>                callbacks.run(<span class="hljs-string">&#x27;on_train_batch_end&#x27;</span>, ni, model, imgs, targets, paths, plots)<br>                <span class="hljs-keyword">if</span> callbacks.stop_training:<br>                    <span class="hljs-keyword">return</span><br>            <span class="hljs-comment"># end batch ------------------------------------------------------------------------------------------------</span><br><br>        <span class="hljs-comment"># </span><br>        lr = [x[<span class="hljs-string">&#x27;lr&#x27;</span>] <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> optimizer.param_groups]  <span class="hljs-comment"># for loggers</span><br>        scheduler.step()<br><br>        <span class="hljs-keyword">if</span> RANK <span class="hljs-keyword">in</span> (-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>):<br>            <span class="hljs-comment"># mAP</span><br>            callbacks.run(<span class="hljs-string">&#x27;on_train_epoch_end&#x27;</span>, epoch=epoch)<br>            ema.update_attr(model, include=[<span class="hljs-string">&#x27;yaml&#x27;</span>, <span class="hljs-string">&#x27;nc&#x27;</span>, <span class="hljs-string">&#x27;hyp&#x27;</span>, <span class="hljs-string">&#x27;names&#x27;</span>, <span class="hljs-string">&#x27;stride&#x27;</span>, <span class="hljs-string">&#x27;class_weights&#x27;</span>])<br>            final_epoch = (epoch + <span class="hljs-number">1</span> == epochs) <span class="hljs-keyword">or</span> stopper.possible_stop<br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> noval <span class="hljs-keyword">or</span> final_epoch:  <span class="hljs-comment"># Calculate mAP</span><br>                results, maps, _ = val.run(data_dict,<span class="hljs-comment"># mAPval.py</span><br>                                           batch_size=batch_size // WORLD_SIZE * <span class="hljs-number">2</span>,<br>                                           imgsz=imgsz,<br>                                           model=ema.ema,<br>                                           single_cls=single_cls,<br>                                           dataloader=val_loader,<br>                                           save_dir=save_dir,<br>                                           plots=<span class="hljs-literal">False</span>,<br>                                           callbacks=callbacks,<br>                                           compute_loss=compute_loss)<br><br>            <span class="hljs-comment"># mAP</span><br>            fi = fitness(np.array(results).reshape(<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>))  <span class="hljs-comment"># weighted combination of [P, R, mAP@.5, mAP@.5-.95]</span><br>            <span class="hljs-keyword">if</span> fi &gt; best_fitness:<br>                best_fitness = fi<br>            log_vals = <span class="hljs-built_in">list</span>(mloss) + <span class="hljs-built_in">list</span>(results) + lr<br>            callbacks.run(<span class="hljs-string">&#x27;on_fit_epoch_end&#x27;</span>, log_vals, epoch, best_fitness, fi)<br><br>            <span class="hljs-comment"># </span><br>            <span class="hljs-keyword">if</span> (<span class="hljs-keyword">not</span> nosave) <span class="hljs-keyword">or</span> (final_epoch <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> evolve):  <span class="hljs-comment"># if save</span><br>                ckpt = &#123;<br>                    <span class="hljs-string">&#x27;epoch&#x27;</span>: epoch,<br>                    <span class="hljs-string">&#x27;best_fitness&#x27;</span>: best_fitness,<br>                    <span class="hljs-string">&#x27;model&#x27;</span>: deepcopy(de_parallel(model)).half(),<br>                    <span class="hljs-string">&#x27;ema&#x27;</span>: deepcopy(ema.ema).half(),<br>                    <span class="hljs-string">&#x27;updates&#x27;</span>: ema.updates,<br>                    <span class="hljs-string">&#x27;optimizer&#x27;</span>: optimizer.state_dict(),<br>                    <span class="hljs-string">&#x27;wandb_id&#x27;</span>: loggers.wandb.wandb_run.<span class="hljs-built_in">id</span> <span class="hljs-keyword">if</span> loggers.wandb <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>,<br>                    <span class="hljs-string">&#x27;date&#x27;</span>: datetime.now().isoformat()&#125;<br><br>                <span class="hljs-comment"># </span><br>                torch.save(ckpt, last)<br>                <span class="hljs-keyword">if</span> best_fitness == fi:<br>                    torch.save(ckpt, best)<br>                <span class="hljs-keyword">if</span> (epoch &gt; <span class="hljs-number">0</span>) <span class="hljs-keyword">and</span> (opt.save_period &gt; <span class="hljs-number">0</span>) <span class="hljs-keyword">and</span> (epoch % opt.save_period == <span class="hljs-number">0</span>):<br>                    torch.save(ckpt, w / <span class="hljs-string">f&#x27;epoch<span class="hljs-subst">&#123;epoch&#125;</span>.pt&#x27;</span>)<br>                <span class="hljs-keyword">del</span> ckpt<br>                callbacks.run(<span class="hljs-string">&#x27;on_model_save&#x27;</span>, last, epoch, final_epoch, best_fitness, fi)<br><br>            <span class="hljs-comment"># Stop Single-GPU</span><br>            <span class="hljs-keyword">if</span> RANK == -<span class="hljs-number">1</span> <span class="hljs-keyword">and</span> stopper(epoch=epoch, fitness=fi):<br>                <span class="hljs-keyword">break</span><br><br>            <span class="hljs-comment"># Stop DDP <span class="hljs-doctag">TODO:</span> known issues shttps://github.com/ultralytics/yolov5/pull/4576</span><br>            <span class="hljs-comment"># stop = stopper(epoch=epoch, fitness=fi)</span><br>            <span class="hljs-comment"># if RANK == 0:</span><br>            <span class="hljs-comment">#    dist.broadcast_object_list([stop], 0)  # broadcast &#x27;stop&#x27; to all ranks</span><br><br>        <span class="hljs-comment"># Stop DPP</span><br>        <span class="hljs-comment"># with torch_distributed_zero_first(RANK):</span><br>        <span class="hljs-comment"># if stop:</span><br>        <span class="hljs-comment">#    break  # must break all DDP ranks</span><br><br>        <span class="hljs-comment"># end epoch ----------------------------------------------------------------------------------------------------</span><br>    <span class="hljs-comment"># end training -----------------------------------------------------------------------------------------------------</span><br>    <span class="hljs-keyword">if</span> RANK <span class="hljs-keyword">in</span> (-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>):<br>        LOGGER.info(<span class="hljs-string">f&#x27;\n<span class="hljs-subst">&#123;epoch - start_epoch + <span class="hljs-number">1</span>&#125;</span> epochs completed in <span class="hljs-subst">&#123;(time.time() - t0) / <span class="hljs-number">3600</span>:<span class="hljs-number">.3</span>f&#125;</span> hours.&#x27;</span>)<br>        <span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> last, best:<br>            <span class="hljs-keyword">if</span> f.exists():<br>                strip_optimizer(f)  <span class="hljs-comment"># strip optimizers</span><br>                <span class="hljs-keyword">if</span> f <span class="hljs-keyword">is</span> best:<br>                    LOGGER.info(<span class="hljs-string">f&#x27;\nValidating <span class="hljs-subst">&#123;f&#125;</span>...&#x27;</span>)<br>                    results, _, _ = val.run(<span class="hljs-comment"># mAP</span><br>                        data_dict,<br>                        batch_size=batch_size // WORLD_SIZE * <span class="hljs-number">2</span>,<br>                        imgsz=imgsz,<br>                        model=attempt_load(f, device).half(),<br>                        iou_thres=<span class="hljs-number">0.65</span> <span class="hljs-keyword">if</span> is_coco <span class="hljs-keyword">else</span> <span class="hljs-number">0.60</span>,  <span class="hljs-comment"># best pycocotools results at 0.65</span><br>                        single_cls=single_cls,<br>                        dataloader=val_loader,<br>                        save_dir=save_dir,<br>                        save_json=is_coco,<br>                        verbose=<span class="hljs-literal">True</span>,<br>                        plots=plots,<br>                        callbacks=callbacks,<br>                        compute_loss=compute_loss)  <span class="hljs-comment"># val best model with plots</span><br>                    <span class="hljs-keyword">if</span> is_coco:<br>                        callbacks.run(<span class="hljs-string">&#x27;on_fit_epoch_end&#x27;</span>, <span class="hljs-built_in">list</span>(mloss) + <span class="hljs-built_in">list</span>(results) + lr, epoch, best_fitness, fi)<br><br>        callbacks.run(<span class="hljs-string">&#x27;on_train_end&#x27;</span>, last, best, plots, epoch, results)<br>        LOGGER.info(<span class="hljs-string">f&quot;Results saved to <span class="hljs-subst">&#123;colorstr(<span class="hljs-string">&#x27;bold&#x27;</span>, save_dir)&#125;</span>&quot;</span>)<br><br>    torch.cuda.empty_cache()<br>    <span class="hljs-keyword">return</span> results<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">parse_opt</span>(<span class="hljs-params">known=<span class="hljs-literal">False</span></span>):<br>    <span class="hljs-comment"># </span><br>    parser = argparse.ArgumentParser()<br>    <span class="hljs-comment"># </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--weights&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=ROOT / <span class="hljs-string">&#x27;yolov5s.pt&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;initial weights path&#x27;</span>)<br>    <span class="hljs-comment"># yaml</span><br>    parser.add_argument(<span class="hljs-string">&#x27;--cfg&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=<span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;model.yaml path&#x27;</span>)<br>    <span class="hljs-comment"># yaml</span><br>    parser.add_argument(<span class="hljs-string">&#x27;--data&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=ROOT / <span class="hljs-string">&#x27;data/coco128.yaml&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;dataset.yaml path&#x27;</span>)<br>    <span class="hljs-comment"># yaml</span><br>    parser.add_argument(<span class="hljs-string">&#x27;--hyp&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=ROOT / <span class="hljs-string">&#x27;data/hyps/hyp.scratch-low.yaml&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;hyperparameters path&#x27;</span>)<br>    <span class="hljs-comment"># epoch</span><br>    parser.add_argument(<span class="hljs-string">&#x27;--epochs&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">300</span>)<br>    <span class="hljs-comment"># batch_size</span><br>    parser.add_argument(<span class="hljs-string">&#x27;--batch-size&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">16</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;total batch size for all GPUs, -1 for autobatch&#x27;</span>)<br>    <span class="hljs-comment"># size</span><br>    parser.add_argument(<span class="hljs-string">&#x27;--imgsz&#x27;</span>, <span class="hljs-string">&#x27;--img&#x27;</span>, <span class="hljs-string">&#x27;--img-size&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">640</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;train, val image size (pixels)&#x27;</span>)<br>    <span class="hljs-comment"># (640,640)32</span><br>    parser.add_argument(<span class="hljs-string">&#x27;--rect&#x27;</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;rectangular training&#x27;</span>)<br>    <span class="hljs-comment"># </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--resume&#x27;</span>, nargs=<span class="hljs-string">&#x27;?&#x27;</span>, const=<span class="hljs-literal">True</span>, default=<span class="hljs-literal">False</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;resume most recent training&#x27;</span>)<br>    <span class="hljs-comment"># pt</span><br>    parser.add_argument(<span class="hljs-string">&#x27;--nosave&#x27;</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;only save final checkpoint&#x27;</span>)<br>    <span class="hljs-comment"># map</span><br>    parser.add_argument(<span class="hljs-string">&#x27;--noval&#x27;</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;only validate final epoch&#x27;</span>)<br>    <span class="hljs-comment"># </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--noautoanchor&#x27;</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;disable AutoAnchor&#x27;</span>)<br>    <span class="hljs-comment"># </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--noplots&#x27;</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;save no plot files&#x27;</span>)<br>    <span class="hljs-comment"># </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--evolve&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, nargs=<span class="hljs-string">&#x27;?&#x27;</span>, const=<span class="hljs-number">300</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;evolve hyperparameters for x generations&#x27;</span>)<br>    <span class="hljs-comment"># </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--bucket&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=<span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;gsutil bucket&#x27;</span>)<br>    <span class="hljs-comment"># </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--cache&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, nargs=<span class="hljs-string">&#x27;?&#x27;</span>, const=<span class="hljs-string">&#x27;ram&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;--cache images in &quot;ram&quot; (default) or &quot;disk&quot;&#x27;</span>)<br>    <span class="hljs-comment"># </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--image-weights&#x27;</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;use weighted image selection for training&#x27;</span>)<br>    <span class="hljs-comment"># </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--device&#x27;</span>, default=<span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;cuda device, i.e. 0 or 0,1,2,3 or cpu&#x27;</span>)<br>    <span class="hljs-comment"># </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--multi-scale&#x27;</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;vary img-size +/- 50%%&#x27;</span>)<br>    <span class="hljs-comment"># </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--single-cls&#x27;</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;train multi-class data as single-class&#x27;</span>)<br>    <span class="hljs-comment"># SGDSGDAdamAdamW</span><br>    parser.add_argument(<span class="hljs-string">&#x27;--optimizer&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, choices=[<span class="hljs-string">&#x27;SGD&#x27;</span>, <span class="hljs-string">&#x27;Adam&#x27;</span>, <span class="hljs-string">&#x27;AdamW&#x27;</span>], default=<span class="hljs-string">&#x27;SGD&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;optimizer&#x27;</span>)<br>    <span class="hljs-comment"># GPU</span><br>    parser.add_argument(<span class="hljs-string">&#x27;--sync-bn&#x27;</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;use SyncBatchNorm, only available in DDP mode&#x27;</span>)<br>    <span class="hljs-comment"># workers</span><br>    parser.add_argument(<span class="hljs-string">&#x27;--workers&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">8</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;max dataloader workers (per RANK in DDP mode)&#x27;</span>)<br>    <span class="hljs-comment"># </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--project&#x27;</span>, default=ROOT / <span class="hljs-string">&#x27;runs/train&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;save to project/name&#x27;</span>)<br>    <span class="hljs-comment"># </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--name&#x27;</span>, default=<span class="hljs-string">&#x27;exp&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;save to project/name&#x27;</span>)<br>    <span class="hljs-comment"># </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--exist-ok&#x27;</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;existing project/name ok, do not increment&#x27;</span>)<br>    <span class="hljs-comment"># </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--quad&#x27;</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;quad dataloader&#x27;</span>)<br>    <span class="hljs-comment"># </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--cos-lr&#x27;</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;cosine LR scheduler&#x27;</span>)<br>    <span class="hljs-comment"># sample</span><br>    parser.add_argument(<span class="hljs-string">&#x27;--label-smoothing&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">float</span>, default=<span class="hljs-number">0.0</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;Label smoothing epsilon&#x27;</span>)<br>    <span class="hljs-comment"># </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--patience&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">100</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;EarlyStopping patience (epochs without improvement)&#x27;</span>)<br>    <span class="hljs-comment"># </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--freeze&#x27;</span>, nargs=<span class="hljs-string">&#x27;+&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=[<span class="hljs-number">0</span>], <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;Freeze layers: backbone=10, first3=0 1 2&#x27;</span>)<br>    <span class="hljs-comment"># epochcheckpoints</span><br>    parser.add_argument(<span class="hljs-string">&#x27;--save-period&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=-<span class="hljs-number">1</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;Save checkpoint every x epochs (disabled if &lt; 1)&#x27;</span>)<br>    <span class="hljs-comment"># </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--local_rank&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=-<span class="hljs-number">1</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;DDP parameter, do not modify&#x27;</span>)<br><br>    <span class="hljs-comment"># Weights &amp; Biases arguments</span><br>    <span class="hljs-comment"># </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--entity&#x27;</span>, default=<span class="hljs-literal">None</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;W&amp;B: Entity&#x27;</span>)<br>    <span class="hljs-comment"># wandb table</span><br>    parser.add_argument(<span class="hljs-string">&#x27;--upload_dataset&#x27;</span>, nargs=<span class="hljs-string">&#x27;?&#x27;</span>, const=<span class="hljs-literal">True</span>, default=<span class="hljs-literal">False</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;W&amp;B: Upload data, &quot;val&quot; option&#x27;</span>)<br>    <span class="hljs-comment"># </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--bbox_interval&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=-<span class="hljs-number">1</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;W&amp;B: Set bounding-box image logging interval&#x27;</span>)<br>    <span class="hljs-comment"># </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--artifact_alias&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=<span class="hljs-string">&#x27;latest&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;W&amp;B: Version of dataset artifact to use&#x27;</span>)<br><span class="hljs-comment"># parse_known_args()NameSpace</span><br>    <span class="hljs-comment"># NameSpace</span><br>    <span class="hljs-comment"># parse_args()NameSpace</span><br>    opt = parser.parse_known_args()[<span class="hljs-number">0</span>] <span class="hljs-keyword">if</span> known <span class="hljs-keyword">else</span> parser.parse_args()<br>    <span class="hljs-keyword">return</span> opt<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>(<span class="hljs-params">opt, callbacks=Callbacks(<span class="hljs-params"></span>)</span>):<br>    <span class="hljs-comment"># Checks</span><br>    <span class="hljs-keyword">if</span> RANK <span class="hljs-keyword">in</span> (-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>):<br>        print_args(<span class="hljs-built_in">vars</span>(opt))<br>        check_git_status()<br>        check_requirements(exclude=[<span class="hljs-string">&#x27;thop&#x27;</span>])<br><br>    <span class="hljs-comment"># </span><br>    <span class="hljs-keyword">if</span> opt.resume <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> check_wandb_resume(opt) <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> opt.evolve:  <span class="hljs-comment"># resume an interrupted run</span><br>        <span class="hljs-comment"># get_last_run()pt</span><br>        ckpt = opt.resume <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(opt.resume, <span class="hljs-built_in">str</span>) <span class="hljs-keyword">else</span> get_latest_run()  <span class="hljs-comment"># specified or most recent path</span><br>        <span class="hljs-comment"># </span><br>        <span class="hljs-keyword">assert</span> os.path.isfile(ckpt), <span class="hljs-string">&#x27;ERROR: --resume checkpoint does not exist&#x27;</span><br>        <span class="hljs-comment"># opt</span><br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(Path(ckpt).parent.parent / <span class="hljs-string">&#x27;opt.yaml&#x27;</span>, errors=<span class="hljs-string">&#x27;ignore&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>            <span class="hljs-comment"># </span><br>            opt = argparse.Namespace(**yaml.safe_load(f)) <br>        <span class="hljs-comment"># </span><br>        opt.cfg, opt.weights, opt.resume = <span class="hljs-string">&#x27;&#x27;</span>, ckpt, <span class="hljs-literal">True</span>  <span class="hljs-comment"># reinstate</span><br>        LOGGER.info(<span class="hljs-string">f&#x27;Resuming training from <span class="hljs-subst">&#123;ckpt&#125;</span>&#x27;</span>)<br>    <span class="hljs-comment"># </span><br><span class="hljs-keyword">else</span>:<br>        <span class="hljs-comment"># </span><br>        opt.data, opt.cfg, opt.hyp, opt.weights, opt.project = \<br>            check_file(opt.data), check_yaml(opt.cfg), check_yaml(opt.hyp), <span class="hljs-built_in">str</span>(opt.weights), <span class="hljs-built_in">str</span>(opt.project)  <br>        <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(opt.cfg) <span class="hljs-keyword">or</span> <span class="hljs-built_in">len</span>(opt.weights), <span class="hljs-string">&#x27;either --cfg or --weights must be specified&#x27;</span><br>        <span class="hljs-comment"># </span><br>        <span class="hljs-keyword">if</span> opt.evolve:<br>            <span class="hljs-comment"># runs/evolve</span><br>            <span class="hljs-keyword">if</span> opt.project == <span class="hljs-built_in">str</span>(ROOT / <span class="hljs-string">&#x27;runs/train&#x27;</span>): <br>                opt.project = <span class="hljs-built_in">str</span>(ROOT / <span class="hljs-string">&#x27;runs/evolve&#x27;</span>)<br>            opt.exist_ok, opt.resume = opt.resume, <span class="hljs-literal">False</span>  <span class="hljs-comment"># pass resume to exist_ok and disable resume</span><br>        <span class="hljs-comment"># namecfgmodel.yaml</span><br>        <span class="hljs-keyword">if</span> opt.name == <span class="hljs-string">&#x27;cfg&#x27;</span>:<br>            opt.name = Path(opt.cfg).stem <br>        opt.save_dir = <span class="hljs-built_in">str</span>(increment_path(Path(opt.project) / opt.name, exist_ok=opt.exist_ok))<br><br>    <span class="hljs-comment"># DDP mode</span><br>    <span class="hljs-comment"># </span><br>    device = select_device(opt.device, batch_size=opt.batch_size)<br>    <span class="hljs-keyword">if</span> LOCAL_RANK != -<span class="hljs-number">1</span>:<br>        msg = <span class="hljs-string">&#x27;is not compatible with YOLOv5 Multi-GPU DDP training&#x27;</span><br>        <span class="hljs-keyword">assert</span> <span class="hljs-keyword">not</span> opt.image_weights, <span class="hljs-string">f&#x27;--image-weights <span class="hljs-subst">&#123;msg&#125;</span>&#x27;</span><br>        <span class="hljs-keyword">assert</span> <span class="hljs-keyword">not</span> opt.evolve, <span class="hljs-string">f&#x27;--evolve <span class="hljs-subst">&#123;msg&#125;</span>&#x27;</span><br>        <span class="hljs-keyword">assert</span> opt.batch_size != -<span class="hljs-number">1</span>, <span class="hljs-string">f&#x27;AutoBatch with --batch-size -1 <span class="hljs-subst">&#123;msg&#125;</span>, please pass a valid --batch-size&#x27;</span><br>        <span class="hljs-keyword">assert</span> opt.batch_size % WORLD_SIZE == <span class="hljs-number">0</span>, <span class="hljs-string">f&#x27;--batch-size <span class="hljs-subst">&#123;opt.batch_size&#125;</span> must be multiple of WORLD_SIZE&#x27;</span><br>        <span class="hljs-keyword">assert</span> torch.cuda.device_count() &gt; LOCAL_RANK, <span class="hljs-string">&#x27;insufficient CUDA devices for DDP command&#x27;</span><br>        torch.cuda.set_device(LOCAL_RANK)<br>        device = torch.device(<span class="hljs-string">&#x27;cuda&#x27;</span>, LOCAL_RANK)<br>        dist.init_process_group(backend=<span class="hljs-string">&quot;nccl&quot;</span> <span class="hljs-keyword">if</span> dist.is_nccl_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;gloo&quot;</span>)<br><br>    <span class="hljs-comment"># Train</span><br>    <span class="hljs-comment"># </span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> opt.evolve:<br>        <span class="hljs-comment"># train()train()</span><br>        train(opt.hyp, opt, device, callbacks)<br>        <span class="hljs-keyword">if</span> WORLD_SIZE &gt; <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> RANK == <span class="hljs-number">0</span>:<br>            LOGGER.info(<span class="hljs-string">&#x27;Destroying process group... &#x27;</span>)<br>            dist.destroy_process_group()<br><br>    <span class="hljs-comment"># main()</span><br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-comment"># Hyperparameter evolution metadata (mutation scale 0-1, lower_limit, upper_limit)</span><br>        meta = &#123;<br>            <span class="hljs-string">&#x27;lr0&#x27;</span>: (<span class="hljs-number">1</span>, <span class="hljs-number">1e-5</span>, <span class="hljs-number">1e-1</span>),  <span class="hljs-comment"># initial learning rate (SGD=1E-2, Adam=1E-3)</span><br>            <span class="hljs-string">&#x27;lrf&#x27;</span>: (<span class="hljs-number">1</span>, <span class="hljs-number">0.01</span>, <span class="hljs-number">1.0</span>),  <span class="hljs-comment"># final OneCycleLR learning rate (lr0 * lrf)</span><br>            <span class="hljs-string">&#x27;momentum&#x27;</span>: (<span class="hljs-number">0.3</span>, <span class="hljs-number">0.6</span>, <span class="hljs-number">0.98</span>),  <span class="hljs-comment"># SGD momentum/Adam beta1</span><br>            <span class="hljs-string">&#x27;weight_decay&#x27;</span>: (<span class="hljs-number">1</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.001</span>),  <span class="hljs-comment"># optimizer weight decay</span><br>            <span class="hljs-string">&#x27;warmup_epochs&#x27;</span>: (<span class="hljs-number">1</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">5.0</span>),  <span class="hljs-comment"># warmup epochs (fractions ok)</span><br>            <span class="hljs-string">&#x27;warmup_momentum&#x27;</span>: (<span class="hljs-number">1</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.95</span>),  <span class="hljs-comment"># warmup initial momentum</span><br>            <span class="hljs-string">&#x27;warmup_bias_lr&#x27;</span>: (<span class="hljs-number">1</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.2</span>),  <span class="hljs-comment"># warmup initial bias lr</span><br>            <span class="hljs-string">&#x27;box&#x27;</span>: (<span class="hljs-number">1</span>, <span class="hljs-number">0.02</span>, <span class="hljs-number">0.2</span>),  <span class="hljs-comment"># box loss gain</span><br>            <span class="hljs-string">&#x27;cls&#x27;</span>: (<span class="hljs-number">1</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">4.0</span>),  <span class="hljs-comment"># cls loss gain</span><br>            <span class="hljs-string">&#x27;cls_pw&#x27;</span>: (<span class="hljs-number">1</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">2.0</span>),  <span class="hljs-comment"># cls BCELoss positive_weight</span><br>            <span class="hljs-string">&#x27;obj&#x27;</span>: (<span class="hljs-number">1</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">4.0</span>),  <span class="hljs-comment"># obj loss gain (scale with pixels)</span><br>            <span class="hljs-string">&#x27;obj_pw&#x27;</span>: (<span class="hljs-number">1</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">2.0</span>),  <span class="hljs-comment"># obj BCELoss positive_weight</span><br>            <span class="hljs-string">&#x27;iou_t&#x27;</span>: (<span class="hljs-number">0</span>, <span class="hljs-number">0.1</span>, <span class="hljs-number">0.7</span>),  <span class="hljs-comment"># IoU training threshold</span><br>            <span class="hljs-string">&#x27;anchor_t&#x27;</span>: (<span class="hljs-number">1</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">8.0</span>),  <span class="hljs-comment"># anchor-multiple threshold</span><br>            <span class="hljs-string">&#x27;anchors&#x27;</span>: (<span class="hljs-number">2</span>, <span class="hljs-number">2.0</span>, <span class="hljs-number">10.0</span>),  <span class="hljs-comment"># anchors per output grid (0 to ignore)</span><br>            <span class="hljs-string">&#x27;fl_gamma&#x27;</span>: (<span class="hljs-number">0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">2.0</span>),  <span class="hljs-comment"># focal loss gamma (efficientDet default gamma=1.5)</span><br>            <span class="hljs-string">&#x27;hsv_h&#x27;</span>: (<span class="hljs-number">1</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.1</span>),  <span class="hljs-comment"># image HSV-Hue augmentation (fraction)</span><br>            <span class="hljs-string">&#x27;hsv_s&#x27;</span>: (<span class="hljs-number">1</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.9</span>),  <span class="hljs-comment"># image HSV-Saturation augmentation (fraction)</span><br>            <span class="hljs-string">&#x27;hsv_v&#x27;</span>: (<span class="hljs-number">1</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.9</span>),  <span class="hljs-comment"># image HSV-Value augmentation (fraction)</span><br>            <span class="hljs-string">&#x27;degrees&#x27;</span>: (<span class="hljs-number">1</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">45.0</span>),  <span class="hljs-comment"># image rotation (+/- deg)</span><br>            <span class="hljs-string">&#x27;translate&#x27;</span>: (<span class="hljs-number">1</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.9</span>),  <span class="hljs-comment"># image translation (+/- fraction)</span><br>            <span class="hljs-string">&#x27;scale&#x27;</span>: (<span class="hljs-number">1</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.9</span>),  <span class="hljs-comment"># image scale (+/- gain)</span><br>            <span class="hljs-string">&#x27;shear&#x27;</span>: (<span class="hljs-number">1</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">10.0</span>),  <span class="hljs-comment"># image shear (+/- deg)</span><br>            <span class="hljs-string">&#x27;perspective&#x27;</span>: (<span class="hljs-number">0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.001</span>),  <span class="hljs-comment"># image perspective (+/- fraction), range 0-0.001</span><br>            <span class="hljs-string">&#x27;flipud&#x27;</span>: (<span class="hljs-number">1</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>),  <span class="hljs-comment"># image flip up-down (probability)</span><br>            <span class="hljs-string">&#x27;fliplr&#x27;</span>: (<span class="hljs-number">0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>),  <span class="hljs-comment"># image flip left-right (probability)</span><br>            <span class="hljs-string">&#x27;mosaic&#x27;</span>: (<span class="hljs-number">1</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>),  <span class="hljs-comment"># image mixup (probability)</span><br>            <span class="hljs-string">&#x27;mixup&#x27;</span>: (<span class="hljs-number">1</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>),  <span class="hljs-comment"># image mixup (probability)</span><br>            <span class="hljs-string">&#x27;copy_paste&#x27;</span>: (<span class="hljs-number">1</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">1.0</span>)&#125;  <span class="hljs-comment"># segment copy-paste (probability)</span><br><br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(opt.hyp, errors=<span class="hljs-string">&#x27;ignore&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>            hyp = yaml.safe_load(f)  <span class="hljs-comment"># load hyps dict</span><br>            <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;anchors&#x27;</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> hyp:  <span class="hljs-comment"># anchors commented in hyp.yaml</span><br>                hyp[<span class="hljs-string">&#x27;anchors&#x27;</span>] = <span class="hljs-number">3</span><br>        opt.noval, opt.nosave, save_dir = <span class="hljs-literal">True</span>, <span class="hljs-literal">True</span>, Path(opt.save_dir)  <span class="hljs-comment"># only val/save final epoch</span><br>        <span class="hljs-comment"># ei = [isinstance(x, (int, float)) for x in hyp.values()]  # evolvable indices</span><br>        evolve_yaml, evolve_csv = save_dir / <span class="hljs-string">&#x27;hyp_evolve.yaml&#x27;</span>, save_dir / <span class="hljs-string">&#x27;evolve.csv&#x27;</span><br>        <span class="hljs-keyword">if</span> opt.bucket:<br>            os.system(<span class="hljs-string">f&#x27;gsutil cp gs://<span class="hljs-subst">&#123;opt.bucket&#125;</span>/evolve.csv <span class="hljs-subst">&#123;evolve_csv&#125;</span>&#x27;</span>)  <span class="hljs-comment"># download evolve.csv if exists</span><br><br>        <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(opt.evolve):  <span class="hljs-comment"># generations to evolve</span><br>            <span class="hljs-keyword">if</span> evolve_csv.exists():  <span class="hljs-comment"># if evolve.csv exists: select best hyps and mutate</span><br>                <span class="hljs-comment"># Select parent(s)</span><br>                parent = <span class="hljs-string">&#x27;single&#x27;</span>  <span class="hljs-comment"># parent selection method: &#x27;single&#x27; or &#x27;weighted&#x27;</span><br>                x = np.loadtxt(evolve_csv, ndmin=<span class="hljs-number">2</span>, delimiter=<span class="hljs-string">&#x27;,&#x27;</span>, skiprows=<span class="hljs-number">1</span>)<br>                n = <span class="hljs-built_in">min</span>(<span class="hljs-number">5</span>, <span class="hljs-built_in">len</span>(x))  <span class="hljs-comment"># number of previous results to consider</span><br>                x = x[np.argsort(-fitness(x))][:n]  <span class="hljs-comment"># top n mutations</span><br>                w = fitness(x) - fitness(x).<span class="hljs-built_in">min</span>() + <span class="hljs-number">1E-6</span>  <span class="hljs-comment"># weights (sum &gt; 0)</span><br>                <span class="hljs-keyword">if</span> parent == <span class="hljs-string">&#x27;single&#x27;</span> <span class="hljs-keyword">or</span> <span class="hljs-built_in">len</span>(x) == <span class="hljs-number">1</span>:<br>                    <span class="hljs-comment"># x = x[random.randint(0, n - 1)]  # random selection</span><br>                    x = x[random.choices(<span class="hljs-built_in">range</span>(n), weights=w)[<span class="hljs-number">0</span>]]  <span class="hljs-comment"># weighted selection</span><br>                <span class="hljs-keyword">elif</span> parent == <span class="hljs-string">&#x27;weighted&#x27;</span>:<br>                    x = (x * w.reshape(n, <span class="hljs-number">1</span>)).<span class="hljs-built_in">sum</span>(<span class="hljs-number">0</span>) / w.<span class="hljs-built_in">sum</span>()  <span class="hljs-comment"># weighted combination</span><br><br>                <span class="hljs-comment"># Mutate</span><br>                mp, s = <span class="hljs-number">0.8</span>, <span class="hljs-number">0.2</span>  <span class="hljs-comment"># mutation probability, sigma</span><br>                npr = np.random<br>                npr.seed(<span class="hljs-built_in">int</span>(time.time()))<br>                g = np.array([meta[k][<span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> hyp.keys()])  <span class="hljs-comment"># gains 0-1</span><br>                ng = <span class="hljs-built_in">len</span>(meta)<br>                v = np.ones(ng)<br>                <span class="hljs-keyword">while</span> <span class="hljs-built_in">all</span>(v == <span class="hljs-number">1</span>):  <span class="hljs-comment"># mutate until a change occurs (prevent duplicates)</span><br>                    v = (g * (npr.random(ng) &lt; mp) * npr.randn(ng) * npr.random() * s + <span class="hljs-number">1</span>).clip(<span class="hljs-number">0.3</span>, <span class="hljs-number">3.0</span>)<br>                <span class="hljs-keyword">for</span> i, k <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(hyp.keys()):  <span class="hljs-comment"># plt.hist(v.ravel(), 300)</span><br>                    hyp[k] = <span class="hljs-built_in">float</span>(x[i + <span class="hljs-number">7</span>] * v[i])  <span class="hljs-comment"># mutate</span><br><br>            <span class="hljs-comment"># Constrain to limits</span><br>            <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> meta.items():<br>                hyp[k] = <span class="hljs-built_in">max</span>(hyp[k], v[<span class="hljs-number">1</span>])  <span class="hljs-comment"># lower limit</span><br>                hyp[k] = <span class="hljs-built_in">min</span>(hyp[k], v[<span class="hljs-number">2</span>])  <span class="hljs-comment"># upper limit</span><br>                hyp[k] = <span class="hljs-built_in">round</span>(hyp[k], <span class="hljs-number">5</span>)  <span class="hljs-comment"># significant digits</span><br><br>            <span class="hljs-comment"># Train mutation</span><br>            results = train(hyp.copy(), opt, device, callbacks)<br>            callbacks = Callbacks()<br>            <span class="hljs-comment"># Write mutation results</span><br>            print_mutation(results, hyp.copy(), save_dir, opt.bucket)<br><br>        <span class="hljs-comment"># Plot results</span><br>        plot_evolve(evolve_csv)<br>        LOGGER.info(<span class="hljs-string">f&#x27;Hyperparameter evolution finished <span class="hljs-subst">&#123;opt.evolve&#125;</span> generations\n&#x27;</span><br>                    <span class="hljs-string">f&quot;Results saved to <span class="hljs-subst">&#123;colorstr(<span class="hljs-string">&#x27;bold&#x27;</span>, save_dir)&#125;</span>\n&quot;</span><br>                    <span class="hljs-string">f&#x27;Usage example: $ python train.py --hyp <span class="hljs-subst">&#123;evolve_yaml&#125;</span>&#x27;</span>)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">run</span>(<span class="hljs-params">**kwargs</span>):<br>    <span class="hljs-comment"># Usage: import train; train.run(data=&#x27;coco128.yaml&#x27;, imgsz=320, weights=&#x27;yolov5m.pt&#x27;)</span><br>    opt = parse_opt(<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> kwargs.items():<br>        <span class="hljs-comment"># opt.k = v</span><br>        <span class="hljs-built_in">setattr</span>(opt, k, v)<br>    main(opt)<br>    <span class="hljs-keyword">return</span> opt<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    opt = parse_opt()<br>    main(opt)<br></code></pre></div></td></tr></table></figure><h1 id="detect.py">detect.py</h1><ul><li><ul><li>run()</li><li>parse_opt()</li><li>run()</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-meta">@torch.no_grad()</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">run</span>(<span class="hljs-params"></span><br><span class="hljs-params">        weights=ROOT / <span class="hljs-string">&#x27;yolov5s.pt&#x27;</span>,  <span class="hljs-comment"># model.pt path(s)</span></span><br><span class="hljs-params">        source=ROOT / <span class="hljs-string">&#x27;data/images&#x27;</span>,  <span class="hljs-comment"># file/dir/URL/glob, 0 for webcam</span></span><br><span class="hljs-params">        data=ROOT / <span class="hljs-string">&#x27;data/coco128.yaml&#x27;</span>,  <span class="hljs-comment"># dataset.yaml path</span></span><br><span class="hljs-params">        imgsz=(<span class="hljs-params"><span class="hljs-number">640</span>, <span class="hljs-number">640</span></span>),  <span class="hljs-comment"># inference size (height, width)</span></span><br><span class="hljs-params">        conf_thres=<span class="hljs-number">0.25</span>,  <span class="hljs-comment"># confidence threshold</span></span><br><span class="hljs-params">        iou_thres=<span class="hljs-number">0.45</span>,  <span class="hljs-comment"># NMS IOU threshold</span></span><br><span class="hljs-params">        max_det=<span class="hljs-number">1000</span>,  <span class="hljs-comment"># maximum detections per image</span></span><br><span class="hljs-params">        device=<span class="hljs-string">&#x27;&#x27;</span>,  <span class="hljs-comment"># cuda device, i.e. 0 or 0,1,2,3 or cpu</span></span><br><span class="hljs-params">        view_img=<span class="hljs-literal">False</span>,  <span class="hljs-comment"># show results</span></span><br><span class="hljs-params">        save_txt=<span class="hljs-literal">False</span>,  <span class="hljs-comment"># save results to *.txt</span></span><br><span class="hljs-params">        save_conf=<span class="hljs-literal">False</span>,  <span class="hljs-comment"># save confidences in --save-txt labels</span></span><br><span class="hljs-params">        save_crop=<span class="hljs-literal">False</span>,  <span class="hljs-comment"># save cropped prediction boxes</span></span><br><span class="hljs-params">        nosave=<span class="hljs-literal">False</span>,  <span class="hljs-comment"># do not save images/videos</span></span><br><span class="hljs-params">        classes=<span class="hljs-literal">None</span>,  <span class="hljs-comment"># filter by class: --class 0, or --class 0 2 3</span></span><br><span class="hljs-params">        agnostic_nms=<span class="hljs-literal">False</span>,  <span class="hljs-comment"># class-agnostic NMS</span></span><br><span class="hljs-params">        augment=<span class="hljs-literal">False</span>,  <span class="hljs-comment"># augmented inference</span></span><br><span class="hljs-params">        visualize=<span class="hljs-literal">False</span>,  <span class="hljs-comment"># visualize features</span></span><br><span class="hljs-params">        update=<span class="hljs-literal">False</span>,  <span class="hljs-comment"># update all models</span></span><br><span class="hljs-params">        project=ROOT / <span class="hljs-string">&#x27;runs/detect&#x27;</span>,  <span class="hljs-comment"># save results to project/name</span></span><br><span class="hljs-params">        name=<span class="hljs-string">&#x27;exp&#x27;</span>,  <span class="hljs-comment"># save results to project/name</span></span><br><span class="hljs-params">        exist_ok=<span class="hljs-literal">False</span>,  <span class="hljs-comment"># existing project/name ok, do not increment</span></span><br><span class="hljs-params">        line_thickness=<span class="hljs-number">3</span>,  <span class="hljs-comment"># bounding box thickness (pixels)</span></span><br><span class="hljs-params">        hide_labels=<span class="hljs-literal">False</span>,  <span class="hljs-comment"># hide labels</span></span><br><span class="hljs-params">        hide_conf=<span class="hljs-literal">False</span>,  <span class="hljs-comment"># hide confidences</span></span><br><span class="hljs-params">        half=<span class="hljs-literal">False</span>,  <span class="hljs-comment"># use FP16 half-precision inference</span></span><br><span class="hljs-params">        dnn=<span class="hljs-literal">False</span>,  <span class="hljs-comment"># use OpenCV DNN for ONNX inference</span></span><br><span class="hljs-params"></span>):<br>    source = <span class="hljs-built_in">str</span>(source)<br>    save_img = <span class="hljs-keyword">not</span> nosave <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> source.endswith(<span class="hljs-string">&#x27;.txt&#x27;</span>)  <span class="hljs-comment"># save inference images</span><br>    is_file = Path(source).suffix[<span class="hljs-number">1</span>:] <span class="hljs-keyword">in</span> (IMG_FORMATS + VID_FORMATS)    <span class="hljs-comment"># suffix.jpgsuffix[1:]jpg</span><br>    is_url = source.lower().startswith((<span class="hljs-string">&#x27;rtsp://&#x27;</span>, <span class="hljs-string">&#x27;rtmp://&#x27;</span>, <span class="hljs-string">&#x27;http://&#x27;</span>, <span class="hljs-string">&#x27;https://&#x27;</span>))   <span class="hljs-comment"># </span><br>    webcam = source.isnumeric() <span class="hljs-keyword">or</span> source.endswith(<span class="hljs-string">&#x27;.txt&#x27;</span>) <span class="hljs-keyword">or</span> (is_url <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> is_file)<br>    <span class="hljs-keyword">if</span> is_url <span class="hljs-keyword">and</span> is_file:<br>        source = check_file(source)  <span class="hljs-comment"># download</span><br><br>    <span class="hljs-comment"># </span><br>    save_dir = increment_path(Path(project) / name, exist_ok=exist_ok)  <span class="hljs-comment"># increment run</span><br>    <span class="hljs-comment"># </span><br>    (save_dir / <span class="hljs-string">&#x27;labels&#x27;</span> <span class="hljs-keyword">if</span> save_txt <span class="hljs-keyword">else</span> save_dir).mkdir(parents=<span class="hljs-literal">True</span>, exist_ok=<span class="hljs-literal">True</span>)  <span class="hljs-comment"># make dir</span><br><br>    <span class="hljs-comment"># Load model</span><br>    device = select_device(device) <span class="hljs-comment"># </span><br>    <span class="hljs-comment"># </span><br>    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)<br>    stride, names, pt = model.stride, model.names, model.pt<span class="hljs-comment"># </span><br>    imgsz = check_img_size(imgsz, s=stride)  <span class="hljs-comment"># check image size</span><br><br>    <span class="hljs-comment"># Dataloader</span><br>    <span class="hljs-keyword">if</span> webcam:<span class="hljs-comment"># </span><br>        view_img = check_imshow()<br>        cudnn.benchmark = <span class="hljs-literal">True</span>  <span class="hljs-comment"># set True to speed up constant image size inference</span><br>        dataset = LoadStreams(source, img_size=imgsz, stride=stride, auto=pt)<br>        bs = <span class="hljs-built_in">len</span>(dataset)  <span class="hljs-comment"># batch_size</span><br>    <span class="hljs-keyword">else</span>:<br>        dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt)<br>        bs = <span class="hljs-number">1</span>  <span class="hljs-comment"># batch_size</span><br>    vid_path, vid_writer = [<span class="hljs-literal">None</span>] * bs, [<span class="hljs-literal">None</span>] * bs<br><br>    <span class="hljs-comment"># Run inference</span><br>    model.warmup(imgsz=(<span class="hljs-number">1</span> <span class="hljs-keyword">if</span> pt <span class="hljs-keyword">else</span> bs, <span class="hljs-number">3</span>, *imgsz))  <span class="hljs-comment"># warmup</span><br>    dt, seen = [<span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>], <span class="hljs-number">0</span>   <span class="hljs-comment"># dt</span><br>    <span class="hljs-keyword">for</span> path, im, im0s, vid_cap, s <span class="hljs-keyword">in</span> dataset:  <span class="hljs-comment"># img:resizeimg0capnones</span><br>        t1 = time_sync()<br>        im = torch.from_numpy(im).to(device)<span class="hljs-comment"># torch.size=[3, 640, 480]</span><br>        im = im.half() <span class="hljs-keyword">if</span> model.fp16 <span class="hljs-keyword">else</span> im.<span class="hljs-built_in">float</span>()  <span class="hljs-comment"># uint8 to fp16/32</span><br>        im /= <span class="hljs-number">255</span>  <span class="hljs-comment"># [0 ~ 255] -&gt; [0.0 ~ 1.0] </span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(im.shape) == <span class="hljs-number">3</span>:<br>            im = im[<span class="hljs-literal">None</span>]  <span class="hljs-comment"># expand for batch dim batch[1, 3, 640, 480]</span><br>        t2 = time_sync()<br>        dt[<span class="hljs-number">0</span>] += t2 - t1<br><br>        <span class="hljs-comment"># Inference </span><br>        visualize = increment_path(save_dir / Path(path).stem, mkdir=<span class="hljs-literal">True</span>) <span class="hljs-keyword">if</span> visualize <span class="hljs-keyword">else</span> <span class="hljs-literal">False</span><br>        pred = model(im, augment=augment, visualize=visualize)  <span class="hljs-comment"># torch.Size([1, 18900, 85]) 18900 85</span><br>        t3 = time_sync()<br>        dt[<span class="hljs-number">1</span>] += t3 - t2<br><br>        <span class="hljs-comment"># NMS</span><br>        pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det) <span class="hljs-comment"># 1, 5, 6</span><br>        dt[<span class="hljs-number">2</span>] += time_sync() - t3<br><br>        <span class="hljs-comment"># Second-stage classifier (optional)</span><br>        <span class="hljs-comment"># pred = utils.general.apply_classifier(pred, classifier_model, im, im0s)</span><br><br>        <span class="hljs-comment"># </span><br>        <span class="hljs-keyword">for</span> i, det <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(pred):  <span class="hljs-comment"># per image predbatch det</span><br>            seen += <span class="hljs-number">1</span><span class="hljs-comment"># </span><br>            <span class="hljs-keyword">if</span> webcam:  <span class="hljs-comment"># batch_size &gt;= 1</span><br>                p, im0, frame = path[i], im0s[i].copy(), dataset.count<br>                s += <span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;i&#125;</span>: &#x27;</span><br>            <span class="hljs-keyword">else</span>:<br>                p, im0, frame = path, im0s.copy(), <span class="hljs-built_in">getattr</span>(dataset, <span class="hljs-string">&#x27;frame&#x27;</span>, <span class="hljs-number">0</span>)<br><br>            p = Path(p)  <span class="hljs-comment"># to Path</span><br>            save_path = <span class="hljs-built_in">str</span>(save_dir / p.name)  <span class="hljs-comment"># im.jpg</span><br>            txt_path = <span class="hljs-built_in">str</span>(save_dir / <span class="hljs-string">&#x27;labels&#x27;</span> / p.stem) + (<span class="hljs-string">&#x27;&#x27;</span> <span class="hljs-keyword">if</span> dataset.mode == <span class="hljs-string">&#x27;image&#x27;</span> <span class="hljs-keyword">else</span> <span class="hljs-string">f&#x27;_<span class="hljs-subst">&#123;frame&#125;</span>&#x27;</span>)  <span class="hljs-comment"># im.txt</span><br>            s += <span class="hljs-string">&#x27;%gx%g &#x27;</span> % im.shape[<span class="hljs-number">2</span>:]  <span class="hljs-comment"># print string</span><br>            gn = torch.tensor(im0.shape)[[<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>]]  <span class="hljs-comment"># normalization gain whwh</span><br>            imc = im0.copy() <span class="hljs-keyword">if</span> save_crop <span class="hljs-keyword">else</span> im0  <span class="hljs-comment"># for save_crop</span><br>            annotator = Annotator(im0, line_width=line_thickness, example=<span class="hljs-built_in">str</span>(names))   <span class="hljs-comment"># </span><br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(det):<span class="hljs-comment"># </span><br>                <span class="hljs-comment"># Rescale boxes from img_size to im0 size</span><br>                det[:, :<span class="hljs-number">4</span>] = scale_coords(im.shape[<span class="hljs-number">2</span>:], det[:, :<span class="hljs-number">4</span>], im0.shape).<span class="hljs-built_in">round</span>() <span class="hljs-comment"># </span><br><br>                <span class="hljs-comment"># Print results</span><br>                <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> det[:, -<span class="hljs-number">1</span>].unique():<br>                    n = (det[:, -<span class="hljs-number">1</span>] == c).<span class="hljs-built_in">sum</span>()  <span class="hljs-comment"># detections per class</span><br>                    s += <span class="hljs-string">f&quot;<span class="hljs-subst">&#123;n&#125;</span> <span class="hljs-subst">&#123;names[<span class="hljs-built_in">int</span>(c)]&#125;</span><span class="hljs-subst">&#123;<span class="hljs-string">&#x27;s&#x27;</span> * (n &gt; <span class="hljs-number">1</span>)&#125;</span>, &quot;</span>  <span class="hljs-comment"># add to string</span><br><br>                <span class="hljs-comment"># Write results</span><br>                <span class="hljs-keyword">for</span> *xyxy, conf, cls <span class="hljs-keyword">in</span> <span class="hljs-built_in">reversed</span>(det):<br>                    <span class="hljs-keyword">if</span> save_txt:  <span class="hljs-comment"># Write to file </span><br>                        xywh = (xyxy2xywh(torch.tensor(xyxy).view(<span class="hljs-number">1</span>, <span class="hljs-number">4</span>)) / gn).view(-<span class="hljs-number">1</span>).tolist()  <span class="hljs-comment"># normalized xywh</span><br>                        line = (cls, *xywh, conf) <span class="hljs-keyword">if</span> save_conf <span class="hljs-keyword">else</span> (cls, *xywh)  <span class="hljs-comment"># label format</span><br>                        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(txt_path + <span class="hljs-string">&#x27;.txt&#x27;</span>, <span class="hljs-string">&#x27;a&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>                            f.write((<span class="hljs-string">&#x27;%g &#x27;</span> * <span class="hljs-built_in">len</span>(line)).rstrip() % line + <span class="hljs-string">&#x27;\n&#x27;</span>)<br><br>                    <span class="hljs-keyword">if</span> save_img <span class="hljs-keyword">or</span> save_crop <span class="hljs-keyword">or</span> view_img:  <span class="hljs-comment"># Add bbox to image</span><br>                        c = <span class="hljs-built_in">int</span>(cls)  <span class="hljs-comment"># integer class</span><br>                        <span class="hljs-comment"># <span class="hljs-doctag">FIXME:</span></span><br><br>                        <span class="hljs-keyword">if</span> save_img <span class="hljs-keyword">or</span> save_crop <span class="hljs-keyword">or</span> view_img:  <span class="hljs-comment"># Add bbox to image</span><br>                            c = <span class="hljs-built_in">int</span>(cls)  <span class="hljs-comment"># integer class</span><br>                            <span class="hljs-comment"># <span class="hljs-doctag">FIXME:</span></span><br>                            <span class="hljs-keyword">if</span> names[<span class="hljs-built_in">int</span>(cls)] <span class="hljs-keyword">in</span> (<span class="hljs-string">&#x27;person&#x27;</span>):<br>                                label = <span class="hljs-literal">None</span> <span class="hljs-keyword">if</span> hide_labels <span class="hljs-keyword">else</span> (names[c] <span class="hljs-keyword">if</span> hide_conf <span class="hljs-keyword">else</span> <span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;names[c]&#125;</span> <span class="hljs-subst">&#123;conf:<span class="hljs-number">.2</span>f&#125;</span>&#x27;</span>)<br>                                annotator.box_label(xyxy, label, color=colors(c, <span class="hljs-literal">True</span>), )<br>                                <span class="hljs-keyword">if</span> save_crop:<br>                                    save_one_box(xyxy, imc, file=save_dir / <span class="hljs-string">&#x27;crops&#x27;</span> / names[c] / <span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;p.stem&#125;</span>.jpg&#x27;</span>,<br>                                                 BGR=<span class="hljs-literal">True</span>)<br><br>            <span class="hljs-comment"># Stream results</span><br>            im0 = annotator.result()<span class="hljs-comment"># </span><br>            <span class="hljs-keyword">if</span> view_img:<br>                cv2.imshow(<span class="hljs-built_in">str</span>(p), im0)<br>                cv2.waitKey(<span class="hljs-number">1</span>)  <span class="hljs-comment"># 1 millisecond</span><br><br>            <span class="hljs-comment"># Save results (image with detections)</span><br>            <span class="hljs-keyword">if</span> save_img:<br>                <span class="hljs-keyword">if</span> dataset.mode == <span class="hljs-string">&#x27;image&#x27;</span>:<br>                    cv2.imwrite(save_path, im0)<br>                <span class="hljs-keyword">else</span>:  <span class="hljs-comment"># &#x27;video&#x27; or &#x27;stream&#x27;</span><br>                    <span class="hljs-keyword">if</span> vid_path[i] != save_path:  <span class="hljs-comment"># new video</span><br>                        vid_path[i] = save_path<br>                        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(vid_writer[i], cv2.VideoWriter):<br>                            vid_writer[i].release()  <span class="hljs-comment"># release previous video writer</span><br>                        <span class="hljs-keyword">if</span> vid_cap:  <span class="hljs-comment"># video</span><br>                            fps = vid_cap.get(cv2.CAP_PROP_FPS)<br>                            w = <span class="hljs-built_in">int</span>(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))<br>                            h = <span class="hljs-built_in">int</span>(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))<br>                        <span class="hljs-keyword">else</span>:  <span class="hljs-comment"># stream</span><br>                            fps, w, h = <span class="hljs-number">30</span>, im0.shape[<span class="hljs-number">1</span>], im0.shape[<span class="hljs-number">0</span>]<br>                        save_path = <span class="hljs-built_in">str</span>(Path(save_path).with_suffix(<span class="hljs-string">&#x27;.mp4&#x27;</span>))  <span class="hljs-comment"># force *.mp4 suffix on results videos</span><br>                        vid_writer[i] = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*<span class="hljs-string">&#x27;mp4v&#x27;</span>), fps, (w, h))<br>                    vid_writer[i].write(im0)<br><br>        <span class="hljs-comment"># Print time (inference-only)</span><br>        LOGGER.info(<span class="hljs-string">f&#x27;<span class="hljs-subst">&#123;s&#125;</span>Done. (<span class="hljs-subst">&#123;t3 - t2:<span class="hljs-number">.3</span>f&#125;</span>s)&#x27;</span>)<br><br>    <span class="hljs-comment"># Print results </span><br>    t = <span class="hljs-built_in">tuple</span>(x / seen * <span class="hljs-number">1E3</span> <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> dt)  <span class="hljs-comment"># speeds per image</span><br>    LOGGER.info(<span class="hljs-string">f&#x27;Speed: %.1fms pre-process, %.1fms inference, %.1fms NMS per image at shape <span class="hljs-subst">&#123;(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, *imgsz)&#125;</span>&#x27;</span> % t)<br>    <span class="hljs-keyword">if</span> save_txt <span class="hljs-keyword">or</span> save_img:<br>        s = <span class="hljs-string">f&quot;\n<span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(<span class="hljs-built_in">list</span>(save_dir.glob(<span class="hljs-string">&#x27;labels/*.txt&#x27;</span>)))&#125;</span> labels saved to <span class="hljs-subst">&#123;save_dir / <span class="hljs-string">&#x27;labels&#x27;</span>&#125;</span>&quot;</span> <span class="hljs-keyword">if</span> save_txt <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;&#x27;</span><br>        LOGGER.info(<span class="hljs-string">f&quot;Results saved to <span class="hljs-subst">&#123;colorstr(<span class="hljs-string">&#x27;bold&#x27;</span>, save_dir)&#125;</span><span class="hljs-subst">&#123;s&#125;</span>&quot;</span>)<br>    <span class="hljs-keyword">if</span> update:<br>        strip_optimizer(weights)  <span class="hljs-comment"># update model (to fix SourceChangeWarning)</span><br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">parse_opt</span>():<br>    parser = argparse.ArgumentParser()<br>    <span class="hljs-comment"># </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--weights&#x27;</span>, nargs=<span class="hljs-string">&#x27;+&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=ROOT / <span class="hljs-string">&#x27;yolov5m.pt&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;model path(s)&#x27;</span>)<br>    <span class="hljs-comment"># </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--source&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=ROOT / <span class="hljs-string">&#x27;data/images&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;file/dir/URL/glob, 0 for webcam&#x27;</span>)<br>    <span class="hljs-comment"># yaml</span><br>    parser.add_argument(<span class="hljs-string">&#x27;--data&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">str</span>, default=ROOT / <span class="hljs-string">&#x27;data/coco128.yaml&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;(optional) dataset.yaml path&#x27;</span>)<br>    <span class="hljs-comment"># image size</span><br>    parser.add_argument(<span class="hljs-string">&#x27;--imgsz&#x27;</span>, <span class="hljs-string">&#x27;--img&#x27;</span>, <span class="hljs-string">&#x27;--img-size&#x27;</span>, nargs=<span class="hljs-string">&#x27;+&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=[<span class="hljs-number">640</span>], <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;inference size h,w&#x27;</span>)<br>    <span class="hljs-comment"># </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--conf-thres&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">float</span>, default=<span class="hljs-number">0.5</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;confidence threshold&#x27;</span>)<br>    <span class="hljs-comment"># Iou</span><br>    parser.add_argument(<span class="hljs-string">&#x27;--iou-thres&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">float</span>, default=<span class="hljs-number">0.45</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;NMS IoU threshold&#x27;</span>)<br>    <span class="hljs-comment"># </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--max-det&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, default=<span class="hljs-number">1000</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;maximum detections per image&#x27;</span>)<br>    <span class="hljs-comment"># </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--device&#x27;</span>, default=<span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;cuda device, i.e. 0 or 0,1,2,3 or cpu&#x27;</span>)<br>    <span class="hljs-comment"># </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--view-img&#x27;</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;show results&#x27;</span>)<br>    <span class="hljs-comment"># txt</span><br>    parser.add_argument(<span class="hljs-string">&#x27;--save-txt&#x27;</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;save results to *.txt&#x27;</span>)<br>    <span class="hljs-comment"># txt</span><br>    parser.add_argument(<span class="hljs-string">&#x27;--save-conf&#x27;</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;save confidences in --save-txt labels&#x27;</span>)<br>    <span class="hljs-comment"># </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--save-crop&#x27;</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;save cropped prediction boxes&#x27;</span>)<br>    <span class="hljs-comment"># </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--nosave&#x27;</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;do not save images/videos&#x27;</span>)<br>    <span class="hljs-comment"># </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--classes&#x27;</span>, nargs=<span class="hljs-string">&#x27;+&#x27;</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;filter by class: --classes 0, or --classes 0 2 3&#x27;</span>)<br>    <span class="hljs-comment"># NMS, False</span><br>    parser.add_argument(<span class="hljs-string">&#x27;--agnostic-nms&#x27;</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;class-agnostic NMS&#x27;</span>)<br>    <span class="hljs-comment"># /</span><br>    parser.add_argument(<span class="hljs-string">&#x27;--augment&#x27;</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;augmented inference&#x27;</span>)<br>    <span class="hljs-comment"># </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--visualize&#x27;</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;visualize features&#x27;</span>)<br>    <span class="hljs-comment"># True,strip_optimizer,pt,False</span><br>    parser.add_argument(<span class="hljs-string">&#x27;--update&#x27;</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;update all models&#x27;</span>)<br>    <span class="hljs-comment"># </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--project&#x27;</span>, default=ROOT / <span class="hljs-string">&#x27;runs/detect&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;save results to project/name&#x27;</span>)<br>    <span class="hljs-comment"># , project/name</span><br>    parser.add_argument(<span class="hljs-string">&#x27;--name&#x27;</span>, default=<span class="hljs-string">&#x27;exp&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;save results to project/name&#x27;</span>)<br>    <span class="hljs-comment"># , False</span><br>    parser.add_argument(<span class="hljs-string">&#x27;--exist-ok&#x27;</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;existing project/name ok, do not increment&#x27;</span>)<br>    <span class="hljs-comment"># </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--line-thickness&#x27;</span>, default=<span class="hljs-number">3</span>, <span class="hljs-built_in">type</span>=<span class="hljs-built_in">int</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;bounding box thickness (pixels)&#x27;</span>)<br>    <span class="hljs-comment"># </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--hide-labels&#x27;</span>, default=<span class="hljs-literal">False</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;hide labels&#x27;</span>)<br>    <span class="hljs-comment"># </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--hide-conf&#x27;</span>, default=<span class="hljs-literal">False</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;hide confidences&#x27;</span>)<br>    <span class="hljs-comment"># F16, </span><br>    parser.add_argument(<span class="hljs-string">&#x27;--half&#x27;</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;use FP16 half-precision inference&#x27;</span>)<br>    <span class="hljs-comment"># OpenCV DNN</span><br>    parser.add_argument(<span class="hljs-string">&#x27;--dnn&#x27;</span>, action=<span class="hljs-string">&#x27;store_true&#x27;</span>, <span class="hljs-built_in">help</span>=<span class="hljs-string">&#x27;use OpenCV DNN for ONNX inference&#x27;</span>)<br>    opt = parser.parse_args()<br>    opt.imgsz *= <span class="hljs-number">2</span> <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(opt.imgsz) == <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-number">1</span>  <span class="hljs-comment"># expand</span><br>    print_args(<span class="hljs-built_in">vars</span>(opt))<br>    <span class="hljs-keyword">return</span> opt<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>(<span class="hljs-params">opt</span>):<br>    check_requirements(exclude=(<span class="hljs-string">&#x27;tensorboard&#x27;</span>, <span class="hljs-string">&#x27;thop&#x27;</span>))<br>    run(**<span class="hljs-built_in">vars</span>(opt))<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    opt = parse_opt()<br>    main(opt<br></code></pre></div></td></tr></table></figure><h1 id="loss.py">loss.py</h1><p></p><p>https://blog.csdn.net/shandianfengfan/article/details/122532156?spm=1001.2101.3001.6650.1&amp;utm_medium=distribute.pc_relevant.none-task-blog-2<sub>default</sub>CTRLIST<sub>default-1-122532156-blog-108844004.pc_relevant_blogantidownloadv1&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-2</sub>default<sub>CTRLIST</sub>default-1-122532156-blog-108844004.pc_relevant_blogantidownloadv1&amp;utm_relevant_index=2</p><p>yolov5loss</p><ul><li>ComputeLoss</li></ul><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">smooth_BCE</span>(<span class="hljs-params">eps=<span class="hljs-number">0.1</span></span>):  <span class="hljs-comment"># https://github.com/ultralytics/yolov3/issues/238#issuecomment-598028441</span><br>    <span class="hljs-comment"># return positive, negative label smoothing BCE targets</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1.0</span> - <span class="hljs-number">0.5</span> * eps, <span class="hljs-number">0.5</span> * eps<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">BCEBlurWithLogitsLoss</span>(nn.Module):<br>    <span class="hljs-comment"># BCEwithLogitLoss() with reduced missing label effects.</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, alpha=<span class="hljs-number">0.05</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.loss_fcn = nn.BCEWithLogitsLoss(reduction=<span class="hljs-string">&#x27;none&#x27;</span>)  <span class="hljs-comment"># must be nn.BCEWithLogitsLoss()</span><br>        self.alpha = alpha<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, pred, true</span>):<br>        loss = self.loss_fcn(pred, true)<br>        pred = torch.sigmoid(pred)  <span class="hljs-comment"># prob from logits</span><br>        dx = pred - true  <span class="hljs-comment"># reduce only missing label effects</span><br>        <span class="hljs-comment"># dx = (pred - true).abs()  # reduce missing label and false label effects</span><br>        alpha_factor = <span class="hljs-number">1</span> - torch.exp((dx - <span class="hljs-number">1</span>) / (self.alpha + <span class="hljs-number">1e-4</span>))<br>        loss *= alpha_factor<br>        <span class="hljs-keyword">return</span> loss.mean()<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">FocalLoss</span>(nn.Module):<br>    <span class="hljs-comment"># Wraps focal loss around existing loss_fcn(), i.e. criteria = FocalLoss(nn.BCEWithLogitsLoss(), gamma=1.5)</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, loss_fcn, gamma=<span class="hljs-number">1.5</span>, alpha=<span class="hljs-number">0.25</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.loss_fcn = loss_fcn  <span class="hljs-comment"># must be nn.BCEWithLogitsLoss()</span><br>        self.gamma = gamma<br>        self.alpha = alpha<br>        <span class="hljs-comment"># lossreduction</span><br>        <span class="hljs-comment"># &#x27;none&#x27;: </span><br>        <span class="hljs-comment"># &#x27;mean&#x27;: </span><br>        <span class="hljs-comment"># &#x27;sum&#x27;: </span><br>        self.reduction = loss_fcn.reduction<br>        self.loss_fcn.reduction = <span class="hljs-string">&#x27;none&#x27;</span>  <span class="hljs-comment"># required to apply FL to each element</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, pred, true</span>):<br>        loss = self.loss_fcn(pred, true)<br>        <span class="hljs-comment"># p_t = torch.exp(-loss)</span><br>        <span class="hljs-comment"># loss *= self.alpha * (1.000001 - p_t) ** self.gamma  # non-zero power for gradient stability</span><br><br>        <span class="hljs-comment"># TF implementation https://github.com/tensorflow/addons/blob/v0.7.1/tensorflow_addons/losses/focal_loss.py</span><br>        pred_prob = torch.sigmoid(pred)  <span class="hljs-comment"># prob from logits</span><br>        p_t = true * pred_prob + (<span class="hljs-number">1</span> - true) * (<span class="hljs-number">1</span> - pred_prob)<br>        alpha_factor = true * self.alpha + (<span class="hljs-number">1</span> - true) * (<span class="hljs-number">1</span> - self.alpha)<br>        modulating_factor = (<span class="hljs-number">1.0</span> - p_t) ** self.gamma<br>        loss *= alpha_factor * modulating_factor<br><br>        <span class="hljs-keyword">if</span> self.reduction == <span class="hljs-string">&#x27;mean&#x27;</span>:<br>            <span class="hljs-keyword">return</span> loss.mean()<br>        <span class="hljs-keyword">elif</span> self.reduction == <span class="hljs-string">&#x27;sum&#x27;</span>:<br>            <span class="hljs-keyword">return</span> loss.<span class="hljs-built_in">sum</span>()<br>        <span class="hljs-keyword">else</span>:  <span class="hljs-comment"># &#x27;none&#x27;</span><br>            <span class="hljs-keyword">return</span> loss<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">QFocalLoss</span>(nn.Module):<br>    <span class="hljs-comment"># Wraps Quality focal loss around existing loss_fcn(), i.e. criteria = FocalLoss(nn.BCEWithLogitsLoss(), gamma=1.5)</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, loss_fcn, gamma=<span class="hljs-number">1.5</span>, alpha=<span class="hljs-number">0.25</span></span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.loss_fcn = loss_fcn  <span class="hljs-comment"># must be nn.BCEWithLogitsLoss()</span><br>        self.gamma = gamma<br>        self.alpha = alpha<br>        self.reduction = loss_fcn.reduction<br>        self.loss_fcn.reduction = <span class="hljs-string">&#x27;none&#x27;</span>  <span class="hljs-comment"># required to apply FL to each element</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, pred, true</span>):<br>        loss = self.loss_fcn(pred, true)<br><br>        pred_prob = torch.sigmoid(pred)  <span class="hljs-comment"># prob from logits</span><br>        alpha_factor = true * self.alpha + (<span class="hljs-number">1</span> - true) * (<span class="hljs-number">1</span> - self.alpha)<br>        modulating_factor = torch.<span class="hljs-built_in">abs</span>(true - pred_prob) ** self.gamma<br>        loss *= alpha_factor * modulating_factor<br><br>        <span class="hljs-keyword">if</span> self.reduction == <span class="hljs-string">&#x27;mean&#x27;</span>:<br>            <span class="hljs-keyword">return</span> loss.mean()<br>        <span class="hljs-keyword">elif</span> self.reduction == <span class="hljs-string">&#x27;sum&#x27;</span>:<br>            <span class="hljs-keyword">return</span> loss.<span class="hljs-built_in">sum</span>()<br>        <span class="hljs-keyword">else</span>:  <span class="hljs-comment"># &#x27;none&#x27;</span><br>            <span class="hljs-keyword">return</span> loss<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ComputeLoss</span>:<br>    sort_obj_iou = <span class="hljs-literal">False</span><br><br>    <span class="hljs-comment"># Compute losses</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, model, autobalance=<span class="hljs-literal">False</span></span>):<br>        device = <span class="hljs-built_in">next</span>(model.parameters()).device  <span class="hljs-comment"># get model device</span><br>        h = model.hyp  <span class="hljs-comment"># hyperparameters</span><br>        <br>        <span class="hljs-comment"># objBCELoss()</span><br>        <span class="hljs-comment"># YOLOV5BCEloss,sigmoidsoftmax</span><br>        <span class="hljs-comment"># 2</span><br>        <span class="hljs-comment"># nn.BCEWithLogitsLosssigmoidnn.BCELoss</span><br><br>        <span class="hljs-comment"># Define criteria</span><br>        <span class="hljs-comment"># pos_weight</span><br>        BCEcls = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h[<span class="hljs-string">&#x27;cls_pw&#x27;</span>]], device=device))<br>        BCEobj = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([h[<span class="hljs-string">&#x27;obj_pw&#x27;</span>]], device=device))<br><br>        <span class="hljs-comment"># ,eps=0,cp=1,cn=0 cpcn</span><br>        <span class="hljs-comment"># Class label smoothing https://arxiv.org/pdf/1902.04103.pdf eqn 3</span><br>        self.cp, self.cn = smooth_BCE(eps=h.get(<span class="hljs-string">&#x27;label_smoothing&#x27;</span>, <span class="hljs-number">0.0</span>))  <span class="hljs-comment"># positive, negative BCE targets</span><br><br>        <span class="hljs-comment"># Focal loss</span><br>        <span class="hljs-comment"># focal losshttps://blog.csdn.net/cxkyxx/article/details/108455805</span><br>        <span class="hljs-comment"># g0focal loss</span><br>        g = h[<span class="hljs-string">&#x27;fl_gamma&#x27;</span>]  <span class="hljs-comment"># focal loss gamma</span><br>        <span class="hljs-keyword">if</span> g &gt; <span class="hljs-number">0</span>:<br>            <span class="hljs-comment"># FocalLoss</span><br>            BCEcls, BCEobj = FocalLoss(BCEcls, g), FocalLoss(BCEobj, g)<br><br>        <span class="hljs-comment"># balance</span><br>        <span class="hljs-comment"># ()(),.</span><br>        <span class="hljs-comment">#    </span><br>        m = de_parallel(model).model[-<span class="hljs-number">1</span>]  <span class="hljs-comment"># Detect() module</span><br>        self.balance = &#123;<span class="hljs-number">3</span>: [<span class="hljs-number">4.0</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">0.4</span>]&#125;.get(m.nl, [<span class="hljs-number">4.0</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">0.25</span>, <span class="hljs-number">0.06</span>, <span class="hljs-number">0.02</span>])  <span class="hljs-comment"># P3-P7</span><br>        self.ssi = <span class="hljs-built_in">list</span>(m.stride).index(<span class="hljs-number">16</span>) <span class="hljs-keyword">if</span> autobalance <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>  <span class="hljs-comment"># stride 16 index</span><br>        self.BCEcls, self.BCEobj, self.gr, self.hyp, self.autobalance = BCEcls, BCEobj, <span class="hljs-number">1.0</span>, h, autobalance<br>        self.na = m.na  <span class="hljs-comment"># number of anchors</span><br>        self.nc = m.nc  <span class="hljs-comment"># number of classes</span><br>        self.nl = m.nl  <span class="hljs-comment"># number of layers</span><br>        self.anchors = m.anchors<br>        self.device = device<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, p, targets</span>):  <span class="hljs-comment"># predictions, targets</span><br>        lcls = torch.zeros(<span class="hljs-number">1</span>, device=self.device)  <span class="hljs-comment"># class loss</span><br>        lbox = torch.zeros(<span class="hljs-number">1</span>, device=self.device)  <span class="hljs-comment"># box loss</span><br>        lobj = torch.zeros(<span class="hljs-number">1</span>, device=self.device)  <span class="hljs-comment"># object loss</span><br>        <span class="hljs-comment"># build_targets()</span><br>        tcls, tbox, indices, anchors = self.build_targets(p, targets)  <span class="hljs-comment"># targets</span><br><br>        <span class="hljs-comment"># Losses</span><br>        <span class="hljs-keyword">for</span> i, pi <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(p):  <span class="hljs-comment"># layer index, layer predictions</span><br>            b, a, gj, gi = indices[i]  <span class="hljs-comment"># image, anchor, gridy, gridx</span><br>            tobj = torch.zeros(pi.shape[:<span class="hljs-number">4</span>], dtype=pi.dtype, device=self.device)  <span class="hljs-comment"># target obj</span><br><br>            n = b.shape[<span class="hljs-number">0</span>]  <span class="hljs-comment"># number of targets</span><br>            <span class="hljs-keyword">if</span> n:<br>                <span class="hljs-comment"># pxy, pwh, _, pcls = pi[b, a, gj, gi].tensor_split((2, 4, 5), dim=1)  # faster, requires torch 1.8.0</span><br>                pxy, pwh, _, pcls = pi[b, a, gj, gi].split((<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, self.nc), <span class="hljs-number">1</span>)  <span class="hljs-comment"># target-subset of predictions</span><br><br>                <span class="hljs-comment"># Regression</span><br>                pxy = pxy.sigmoid() * <span class="hljs-number">2</span> - <span class="hljs-number">0.5</span><br>                pwh = (pwh.sigmoid() * <span class="hljs-number">2</span>) ** <span class="hljs-number">2</span> * anchors[i]<br>                pbox = torch.cat((pxy, pwh), <span class="hljs-number">1</span>)  <span class="hljs-comment"># predicted box</span><br>                iou = bbox_iou(pbox, tbox[i], CIoU=<span class="hljs-literal">True</span>).squeeze()  <span class="hljs-comment"># iou(prediction, target)</span><br>                lbox += (<span class="hljs-number">1.0</span> - iou).mean()  <span class="hljs-comment"># iou loss</span><br><br>                <span class="hljs-comment"># Objectness</span><br>                iou = iou.detach().clamp(<span class="hljs-number">0</span>).<span class="hljs-built_in">type</span>(tobj.dtype)<br>                <span class="hljs-keyword">if</span> self.sort_obj_iou:<br>                    j = iou.argsort()<br>                    b, a, gj, gi, iou = b[j], a[j], gj[j], gi[j], iou[j]<br>                <span class="hljs-keyword">if</span> self.gr &lt; <span class="hljs-number">1</span>:<br>                    iou = (<span class="hljs-number">1.0</span> - self.gr) + self.gr * iou<br>                tobj[b, a, gj, gi] = iou  <span class="hljs-comment"># iou ratio</span><br><br>                <span class="hljs-comment"># Classification</span><br>                <span class="hljs-keyword">if</span> self.nc &gt; <span class="hljs-number">1</span>:  <span class="hljs-comment"># cls loss (only if multiple classes)</span><br>                    t = torch.full_like(pcls, self.cn, device=self.device)  <span class="hljs-comment"># targets</span><br>                    t[<span class="hljs-built_in">range</span>(n), tcls[i]] = self.cp<br>                    lcls += self.BCEcls(pcls, t)  <span class="hljs-comment"># BCE</span><br><br>                <span class="hljs-comment"># Append targets to text file</span><br>                <span class="hljs-comment"># with open(&#x27;targets.txt&#x27;, &#x27;a&#x27;) as file:</span><br>                <span class="hljs-comment">#     [file.write(&#x27;%11.5g &#x27; * 4 % tuple(x) + &#x27;\n&#x27;) for x in torch.cat((txy[i], twh[i]), 1)]</span><br><br>            obji = self.BCEobj(pi[..., <span class="hljs-number">4</span>], tobj)<br>            lobj += obji * self.balance[i]  <span class="hljs-comment"># obj loss</span><br>            <span class="hljs-keyword">if</span> self.autobalance:<br>                self.balance[i] = self.balance[i] * <span class="hljs-number">0.9999</span> + <span class="hljs-number">0.0001</span> / obji.detach().item()<br><br>        <span class="hljs-keyword">if</span> self.autobalance:<br>            self.balance = [x / self.balance[self.ssi] <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> self.balance]<br>        lbox *= self.hyp[<span class="hljs-string">&#x27;box&#x27;</span>]<br>        lobj *= self.hyp[<span class="hljs-string">&#x27;obj&#x27;</span>]<br>        lcls *= self.hyp[<span class="hljs-string">&#x27;cls&#x27;</span>]<br>        bs = tobj.shape[<span class="hljs-number">0</span>]  <span class="hljs-comment"># batch size</span><br><br>        <span class="hljs-keyword">return</span> (lbox + lobj + lcls) * bs, torch.cat((lbox, lobj, lcls)).detach()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">build_targets</span>(<span class="hljs-params">self, p, targets</span>):<br>        <span class="hljs-comment"># p: List[torch.tensor * 3], p[i].shape = (b, 3, h, w, nc+5)</span><br>        <span class="hljs-comment"># target: target.shape = (nt, 6) 6i class x y w h</span><br>        <span class="hljs-comment"># ii c xywh</span><br>        <br>        <span class="hljs-comment"># Build targets for compute_loss(), input targets(image,class,x,y,w,h)</span><br>        na, nt = self.na, targets.shape[<span class="hljs-number">0</span>]  <span class="hljs-comment"># number of anchors, number of targets</span><br>        tcls, tbox, indices, anch = [], [], [], []<br>        <span class="hljs-comment"># gaintarget(na,nt,7)xywh</span><br>        <span class="hljs-comment"># 7 i c x y w h ai</span><br>        gain = torch.ones(<span class="hljs-number">7</span>, device=self.device)  <span class="hljs-comment"># normalized to gridspace gain</span><br>        <span class="hljs-comment"># nanaai012</span><br>        <span class="hljs-comment"># ai = [[0, 0, ..., 0],</span><br>        <span class="hljs-comment">#       [1, 1, ..., 1],</span><br>        <span class="hljs-comment">#       [2, 2, ..., 2]]</span><br>        ai = torch.arange(na, device=self.device).<span class="hljs-built_in">float</span>().view(na, <span class="hljs-number">1</span>).repeat(<span class="hljs-number">1</span>, nt)  <span class="hljs-comment"># same as .repeat_interleave(nt)</span><br>        <span class="hljs-comment"># targets.shape = (na, nt, 7)</span><br>        <span class="hljs-comment"># targets = [[[image1, c, x, y, w, h, 0],</span><br>        <span class="hljs-comment">#             [image2, c, x, y, w, h, 0],</span><br>        <span class="hljs-comment">#             ...</span><br>        <span class="hljs-comment">#             [imageN, c, x, y, w, h, 0]],</span><br>        <span class="hljs-comment">#            [[image1, c, x, y, w, h, 1],</span><br>        <span class="hljs-comment">#             [image2, c, x, y, w, h, 1],</span><br>        <span class="hljs-comment">#             ...</span><br>        <span class="hljs-comment">#             [imageN, c, x, y, w, h, 1]],]</span><br>        <span class="hljs-comment">#            [[image1, c, x, y, w, h, 2],</span><br>        <span class="hljs-comment">#             [image2, c, x, y, w, h, 2],</span><br>        <span class="hljs-comment">#             ...</span><br>        <span class="hljs-comment">#             [imageN, c, x, y, w, h, 2]]]</span><br>        targets = torch.cat((targets.repeat(na, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>), ai[..., <span class="hljs-literal">None</span>]), <span class="hljs-number">2</span>)  <span class="hljs-comment"># append anchor indices</span><br><br>        g = <span class="hljs-number">0.5</span>  <span class="hljs-comment"># bias</span><br>        off = torch.tensor(<br>            [<br>                [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>],<br>                [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>],<br>                [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>],<br>                [-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>],<br>                [<span class="hljs-number">0</span>, -<span class="hljs-number">1</span>],  <span class="hljs-comment"># j,k,l,m</span><br>                <span class="hljs-comment"># [1, 1], [1, -1], [-1, 1], [-1, -1],  # jk,jm,lk,lm</span><br>            ],<br>            device=self.device).<span class="hljs-built_in">float</span>() * g  <span class="hljs-comment"># offsets</span><br><br>        <span class="hljs-comment"># </span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.nl):<br>            <span class="hljs-comment"># self.anchors: (3, 3, 2) anchor,2</span><br>            <span class="hljs-comment"># anchors: (3, 2) anchor</span><br>            <span class="hljs-comment"># targetsxywh</span><br>            <span class="hljs-comment"># i c x y w h ai[1, 1, , , , , 1]</span><br>            anchors = self.anchors[i]<br>            <span class="hljs-comment"># </span><br>            <span class="hljs-comment"># gain = [1, 1, nx, ny, nx, ny, 1]</span><br>            gain[<span class="hljs-number">2</span>:<span class="hljs-number">6</span>] = torch.tensor(p[i].shape)[[<span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>]]  <span class="hljs-comment"># xyxy gain</span><br><br>            <span class="hljs-comment"># Match targets to anchors</span><br>            <span class="hljs-comment"># </span><br>            t = targets * gain  <span class="hljs-comment"># shape(3,n,7)</span><br>            <span class="hljs-keyword">if</span> nt:<br>                <span class="hljs-comment"># Matches</span><br>                <span class="hljs-comment"># t.shape=(na, nt, 7), r.shape=[na, nt, 2]</span><br>                <span class="hljs-comment"># ranchor</span><br>                r = t[..., <span class="hljs-number">4</span>:<span class="hljs-number">6</span>] / anchors[:, <span class="hljs-literal">None</span>]  <span class="hljs-comment"># wh ratio</span><br>                <span class="hljs-comment"># GTanchor</span><br>                <span class="hljs-comment"># torch.max(r, 1 / r)</span><br>                <span class="hljs-comment"># max(2)</span><br>                <span class="hljs-comment"># [0]torch.maxvalueindexvalue</span><br>                <span class="hljs-comment"># j.shape = (na, nt)</span><br>                <span class="hljs-comment"># j = [[bool, bool, ..., bool], ..., [bool, bool, ..., bool]]</span><br>                j = torch.<span class="hljs-built_in">max</span>(r, <span class="hljs-number">1</span> / r).<span class="hljs-built_in">max</span>(<span class="hljs-number">2</span>)[<span class="hljs-number">0</span>] &lt; self.hyp[<span class="hljs-string">&#x27;anchor_t&#x27;</span>]  <span class="hljs-comment"># compare</span><br>                <span class="hljs-comment"># j = wh_iou(anchors, t[:, 4:6]) &gt; model.hyp[&#x27;iou_t&#x27;]  </span><br>                <span class="hljs-comment"># iou(3,n)=wh_iou(anchors(3,2), gwh(n,2))</span><br>                <span class="hljs-comment">#  t:(na,nt,7) j:(na,nt)</span><br>                <span class="hljs-comment">#  t:(NTrue, 7) NTrue</span><br>                t = t[j]  <span class="hljs-comment"># filter 4anchor</span><br><br>                <span class="hljs-comment"># Offsets</span><br>                <span class="hljs-comment"># gxy.shape = [NTrue, 2], </span><br>                <span class="hljs-comment"># gxi.shape = [NTrue, 2], w - x, h = y, </span><br>                gxy = t[:, <span class="hljs-number">2</span>:<span class="hljs-number">4</span>]  <span class="hljs-comment"># grid xy</span><br>                gxi = gain[[<span class="hljs-number">2</span>, <span class="hljs-number">3</span>]] - gxy  <span class="hljs-comment"># inverse</span><br>                <span class="hljs-comment"># gxy % 1 grid</span><br>                <span class="hljs-comment"># gxi % 1 grid</span><br>                <span class="hljs-comment"># 0.51</span><br>                <span class="hljs-comment"># j.shape = [NTrue], j = [bool, bool, ..., bool]; k, l, m</span><br>                j, k = ((gxy % <span class="hljs-number">1</span> &lt; g) &amp; (gxy &gt; <span class="hljs-number">1</span>)).T<br>                l, m = ((gxi % <span class="hljs-number">1</span> &lt; g) &amp; (gxi &gt; <span class="hljs-number">1</span>)).T<br>                <span class="hljs-comment"># j.shape = [5, NTrue]</span><br>                <span class="hljs-comment"># trepeatt.shape = [5, NTrue, 7]</span><br>                <span class="hljs-comment"># jshape[NOff, 7] NOffNTrue + (jklmTrue)</span><br>                <span class="hljs-comment"># torch.zeros_like(gxy)[None].shape = [1,NTrue,2]</span><br>                <span class="hljs-comment"># off[:, None].shape = [5,1,2]</span><br>                <span class="hljs-comment"># shape = [5,NTrue,2]</span><br>                <span class="hljs-comment"># joffsets.shape = [NOff,2]</span><br>                <span class="hljs-comment"># grid0.5grid</span><br>                j = torch.stack((torch.ones_like(j), j, k, l, m))<br>                t = t.repeat((<span class="hljs-number">5</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>))[j]<br>                offsets = (torch.zeros_like(gxy)[<span class="hljs-literal">None</span>] + off[:, <span class="hljs-literal">None</span>])[j]<br>            <span class="hljs-keyword">else</span>:<br>                t = targets[<span class="hljs-number">0</span>]<br>                offsets = <span class="hljs-number">0</span><br><br>            <span class="hljs-comment"># Define</span><br>            bc, gxy, gwh, a = t.chunk(<span class="hljs-number">4</span>, <span class="hljs-number">1</span>)  <span class="hljs-comment"># (image, class), grid xy, grid wh, anchors</span><br>            a, (b, c) = a.long().view(-<span class="hljs-number">1</span>), bc.long().T  <span class="hljs-comment"># anchors, image, class</span><br>            gij = (gxy - offsets).long()<br>            gi, gj = gij.T  <span class="hljs-comment"># grid indices</span><br><br>            <span class="hljs-comment"># Append</span><br>            <span class="hljs-comment"># tboxgrid[0,1] shape = [nl,NOff]</span><br>            <span class="hljs-comment"># anchanchors shape = [nl,NOff,2]</span><br>            <span class="hljs-comment"># indices = [image, anchor, gridy, gridx] shape = [nl,4,NOff]</span><br>            <span class="hljs-comment"># tcls shape = [nl,NOff]</span><br>            indices.append((b, a, gj.clamp_(<span class="hljs-number">0</span>, gain[<span class="hljs-number">3</span>] - <span class="hljs-number">1</span>), gi.clamp_(<span class="hljs-number">0</span>, gain[<span class="hljs-number">2</span>] - <span class="hljs-number">1</span>)))  <span class="hljs-comment"># image, anchor, grid indices</span><br>            tbox.append(torch.cat((gxy - gij, gwh), <span class="hljs-number">1</span>))  <span class="hljs-comment"># box</span><br>            anch.append(anchors[a])  <span class="hljs-comment"># anchors</span><br>            tcls.append(c)  <span class="hljs-comment"># class</span><br><br>        <span class="hljs-keyword">return</span> tcls, tbox, indices, anch<br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>cv</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>yolov1</title>
    <link href="/2022/09/30/yolov1/"/>
    <url>/2022/09/30/yolov1/</url>
    
    <content type="html"><![CDATA[<h1 id=""></h1><p><img src="/img/cv/image-20220930153754299.png" /></p><p><img src="/img/cv/image-20220930153824653.png" /></p><p><img src="/img/cv/image-20220930153848083.png" /></p><p><img src="/img/cv/image-20220930153904048.png" /></p><p><img src="/img/cv/image-20220930153921376.png" /></p>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>cv</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>SSD</title>
    <link href="/2022/09/30/SSD/"/>
    <url>/2022/09/30/SSD/</url>
    
    <content type="html"><![CDATA[<h1 id=""></h1><p><img src="/img/cv/image-20220930152818338.png" /></p><p><img src="/img/cv/image-20220930152839522.png" /></p><p><img src="/img/cv/image-20220930152851705.png" /></p><p><img src="/img/cv/image-20220930152903880.png" /></p><p><img src="/img/cv/image-20220930152918813.png" /></p><p><img src="/img/cv/image-20220930152930806.png" /></p><p><img src="/img/cv/image-20220930152941778.png" /></p><p><img src="/img/cv/image-20220930152952521.png" /></p><p><img src="/img/cv/image-20220930153004458.png" /></p><p><img src="/img/cv/image-20220930153015647.png" /></p><p><img src="/img/cv/image-20220930153028568.png" /></p><p><img src="/img/cv/image-20220930153042132.png" /></p><p><img src="/img/cv/image-20220930153054831.png" /></p><p><img src="/img/cv/image-20220930153110871.png" /></p><p><img src="/img/cv/image-20220930153121772.png" /></p><p><img src="/img/cv/image-20220930153132417.png" /></p><p><img src="/img/cv/image-20220930153142800.png" /></p>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>cv</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>FPN</title>
    <link href="/2022/09/30/FPN/"/>
    <url>/2022/09/30/FPN/</url>
    
    <content type="html"><![CDATA[<h1 id=""></h1><p><img src="/img/cv/image-20220930111912244.png" /></p><p><img src="/img/cv/image-20220930111926838.png" /></p><p><img src="/img/cv/image-20220930111940668.png" /></p><p><img src="/img/cv/image-20220930112000674.png" /></p><p><img src="/img/cv/image-20220930112024501.png" /></p><p><img src="/img/cv/image-20220930112036794.png" /></p>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>cv</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Faster_R-CNN</title>
    <link href="/2022/09/30/Faster-R-CNN/"/>
    <url>/2022/09/30/Faster-R-CNN/</url>
    
    <content type="html"><![CDATA[<h1 id=""></h1><p><img src="/img/cv/image-20220930104009662.png" /></p><p><img src="/img/cv/image-20220930104029226.png" /></p><p><img src="/img/cv/image-20220930104047080.png" /></p><p><img src="/img/cv/image-20220930104101860.png" /></p><p><img src="/img/cv/image-20220930104253294.png" /></p><p><img src="/img/cv/image-20220930104309535.png" /></p><p><img src="/img/cv/image-20220930104322156.png" /></p><p><img src="/img/cv/image-20220930104332006.png" /></p><p><img src="/img/cv/image-20220930104345120.png" /></p><p><img src="/img/cv/image-20220930104356421.png" /></p><p><img src="/img/cv/image-20220930104409007.png" /></p><p><img src="/img/cv/image-20220930104420565.png" /></p><p><img src="/img/cv/image-20220930104433453.png" /></p><p><img src="/img/cv/image-20220930104446017.png" /></p><p><img src="/img/cv/image-20220930104500570.png" /></p>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>cv</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Fast_R-CNN</title>
    <link href="/2022/09/30/Fast-R-CNN/"/>
    <url>/2022/09/30/Fast-R-CNN/</url>
    
    <content type="html"><![CDATA[<h1 id=""></h1><p><img src="/img/cv/image-20220930103138705.png" /></p><p><img src="/img/cv/image-20220930103151991.png" /></p><p><img src="/img/cv/image-20220930103204019.png" /></p><p><img src="/img/cv/image-20220930103243703.png" /></p><p><img src="/img/cv/image-20220930103316912.png" /></p><p><img src="/img/cv/image-20220930103331647.png" /></p><p><img src="/img/cv/image-20220930103413400.png" /></p><p><img src="/img/cv/image-20220930103431178.png" /></p><p><img src="/img/cv/image-20220930103445275.png" /></p><p><img src="/img/cv/image-20220930103507638.png" /></p><p><img src="/img/cv/image-20220930103520918.png" /></p><p><img src="/img/cv/image-20220930103548664.png" /></p><p><img src="/img/cv/image-20220930103600909.png" /></p><p><img src="/img/cv/image-20220930103638505.png" /></p><p><img src="/img/cv/image-20220930103656760.png" /></p><p><img src="/img/cv/image-20220930103721592.png" /></p><p><img src="/img/cv/image-20220930103736379.png" /></p>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>cv</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>RCNN</title>
    <link href="/2022/09/29/RCNN/"/>
    <url>/2022/09/29/RCNN/</url>
    
    <content type="html"><![CDATA[<h1 id=""></h1><p><img src="/img/cv/image-20220929174947399.png" /></p><p><img src="/img/cv/image-20220929174959830.png" /></p><p><img src="/img/cv/image-20220929175012228.png" /></p><p><img src="/img/cv/image-20220929175024811.png" /></p><p><img src="/img/cv/image-20220929175035980.png" /></p><p><img src="/img/cv/image-20220929175055640.png" /></p><p><img src="/img/cv/image-20220929175116843.png" /></p><p><img src="/img/cv/image-20220929175137830.png" /></p><p><img src="/img/cv/image-20220929175155293.png" /></p><p><img src="/img/cv/image-20220929175207362.png" /></p>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>cv</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>GoogleNet</title>
    <link href="/2022/09/29/GoogleNet/"/>
    <url>/2022/09/29/GoogleNet/</url>
    
    <content type="html"><![CDATA[<h1 id=""></h1><p><img src="/img/cv/image-20220929165102079.png" /></p><p><img src="/img/cv/image-20220929165115906.png" /></p><p><img src="/img/cv/image-20220929165128922.png" /></p><p><img src="/img/cv/image-20220929165145364.png" /></p><p><img src="/img/cv/image-20220929165157614.png" /></p><p><img src="/img/cv/image-20220929165210033.png" /></p><p><img src="/img/cv/image-20220929165223735.png" /></p><h1 id=""></h1><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">GoogLeNet</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, num_classes=<span class="hljs-number">1000</span>, aux_logits=<span class="hljs-literal">True</span>, init_weights=<span class="hljs-literal">False</span></span>):<br>        <span class="hljs-built_in">super</span>(GoogLeNet, self).__init__()<br>        self.aux_logits = aux_logits<br><br>        self.conv1 = BasicConv2d(<span class="hljs-number">3</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">7</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">3</span>)<br>        self.maxpool1 = nn.MaxPool2d(<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, ceil_mode=<span class="hljs-literal">True</span>)<br><br>        self.conv2 = BasicConv2d(<span class="hljs-number">64</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">1</span>)<br>        self.conv3 = BasicConv2d(<span class="hljs-number">64</span>, <span class="hljs-number">192</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>)<br>        self.maxpool2 = nn.MaxPool2d(<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, ceil_mode=<span class="hljs-literal">True</span>)<br><br>        self.inception3a = Inception(<span class="hljs-number">192</span>, <span class="hljs-number">64</span>, <span class="hljs-number">96</span>, <span class="hljs-number">128</span>, <span class="hljs-number">16</span>, <span class="hljs-number">32</span>, <span class="hljs-number">32</span>)<br>        self.inception3b = Inception(<span class="hljs-number">256</span>, <span class="hljs-number">128</span>, <span class="hljs-number">128</span>, <span class="hljs-number">192</span>, <span class="hljs-number">32</span>, <span class="hljs-number">96</span>, <span class="hljs-number">64</span>)<br>        self.maxpool3 = nn.MaxPool2d(<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, ceil_mode=<span class="hljs-literal">True</span>)<br><br>        self.inception4a = Inception(<span class="hljs-number">480</span>, <span class="hljs-number">192</span>, <span class="hljs-number">96</span>, <span class="hljs-number">208</span>, <span class="hljs-number">16</span>, <span class="hljs-number">48</span>, <span class="hljs-number">64</span>)<br>        self.inception4b = Inception(<span class="hljs-number">512</span>, <span class="hljs-number">160</span>, <span class="hljs-number">112</span>, <span class="hljs-number">224</span>, <span class="hljs-number">24</span>, <span class="hljs-number">64</span>, <span class="hljs-number">64</span>)<br>        self.inception4c = Inception(<span class="hljs-number">512</span>, <span class="hljs-number">128</span>, <span class="hljs-number">128</span>, <span class="hljs-number">256</span>, <span class="hljs-number">24</span>, <span class="hljs-number">64</span>, <span class="hljs-number">64</span>)<br>        self.inception4d = Inception(<span class="hljs-number">512</span>, <span class="hljs-number">112</span>, <span class="hljs-number">144</span>, <span class="hljs-number">288</span>, <span class="hljs-number">32</span>, <span class="hljs-number">64</span>, <span class="hljs-number">64</span>)<br>        self.inception4e = Inception(<span class="hljs-number">528</span>, <span class="hljs-number">256</span>, <span class="hljs-number">160</span>, <span class="hljs-number">320</span>, <span class="hljs-number">32</span>, <span class="hljs-number">128</span>, <span class="hljs-number">128</span>)<br>        self.maxpool4 = nn.MaxPool2d(<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, ceil_mode=<span class="hljs-literal">True</span>)<br><br>        self.inception5a = Inception(<span class="hljs-number">832</span>, <span class="hljs-number">256</span>, <span class="hljs-number">160</span>, <span class="hljs-number">320</span>, <span class="hljs-number">32</span>, <span class="hljs-number">128</span>, <span class="hljs-number">128</span>)<br>        self.inception5b = Inception(<span class="hljs-number">832</span>, <span class="hljs-number">384</span>, <span class="hljs-number">192</span>, <span class="hljs-number">384</span>, <span class="hljs-number">48</span>, <span class="hljs-number">128</span>, <span class="hljs-number">128</span>)<br><br>        <span class="hljs-keyword">if</span> self.aux_logits:<br>            self.aux1 = InceptionAux(<span class="hljs-number">512</span>, num_classes)<br>            self.aux2 = InceptionAux(<span class="hljs-number">528</span>, num_classes)<br><br>        self.avgpool = nn.AdaptiveAvgPool2d((<span class="hljs-number">1</span>, <span class="hljs-number">1</span>))<br>        self.dropout = nn.Dropout(<span class="hljs-number">0.4</span>)<br>        self.fc = nn.Linear(<span class="hljs-number">1024</span>, num_classes)<br>        <span class="hljs-keyword">if</span> init_weights:<br>            self._initialize_weights()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># N x 3 x 224 x 224</span><br>        x = self.conv1(x)<br>        <span class="hljs-comment"># N x 64 x 112 x 112</span><br>        x = self.maxpool1(x)<br>        <span class="hljs-comment"># N x 64 x 56 x 56</span><br>        x = self.conv2(x)<br>        <span class="hljs-comment"># N x 64 x 56 x 56</span><br>        x = self.conv3(x)<br>        <span class="hljs-comment"># N x 192 x 56 x 56</span><br>        x = self.maxpool2(x)<br><br>        <span class="hljs-comment"># N x 192 x 28 x 28</span><br>        x = self.inception3a(x)<br>        <span class="hljs-comment"># N x 256 x 28 x 28</span><br>        x = self.inception3b(x)<br>        <span class="hljs-comment"># N x 480 x 28 x 28</span><br>        x = self.maxpool3(x)<br>        <span class="hljs-comment"># N x 480 x 14 x 14</span><br>        x = self.inception4a(x)<br>        <span class="hljs-comment"># N x 512 x 14 x 14</span><br>        <span class="hljs-keyword">if</span> self.training <span class="hljs-keyword">and</span> self.aux_logits:    <span class="hljs-comment"># eval model lose this layer</span><br>            aux1 = self.aux1(x)<br><br>        x = self.inception4b(x)<br>        <span class="hljs-comment"># N x 512 x 14 x 14</span><br>        x = self.inception4c(x)<br>        <span class="hljs-comment"># N x 512 x 14 x 14</span><br>        x = self.inception4d(x)<br>        <span class="hljs-comment"># N x 528 x 14 x 14</span><br>        <span class="hljs-keyword">if</span> self.training <span class="hljs-keyword">and</span> self.aux_logits:    <span class="hljs-comment"># eval model lose this layer</span><br>            aux2 = self.aux2(x)<br><br>        x = self.inception4e(x)<br>        <span class="hljs-comment"># N x 832 x 14 x 14</span><br>        x = self.maxpool4(x)<br>        <span class="hljs-comment"># N x 832 x 7 x 7</span><br>        x = self.inception5a(x)<br>        <span class="hljs-comment"># N x 832 x 7 x 7</span><br>        x = self.inception5b(x)<br>        <span class="hljs-comment"># N x 1024 x 7 x 7</span><br><br>        x = self.avgpool(x)<br>        <span class="hljs-comment"># N x 1024 x 1 x 1</span><br>        x = torch.flatten(x, <span class="hljs-number">1</span>)<br>        <span class="hljs-comment"># N x 1024</span><br>        x = self.dropout(x)<br>        x = self.fc(x)<br>        <span class="hljs-comment"># N x 1000 (num_classes)</span><br>        <span class="hljs-keyword">if</span> self.training <span class="hljs-keyword">and</span> self.aux_logits:   <span class="hljs-comment"># eval model lose this layer</span><br>            <span class="hljs-keyword">return</span> x, aux2, aux1<br>        <span class="hljs-keyword">return</span> x<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_initialize_weights</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> self.modules():<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m, nn.Conv2d):<br>                nn.init.kaiming_normal_(m.weight, mode=<span class="hljs-string">&#x27;fan_out&#x27;</span>, nonlinearity=<span class="hljs-string">&#x27;relu&#x27;</span>)<br>                <span class="hljs-keyword">if</span> m.bias <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                    nn.init.constant_(m.bias, <span class="hljs-number">0</span>)<br>            <span class="hljs-keyword">elif</span> <span class="hljs-built_in">isinstance</span>(m, nn.Linear):<br>                nn.init.normal_(m.weight, <span class="hljs-number">0</span>, <span class="hljs-number">0.01</span>)<br>                nn.init.constant_(m.bias, <span class="hljs-number">0</span>)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Inception</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, in_channels, ch1x1, ch3x3red, ch3x3, ch5x5red, ch5x5, pool_proj</span>):<br>        <span class="hljs-built_in">super</span>(Inception, self).__init__()<br><br>        self.branch1 = BasicConv2d(in_channels, ch1x1, kernel_size=<span class="hljs-number">1</span>)<br><br>        self.branch2 = nn.Sequential(<br>            BasicConv2d(in_channels, ch3x3red, kernel_size=<span class="hljs-number">1</span>),<br>            BasicConv2d(ch3x3red, ch3x3, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>)   <span class="hljs-comment"># </span><br>        )<br><br>        self.branch3 = nn.Sequential(<br>            BasicConv2d(in_channels, ch5x5red, kernel_size=<span class="hljs-number">1</span>),<br>            <span class="hljs-comment"># 3x3kernel5x5issue</span><br>            <span class="hljs-comment"># Please see https://github.com/pytorch/vision/issues/906 for details.</span><br>            BasicConv2d(ch5x5red, ch5x5, kernel_size=<span class="hljs-number">5</span>, padding=<span class="hljs-number">2</span>)   <span class="hljs-comment"># </span><br>        )<br><br>        self.branch4 = nn.Sequential(<br>            nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>),<br>            BasicConv2d(in_channels, pool_proj, kernel_size=<span class="hljs-number">1</span>)<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        branch1 = self.branch1(x)<br>        branch2 = self.branch2(x)<br>        branch3 = self.branch3(x)<br>        branch4 = self.branch4(x)<br><br>        outputs = [branch1, branch2, branch3, branch4]<br>        <span class="hljs-keyword">return</span> torch.cat(outputs, <span class="hljs-number">1</span>)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">InceptionAux</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, in_channels, num_classes</span>):<br>        <span class="hljs-built_in">super</span>(InceptionAux, self).__init__()<br>        self.averagePool = nn.AvgPool2d(kernel_size=<span class="hljs-number">5</span>, stride=<span class="hljs-number">3</span>)<br>        self.conv = BasicConv2d(in_channels, <span class="hljs-number">128</span>, kernel_size=<span class="hljs-number">1</span>)  <span class="hljs-comment"># output[batch, 128, 4, 4]</span><br><br>        self.fc1 = nn.Linear(<span class="hljs-number">2048</span>, <span class="hljs-number">1024</span>)<br>        self.fc2 = nn.Linear(<span class="hljs-number">1024</span>, num_classes)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># aux1: N x 512 x 14 x 14, aux2: N x 528 x 14 x 14</span><br>        x = self.averagePool(x)<br>        <span class="hljs-comment"># aux1: N x 512 x 4 x 4, aux2: N x 528 x 4 x 4</span><br>        x = self.conv(x)<br>        <span class="hljs-comment"># N x 128 x 4 x 4</span><br>        x = torch.flatten(x, <span class="hljs-number">1</span>)<br>        x = F.dropout(x, <span class="hljs-number">0.5</span>, training=self.training)<br>        <span class="hljs-comment"># N x 2048</span><br>        x = F.relu(self.fc1(x), inplace=<span class="hljs-literal">True</span>)<br>        x = F.dropout(x, <span class="hljs-number">0.5</span>, training=self.training)<br>        <span class="hljs-comment"># N x 1024</span><br>        x = self.fc2(x)<br>        <span class="hljs-comment"># N x num_classes</span><br>        <span class="hljs-keyword">return</span> x<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">BasicConv2d</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, in_channels, out_channels, **kwargs</span>):<br>        <span class="hljs-built_in">super</span>(BasicConv2d, self).__init__()<br>        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs)<br>        self.relu = nn.ReLU(inplace=<span class="hljs-literal">True</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.conv(x)<br>        x = self.relu(x)<br>        <span class="hljs-keyword">return</span> x<br></code></pre></div></td></tr></table></figure><h1 id=""></h1><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> sys<br><span class="hljs-keyword">import</span> json<br><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms, datasets<br><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><br><span class="hljs-keyword">from</span> model <span class="hljs-keyword">import</span> GoogLeNet<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>    device = torch.device(<span class="hljs-string">&quot;cuda:0&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;using &#123;&#125; device.&quot;</span>.<span class="hljs-built_in">format</span>(device))<br><br>    data_transform = &#123;<br>        <span class="hljs-string">&quot;train&quot;</span>: transforms.Compose([transforms.RandomResizedCrop(<span class="hljs-number">224</span>),<br>                                     transforms.RandomHorizontalFlip(),<br>                                     transforms.ToTensor(),<br>                                     transforms.Normalize((<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>), (<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>))]),<br>        <span class="hljs-string">&quot;val&quot;</span>: transforms.Compose([transforms.Resize((<span class="hljs-number">224</span>, <span class="hljs-number">224</span>)),<br>                                   transforms.ToTensor(),<br>                                   transforms.Normalize((<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>), (<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>))])&#125;<br><br>    data_root = os.path.abspath(os.path.join(os.getcwd(), <span class="hljs-string">&quot;../..&quot;</span>))  <span class="hljs-comment"># get data root path</span><br>    image_path = os.path.join(data_root, <span class="hljs-string">&quot;data_set&quot;</span>, <span class="hljs-string">&quot;flower_data&quot;</span>)  <span class="hljs-comment"># flower data set path</span><br>    <span class="hljs-keyword">assert</span> os.path.exists(image_path), <span class="hljs-string">&quot;&#123;&#125; path does not exist.&quot;</span>.<span class="hljs-built_in">format</span>(image_path)<br>    train_dataset = datasets.ImageFolder(root=os.path.join(image_path, <span class="hljs-string">&quot;train&quot;</span>),<br>                                         transform=data_transform[<span class="hljs-string">&quot;train&quot;</span>])<br>    train_num = <span class="hljs-built_in">len</span>(train_dataset)<br><br>    <span class="hljs-comment"># &#123;&#x27;daisy&#x27;:0, &#x27;dandelion&#x27;:1, &#x27;roses&#x27;:2, &#x27;sunflower&#x27;:3, &#x27;tulips&#x27;:4&#125;</span><br>    flower_list = train_dataset.class_to_idx<br>    cla_dict = <span class="hljs-built_in">dict</span>((val, key) <span class="hljs-keyword">for</span> key, val <span class="hljs-keyword">in</span> flower_list.items())<br>    <span class="hljs-comment"># write dict into json file</span><br>    json_str = json.dumps(cla_dict, indent=<span class="hljs-number">4</span>)<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;class_indices.json&#x27;</span>, <span class="hljs-string">&#x27;w&#x27;</span>) <span class="hljs-keyword">as</span> json_file:<br>        json_file.write(json_str)<br><br>    batch_size = <span class="hljs-number">32</span><br>    nw = <span class="hljs-built_in">min</span>([os.cpu_count(), batch_size <span class="hljs-keyword">if</span> batch_size &gt; <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>, <span class="hljs-number">8</span>])  <span class="hljs-comment"># number of workers</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Using &#123;&#125; dataloader workers every process&#x27;</span>.<span class="hljs-built_in">format</span>(nw))<br><br>    train_loader = torch.utils.data.DataLoader(train_dataset,<br>                                               batch_size=batch_size, shuffle=<span class="hljs-literal">True</span>,<br>                                               num_workers=nw)<br><br>    validate_dataset = datasets.ImageFolder(root=os.path.join(image_path, <span class="hljs-string">&quot;val&quot;</span>),<br>                                            transform=data_transform[<span class="hljs-string">&quot;val&quot;</span>])<br>    val_num = <span class="hljs-built_in">len</span>(validate_dataset)<br>    validate_loader = torch.utils.data.DataLoader(validate_dataset,<br>                                                  batch_size=batch_size, shuffle=<span class="hljs-literal">False</span>,<br>                                                  num_workers=nw)<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;using &#123;&#125; images for training, &#123;&#125; images for validation.&quot;</span>.<span class="hljs-built_in">format</span>(train_num,<br>                                                                           val_num))<br><br>    <span class="hljs-comment"># test_data_iter = iter(validate_loader)</span><br>    <span class="hljs-comment"># test_image, test_label = test_data_iter.next()</span><br><br>    net = GoogLeNet(num_classes=<span class="hljs-number">5</span>, aux_logits=<span class="hljs-literal">True</span>, init_weights=<span class="hljs-literal">True</span>)<br>    <span class="hljs-comment"># </span><br>    <span class="hljs-comment"># bn</span><br>    <span class="hljs-comment"># import torchvision</span><br>    <span class="hljs-comment"># net = torchvision.models.googlenet(num_classes=5)</span><br>    <span class="hljs-comment"># model_dict = net.state_dict()</span><br>    <span class="hljs-comment"># # : https://download.pytorch.org/models/googlenet-1378be20.pth</span><br>    <span class="hljs-comment"># pretrain_model = torch.load(&quot;googlenet.pth&quot;)</span><br>    <span class="hljs-comment"># del_list = [&quot;aux1.fc2.weight&quot;, &quot;aux1.fc2.bias&quot;,</span><br>    <span class="hljs-comment">#             &quot;aux2.fc2.weight&quot;, &quot;aux2.fc2.bias&quot;,</span><br>    <span class="hljs-comment">#             &quot;fc.weight&quot;, &quot;fc.bias&quot;]</span><br>    <span class="hljs-comment"># pretrain_dict = &#123;k: v for k, v in pretrain_model.items() if k not in del_list&#125;</span><br>    <span class="hljs-comment"># model_dict.update(pretrain_dict)</span><br>    <span class="hljs-comment"># net.load_state_dict(model_dict)</span><br>    net.to(device)<br>    loss_function = nn.CrossEntropyLoss()<br>    optimizer = optim.Adam(net.parameters(), lr=<span class="hljs-number">0.0003</span>)<br><br>    epochs = <span class="hljs-number">30</span><br>    best_acc = <span class="hljs-number">0.0</span><br>    save_path = <span class="hljs-string">&#x27;./googleNet.pth&#x27;</span><br>    train_steps = <span class="hljs-built_in">len</span>(train_loader)<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):<br>        <span class="hljs-comment"># train</span><br>        net.train()<br>        running_loss = <span class="hljs-number">0.0</span><br>        train_bar = tqdm(train_loader, file=sys.stdout)<br>        <span class="hljs-keyword">for</span> step, data <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_bar):<br>            images, labels = data<br>            optimizer.zero_grad()<br>            logits, aux_logits2, aux_logits1 = net(images.to(device))<br>            loss0 = loss_function(logits, labels.to(device))<br>            loss1 = loss_function(aux_logits1, labels.to(device))<br>            loss2 = loss_function(aux_logits2, labels.to(device))<br>            loss = loss0 + loss1 * <span class="hljs-number">0.3</span> + loss2 * <span class="hljs-number">0.3</span><br>            loss.backward()<br>            optimizer.step()<br><br>            <span class="hljs-comment"># print statistics</span><br>            running_loss += loss.item()<br><br>            train_bar.desc = <span class="hljs-string">&quot;train epoch[&#123;&#125;/&#123;&#125;] loss:&#123;:.3f&#125;&quot;</span>.<span class="hljs-built_in">format</span>(epoch + <span class="hljs-number">1</span>,<br>                                                                     epochs,<br>                                                                     loss)<br><br>        <span class="hljs-comment"># validate</span><br>        net.<span class="hljs-built_in">eval</span>()<br>        acc = <span class="hljs-number">0.0</span>  <span class="hljs-comment"># accumulate accurate number / epoch</span><br>        <span class="hljs-keyword">with</span> torch.no_grad():<br>            val_bar = tqdm(validate_loader, file=sys.stdout)<br>            <span class="hljs-keyword">for</span> val_data <span class="hljs-keyword">in</span> val_bar:<br>                val_images, val_labels = val_data<br>                outputs = net(val_images.to(device))  <span class="hljs-comment"># eval model only have last output layer</span><br>                predict_y = torch.<span class="hljs-built_in">max</span>(outputs, dim=<span class="hljs-number">1</span>)[<span class="hljs-number">1</span>]<br>                acc += torch.eq(predict_y, val_labels.to(device)).<span class="hljs-built_in">sum</span>().item()<br><br>        val_accurate = acc / val_num<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;[epoch %d] train_loss: %.3f  val_accuracy: %.3f&#x27;</span> %<br>              (epoch + <span class="hljs-number">1</span>, running_loss / train_steps, val_accurate))<br><br>        <span class="hljs-keyword">if</span> val_accurate &gt; best_acc:<br>            best_acc = val_accurate<br>            torch.save(net.state_dict(), save_path)<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Finished Training&#x27;</span>)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    main()\<br></code></pre></div></td></tr></table></figure><h1 id=""></h1><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> json<br><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-keyword">from</span> model <span class="hljs-keyword">import</span> GoogLeNet<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>    device = torch.device(<span class="hljs-string">&quot;cuda:0&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br><br>    data_transform = transforms.Compose(<br>        [transforms.Resize((<span class="hljs-number">224</span>, <span class="hljs-number">224</span>)),<br>         transforms.ToTensor(),<br>         transforms.Normalize((<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>), (<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>))])<br><br>    <span class="hljs-comment"># load image</span><br>    img_path = <span class="hljs-string">&quot;../tulip.jpg&quot;</span><br>    <span class="hljs-keyword">assert</span> os.path.exists(img_path), <span class="hljs-string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="hljs-built_in">format</span>(img_path)<br>    img = Image.<span class="hljs-built_in">open</span>(img_path)<br>    plt.imshow(img)<br>    <span class="hljs-comment"># [N, C, H, W]</span><br>    img = data_transform(img)<br>    <span class="hljs-comment"># expand batch dimension</span><br>    img = torch.unsqueeze(img, dim=<span class="hljs-number">0</span>)<br><br>    <span class="hljs-comment"># read class_indict</span><br>    json_path = <span class="hljs-string">&#x27;./class_indices.json&#x27;</span><br>    <span class="hljs-keyword">assert</span> os.path.exists(json_path), <span class="hljs-string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="hljs-built_in">format</span>(json_path)<br><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(json_path, <span class="hljs-string">&quot;r&quot;</span>) <span class="hljs-keyword">as</span> f:<br>        class_indict = json.load(f)<br><br>    <span class="hljs-comment"># create model</span><br>    model = GoogLeNet(num_classes=<span class="hljs-number">5</span>, aux_logits=<span class="hljs-literal">False</span>).to(device)<br><br>    <span class="hljs-comment"># load model weights</span><br>    weights_path = <span class="hljs-string">&quot;./googleNet.pth&quot;</span><br>    <span class="hljs-keyword">assert</span> os.path.exists(weights_path), <span class="hljs-string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="hljs-built_in">format</span>(weights_path)<br>    missing_keys, unexpected_keys = model.load_state_dict(torch.load(weights_path, map_location=device),<br>                                                          strict=<span class="hljs-literal">False</span>)<br><br>    model.<span class="hljs-built_in">eval</span>()<br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-comment"># predict class</span><br>        output = torch.squeeze(model(img.to(device))).cpu()<br>        predict = torch.softmax(output, dim=<span class="hljs-number">0</span>)<br>        predict_cla = torch.argmax(predict).numpy()<br><br>    print_res = <span class="hljs-string">&quot;class: &#123;&#125;   prob: &#123;:.3&#125;&quot;</span>.<span class="hljs-built_in">format</span>(class_indict[<span class="hljs-built_in">str</span>(predict_cla)],<br>                                                 predict[predict_cla].numpy())<br>    plt.title(print_res)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(predict)):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;class: &#123;:10&#125;   prob: &#123;:.3&#125;&quot;</span>.<span class="hljs-built_in">format</span>(class_indict[<span class="hljs-built_in">str</span>(i)],<br>                                                  predict[i].numpy()))<br>    plt.show()<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    main()<br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>cv</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>AlexNet</title>
    <link href="/2022/09/29/AlexNet/"/>
    <url>/2022/09/29/AlexNet/</url>
    
    <content type="html"><![CDATA[<h1 id=""></h1><p><img src="/img/cv/image-20220929160500941.png" /></p><p><img src="/img/cv/image-20220929160537393.png" /></p><p><img src="/img/cv/image-20220929160556682.png" /></p><p><img src="/img/cv/image-20220929160608567.png" /></p><ul><li></li></ul><p><img src="/img/cv/image-20220929160655961.png" /></p><p><img src="/img/cv/image-20220929160708562.png" /></p><h1 id=""></h1><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">AlexNet</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, num_classes=<span class="hljs-number">1000</span>, init_weights=<span class="hljs-literal">False</span></span>):<br>        <span class="hljs-built_in">super</span>(AlexNet, self).__init__()<br>        self.features = nn.Sequential(<br>            nn.Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">48</span>, kernel_size=<span class="hljs-number">11</span>, stride=<span class="hljs-number">4</span>, padding=<span class="hljs-number">2</span>),  <span class="hljs-comment"># input[3, 224, 224]  output[48, 55, 55]</span><br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>),                  <span class="hljs-comment"># output[48, 27, 27]</span><br>            nn.Conv2d(<span class="hljs-number">48</span>, <span class="hljs-number">128</span>, kernel_size=<span class="hljs-number">5</span>, padding=<span class="hljs-number">2</span>),           <span class="hljs-comment"># output[128, 27, 27]</span><br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>),                  <span class="hljs-comment"># output[128, 13, 13]</span><br>            nn.Conv2d(<span class="hljs-number">128</span>, <span class="hljs-number">192</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>),          <span class="hljs-comment"># output[192, 13, 13]</span><br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            nn.Conv2d(<span class="hljs-number">192</span>, <span class="hljs-number">192</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>),          <span class="hljs-comment"># output[192, 13, 13]</span><br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            nn.Conv2d(<span class="hljs-number">192</span>, <span class="hljs-number">128</span>, kernel_size=<span class="hljs-number">3</span>, padding=<span class="hljs-number">1</span>),          <span class="hljs-comment"># output[128, 13, 13]</span><br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>),                  <span class="hljs-comment"># output[128, 6, 6]</span><br>        )<br>        self.classifier = nn.Sequential(<br>            nn.Dropout(p=<span class="hljs-number">0.5</span>),<br>            nn.Linear(<span class="hljs-number">128</span> * <span class="hljs-number">6</span> * <span class="hljs-number">6</span>, <span class="hljs-number">2048</span>),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            nn.Dropout(p=<span class="hljs-number">0.5</span>),<br>            nn.Linear(<span class="hljs-number">2048</span>, <span class="hljs-number">2048</span>),<br>            nn.ReLU(inplace=<span class="hljs-literal">True</span>),<br>            nn.Linear(<span class="hljs-number">2048</span>, num_classes),<br>        )<br>        <span class="hljs-keyword">if</span> init_weights:<br>            self._initialize_weights()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.features(x)<br>        x = torch.flatten(x, start_dim=<span class="hljs-number">1</span>)<br>        x = self.classifier(x)<br>        <span class="hljs-keyword">return</span> x<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_initialize_weights</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> self.modules():<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m, nn.Conv2d):<br>                nn.init.kaiming_normal_(m.weight, mode=<span class="hljs-string">&#x27;fan_out&#x27;</span>, nonlinearity=<span class="hljs-string">&#x27;relu&#x27;</span>)<br>                <span class="hljs-keyword">if</span> m.bias <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                    nn.init.constant_(m.bias, <span class="hljs-number">0</span>)<br>            <span class="hljs-keyword">elif</span> <span class="hljs-built_in">isinstance</span>(m, nn.Linear):<br>                nn.init.normal_(m.weight, <span class="hljs-number">0</span>, <span class="hljs-number">0.01</span>)<br>                nn.init.constant_(m.bias, <span class="hljs-number">0</span>)<br></code></pre></div></td></tr></table></figure><h1 id=""></h1><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> sys<br><span class="hljs-keyword">import</span> json<br><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms, datasets, utils<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim<br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><br><span class="hljs-keyword">from</span> model <span class="hljs-keyword">import</span> AlexNet<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>    device = torch.device(<span class="hljs-string">&quot;cuda:0&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;using &#123;&#125; device.&quot;</span>.<span class="hljs-built_in">format</span>(device))<br><br>    data_transform = &#123;<br>        <span class="hljs-string">&quot;train&quot;</span>: transforms.Compose([transforms.RandomResizedCrop(<span class="hljs-number">224</span>),<br>                                     transforms.RandomHorizontalFlip(),<br>                                     transforms.ToTensor(),<br>                                     transforms.Normalize((<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>), (<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>))]),<br>        <span class="hljs-string">&quot;val&quot;</span>: transforms.Compose([transforms.Resize((<span class="hljs-number">224</span>, <span class="hljs-number">224</span>)),  <span class="hljs-comment"># cannot 224, must (224, 224)</span><br>                                   transforms.ToTensor(),<br>                                   transforms.Normalize((<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>), (<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>))])&#125;<br><br>    data_root = os.path.abspath(os.path.join(os.getcwd(), <span class="hljs-string">&quot;../..&quot;</span>))  <span class="hljs-comment"># get data root path</span><br>    image_path = os.path.join(data_root, <span class="hljs-string">&quot;data_set&quot;</span>, <span class="hljs-string">&quot;flower_data&quot;</span>)  <span class="hljs-comment"># flower data set path</span><br>    <span class="hljs-keyword">assert</span> os.path.exists(image_path), <span class="hljs-string">&quot;&#123;&#125; path does not exist.&quot;</span>.<span class="hljs-built_in">format</span>(image_path)<br>    train_dataset = datasets.ImageFolder(root=os.path.join(image_path, <span class="hljs-string">&quot;train&quot;</span>),<br>                                         transform=data_transform[<span class="hljs-string">&quot;train&quot;</span>])<br>    train_num = <span class="hljs-built_in">len</span>(train_dataset)<br><br>    <span class="hljs-comment"># &#123;&#x27;daisy&#x27;:0, &#x27;dandelion&#x27;:1, &#x27;roses&#x27;:2, &#x27;sunflower&#x27;:3, &#x27;tulips&#x27;:4&#125;</span><br>    flower_list = train_dataset.class_to_idx<br>    cla_dict = <span class="hljs-built_in">dict</span>((val, key) <span class="hljs-keyword">for</span> key, val <span class="hljs-keyword">in</span> flower_list.items())<br>    <span class="hljs-comment"># write dict into json file</span><br>    json_str = json.dumps(cla_dict, indent=<span class="hljs-number">4</span>)<br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;class_indices.json&#x27;</span>, <span class="hljs-string">&#x27;w&#x27;</span>) <span class="hljs-keyword">as</span> json_file:<br>        json_file.write(json_str)<br><br>    batch_size = <span class="hljs-number">32</span><br>    nw = <span class="hljs-built_in">min</span>([os.cpu_count(), batch_size <span class="hljs-keyword">if</span> batch_size &gt; <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>, <span class="hljs-number">8</span>])  <span class="hljs-comment"># number of workers</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Using &#123;&#125; dataloader workers every process&#x27;</span>.<span class="hljs-built_in">format</span>(nw))<br><br>    train_loader = torch.utils.data.DataLoader(train_dataset,<br>                                               batch_size=batch_size, shuffle=<span class="hljs-literal">True</span>,<br>                                               num_workers=nw)<br><br>    validate_dataset = datasets.ImageFolder(root=os.path.join(image_path, <span class="hljs-string">&quot;val&quot;</span>),<br>                                            transform=data_transform[<span class="hljs-string">&quot;val&quot;</span>])<br>    val_num = <span class="hljs-built_in">len</span>(validate_dataset)<br>    validate_loader = torch.utils.data.DataLoader(validate_dataset,<br>                                                  batch_size=<span class="hljs-number">4</span>, shuffle=<span class="hljs-literal">False</span>,<br>                                                  num_workers=nw)<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;using &#123;&#125; images for training, &#123;&#125; images for validation.&quot;</span>.<span class="hljs-built_in">format</span>(train_num,<br>                                                                           val_num))<br>    <span class="hljs-comment"># test_data_iter = iter(validate_loader)</span><br>    <span class="hljs-comment"># test_image, test_label = test_data_iter.next()</span><br>    <span class="hljs-comment">#</span><br>    <span class="hljs-comment"># def imshow(img):</span><br>    <span class="hljs-comment">#     img = img / 2 + 0.5  # unnormalize</span><br>    <span class="hljs-comment">#     npimg = img.numpy()</span><br>    <span class="hljs-comment">#     plt.imshow(np.transpose(npimg, (1, 2, 0)))</span><br>    <span class="hljs-comment">#     plt.show()</span><br>    <span class="hljs-comment">#</span><br>    <span class="hljs-comment"># print(&#x27; &#x27;.join(&#x27;%5s&#x27; % cla_dict[test_label[j].item()] for j in range(4)))</span><br>    <span class="hljs-comment"># imshow(utils.make_grid(test_image))</span><br><br>    net = AlexNet(num_classes=<span class="hljs-number">5</span>, init_weights=<span class="hljs-literal">True</span>)<br><br>    net.to(device)<br>    loss_function = nn.CrossEntropyLoss()<br>    <span class="hljs-comment"># pata = list(net.parameters())</span><br>    optimizer = optim.Adam(net.parameters(), lr=<span class="hljs-number">0.0002</span>)<br><br>    epochs = <span class="hljs-number">10</span><br>    save_path = <span class="hljs-string">&#x27;./AlexNet.pth&#x27;</span><br>    best_acc = <span class="hljs-number">0.0</span><br>    train_steps = <span class="hljs-built_in">len</span>(train_loader)<br>    <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):<br>        <span class="hljs-comment"># train</span><br>        net.train()<br>        running_loss = <span class="hljs-number">0.0</span><br>        train_bar = tqdm(train_loader, file=sys.stdout)<br>        <span class="hljs-keyword">for</span> step, data <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(train_bar):<br>            images, labels = data<br>            optimizer.zero_grad()<br>            outputs = net(images.to(device))<br>            loss = loss_function(outputs, labels.to(device))<br>            loss.backward()<br>            optimizer.step()<br><br>            <span class="hljs-comment"># print statistics</span><br>            running_loss += loss.item()<br><br>            train_bar.desc = <span class="hljs-string">&quot;train epoch[&#123;&#125;/&#123;&#125;] loss:&#123;:.3f&#125;&quot;</span>.<span class="hljs-built_in">format</span>(epoch + <span class="hljs-number">1</span>,<br>                                                                     epochs,<br>                                                                     loss)<br><br>        <span class="hljs-comment"># validate</span><br>        net.<span class="hljs-built_in">eval</span>()<br>        acc = <span class="hljs-number">0.0</span>  <span class="hljs-comment"># accumulate accurate number / epoch</span><br>        <span class="hljs-keyword">with</span> torch.no_grad():<br>            val_bar = tqdm(validate_loader, file=sys.stdout)<br>            <span class="hljs-keyword">for</span> val_data <span class="hljs-keyword">in</span> val_bar:<br>                val_images, val_labels = val_data<br>                outputs = net(val_images.to(device))<br>                predict_y = torch.<span class="hljs-built_in">max</span>(outputs, dim=<span class="hljs-number">1</span>)[<span class="hljs-number">1</span>]<br>                acc += torch.eq(predict_y, val_labels.to(device)).<span class="hljs-built_in">sum</span>().item()<br><br>        val_accurate = acc / val_num<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;[epoch %d] train_loss: %.3f  val_accuracy: %.3f&#x27;</span> %<br>              (epoch + <span class="hljs-number">1</span>, running_loss / train_steps, val_accurate))<br><br>        <span class="hljs-keyword">if</span> val_accurate &gt; best_acc:<br>            best_acc = val_accurate<br>            torch.save(net.state_dict(), save_path)<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;Finished Training&#x27;</span>)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    main()<br></code></pre></div></td></tr></table></figure><h1 id=""></h1><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> json<br><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-keyword">from</span> model <span class="hljs-keyword">import</span> AlexNet<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>    device = torch.device(<span class="hljs-string">&quot;cuda:0&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)<br><br>    data_transform = transforms.Compose(<br>        [transforms.Resize((<span class="hljs-number">224</span>, <span class="hljs-number">224</span>)),<br>         transforms.ToTensor(),<br>         transforms.Normalize((<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>), (<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>))])<br><br>    <span class="hljs-comment"># load image</span><br>    img_path = <span class="hljs-string">&quot;../tulip.jpg&quot;</span><br>    <span class="hljs-keyword">assert</span> os.path.exists(img_path), <span class="hljs-string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="hljs-built_in">format</span>(img_path)<br>    img = Image.<span class="hljs-built_in">open</span>(img_path)<br><br>    plt.imshow(img)<br>    <span class="hljs-comment"># [N, C, H, W]</span><br>    img = data_transform(img)<br>    <span class="hljs-comment"># expand batch dimension</span><br>    img = torch.unsqueeze(img, dim=<span class="hljs-number">0</span>)<br><br>    <span class="hljs-comment"># read class_indict</span><br>    json_path = <span class="hljs-string">&#x27;./class_indices.json&#x27;</span><br>    <span class="hljs-keyword">assert</span> os.path.exists(json_path), <span class="hljs-string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="hljs-built_in">format</span>(json_path)<br><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(json_path, <span class="hljs-string">&quot;r&quot;</span>) <span class="hljs-keyword">as</span> f:<br>        class_indict = json.load(f)<br><br>    <span class="hljs-comment"># create model</span><br>    model = AlexNet(num_classes=<span class="hljs-number">5</span>).to(device)<br><br>    <span class="hljs-comment"># load model weights</span><br>    weights_path = <span class="hljs-string">&quot;./AlexNet.pth&quot;</span><br>    <span class="hljs-keyword">assert</span> os.path.exists(weights_path), <span class="hljs-string">&quot;file: &#x27;&#123;&#125;&#x27; dose not exist.&quot;</span>.<span class="hljs-built_in">format</span>(weights_path)<br>    model.load_state_dict(torch.load(weights_path))<br><br>    model.<span class="hljs-built_in">eval</span>()<br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-comment"># predict class</span><br>        output = torch.squeeze(model(img.to(device))).cpu()<br>        predict = torch.softmax(output, dim=<span class="hljs-number">0</span>)<br>        predict_cla = torch.argmax(predict).numpy()<br><br>    print_res = <span class="hljs-string">&quot;class: &#123;&#125;   prob: &#123;:.3&#125;&quot;</span>.<span class="hljs-built_in">format</span>(class_indict[<span class="hljs-built_in">str</span>(predict_cla)],<br>                                                 predict[predict_cla].numpy())<br>    plt.title(print_res)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(predict)):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;class: &#123;:10&#125;   prob: &#123;:.3&#125;&quot;</span>.<span class="hljs-built_in">format</span>(class_indict[<span class="hljs-built_in">str</span>(i)],<br>                                                  predict[i].numpy()))<br>    plt.show()<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    main()<br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>cv</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>redis</title>
    <link href="/2022/09/19/redis/"/>
    <url>/2022/09/19/redis/</url>
    
    <content type="html"><![CDATA[<p></p>]]></content>
    
    
    <categories>
      
      <category></category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2022/08/18/%E9%80%92%E5%BD%92/"/>
    <url>/2022/08/18/%E9%80%92%E5%BD%92/</url>
    
    <content type="html"><![CDATA[<h2 id="powx-n">50Pow(x, n)</h2><p><img src="/img/LeetCode//50.png" /></p><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">myPow</span>(<span class="hljs-params">self, x: <span class="hljs-built_in">float</span>, n: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">float</span>:<br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">quickPow</span>(<span class="hljs-params">N</span>):<br>            <span class="hljs-keyword">if</span> N == <span class="hljs-number">0</span>:<br>                <span class="hljs-keyword">return</span> <span class="hljs-number">1.0</span><br>            y = quickPow(N // <span class="hljs-number">2</span>)<br>            <span class="hljs-keyword">return</span> y * y <span class="hljs-keyword">if</span> N % <span class="hljs-number">2</span> == <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> y * y * x<br>        <span class="hljs-keyword">return</span> quickPow(n) <span class="hljs-keyword">if</span> n &gt;= <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-number">1.0</span> / quickPow(-n)<br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>LeetCode</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>SpringBoot</title>
    <link href="/2022/07/26/SpringBoot/"/>
    <url>/2022/07/26/SpringBoot/</url>
    
    <content type="html"><![CDATA[<h1 id=""></h1><h2 id=""></h2><p>propertieszh_CNResourceBundle</p><p><img src="/img//SpringBoot/1.png" /></p><p>Resource Bundle EditorResourceBundle</p><p><img src="/img//SpringBoot/2.png" /></p><p></p><p><img src="/img//SpringBoot/3.png" /></p><p></p><p><img src="/img//SpringBoot/4.png" /></p><p></p><p><img src="/img//SpringBoot/5.png" /></p><p>application.properties</p><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"># <br>spring.messages.basename=i18n.login<br></code></pre></div></td></tr></table></figure><p>html#{xxxx}</p><figure class="highlight html"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs html"><span class="hljs-tag">&lt;<span class="hljs-name">input</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;text&quot;</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-control&quot;</span> <span class="hljs-attr">th:placeholder</span>=<span class="hljs-string">&quot;#&#123;login.username&#125;&quot;</span> <span class="hljs-attr">required</span>=<span class="hljs-string">&quot;&quot;</span> <span class="hljs-attr">autofocus</span>=<span class="hljs-string">&quot;&quot;</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">input</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;password&quot;</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-control&quot;</span> <span class="hljs-attr">th:placeholder</span>=<span class="hljs-string">&quot;#&#123;login.password&#125;&quot;</span> <span class="hljs-attr">required</span>=<span class="hljs-string">&quot;&quot;</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">input</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;checkbox&quot;</span> <span class="hljs-attr">value</span>=<span class="hljs-string">&quot;remember-me&quot;</span>&gt;</span>[[#&#123;login.remember&#125;]]<br><span class="hljs-tag">&lt;<span class="hljs-name">button</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;btn btn-lg btn-primary btn-block&quot;</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;submit&quot;</span> <span class="hljs-attr">th:text</span>=<span class="hljs-string">&quot;#&#123;login.btn&#125;&quot;</span>&gt;</span>Sign in<span class="hljs-tag">&lt;/<span class="hljs-name">button</span>&gt;</span><br></code></pre></div></td></tr></table></figure><p>htmlconfigMyLocaleResolver</p><figure class="highlight html"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs html"><span class="hljs-tag">&lt;<span class="hljs-name">a</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;btn btn-sm&quot;</span> <span class="hljs-attr">th:href</span>=<span class="hljs-string">&quot;@&#123;/index.html(l=&#x27;zh_CN&#x27;)&#125;&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">a</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">a</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;btn btn-sm&quot;</span> <span class="hljs-attr">th:href</span>=<span class="hljs-string">&quot;@&#123;/index.html(l=&#x27;en_US&#x27;)&#125;&quot;</span>&gt;</span>English<span class="hljs-tag">&lt;/<span class="hljs-name">a</span>&gt;</span><br></code></pre></div></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">MyLocaleResolver</span> <span class="hljs-keyword">implements</span> <span class="hljs-title class_">LocaleResolver</span> &#123;<br><br>    <span class="hljs-comment">//</span><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> Locale <span class="hljs-title function_">resolveLocale</span><span class="hljs-params">(HttpServletRequest httpServletRequest)</span> &#123;<br>        <span class="hljs-comment">//</span><br>        <span class="hljs-type">String</span> <span class="hljs-variable">language</span> <span class="hljs-operator">=</span> httpServletRequest.getParameter(<span class="hljs-string">&quot;l&quot;</span>);<br>        <br>        <span class="hljs-comment">//</span><br>        <span class="hljs-type">Locale</span> <span class="hljs-variable">locale</span> <span class="hljs-operator">=</span> Locale.getDefault();<br>        <br>        <span class="hljs-comment">//</span><br>        <span class="hljs-keyword">if</span> (!StringUtils.isEmpty(language)) &#123;<br>            <span class="hljs-comment">//zh_CN</span><br>            String[] split = language.split(<span class="hljs-string">&quot;_&quot;</span>);<br>            <span class="hljs-comment">//</span><br>            locale = <span class="hljs-keyword">new</span> <span class="hljs-title class_">Locale</span>(split[<span class="hljs-number">0</span>], split[<span class="hljs-number">1</span>]);<br>        &#125;<br>        <span class="hljs-keyword">return</span> locale;<br>    &#125;<br><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">setLocale</span><span class="hljs-params">(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Locale locale)</span> &#123;<br><br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><p>Bean</p><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-meta">@Configuration</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">MyMVCConfig</span> <span class="hljs-keyword">implements</span> <span class="hljs-title class_">WebMvcConfigurer</span> &#123;<br><br>    <span class="hljs-comment">//</span><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">addViewControllers</span><span class="hljs-params">(ViewControllerRegistry registry)</span> &#123;<br>        registry.addViewController(<span class="hljs-string">&quot;/&quot;</span>).setViewName(<span class="hljs-string">&quot;index&quot;</span>);<br>        registry.addViewController(<span class="hljs-string">&quot;/index.html&quot;</span>).setViewName(<span class="hljs-string">&quot;index&quot;</span>);<br>    &#125;<br><br>    <span class="hljs-comment">//</span><br>    <span class="hljs-meta">@Bean</span><br>    <span class="hljs-keyword">public</span> LocaleResolver <span class="hljs-title function_">localeResolver</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">MyLocaleResolver</span>();<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><h2 id=""></h2><p>html</p><figure class="highlight html"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs html"><span class="hljs-tag">&lt;<span class="hljs-name">form</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-signin&quot;</span> <span class="hljs-attr">th:action</span>=<span class="hljs-string">&quot;@&#123;/user/login&#125;&quot;</span>&gt;</span><br></code></pre></div></td></tr></table></figure><p>LoginController</p><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-meta">@Controller</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">LoginController</span> &#123;<br><br>    <span class="hljs-meta">@RequestMapping(&quot;/user/login&quot;)</span><br>    <span class="hljs-keyword">public</span> String <span class="hljs-title function_">login</span><span class="hljs-params">(<span class="hljs-meta">@RequestParam(&quot;username&quot;)</span> String username, <span class="hljs-meta">@RequestParam(&quot;username&quot;)</span> String password, Model model)</span> &#123;<br>        <span class="hljs-comment">//</span><br>        <span class="hljs-keyword">if</span> (!StringUtils.isEmpty(username) &amp;&amp; <span class="hljs-string">&quot;123123&quot;</span>.equals(password)) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;dashboard&quot;</span>;<br>        &#125;<br>        <span class="hljs-keyword">else</span> &#123;<br>            <span class="hljs-comment">//</span><br>            model.addAttribute(<span class="hljs-string">&quot;msg&quot;</span>, <span class="hljs-string">&quot;&quot;</span>);<br>            <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;index&quot;</span>;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><p></p><figure class="highlight html"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs html"><span class="hljs-comment">&lt;!--msg--&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">p</span> <span class="hljs-attr">style</span>=<span class="hljs-string">&quot;color: red&quot;</span> <span class="hljs-attr">th:text</span>=<span class="hljs-string">&quot;$&#123;msg&#125;&quot;</span> <span class="hljs-attr">th:if</span>=<span class="hljs-string">&quot;$&#123;not #strings.isEmpty(msg)&#125;&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span><br></code></pre></div></td></tr></table></figure><p></p><p>main.html</p><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-comment">//</span><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">addViewControllers</span><span class="hljs-params">(ViewControllerRegistry registry)</span> &#123;<br>        registry.addViewController(<span class="hljs-string">&quot;/&quot;</span>).setViewName(<span class="hljs-string">&quot;index&quot;</span>);<br>        registry.addViewController(<span class="hljs-string">&quot;/index.html&quot;</span>).setViewName(<span class="hljs-string">&quot;index&quot;</span>);<br>        registry.addViewController(<span class="hljs-string">&quot;/main.html&quot;</span>).setViewName(<span class="hljs-string">&quot;dashboard&quot;</span>);<br>    &#125;<br></code></pre></div></td></tr></table></figure><p>controller</p><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-keyword">if</span> (!StringUtils.isEmpty(username) &amp;&amp; <span class="hljs-string">&quot;123123&quot;</span>.equals(password)) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;redirect:/main.html&quot;</span>;<br>        &#125;<br></code></pre></div></td></tr></table></figure><p></p><h2 id=""></h2><p>sessionLoginControllerHttpSessionsession</p><p><code>addPathPatterns/**</code><code>excludePathPatterns</code></p><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-meta">@Controller</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">LoginController</span> &#123;<br><br>    <span class="hljs-meta">@RequestMapping(&quot;/user/login&quot;)</span><br>    <span class="hljs-keyword">public</span> String <span class="hljs-title function_">login</span><span class="hljs-params">(<span class="hljs-meta">@RequestParam(&quot;username&quot;)</span> String username, <span class="hljs-meta">@RequestParam(&quot;password&quot;)</span> String password, Model model, HttpSession session)</span> &#123;<br>        <span class="hljs-comment">//</span><br>        <span class="hljs-keyword">if</span> (!StringUtils.isEmpty(username) &amp;&amp; <span class="hljs-string">&quot;123123&quot;</span>.equals(password)) &#123;<br>            session.setAttribute(<span class="hljs-string">&quot;loginUser&quot;</span>, username);<br>            <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;redirect:/main.html&quot;</span>;<br>        &#125;<br>        <span class="hljs-keyword">else</span> &#123;<br>            <span class="hljs-comment">//</span><br>            model.addAttribute(<span class="hljs-string">&quot;msg&quot;</span>, <span class="hljs-string">&quot;&quot;</span>);<br>            <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;index&quot;</span>;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><p>ConfigLoginHandlerInterceptortruefalse</p><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">LoginHandlerInterceptor</span> <span class="hljs-keyword">implements</span> <span class="hljs-title class_">HandlerInterceptor</span> &#123;<br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">preHandle</span><span class="hljs-params">(HttpServletRequest request, HttpServletResponse response, Object handler)</span> <span class="hljs-keyword">throws</span> Exception &#123;<br><br>        <span class="hljs-comment">//session</span><br>        <span class="hljs-type">Object</span> <span class="hljs-variable">loginUser</span> <span class="hljs-operator">=</span> request.getSession().getAttribute(<span class="hljs-string">&quot;loginUser&quot;</span>);<br><br>        <span class="hljs-keyword">if</span> (loginUser == <span class="hljs-literal">null</span>) &#123;<br>            request.setAttribute(<span class="hljs-string">&quot;msg&quot;</span>, <span class="hljs-string">&quot;&quot;</span>);<br>            request.getRequestDispatcher(<span class="hljs-string">&quot;/index.html&quot;</span>).forward(request, response);<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>        &#125;<br>        <span class="hljs-keyword">else</span> &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><p>excludePathPatterns</p><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">addInterceptors</span><span class="hljs-params">(InterceptorRegistry registry)</span> &#123;<br>        registry.addInterceptor(<span class="hljs-keyword">new</span> <span class="hljs-title class_">LoginHandlerInterceptor</span>()).addPathPatterns(<span class="hljs-string">&quot;/**&quot;</span>).excludePathPatterns(<span class="hljs-string">&quot;/index.html&quot;</span>, <span class="hljs-string">&quot;/&quot;</span>, <span class="hljs-string">&quot;/user/login&quot;</span>, <span class="hljs-string">&quot;/static/**&quot;</span>);<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><h2 id=""></h2><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-meta">@Controller</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">EmploeeController</span> &#123;<br><br>    <span class="hljs-meta">@Autowired</span><br>    EmployeeDao employeeDao;<br><br>    <span class="hljs-meta">@RequestMapping(&quot;/emps&quot;)</span><br>    <span class="hljs-keyword">public</span> String <span class="hljs-title function_">list</span><span class="hljs-params">(Model model)</span> &#123;<br>        Collection&lt;Employee&gt; employees = employeeDao.getAll();<br>        model.addAttribute(<span class="hljs-string">&quot;emps&quot;</span>, employees);<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;emp/list&quot;</span>;<br>    &#125;<br><br>&#125;<br></code></pre></div></td></tr></table></figure><figure class="highlight html"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs html"><span class="hljs-tag">&lt;<span class="hljs-name">main</span> <span class="hljs-attr">role</span>=<span class="hljs-string">&quot;main&quot;</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;col-md-9 ml-sm-auto col-lg-10 pt-3 px-4&quot;</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">h2</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">a</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;btn btn-sm btn-success&quot;</span> <span class="hljs-attr">th:href</span>=<span class="hljs-string">&quot;@&#123;/emp&#125;&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">a</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">h2</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;table-responsive&quot;</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">table</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;table table-striped table-sm&quot;</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">thead</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">tr</span>&gt;</span><br>                        <span class="hljs-tag">&lt;<span class="hljs-name">th</span>&gt;</span>id<span class="hljs-tag">&lt;/<span class="hljs-name">th</span>&gt;</span><br>                        <span class="hljs-tag">&lt;<span class="hljs-name">th</span>&gt;</span>lastName<span class="hljs-tag">&lt;/<span class="hljs-name">th</span>&gt;</span><br>                        <span class="hljs-tag">&lt;<span class="hljs-name">th</span>&gt;</span>email<span class="hljs-tag">&lt;/<span class="hljs-name">th</span>&gt;</span><br>                        <span class="hljs-tag">&lt;<span class="hljs-name">th</span>&gt;</span>gender<span class="hljs-tag">&lt;/<span class="hljs-name">th</span>&gt;</span><br>                        <span class="hljs-tag">&lt;<span class="hljs-name">th</span>&gt;</span>department<span class="hljs-tag">&lt;/<span class="hljs-name">th</span>&gt;</span><br>                        <span class="hljs-tag">&lt;<span class="hljs-name">th</span>&gt;</span>birth<span class="hljs-tag">&lt;/<span class="hljs-name">th</span>&gt;</span><br>                        <span class="hljs-tag">&lt;<span class="hljs-name">th</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">th</span>&gt;</span><br>                    <span class="hljs-tag">&lt;/<span class="hljs-name">tr</span>&gt;</span><br>                    <span class="hljs-tag">&lt;/<span class="hljs-name">thead</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">tbody</span>&gt;</span><br>                        <span class="hljs-tag">&lt;<span class="hljs-name">tr</span> <span class="hljs-attr">th:each</span>=<span class="hljs-string">&quot;emp:$&#123;emps&#125;&quot;</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">td</span> <span class="hljs-attr">th:text</span>=<span class="hljs-string">&quot;$&#123;emp.getId()&#125;&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">td</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">td</span> <span class="hljs-attr">th:text</span>=<span class="hljs-string">&quot;$&#123;emp.getLastName()&#125;&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">td</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">td</span> <span class="hljs-attr">th:text</span>=<span class="hljs-string">&quot;$&#123;emp.getEmail()&#125;&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">td</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">td</span> <span class="hljs-attr">th:text</span>=<span class="hljs-string">&quot;$&#123;emp.getGender()==0?&#x27;&#x27;:&#x27;&#x27;&#125;&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">td</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">td</span> <span class="hljs-attr">th:text</span>=<span class="hljs-string">&quot;$&#123;emp.getDepartment().getDepartmentName()&#125;&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">td</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">td</span> <span class="hljs-attr">th:text</span>=<span class="hljs-string">&quot;$&#123;#dates.format(emp.getBirth(), &#x27;yyyy-MM-dd HH:mm:ss&#x27;)&#125;&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">td</span>&gt;</span><br>                            <span class="hljs-tag">&lt;<span class="hljs-name">td</span>&gt;</span><br>                                <span class="hljs-tag">&lt;<span class="hljs-name">button</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;btn btn-sm btn-primary&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">button</span>&gt;</span><br>                                <span class="hljs-tag">&lt;<span class="hljs-name">button</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;btn btn-sm btn-danger&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">button</span>&gt;</span><br>                            <span class="hljs-tag">&lt;/<span class="hljs-name">td</span>&gt;</span><br>                        <span class="hljs-tag">&lt;/<span class="hljs-name">tr</span>&gt;</span><br>                    <span class="hljs-tag">&lt;/<span class="hljs-name">tbody</span>&gt;</span><br>                <span class="hljs-tag">&lt;/<span class="hljs-name">table</span>&gt;</span><br>            <span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">main</span>&gt;</span><br></code></pre></div></td></tr></table></figure><h2 id=""></h2><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-meta">@PostMapping(&quot;/emp&quot;)</span><br>    <span class="hljs-keyword">public</span> String <span class="hljs-title function_">addEmp</span><span class="hljs-params">(Employee employee)</span> &#123;<br><br>        employeeDao.save(employee);<br><br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;redirect:/emps&quot;</span>;<br>    &#125;<br></code></pre></div></td></tr></table></figure><figure class="highlight html"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs html"><span class="hljs-tag">&lt;<span class="hljs-name">form</span> <span class="hljs-attr">th:action</span>=<span class="hljs-string">&quot;@&#123;/emp&#125;&quot;</span> <span class="hljs-attr">method</span>=<span class="hljs-string">&quot;post&quot;</span>&gt;</span><br>             <span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-group&quot;</span>&gt;</span><br>                 <span class="hljs-tag">&lt;<span class="hljs-name">label</span>&gt;</span>LastName<span class="hljs-tag">&lt;/<span class="hljs-name">label</span>&gt;</span><br>                 <span class="hljs-tag">&lt;<span class="hljs-name">input</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;text&quot;</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;lastName&quot;</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-control&quot;</span> <span class="hljs-attr">placeholder</span>=<span class="hljs-string">&quot;&quot;</span>&gt;</span><br>             <span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span><br>             <span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-group&quot;</span>&gt;</span><br>                 <span class="hljs-tag">&lt;<span class="hljs-name">label</span>&gt;</span>Email<span class="hljs-tag">&lt;/<span class="hljs-name">label</span>&gt;</span><br>                 <span class="hljs-tag">&lt;<span class="hljs-name">input</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;email&quot;</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;email&quot;</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-control&quot;</span> <span class="hljs-attr">placeholder</span>=<span class="hljs-string">&quot;1176244270@qq.com&quot;</span>&gt;</span><br>             <span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span><br>             <span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-group&quot;</span>&gt;</span><br>                 <span class="hljs-tag">&lt;<span class="hljs-name">label</span>&gt;</span>Gender<span class="hljs-tag">&lt;/<span class="hljs-name">label</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">br</span>&gt;</span><br>                 <span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-check form-check-inline&quot;</span>&gt;</span><br>                     <span class="hljs-tag">&lt;<span class="hljs-name">input</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-check-input&quot;</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;radio&quot;</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;gender&quot;</span> <span class="hljs-attr">value</span>=<span class="hljs-string">&quot;1&quot;</span>&gt;</span><br>                     <span class="hljs-tag">&lt;<span class="hljs-name">label</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-check-label&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">label</span>&gt;</span><br>                 <span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span><br>                 <span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-check form-check-inline&quot;</span>&gt;</span><br>                     <span class="hljs-tag">&lt;<span class="hljs-name">input</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-check-input&quot;</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;radio&quot;</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;gender&quot;</span> <span class="hljs-attr">value</span>=<span class="hljs-string">&quot;0&quot;</span>&gt;</span><br>                     <span class="hljs-tag">&lt;<span class="hljs-name">label</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-check-label&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">label</span>&gt;</span><br>                 <span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span><br>             <span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span><br>             <span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-group&quot;</span>&gt;</span><br>                 <span class="hljs-tag">&lt;<span class="hljs-name">label</span>&gt;</span>department<span class="hljs-tag">&lt;/<span class="hljs-name">label</span>&gt;</span><br>                 <span class="hljs-tag">&lt;<span class="hljs-name">select</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-control&quot;</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;department.id&quot;</span>&gt;</span><br>                     <span class="hljs-tag">&lt;<span class="hljs-name">option</span> <span class="hljs-attr">th:each</span>=<span class="hljs-string">&quot;dept:$&#123;departments&#125;&quot;</span> <span class="hljs-attr">th:text</span>=<span class="hljs-string">&quot;$&#123;dept.getDepartmentName()&#125;&quot;</span> <span class="hljs-attr">th:value</span>=<span class="hljs-string">&quot;$&#123;dept.getId()&#125;&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">option</span>&gt;</span><br>                 <span class="hljs-tag">&lt;/<span class="hljs-name">select</span>&gt;</span><br>             <span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span><br>             <span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-group&quot;</span>&gt;</span><br>                 <span class="hljs-tag">&lt;<span class="hljs-name">label</span>&gt;</span>Birth<span class="hljs-tag">&lt;/<span class="hljs-name">label</span>&gt;</span><br>                 <span class="hljs-tag">&lt;<span class="hljs-name">input</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;text&quot;</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;birth&quot;</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-control&quot;</span> <span class="hljs-attr">placeholder</span>=<span class="hljs-string">&quot;&quot;</span>&gt;</span><br>             <span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span><br>             <span class="hljs-tag">&lt;<span class="hljs-name">button</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;submit&quot;</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;btn btn-primary&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">button</span>&gt;</span><br>         <span class="hljs-tag">&lt;/<span class="hljs-name">form</span>&gt;</span><br></code></pre></div></td></tr></table></figure><h2 id=""></h2><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-comment">//</span><br>    <span class="hljs-meta">@GetMapping(&quot;/emp/&#123;id&#125;&quot;)</span><br>    <span class="hljs-keyword">public</span> String <span class="hljs-title function_">toUpdateEmp</span><span class="hljs-params">(<span class="hljs-meta">@PathVariable(&quot;id&quot;)</span>Integer id, Model model)</span> &#123;<br>        <span class="hljs-comment">//</span><br>        <span class="hljs-type">Employee</span> <span class="hljs-variable">employee</span> <span class="hljs-operator">=</span> employeeDao.getEmployById(id);<br>        model.addAttribute(<span class="hljs-string">&quot;emp&quot;</span>, employee);<br><br>        Collection&lt;Department&gt; departments = departmentDao.getDepartments();<br>        model.addAttribute(<span class="hljs-string">&quot;departments&quot;</span>, departments);<br><br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;emp/update&quot;</span>;<br>    &#125;<br><br>    <span class="hljs-meta">@PostMapping(&quot;/updateEmp&quot;)</span><br>    <span class="hljs-keyword">public</span> String <span class="hljs-title function_">updateEmp</span><span class="hljs-params">(Employee employee)</span> &#123;<br>        employeeDao.save(employee);<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;redirect:/emps&quot;</span>;<br>    &#125;<br></code></pre></div></td></tr></table></figure><figure class="highlight html"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs html"><span class="hljs-tag">&lt;<span class="hljs-name">a</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;btn btn-sm btn-primary&quot;</span> <span class="hljs-attr">th:href</span>=<span class="hljs-string">&quot;@&#123;/emp/&#123;id&#125;(id=$&#123;emp.getId()&#125;)&#125;&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">a</span>&gt;</span><br></code></pre></div></td></tr></table></figure><figure class="highlight html"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs html"><span class="hljs-tag">&lt;<span class="hljs-name">form</span> <span class="hljs-attr">th:action</span>=<span class="hljs-string">&quot;@&#123;/updateEmp&#125;&quot;</span> <span class="hljs-attr">method</span>=<span class="hljs-string">&quot;post&quot;</span>&gt;</span><br>             <span class="hljs-tag">&lt;<span class="hljs-name">input</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;hidden&quot;</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;id&quot;</span> <span class="hljs-attr">th:value</span>=<span class="hljs-string">&quot;$&#123;emp.getId()&#125;&quot;</span>&gt;</span><br>             <span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-group&quot;</span>&gt;</span><br>                 <span class="hljs-tag">&lt;<span class="hljs-name">label</span>&gt;</span>LastName<span class="hljs-tag">&lt;/<span class="hljs-name">label</span>&gt;</span><br>                 <span class="hljs-tag">&lt;<span class="hljs-name">input</span> <span class="hljs-attr">th:value</span>=<span class="hljs-string">&quot;$&#123;emp.getLastName()&#125;&quot;</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;text&quot;</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;lastName&quot;</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-control&quot;</span> <span class="hljs-attr">placeholder</span>=<span class="hljs-string">&quot;&quot;</span>&gt;</span><br>             <span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span><br>             <span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-group&quot;</span>&gt;</span><br>                 <span class="hljs-tag">&lt;<span class="hljs-name">label</span>&gt;</span>Email<span class="hljs-tag">&lt;/<span class="hljs-name">label</span>&gt;</span><br>                 <span class="hljs-tag">&lt;<span class="hljs-name">input</span> <span class="hljs-attr">th:value</span>=<span class="hljs-string">&quot;$&#123;emp.getEmail()&#125;&quot;</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;email&quot;</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;email&quot;</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-control&quot;</span> <span class="hljs-attr">placeholder</span>=<span class="hljs-string">&quot;1176244270@qq.com&quot;</span>&gt;</span><br>             <span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span><br>             <span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-group&quot;</span>&gt;</span><br>                 <span class="hljs-tag">&lt;<span class="hljs-name">label</span>&gt;</span>Gender<span class="hljs-tag">&lt;/<span class="hljs-name">label</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">br</span>&gt;</span><br>                 <span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-check form-check-inline&quot;</span>&gt;</span><br>                     <span class="hljs-tag">&lt;<span class="hljs-name">input</span> <span class="hljs-attr">th:checked</span>=<span class="hljs-string">&quot;$&#123;emp.getGender()==1&#125;&quot;</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-check-input&quot;</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;radio&quot;</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;gender&quot;</span> <span class="hljs-attr">value</span>=<span class="hljs-string">&quot;1&quot;</span>&gt;</span><br>                     <span class="hljs-tag">&lt;<span class="hljs-name">label</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-check-label&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">label</span>&gt;</span><br>                 <span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span><br>                 <span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-check form-check-inline&quot;</span>&gt;</span><br>                     <span class="hljs-tag">&lt;<span class="hljs-name">input</span> <span class="hljs-attr">th:checked</span>=<span class="hljs-string">&quot;$&#123;emp.getGender()==0&#125;&quot;</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-check-input&quot;</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;radio&quot;</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;gender&quot;</span> <span class="hljs-attr">value</span>=<span class="hljs-string">&quot;0&quot;</span>&gt;</span><br>                     <span class="hljs-tag">&lt;<span class="hljs-name">label</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-check-label&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">label</span>&gt;</span><br>                 <span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span><br>             <span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span><br>             <span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-group&quot;</span>&gt;</span><br>                 <span class="hljs-tag">&lt;<span class="hljs-name">label</span>&gt;</span>department<span class="hljs-tag">&lt;/<span class="hljs-name">label</span>&gt;</span><br>                 <span class="hljs-tag">&lt;<span class="hljs-name">select</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-control&quot;</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;department.id&quot;</span>&gt;</span><br>                     <span class="hljs-tag">&lt;<span class="hljs-name">option</span> <span class="hljs-attr">th:selected</span>=<span class="hljs-string">&quot;$&#123;dept.getId() == emp.getDepartment().getId()&#125;&quot;</span> <span class="hljs-attr">th:each</span>=<span class="hljs-string">&quot;dept:$&#123;departments&#125;&quot;</span> <span class="hljs-attr">th:text</span>=<span class="hljs-string">&quot;$&#123;dept.getDepartmentName()&#125;&quot;</span> <span class="hljs-attr">th:value</span>=<span class="hljs-string">&quot;$&#123;dept.getId()&#125;&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">option</span>&gt;</span><br>                 <span class="hljs-tag">&lt;/<span class="hljs-name">select</span>&gt;</span><br>             <span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span><br>             <span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-group&quot;</span>&gt;</span><br>                 <span class="hljs-tag">&lt;<span class="hljs-name">label</span>&gt;</span>Birth<span class="hljs-tag">&lt;/<span class="hljs-name">label</span>&gt;</span><br>                 <span class="hljs-tag">&lt;<span class="hljs-name">input</span> <span class="hljs-attr">th:value</span>=<span class="hljs-string">&quot;$&#123;#dates.format(emp.getBirth(), &#x27;yyyy-MM-dd HH:mm&#x27;)&#125;&quot;</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;text&quot;</span> <span class="hljs-attr">name</span>=<span class="hljs-string">&quot;birth&quot;</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;form-control&quot;</span> <span class="hljs-attr">placeholder</span>=<span class="hljs-string">&quot;&quot;</span>&gt;</span><br>             <span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span><br>             <span class="hljs-tag">&lt;<span class="hljs-name">button</span> <span class="hljs-attr">type</span>=<span class="hljs-string">&quot;submit&quot;</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;btn btn-primary&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">button</span>&gt;</span><br>         <span class="hljs-tag">&lt;/<span class="hljs-name">form</span>&gt;</span><br></code></pre></div></td></tr></table></figure><h2 id=""></h2><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-comment">//</span><br>    <span class="hljs-meta">@GetMapping(&quot;/deleteEmp/&#123;id&#125;&quot;)</span><br>    <span class="hljs-keyword">public</span> String <span class="hljs-title function_">deleteEmp</span><span class="hljs-params">(<span class="hljs-meta">@PathVariable(&quot;id&quot;)</span> <span class="hljs-type">int</span> id)</span> &#123;<br>        employeeDao.delete(id);<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;redirect:/emps&quot;</span>;<br>    &#125;<br></code></pre></div></td></tr></table></figure><figure class="highlight html"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs html"><span class="hljs-tag">&lt;<span class="hljs-name">a</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;btn btn-sm btn-danger&quot;</span> <span class="hljs-attr">th:href</span>=<span class="hljs-string">&quot;@&#123;/deleteEmp/&#123;id&#125;(id=$&#123;emp.getId()&#125;)&#125;&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">a</span>&gt;</span><br></code></pre></div></td></tr></table></figure><h2 id="section">404</h2><p>SpringBoottemplateserrorerror404.html</p><h2 id=""></h2><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-meta">@RequestMapping(&quot;/user/logout&quot;)</span><br>    <span class="hljs-keyword">public</span> String <span class="hljs-title function_">logout</span><span class="hljs-params">(HttpSession session)</span> &#123;<br>        session.invalidate();<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;redirect:/index.html&quot;</span>;<br>    &#125;<br></code></pre></div></td></tr></table></figure><figure class="highlight html"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs html"><span class="hljs-tag">&lt;<span class="hljs-name">a</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;nav-link&quot;</span> <span class="hljs-attr">th:href</span>=<span class="hljs-string">&quot;@&#123;/user/logout&#125;&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">a</span>&gt;</span><br></code></pre></div></td></tr></table></figure><h1 id="spring-data">Spring Data</h1><h2 id="jdbc">JDBC</h2><p><code>JDBC API</code><code>MYSQL Driver</code></p><p>application.yml</p><figure class="highlight yaml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yaml"><span class="hljs-attr">spring:</span><br>  <span class="hljs-attr">datasource:</span><br>    <span class="hljs-attr">username:</span> <span class="hljs-string">root</span><br>    <span class="hljs-attr">password:</span> <span class="hljs-number">123123</span><br>    <span class="hljs-attr">url:</span> <span class="hljs-string">jdbc:mysql://localhost:3306/mybatis?serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=utf-8</span><br>    <span class="hljs-attr">driver-class-name:</span> <span class="hljs-string">com.mysql.cj.jdbc.Driver</span><br></code></pre></div></td></tr></table></figure><p>Controllerjdbc</p><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-meta">@RestController</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">JDBCController</span> &#123;<br>    <span class="hljs-meta">@Autowired</span><br>    JdbcTemplate jdbcTemplate;<br><br>    <span class="hljs-comment">//</span><br>    <span class="hljs-meta">@GetMapping(&quot;/userList&quot;)</span><br>    <span class="hljs-keyword">public</span> List&lt;Map&lt;String, Object&gt;&gt; <span class="hljs-title function_">userList</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-type">String</span> <span class="hljs-variable">sql</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;select * from user&quot;</span>;<br>        List&lt;Map&lt;String, Object&gt;&gt; list_maps = jdbcTemplate.queryForList(sql);<br>        <span class="hljs-keyword">return</span> list_maps;<br>    &#125;<br><br>    <span class="hljs-meta">@GetMapping(&quot;/addList&quot;)</span><br>    <span class="hljs-keyword">public</span> String <span class="hljs-title function_">addUser</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-type">String</span> <span class="hljs-variable">sql</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;insert into mybatis.user values (4, &#x27;&#x27;, &#x27;123123&#x27;)&quot;</span>;<br>        jdbcTemplate.update(sql);<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;add-ok&quot;</span>;<br>    &#125;<br><br>    <span class="hljs-meta">@GetMapping(&quot;/updateList/&#123;id&#125;&quot;)</span><br>    <span class="hljs-keyword">public</span> String <span class="hljs-title function_">updateUser</span><span class="hljs-params">(<span class="hljs-meta">@PathVariable(&quot;id&quot;)</span> <span class="hljs-type">int</span> id)</span> &#123;<br>        <span class="hljs-type">String</span> <span class="hljs-variable">sql</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;update mybatis.user set name=?, pwd=? where id =&quot;</span> + id;<br>        Object[] objects = <span class="hljs-keyword">new</span> <span class="hljs-title class_">Object</span>[<span class="hljs-number">2</span>];<br>        objects[<span class="hljs-number">0</span>] = <span class="hljs-string">&quot;2&quot;</span>;<br>        objects[<span class="hljs-number">1</span>] = <span class="hljs-string">&quot;asdfasdf&quot;</span>;<br>        jdbcTemplate.update(sql, objects);<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;update-ok&quot;</span>;<br>    &#125;<br><br>    <span class="hljs-meta">@GetMapping(&quot;/deleteList/&#123;id&#125;&quot;)</span><br>    <span class="hljs-keyword">public</span> String <span class="hljs-title function_">deleteUser</span><span class="hljs-params">(<span class="hljs-meta">@PathVariable(&quot;id&quot;)</span> <span class="hljs-type">int</span> id)</span> &#123;<br>        <span class="hljs-type">String</span> <span class="hljs-variable">sql</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;delete from mybatis.user where id=?&quot;</span> ;<br>        jdbcTemplate.update(sql, id);<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;delete-ok&quot;</span>;<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><h2 id="druid">Druid</h2><p></p><figure class="highlight xml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>com.alibaba<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>druid<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>1.2.11<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br></code></pre></div></td></tr></table></figure><p>application.ymlDruid</p><figure class="highlight yaml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs yaml"><span class="hljs-attr">spring:</span><br>  <span class="hljs-attr">datasource:</span><br>    <span class="hljs-attr">username:</span> <span class="hljs-string">root</span><br>    <span class="hljs-attr">password:</span> <span class="hljs-number">123123</span><br>    <span class="hljs-attr">url:</span> <span class="hljs-string">jdbc:mysql://localhost:3306/mybatis?serverTimezone=UTC&amp;useUnicode=true&amp;characterEncoding=utf-8</span><br>    <span class="hljs-attr">driver-class-name:</span> <span class="hljs-string">com.mysql.cj.jdbc.Driver</span><br>    <span class="hljs-attr">type:</span> <span class="hljs-string">com.alibaba.druid.pool.DruidDataSource</span><br><br>    <span class="hljs-comment">#SpringBoot</span><br>    <span class="hljs-comment">#druid</span><br>    <span class="hljs-attr">initialSize:</span> <span class="hljs-number">5</span><br>    <span class="hljs-attr">minIdle:</span> <span class="hljs-number">5</span><br>    <span class="hljs-attr">maxActive:</span> <span class="hljs-number">20</span><br>    <span class="hljs-attr">maxWait:</span> <span class="hljs-number">60000</span><br>    <span class="hljs-attr">timeBetweenEvictionRunsMillis:</span> <span class="hljs-number">60000</span><br>    <span class="hljs-attr">minEvictableIdleTimeMillis:</span> <span class="hljs-number">300000</span><br>    <span class="hljs-attr">validationQuery:</span> <span class="hljs-string">SELECT</span> <span class="hljs-number">1</span> <span class="hljs-string">FROM</span> <span class="hljs-string">DUAL</span><br>    <span class="hljs-attr">testWhileIdle:</span> <span class="hljs-literal">true</span><br>    <span class="hljs-attr">testOnBorrow:</span> <span class="hljs-literal">false</span><br>    <span class="hljs-attr">testOnReturn:</span> <span class="hljs-literal">false</span><br>    <span class="hljs-attr">poolPreparedStatements:</span> <span class="hljs-literal">true</span><br><br>    <span class="hljs-comment">#filtersstatlog4jwallsql</span><br>    <span class="hljs-comment">#java.lang.ClassNotFoundException: org.apache.Log4j.Properity</span><br>    <span class="hljs-comment">#log4j </span><br>    <span class="hljs-attr">filters:</span> <span class="hljs-string">stat,wall,log4j</span><br>    <span class="hljs-attr">maxPoolPreparedStatementPerConnectionSize:</span> <span class="hljs-number">20</span><br>    <span class="hljs-attr">useGlobalDataSourceStat:</span> <span class="hljs-literal">true</span><br>    <span class="hljs-attr">connectionoProperties:</span> <span class="hljs-string">druid.stat.mergeSql=true;druid.stat.slowSqlMillis=500</span><br></code></pre></div></td></tr></table></figure><p>configDruidConfig</p><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-meta">@Configuration</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">DruidConfig</span> &#123;<br><br>    <span class="hljs-meta">@ConfigurationProperties(prefix = &quot;spring.datasource&quot;)</span><br>    <span class="hljs-meta">@Bean</span><br>    <span class="hljs-keyword">public</span> DataSource <span class="hljs-title function_">druidDataSource</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">DruidDataSource</span>();<br>    &#125;<br><br>    <span class="hljs-comment">//</span><br>    <span class="hljs-meta">@Bean</span><br>    <span class="hljs-keyword">public</span> ServletRegistrationBean <span class="hljs-title function_">statViewServlet</span><span class="hljs-params">()</span> &#123;<br>        ServletRegistrationBean&lt;StatViewServlet&gt; bean= <span class="hljs-keyword">new</span> <span class="hljs-title class_">ServletRegistrationBean</span>&lt;&gt;(<span class="hljs-keyword">new</span> <span class="hljs-title class_">StatViewServlet</span>(), <span class="hljs-string">&quot;/druid/*&quot;</span>);<br>        <span class="hljs-comment">//</span><br>        HashMap&lt;String, String&gt; initParameters = <span class="hljs-keyword">new</span> <span class="hljs-title class_">HashMap</span>&lt;&gt;();<br>        <span class="hljs-comment">//</span><br>        initParameters.put(<span class="hljs-string">&quot;loinUsername&quot;</span>, <span class="hljs-string">&quot;admin&quot;</span>); <span class="hljs-comment">//key loinUsernameloginPassword</span><br>        initParameters.put(<span class="hljs-string">&quot;loginPassword&quot;</span>, <span class="hljs-string">&quot;123123&quot;</span>);<br><br>        <span class="hljs-comment">//</span><br>        initParameters.put(<span class="hljs-string">&quot;allow&quot;</span>, <span class="hljs-string">&quot;&quot;</span>);<br><br>        bean.setInitParameters(initParameters);<span class="hljs-comment">//</span><br>        <span class="hljs-keyword">return</span> bean;<br>    &#125;<br></code></pre></div></td></tr></table></figure><p><code>localhost:8080/druid</code>sqlSession</p><h2 id="mybatis">MyBatis</h2><p>SpringBoot</p><figure class="highlight xml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.mybatis.spring.boot<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>mybatis-spring-boot-starter<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>2.2.2<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br></code></pre></div></td></tr></table></figure><p>pojo</p><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-meta">@Data</span><br><span class="hljs-meta">@NoArgsConstructor</span><br><span class="hljs-meta">@AllArgsConstructor</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">User</span> &#123;<br><br>    <span class="hljs-keyword">private</span> <span class="hljs-type">int</span> id;<br>    <span class="hljs-keyword">private</span> String name;<br>    <span class="hljs-keyword">private</span> String pwd;<br>&#125;<br></code></pre></div></td></tr></table></figure><p>Mapper</p><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-comment">//mybatismapper</span><br><span class="hljs-meta">@Mapper</span><br><span class="hljs-meta">@Repository</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">interface</span> <span class="hljs-title class_">UserMapper</span> &#123;<br>    List&lt;User&gt; <span class="hljs-title function_">queryUserList</span><span class="hljs-params">()</span>;<br><br>    User <span class="hljs-title function_">queryUserById</span><span class="hljs-params">(<span class="hljs-type">int</span> id)</span>;<br><br>    <span class="hljs-type">int</span> <span class="hljs-title function_">addUser</span><span class="hljs-params">(User user)</span>;<br><br>    <span class="hljs-type">int</span> <span class="hljs-title function_">updateUser</span><span class="hljs-params">(User user)</span>;<br><br>    <span class="hljs-type">int</span> <span class="hljs-title function_">deleteUser</span><span class="hljs-params">(<span class="hljs-type">int</span> id)</span>;<br>&#125;<br></code></pre></div></td></tr></table></figure><p>Mapperresources</p><ul><li>resources<ul><li>mybatis<ul><li>mapper<ul><li>UserMapper.xml</li></ul></li></ul></li></ul></li></ul><figure class="highlight xml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs xml"><span class="hljs-meta">&lt;?xml version=<span class="hljs-string">&quot;1.0&quot;</span> encoding=<span class="hljs-string">&quot;UTF-8&quot;</span> ?&gt;</span><br><span class="hljs-meta">&lt;!DOCTYPE <span class="hljs-keyword">mapper</span></span><br><span class="hljs-meta">        <span class="hljs-keyword">PUBLIC</span> <span class="hljs-string">&quot;-//mybatis.org//dtd Mapper 3.0//EN&quot;</span></span><br><span class="hljs-meta">        <span class="hljs-string">&quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">mapper</span> <span class="hljs-attr">namespace</span>=<span class="hljs-string">&quot;com.zhou.mapper.UserMapper&quot;</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">select</span> <span class="hljs-attr">id</span>=<span class="hljs-string">&quot;queryUserList&quot;</span> <span class="hljs-attr">resultType</span>=<span class="hljs-string">&quot;User&quot;</span>&gt;</span><br>        select * from user;<br>    <span class="hljs-tag">&lt;/<span class="hljs-name">select</span>&gt;</span><br><br>    <span class="hljs-tag">&lt;<span class="hljs-name">select</span> <span class="hljs-attr">id</span>=<span class="hljs-string">&quot;queryUserById&quot;</span> <span class="hljs-attr">resultType</span>=<span class="hljs-string">&quot;User&quot;</span>&gt;</span><br>        select * from user where id = #&#123;id&#125;;<br>    <span class="hljs-tag">&lt;/<span class="hljs-name">select</span>&gt;</span><br><br>    <span class="hljs-tag">&lt;<span class="hljs-name">insert</span> <span class="hljs-attr">id</span>=<span class="hljs-string">&quot;addUser&quot;</span> <span class="hljs-attr">parameterType</span>=<span class="hljs-string">&quot;User&quot;</span>&gt;</span><br>        insert into mybatis.user(id, name, pwd) VALUES (#&#123;id&#125;,#&#123;name&#125;,#&#123;pwd&#125;);<br>    <span class="hljs-tag">&lt;/<span class="hljs-name">insert</span>&gt;</span><br><br>    <span class="hljs-tag">&lt;<span class="hljs-name">update</span> <span class="hljs-attr">id</span>=<span class="hljs-string">&quot;updateUser&quot;</span> <span class="hljs-attr">parameterType</span>=<span class="hljs-string">&quot;User&quot;</span>&gt;</span><br>        update user set name = #&#123;name&#125;,pwd=#&#123;pwd&#125; where id = #&#123;id&#125;;<br>    <span class="hljs-tag">&lt;/<span class="hljs-name">update</span>&gt;</span><br><br>    <span class="hljs-tag">&lt;<span class="hljs-name">delete</span> <span class="hljs-attr">id</span>=<span class="hljs-string">&quot;deleteUserById&quot;</span> <span class="hljs-attr">parameterType</span>=<span class="hljs-string">&quot;int&quot;</span>&gt;</span><br>        delete from user where id = #&#123;id&#125;;<br>    <span class="hljs-tag">&lt;/<span class="hljs-name">delete</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">mapper</span>&gt;</span><br></code></pre></div></td></tr></table></figure><p>application</p><figure class="highlight properties"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs properties"><span class="hljs-comment"># mybatis</span><br><span class="hljs-attr">mybatis.type-aliases-package</span>=<span class="hljs-string">com.zhou.pojo</span><br><span class="hljs-attr">mybatis.mapper-locations</span>=<span class="hljs-string">classpath:mybatis/mapper/*.xml</span><br></code></pre></div></td></tr></table></figure><p>serviceControllerMapper</p><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-meta">@RestController</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">UserController</span> &#123;<br><br>    <span class="hljs-meta">@Autowired</span><br>    <span class="hljs-keyword">private</span> UserMapper userMapper;<br><br>    <span class="hljs-meta">@GetMapping(&quot;/queryUserList&quot;)</span><br>    <span class="hljs-keyword">public</span> List&lt;User&gt; <span class="hljs-title function_">queryUserList</span><span class="hljs-params">()</span> &#123;<br>        List&lt;User&gt; users = userMapper.queryUserList();<br>        <span class="hljs-keyword">return</span> users;<br>    &#125;<br><br>    <span class="hljs-meta">@GetMapping(&quot;/addUser&quot;)</span><br>    <span class="hljs-keyword">public</span> String <span class="hljs-title function_">addUser</span><span class="hljs-params">()</span> &#123;<br>        userMapper.addUser(<span class="hljs-keyword">new</span> <span class="hljs-title class_">User</span>(<span class="hljs-number">4</span>, <span class="hljs-string">&quot;&quot;</span>, <span class="hljs-string">&quot;123123&quot;</span>));<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;add_finished&quot;</span>;<br>    &#125;<br><br>    <span class="hljs-meta">@GetMapping(&quot;/updateUser&quot;)</span><br>    <span class="hljs-keyword">public</span> String <span class="hljs-title function_">updateUser</span><span class="hljs-params">()</span> &#123;<br>        userMapper.updateUser(<span class="hljs-keyword">new</span> <span class="hljs-title class_">User</span>(<span class="hljs-number">4</span>, <span class="hljs-string">&quot;2&quot;</span>, <span class="hljs-string">&quot;12351234&quot;</span>));<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;update_finished&quot;</span>;<br>    &#125;<br><br>    <span class="hljs-meta">@GetMapping(&quot;/deleteUser&quot;)</span><br>    <span class="hljs-keyword">public</span> String <span class="hljs-title function_">deleteUser</span><span class="hljs-params">()</span> &#123;<br>        userMapper.deleteUser(<span class="hljs-number">4</span>);<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;delete_finished&quot;</span>;<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><h1 id="springsecurity">SpringSecurity</h1><p>shiroSpringSecurity</p><ul><li></li><li></li><li></li><li></li></ul><h2 id=""></h2><p></p><p><img src="/img//SpringBoot/8.png" /></p><p>controller</p><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-meta">@Controller</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">RouterController</span> &#123;<br>    <span class="hljs-meta">@RequestMapping(&#123;&quot;/&quot;,&quot;/index&quot;&#125;)</span><br>    <span class="hljs-keyword">public</span> String <span class="hljs-title function_">index</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;index&quot;</span>;<br>    &#125;<br><br>    <span class="hljs-meta">@RequestMapping(&quot;/toLogin&quot;)</span><br>    <span class="hljs-keyword">public</span> String <span class="hljs-title function_">toLogin</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;views/login&quot;</span>;<br>    &#125;<br><br>    <span class="hljs-meta">@RequestMapping(&quot;/level1/&#123;id&#125;&quot;)</span><br>    <span class="hljs-keyword">public</span> String <span class="hljs-title function_">level1</span><span class="hljs-params">(<span class="hljs-meta">@PathVariable(&quot;id&quot;)</span> <span class="hljs-type">int</span> id)</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;views/level1/&quot;</span> + id;<br>    &#125;<br><br>    <span class="hljs-meta">@RequestMapping(&quot;/level2/&#123;id&#125;&quot;)</span><br>    <span class="hljs-keyword">public</span> String <span class="hljs-title function_">level2</span><span class="hljs-params">(<span class="hljs-meta">@PathVariable(&quot;id&quot;)</span> <span class="hljs-type">int</span> id)</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;views/level2/&quot;</span> + id;<br>    &#125;<br><br>    <span class="hljs-meta">@RequestMapping(&quot;/level3/&#123;id&#125;&quot;)</span><br>    <span class="hljs-keyword">public</span> String <span class="hljs-title function_">level3</span><span class="hljs-params">(<span class="hljs-meta">@PathVariable(&quot;id&quot;)</span> <span class="hljs-type">int</span> id)</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;views/level3/&quot;</span> + id;<br>    &#125;<br><br>&#125;<br></code></pre></div></td></tr></table></figure><p></p><p><img src="/img//SpringBoot/9.png" /></p><p></p><figure class="highlight xml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.springframework.boot<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>spring-boot-starter-security<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br></code></pre></div></td></tr></table></figure><p>vip1level1</p><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-meta">@EnableWebSecurity</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">SecurityConfig</span> <span class="hljs-keyword">extends</span> <span class="hljs-title class_">WebSecurityConfigurerAdapter</span> &#123;<br><br>    <span class="hljs-comment">//</span><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">configure</span><span class="hljs-params">(HttpSecurity http)</span> <span class="hljs-keyword">throws</span> Exception &#123;<br>        <span class="hljs-comment">//</span><br>        <span class="hljs-comment">// vip1</span><br>        http.authorizeRequests()<br>                .antMatchers(<span class="hljs-string">&quot;/&quot;</span>).permitAll()<br>                .antMatchers(<span class="hljs-string">&quot;/level1/**&quot;</span>).hasRole(<span class="hljs-string">&quot;vip1&quot;</span>)<br>                .antMatchers(<span class="hljs-string">&quot;/level2/**&quot;</span>).hasRole(<span class="hljs-string">&quot;vip2&quot;</span>)<br>                .antMatchers(<span class="hljs-string">&quot;/level3/**&quot;</span>).hasRole(<span class="hljs-string">&quot;vip3&quot;</span>);<br><br>        <span class="hljs-comment">//</span><br>        http.formLogin();<br>    &#125;<br><br>    <span class="hljs-comment">//</span><br>    <span class="hljs-comment">//PasswordEncoder</span><br>    <span class="hljs-comment">//Spring Security 5.0+  </span><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">configure</span><span class="hljs-params">(AuthenticationManagerBuilder auth)</span> <span class="hljs-keyword">throws</span> Exception &#123;<br><br>        <span class="hljs-comment">//</span><br>        auth.inMemoryAuthentication().passwordEncoder(<span class="hljs-keyword">new</span> <span class="hljs-title class_">BCryptPasswordEncoder</span>())<br>                .withUser(<span class="hljs-string">&quot;zhouzikai&quot;</span>).password(<span class="hljs-keyword">new</span> <span class="hljs-title class_">BCryptPasswordEncoder</span>().encode(<span class="hljs-string">&quot;123123&quot;</span>)).roles(<span class="hljs-string">&quot;vip2&quot;</span>, <span class="hljs-string">&quot;vip3&quot;</span>)<br>                .and()<br>                .withUser(<span class="hljs-string">&quot;root&quot;</span>).password(<span class="hljs-keyword">new</span> <span class="hljs-title class_">BCryptPasswordEncoder</span>().encode(<span class="hljs-string">&quot;123123&quot;</span>)).roles(<span class="hljs-string">&quot;vip1&quot;</span>, <span class="hljs-string">&quot;vip2&quot;</span>, <span class="hljs-string">&quot;vip3&quot;</span>)<br>                .and()<br>                .withUser(<span class="hljs-string">&quot;guest&quot;</span>).password(<span class="hljs-keyword">new</span> <span class="hljs-title class_">BCryptPasswordEncoder</span>().encode(<span class="hljs-string">&quot;123123&quot;</span>)).roles(<span class="hljs-string">&quot;vip1&quot;</span>);<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><h2 id=""></h2><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-comment">//</span><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">configure</span><span class="hljs-params">(HttpSecurity http)</span> <span class="hljs-keyword">throws</span> Exception &#123;<br>        <span class="hljs-comment">//</span><br>        <span class="hljs-comment">// vip1</span><br>        http.authorizeRequests()<br>                .antMatchers(<span class="hljs-string">&quot;/&quot;</span>).permitAll()<br>                .antMatchers(<span class="hljs-string">&quot;/level1/**&quot;</span>).hasRole(<span class="hljs-string">&quot;vip1&quot;</span>)<br>                .antMatchers(<span class="hljs-string">&quot;/level2/**&quot;</span>).hasRole(<span class="hljs-string">&quot;vip2&quot;</span>)<br>                .antMatchers(<span class="hljs-string">&quot;/level3/**&quot;</span>).hasRole(<span class="hljs-string">&quot;vip3&quot;</span>);<br><br>        <span class="hljs-comment">//</span><br>        http.formLogin();<br><br>        <span class="hljs-comment">//</span><br>        http.logout().logoutSuccessUrl(<span class="hljs-string">&quot;/&quot;</span>);<br>    &#125;<br></code></pre></div></td></tr></table></figure><h2 id=""></h2><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-comment">//:cookie</span><br>        http.rememberMe();<br></code></pre></div></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-comment">//</span><br>        <span class="hljs-comment">//toLogin</span><br>        http.formLogin().loginPage(<span class="hljs-string">&quot;/toLogin&quot;</span>);<br></code></pre></div></td></tr></table></figure><h1 id="swagger">Swagger</h1><h2 id="swagger">swagger</h2><p></p><figure class="highlight xml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs xml"><span class="hljs-comment">&lt;!-- https://mvnrepository.com/artifact/io.springfox/springfox-swagger2 --&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>io.springfox<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>springfox-swagger2<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>2.9.2<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>            <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-comment">&lt;!-- https://mvnrepository.com/artifact/io.springfox/springfox-swagger-ui --&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>io.springfox<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>springfox-swagger-ui<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>2.9.2<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>            <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br></code></pre></div></td></tr></table></figure><p>helloController</p><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-meta">@RestController</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">HelloController</span> &#123;<br><br>    <span class="hljs-meta">@RequestMapping(value = &quot;/hello&quot;)</span><br>    <span class="hljs-keyword">public</span> String <span class="hljs-title function_">hello</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;hello&quot;</span>;<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><p>Swagger</p><ul><li>config.SwaggerConfig.java</li></ul><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-meta">@Configuration</span><br><span class="hljs-meta">@EnableSwagger2</span>   <span class="hljs-comment">//Swagger2</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">SwaggerConfig</span> &#123;<br><br>&#125;<br></code></pre></div></td></tr></table></figure><p></p><ul><li><code>localhost:8080/swagger-ui.html</code></li></ul><p><img src="/img//SpringBoot/10.png" /></p><h2 id="swagger">Swagger</h2><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-comment">//Swaggerbean</span><br>    <span class="hljs-meta">@Bean</span><br>    <span class="hljs-keyword">public</span> Docket <span class="hljs-title function_">docket</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Docket</span>(DocumentationType.SWAGGER_2)<br>                .apiInfo(apiInfo());<br>    &#125;<br><br>    <span class="hljs-comment">//Swagger</span><br>    <span class="hljs-keyword">private</span> ApiInfo <span class="hljs-title function_">apiInfo</span><span class="hljs-params">()</span> &#123;<br><br>        <span class="hljs-comment">//</span><br>        <span class="hljs-type">Contact</span> <span class="hljs-variable">contact</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Contact</span>(<span class="hljs-string">&quot;&quot;</span>, <span class="hljs-string">&quot;https://www.baidu.com&quot;</span>, <span class="hljs-string">&quot;13600004906&quot;</span>);<br><br>        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">ApiInfo</span>(<span class="hljs-string">&quot;SwaggerAPI&quot;</span>,<br>                <span class="hljs-string">&quot;Api Documentation&quot;</span>,<br>                <span class="hljs-string">&quot;1.0&quot;</span>,<br>                <span class="hljs-string">&quot;urn:tos&quot;</span>,<br>                contact,<br>                <span class="hljs-string">&quot;Apache 2.0&quot;</span>,<br>                <span class="hljs-string">&quot;http://www.apache.org/licenses/LICENSE-2.0&quot;</span>,<br>                <span class="hljs-keyword">new</span> <span class="hljs-title class_">ArrayList</span>());<br>    &#125;<br></code></pre></div></td></tr></table></figure><p><img src="/img//SpringBoot/11.png" /></p><h2 id=""></h2><ul><li>select()apis()build()</li></ul><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-comment">//Swaggerbean</span><br>    <span class="hljs-meta">@Bean</span><br>    <span class="hljs-keyword">public</span> Docket <span class="hljs-title function_">docket</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Docket</span>(DocumentationType.SWAGGER_2)<br>                .apiInfo(apiInfo())<br>                .select()<br>                <span class="hljs-comment">//RequestHandlerSelectors</span><br>                <span class="hljs-comment">//basePackage()</span><br>            <span class="hljs-comment">//any()</span><br>                <span class="hljs-comment">//none()</span><br>                <span class="hljs-comment">//withClassAnnotation</span><br>                <span class="hljs-comment">//withMethodAnnotation</span><br>                .apis(RequestHandlerSelectors.basePackage(<span class="hljs-string">&quot;com.example.swagger.controller&quot;</span>))<br>            <span class="hljs-comment">//path()</span><br>                <span class="hljs-comment">//.paths(PathSelectors.ant(&quot;/zhou/**&quot;))</span><br>                .build();<br>    &#125;<br></code></pre></div></td></tr></table></figure><ul><li>enable()swagger</li></ul><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-comment">//Swaggerbean</span><br>    <span class="hljs-meta">@Bean</span><br>    <span class="hljs-keyword">public</span> Docket <span class="hljs-title function_">docket</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Docket</span>(DocumentationType.SWAGGER_2)<br>                .apiInfo(apiInfo())<br>                <span class="hljs-comment">//false</span><br>                .enable(<span class="hljs-literal">false</span>)<br>                .select()<br>                .apis(RequestHandlerSelectors.basePackage(<span class="hljs-string">&quot;com.example.swagger.controller&quot;</span>))<br>                .build();<br>    &#125;<br></code></pre></div></td></tr></table></figure><ul><li></li><li>application-dev.propertiesapplication-prod.properties</li><li>enable()</li></ul><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-meta">@Bean</span><br>    <span class="hljs-keyword">public</span> Docket <span class="hljs-title function_">docket</span><span class="hljs-params">(Environment environment)</span> &#123;<br><br>        <span class="hljs-comment">//Swagger</span><br>        <span class="hljs-type">Profiles</span> <span class="hljs-variable">profiles</span> <span class="hljs-operator">=</span> Profiles.of(<span class="hljs-string">&quot;dev&quot;</span>, <span class="hljs-string">&quot;test&quot;</span>);<br><br>        <span class="hljs-comment">//environment.acceptsProfiles</span><br>        <span class="hljs-type">boolean</span> <span class="hljs-variable">flag</span> <span class="hljs-operator">=</span> environment.acceptsProfiles(profiles);<br><br>        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Docket</span>(DocumentationType.SWAGGER_2)<br>                .apiInfo(apiInfo())<br>                .enable(flag)<br>                .select()<br>                .apis(RequestHandlerSelectors.basePackage(<span class="hljs-string">&quot;com.example.swagger.controller&quot;</span>))<br>                .build();<br>    &#125;<br></code></pre></div></td></tr></table></figure><ul><li>application.properties</li></ul><figure class="highlight properties"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs properties"><span class="hljs-attr">spring.profiles.active</span>=<span class="hljs-string">dev</span><br></code></pre></div></td></tr></table></figure><ul><li>application-dev.properties</li></ul><figure class="highlight properties"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs properties"><span class="hljs-attr">server.port</span>=<span class="hljs-string">8081</span><br></code></pre></div></td></tr></table></figure><ul><li>application-prod.properties</li></ul><figure class="highlight properties"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs properties"><span class="hljs-attr">server.port</span>=<span class="hljs-string">8082</span><br></code></pre></div></td></tr></table></figure><h2 id="api">api</h2><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-meta">@Bean</span><br>   <span class="hljs-keyword">public</span> Docket <span class="hljs-title function_">docket1</span><span class="hljs-params">()</span> &#123;<br>       <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Docket</span>(DocumentationType.SWAGGER_2).groupName(<span class="hljs-string">&quot;A&quot;</span>);<br>   &#125;<br><br>   <span class="hljs-meta">@Bean</span><br>   <span class="hljs-keyword">public</span> Docket <span class="hljs-title function_">docket2</span><span class="hljs-params">()</span> &#123;<br>       <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Docket</span>(DocumentationType.SWAGGER_2).groupName(<span class="hljs-string">&quot;B&quot;</span>);<br>   &#125;<br><br>   <span class="hljs-meta">@Bean</span><br>   <span class="hljs-keyword">public</span> Docket <span class="hljs-title function_">docket3</span><span class="hljs-params">()</span> &#123;<br>       <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Docket</span>(DocumentationType.SWAGGER_2).groupName(<span class="hljs-string">&quot;C&quot;</span>);<br>   &#125;<br><br><span class="hljs-meta">@Bean</span><br>   <span class="hljs-keyword">public</span> Docket <span class="hljs-title function_">docket</span><span class="hljs-params">(Environment environment)</span> &#123;<br><br>       <span class="hljs-type">Profiles</span> <span class="hljs-variable">profiles</span> <span class="hljs-operator">=</span> Profiles.of(<span class="hljs-string">&quot;dev&quot;</span>, <span class="hljs-string">&quot;test&quot;</span>);<br><br>       <span class="hljs-type">boolean</span> <span class="hljs-variable">flag</span> <span class="hljs-operator">=</span> environment.acceptsProfiles(profiles);<br><br>       <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">Docket</span>(DocumentationType.SWAGGER_2)<br>               .apiInfo(apiInfo())<br>               .enable(flag)<br>               .groupName(<span class="hljs-string">&quot;&quot;</span>)<br>               .select()<br>               .apis(RequestHandlerSelectors.basePackage(<span class="hljs-string">&quot;com.example.swagger.controller&quot;</span>))<br>               .build();<br>   &#125;<br></code></pre></div></td></tr></table></figure><ul><li>apiswagger</li></ul><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-meta">@ApiModel(&quot;&quot;)</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">User</span> &#123;<br>    <br>    <span class="hljs-meta">@ApiModelProperty(&quot;&quot;)</span><br>    <span class="hljs-keyword">public</span> String username;<br>    <br>    <span class="hljs-meta">@ApiModelProperty(&quot;&quot;)</span><br>    <span class="hljs-keyword">public</span> String password;<br>&#125;<br></code></pre></div></td></tr></table></figure><ul><li></li></ul><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-meta">@RestController</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">HelloController</span> &#123;<br><br>    <span class="hljs-meta">@ApiOperation(&quot;Hello&quot;)</span><br>    <span class="hljs-meta">@GetMapping(&quot;/hello2&quot;)</span><br>    <span class="hljs-keyword">public</span> String <span class="hljs-title function_">hello2</span><span class="hljs-params">(<span class="hljs-meta">@ApiParam(&quot;&quot;)</span> String username)</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;hello&quot;</span> + username;<br>    &#125;<br>    <br>&#125;<br></code></pre></div></td></tr></table></figure><h1 id=""></h1><p>3</p><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-meta">@Service</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">AsyncService</span> &#123;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">hello</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">try</span>&#123;<br>            Thread.sleep(<span class="hljs-number">3000</span>);<br>        &#125; <span class="hljs-keyword">catch</span> (InterruptedException e) &#123;<br>            e.printStackTrace();<br>        &#125;<br><br>        System.out.println(<span class="hljs-string">&quot;&quot;</span>);<br><br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-meta">@RestController</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">AsyncController</span> &#123;<br><br>    <span class="hljs-meta">@Autowired</span><br>    AsyncService asyncService;<br><br>    <span class="hljs-meta">@RequestMapping(&quot;/hello&quot;)</span><br>    <span class="hljs-keyword">public</span> String <span class="hljs-title function_">hello</span><span class="hljs-params">()</span> &#123;<br>        asyncService.hello();<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;ok&quot;</span>;<br>    &#125;<br><br>&#125;<br></code></pre></div></td></tr></table></figure><p>3</p><ul><li>Service<code>@Async</code></li></ul><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-meta">@Service</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">AsyncService</span> &#123;<br><br>    <span class="hljs-comment">//Spring</span><br>    <span class="hljs-meta">@Async</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">hello</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">try</span>&#123;<br>            Thread.sleep(<span class="hljs-number">3000</span>);<br>        &#125; <span class="hljs-keyword">catch</span> (InterruptedException e) &#123;<br>            e.printStackTrace();<br>        &#125;<br><br>        System.out.println(<span class="hljs-string">&quot;&quot;</span>);<br><br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><ul><li>main</li></ul><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-comment">//</span><br><span class="hljs-meta">@EnableAsync</span><br><span class="hljs-meta">@SpringBootApplication</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">TestApplication</span> &#123;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> &#123;<br>        SpringApplication.run(TestApplication.class, args);<br>    &#125;<br><br>&#125;<br></code></pre></div></td></tr></table></figure><h1 id=""></h1><ul><li></li></ul><figure class="highlight xml"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.springframework.boot<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>spring-boot-starter-mail<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br></code></pre></div></td></tr></table></figure><ul><li></li></ul><figure class="highlight properties"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs properties"><span class="hljs-attr">spring.mail.username</span>=<span class="hljs-string">1735257086@qq.com</span><br><span class="hljs-attr">spring.mail.password</span>=<span class="hljs-string">dzzmxmfwltrpcbid</span><br><span class="hljs-attr">spring.mail.host</span>=<span class="hljs-string">smtp.qq.com</span><br><span class="hljs-comment"># qq</span><br><span class="hljs-attr">spring.mail.properties.mail.smtp.ssl.enable</span>=<span class="hljs-string">true</span><br></code></pre></div></td></tr></table></figure><ul><li></li></ul><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-meta">@SpringBootTest</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">TestApplicationTests</span> &#123;<br><br>    <span class="hljs-meta">@Autowired</span><br>    JavaMailSenderImpl mailSender;<br><br>    <span class="hljs-meta">@Test</span><br>    <span class="hljs-keyword">void</span> <span class="hljs-title function_">contextLoads</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-comment">//</span><br>        <span class="hljs-type">SimpleMailMessage</span> <span class="hljs-variable">mailMessage</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">SimpleMailMessage</span>();<br><br>        mailMessage.setSubject(<span class="hljs-string">&quot;&quot;</span>);<br>        mailMessage.setText(<span class="hljs-string">&quot;,&quot;</span>);<br><br>        mailMessage.setTo(<span class="hljs-string">&quot;1735257086@qq.com&quot;</span>);<br>        mailMessage.setFrom(<span class="hljs-string">&quot;1735257086@qq.com&quot;</span>);<br><br>        mailSender.send(mailMessage);<br>    &#125;<br><br>    <span class="hljs-meta">@Test</span><br>    <span class="hljs-keyword">void</span> <span class="hljs-title function_">contextLoads2</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> MessagingException &#123;<br>        <span class="hljs-comment">//</span><br>        <span class="hljs-type">MimeMessage</span> <span class="hljs-variable">mimeMessage</span> <span class="hljs-operator">=</span> mailSender.createMimeMessage();<br><br>        <span class="hljs-type">MimeMessageHelper</span> <span class="hljs-variable">helper</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">MimeMessageHelper</span>(mimeMessage, <span class="hljs-literal">true</span>);<br><br>        helper.setSubject(<span class="hljs-string">&quot;&quot;</span>);<br>        helper.setText(<span class="hljs-string">&quot;&lt;p style=&#x27;color:red&gt;&lt;/p&gt;&quot;</span>, <span class="hljs-literal">true</span>);   <span class="hljs-comment">//truehtml</span><br><br>        <span class="hljs-comment">//</span><br>        helper.addAttachment(<span class="hljs-string">&quot;1.jpg&quot;</span>, <span class="hljs-keyword">new</span> <span class="hljs-title class_">File</span>(<span class="hljs-string">&quot;D:\\1.jpg&quot;</span>));<br><br>        helper.setTo(<span class="hljs-string">&quot;1735257086@qq.com&quot;</span>);<br>        helper.setFrom(<span class="hljs-string">&quot;1735257086@qq.com&quot;</span>);<br><br>        mailSender.send(mimeMessage);<br>    &#125;<br><br>&#125;<br></code></pre></div></td></tr></table></figure><h1 id=""></h1><ul><li>main</li></ul><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-comment">//</span><br><span class="hljs-meta">@EnableAsync</span><br><span class="hljs-comment">//</span><br><span class="hljs-meta">@EnableScheduling</span><br><span class="hljs-meta">@SpringBootApplication</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">TestApplication</span> &#123;<br><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">main</span><span class="hljs-params">(String[] args)</span> &#123;<br>        SpringApplication.run(TestApplication.class, args);<br>    &#125;<br><br>&#125;<br></code></pre></div></td></tr></table></figure><ul><li></li></ul><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-meta">@Service</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title class_">ScheduledService</span> &#123;<br><br>    <span class="hljs-comment">// Timer</span><br>    <span class="hljs-comment">//Cron</span><br>    <span class="hljs-comment">//     </span><br>    <span class="hljs-comment">/*</span><br><span class="hljs-comment">    * 30 15 10 * *     101530</span><br><span class="hljs-comment">    * 30 0/5 10,18 * * ?    10185</span><br><span class="hljs-comment">    * */</span><br>    <span class="hljs-meta">@Scheduled(cron = &quot;0 * * * * 0-7&quot;)</span>  <span class="hljs-comment">//0</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">hello</span><span class="hljs-params">()</span> &#123;<br>        System.out.println(<span class="hljs-string">&quot;&quot;</span>);<br>    &#125;<br><br>&#125;<br></code></pre></div></td></tr></table></figure><ul><li>cron</li></ul><h1 id="redis">Redis</h1><ul><li>(NoSQL)Spring Data Redis(Access+Driver)</li></ul><h1 id=""></h1>]]></content>
    
    
    <categories>
      
      <category></category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>-NLP</title>
    <link href="/2022/06/15/%E7%AC%AC%E5%8D%81%E4%B8%89%E8%AE%B2-%E5%9F%BA%E4%BA%8E%E4%B8%8A%E4%B8%8B%E6%96%87%E7%9A%84%E8%A1%A8%E5%BE%81%E4%B8%8ENLP%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/"/>
    <url>/2022/06/15/%E7%AC%AC%E5%8D%81%E4%B8%89%E8%AE%B2-%E5%9F%BA%E4%BA%8E%E4%B8%8A%E4%B8%8B%E6%96%87%E7%9A%84%E8%A1%A8%E5%BE%81%E4%B8%8ENLP%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="">1 </h1><h2 id="">1.1 </h2><ul><li><ul><li><ul><li>Word2vecGloVefastText</li></ul></li></ul></li></ul><h2 id="">1.2 </h2><ul><li></li><li>()</li></ul><h2 id="">1.3 </h2><ul><li><p></p></li><li><p><span class="math inline">\(\{\text { wordsoccurring, say }, \geq 5 \text { times }\}\cup\{&lt;\mathrm{UNK}&gt;\}\)</span></p><ul><li><strong></strong> ( 5)<spanclass="math inline">\(&lt;UNK&gt;\)</span></li></ul></li><li><p><strong></strong><spanclass="math inline">\(&lt;UNK&gt;\)</span>OOV</p></li><li><p><strong></strong></p><ul><li> UNK words</li></ul></li></ul><p><strong></strong></p><p> <strong></strong></p><ul><li> QA match on word identity</li></ul><p> <strong></strong> (from Dhingra, Liu, Salakhutdinov,Cohen 2017)</p><ul><li><p><spanclass="math inline">\(&lt;UNK&gt;\)</span></p></li><li><p></p></li><li><p></p></li><li><p></p><ul><li> () <spanclass="math inline">\(&lt;UNK-class&gt;\)</span></li></ul></li></ul><h2 id="">1.4 </h2><p><strong></strong></p><ul><li> word type  word token<ul><li></li></ul></li><li>/ </li></ul><h2 id="">1.5</h2><ul><li>NLM () LSTM</li><li>LSTM</li><li></li></ul><h2 id="-peters-et-al.-2017-taglm-pre-elmo">1.6  Peterset al. (2017): TagLM  Pre-ELMo</h2><ul><li><strong></strong> RNN task-labeled  ( NER )</li><li>NLM</li></ul><h2 id="-tag-lm">1.7  (Tag LM )</h2><ul><li><strong>3</strong> LM</li><li><strong>2</strong> LM</li><li><strong>1</strong></li><li> + RNN model  hidden states</li></ul><p><img src="/img/nlp//1.png" /></p><ul><li>Char CNN / RNN + Token Embedding  bi-LSTM </li><li> hidden states  Pre-trained bi-LM ()  hidden states bi-LSTM </li></ul><p><img src="/img/nlp//2.png" /></p><h2 id="-ner">1.8  (NER)</h2><ul><li>NLP<strong></strong><strong></strong></li></ul><h2 id="-peters-et-al.2017-taglm-pre-elmo">1.9  Peterset al.(2017): TagLM-"Pre-ELMo"</h2><ul><li> <code>Billion word benchmark</code>8</li></ul><p><strong></strong></p><ul><li></li><li> forward  0.2</li><li> ( 30)  ( 48) 0.3</li></ul><p><strong>BiLSTM</strong></p><ul><li>LM88.17 F1<ul><li> BiLSTM </li></ul></li></ul><h2 id="-also-in-the-air-mccann-et-al.2017cove">1.10 Also in the air: McCann et al.2017:CoVe</h2><ul><li><p>NLP</p></li><li><p><strong></strong></p></li><li><p> seq2seq + attention NMT system  Encoder 2 bi-LSTM</p></li><li><p> CoVe  GloVe </p></li><li><p> NLM</p><ul><li>NMT</li><li></li></ul></li></ul><h1 id="elmo">2.ELMo</h1><h2id="-peters-et-al.-2018-elmo-embeddings-from-language-models">2.1 Peters et al. (2018): ELMo: Embeddings from LanguageModels</h2><ul><li><p></p></li><li><p>()</p></li><li><p> Bi-NLM</p></li><li><p> (LM)</p></li><li><p> OK  (LM)</p><ul><li> 2  biLSTM </li><li>() CNN<ul><li>2048  char n-gram filters  2  highway layers512 projection</li></ul></li><li>4096 dim hidden/cell LSTM 512 dim</li><li></li><li> token (softmax) (LM) </li></ul></li><li><p>ELMo  biLM </p></li><li><p>TagLM  LSTM ELMo  BiLSTM</p></li></ul><p><span class="math display">\[\begin{aligned}R_{k} &amp;=\left\{\mathbf{x}_{k}^{L M}, \overrightarrow{\mathbf{h}}_{k,j}^{L M}, \overleftarrow{\mathbf{h}}_{k, j}^{L M} \mid j=1, \ldots,L\right\} \\&amp;=\left\{\mathbf{h}_{k, j}^{L M} \mid j=0, \ldots, L\right\}\end{aligned}\]</span></p><p><span class="math display">\[\mathbf{E L M o}_{k}^{\text {task }}=E\left(R_{k} ; \Theta^{\text {task}}\right)=\gamma^{\text {task }} \sum_{j=0}^{L} s_{j}^{\text {task }}\mathbf{h}_{k, j}^{L M}\]</span></p><ul><li><p><span class="math inline">\(\gamma^{t a s k}\)</span> ELMo</p></li><li><p><span class="math inline">\(s^{task}\)</span> softmax BiLSTMBiLSTM </p></li><li><p> biLM </p></li><li><p> () </p><ul><li> ELMo </li><li> ELMo <ul><li><ul><li> TagLM </li><li></li></ul></li></ul></li></ul></li></ul><h2 id="elmo">2.2 ELMo</h2><p><img src="/img/nlp//3.png" /></p><h2 id="elmo-">2.3 ELMo </h2><ul><li> biLSTM NLM  / <ul><li><ul><li>(part-of-speech tagging)(syntacticdependency)NER</li></ul></li><li><ul><li>SNLI</li></ul></li></ul></li><li></li></ul><h1 id="ulmfit">3.ULMfit</h1><h2 id="ulmfit">3.1 ULMfit</h2><ul><li><p> NLM </p></li><li><p></p><p><img src="/img/nlp//4.png" /></p></li><li><p> biLM </p><ul><li><p> LM</p></li><li><p></p><p><img src="/img/nlp//5.png" /></p></li></ul></li><li><p> <code>1 GPU</code></p></li><li><p>LM</p><ul><li></li><li> (STLR) </li></ul></li><li><p>STLR</p></li><li><p><span class="math inline">\(\left[h_{T},\operatorname{maxpool}(\mathbf{h}), \text { meanpool}(\mathbf{h})\right]\)</span></p></li><li><p></p></li></ul><h1 id="transformer">4.Transformer</h1><h2 id="transformer">4.1 Transformer</h2><p><img src="/img/nlp//6.png" /></p><ul><li>TransformerTransformer</li></ul><p><strong></strong></p><ul><li>Transformer </li></ul><h2 id="transformers-">4.2 Transformers </h2><ul><li><p>RNNs</p></li><li><p> GRUs  LSTMsRNNs path length<strong></strong> </p></li><li><p>RNN?</p></li></ul><h2 id="transformer-">4.3 Transformer </h2><ul><li></li><li><strong></strong></li><li></li><li>/ softmax </li></ul><p><img src="/img/nlp//7.png" /></p><h2 id="transformer-">4.4 Transformer </h2><ul><li> transformer<ul><li><ul><li>http://nlp.seas.harvard.edu/2018/04/03/attention.html</li><li>The Annotated Transformer by Sasha Rush</li></ul></li><li>PyTorchJupyter</li></ul></li><li> Transformer </li></ul><h2 id="-dot-product-attention">4.5  Dot-ProductAttention</h2><ul><li><p><strong></strong><spanclass="math inline">\(q\)</span>-<spanclass="math inline">\((k-v)\)</span></p></li><li><p>Querykeysvaluesand output </p></li><li><p></p></li><li><p></p></li><li><p>Query  keys <spanclass="math inline">\(d_k\)</span>value <spanclass="math inline">\(d_v\)</span></p></li></ul><p><span class="math display">\[A(q, K, V)=\sum_{i} \frac{e^{q \cdot k_{i}}}{\sum_{j} e^{q \cdot k_{j}}}v_{i}\]</span></p><h2 id="">4.6 </h2><ul><li><spanclass="math inline">\(q\)</span><spanclass="math inline">\(Q\)</span></li><li><span class="math inline">\(A(Q, K,V)=\operatorname{softmax}\left(Q K^{T}\right) V\)</span></li></ul><h2 id="">4.7 </h2><ul><li><p><strong></strong><spanclass="math inline">\(d_k\)</span><spanclass="math inline">\(q^Tk\)</span>   softmax  softmax   </p></li><li><p><strong></strong> query / key</p></li></ul><p><span class="math display">\[A(Q, K, V)=\operatorname{softmax}\left(\frac{QK^{T}}{\sqrt{d_{k}}}\right) V\]</span></p><p><img src="/img/nlp//11.png" /></p><p><img src="/img/nlp//9.png" /></p><p><img src="/img/nlp//8.png" /></p><p><img src="/img/nlp//10.png" /></p><h2 id="">4.8 </h2><ul><li><p> querieskeys and values</p></li><li><p><strong></strong></p></li><li><p>= Q = K = V</p></li><li><p></p></li></ul><h2 id="">4.9 </h2><ul><li> self-attention <ul><li></li></ul></li><li><strong></strong><strong></strong></li><li><span class="math inline">\(W\)</span><spanclass="math inline">\(Q\)</span><spanclass="math inline">\(K\)</span><spanclass="math inline">\(V\)</span><spanclass="math inline">\(h=8\)</span></li><li></li></ul><p><span class="math display">\[\operatorname{MultiHead}(\boldsymbol{Q}, \boldsymbol{K},\boldsymbol{V})=\operatorname{Concat}\left(\right.  head  _{1}, \ldots ,head  \left._{h}\right)  where \ head\  hention  _{i}=  Attention (\left.Q W_{i}^{Q}, K W_{i}^{K}, V W_{i}^{V}\right)\]</span></p><p><img src="/img/nlp//12.png" /></p><p><img src="/img/nlp//13.png" /></p><h2 id="transformer">4.10 transformer</h2><ul><li><p> Block </p><ul><li><p> attention</p></li><li><p> ReLU</p></li></ul></li><li><p></p><ul><li></li><li>LayerNorm(x+Sublayer(x))</li><li>01()</li></ul></li></ul><p><span class="math display">\[\mu^{l}=\frac{1}{H} \sum_{i=1}^{H} a_{i}^{l} \quad\sigma^{l}=\sqrt{\frac{1}{H}\sum_{i=1}^{H}\left(a_{i}^{l}-\mu^{l}\right)^{2}} \quadh_{i}=f\left(\frac{g_{i}}{\sigma_{i}}\left(a_{i}-\mu_{i}\right)+b_{i}\right)\]</span></p><h2 id="">4.11 </h2><ul><li><p> byte-pair </p></li><li><p> positional encoding</p></li></ul><p><span class="math display">\[\left\{\begin{array}{l}P E(p o s, 2 i)=\sin \left(p o s / 10000^{2 i / d_{\text {model}}}\right) \\P E(\operatorname{pos}, 2 i+1)=\cos \left(p o s / 10000^{2 i / d_{\text{model }}}\right)\end{array}\right.\]</span></p><p><img src="/img/nlp//14.png" /></p><h2 id="encoder">4.12 Encoder</h2><ul><li><p>encoder  Block <spanclass="math inline">\(Q,K,V\)</span></p></li><li><p>Blocks  6  ()</p></li><li><p></p></li><li><p></p></li></ul><p><img src="/img/nlp//15.png" /></p><h2 id="">4.13 </h2><p><img src="/img/nlp//16.png" /></p><h2 id="transformer">4.14 Transformer</h2><ul><li><p>decoder </p></li><li><p> Masked decoder self-attention</p></li><li><p>Encoder-Decoder Attentionqueries  decoder keys values  encoder </p></li><li><p>Blocks  6 </p></li></ul><p><img src="/img/nlp//17.png" /></p><h2 id="transformer">4.15 Transformer</h2><p><strong></strong>(/)</p><ul><li><p>Byte-pair encodings</p></li><li><p>Checkpoint averaging</p></li><li><p>Adam </p></li><li><p> Dropout</p></li><li><p></p></li><li><p></p></li><li><p> transformerLSTMs</p></li></ul><h1 id="bert">5.BERT</h1><h2 id="-bert-devlin-chang-lee-toutanova-2018">5.1 BERT: Devlin, Chang, Lee, Toutanova (2018)</h2><ul><li><p>BERT transformers</p></li><li><p></p></li><li><p>LMs</p><ul><li><strong>1</strong>[]</li><li><strong>2</strong><code></code></li></ul></li></ul><p><img src="/img/nlp//18.png" /></p><ul><li><p>k% masked words</p></li><li><p></p><ul><li>k=15%</li></ul></li><li><p>Masking </p></li><li><p>Masking </p></li><li><p><strong>GPT</strong> </p></li><li><p><strong>ELMo</strong>context</p></li><li><p><strong>BERT</strong>  mask</p></li></ul><p><img src="/img/nlp//19.png" /></p><h2 id="bert-">5.2 BERT </h2><ul><li></li></ul><p><img src="/img/nlp//120.png" /></p>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>NLP</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>-NLP</title>
    <link href="/2022/06/15/%E7%AC%AC%E5%8D%81%E4%B8%80%E8%AE%B2-NLP%E4%B8%AD%E7%9A%84%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <url>/2022/06/15/%E7%AC%AC%E5%8D%81%E4%B8%80%E8%AE%B2-NLP%E4%B8%AD%E7%9A%84%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>-NLP</title>
    <link href="/2022/06/06/%E7%AC%AC%E5%8D%81%E8%AE%B2-NLP%E4%B8%AD%E7%9A%84%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F/"/>
    <url>/2022/06/06/%E7%AC%AC%E5%8D%81%E8%AE%B2-NLP%E4%B8%AD%E7%9A%84%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="squad">1SQuAD</h1><h2 id="-squad">1.1  (SQuAD)</h2><ul><li><p>Passage</p></li><li><p><span class="math inline">\(1000k\)</span></p></li><li><p></p></li><li><p></p></li></ul><h2 id="squad-v1.1">1.2 SQuAD v1.1</h2><p>3</p><p> -<strong></strong>1/0 -F1</p><p><span class="math display">\[\text { Precision }=\frac{T P}{T P+F P}\]</span></p><p><span class="math display">\[\text { Recall }=\frac{T P}{T P+F N}\]</span></p><p><span class="math display">\[\text { harmonic mean } \mathrm{F} 1=\frac{2 P R}{P+R}\]</span></p><ul><li> ()  F1</li></ul><p>F1</p><ul><li></li><li></li></ul><p> (a, an, the only)</p>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>NLP</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2022/05/20/%E6%96%B0%E9%97%BB%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"/>
    <url>/2022/05/20/%E6%96%B0%E9%97%BB%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/</url>
    
    <content type="html"><![CDATA[<h1 id=""></h1><p></p><p><code></code><code></code></p><ul><li>1TF-IDF + </li></ul><p>TF-IDFSVMLRXGBoost</p><ul><li>2FastText</li></ul><p>FastTextFacebookFastText</p><ul><li>3WordVec + </li></ul><p>WordVecTextCNNTextRNNBiLSTM</p><ul><li>4Bert</li></ul><p>Bert</p><h2 id=""></h2><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">! mkdir ./data<br></code></pre></div></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">train data</span><br>! wget https://tianchi-competition.oss-cn-hangzhou.aliyuncs.com/531810/train_set.csv.zip<br>! unzip train_set.csv.zip -d ./data<br>! rm train_set.csv.zip<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash"><span class="hljs-built_in">test</span> data</span><br>! wget https://tianchi-competition.oss-cn-hangzhou.aliyuncs.com/531810/test_a.csv.zip<br>! unzip test_a.csv.zip -d ./data<br>! rm test_a.csv.zip<br></code></pre></div></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">2.</span><br>! wget http://tianchi-media.oss-cn-beijing.aliyuncs.com/dragonball/NLP/emb.zip<br>! unzip emb.zip<br>! rm emb.zip<br>! mv ./emb/bert-mini/bert_config.json ./emb/bert-mini/config.json <br></code></pre></div></td></tr></table></figure><h2 id=""></h2><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">! mkdir ./save<br></code></pre></div></td></tr></table></figure><h2 id=""></h2><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">! pip install fasttext transformers==2.9.0 gensim torch==1.3.0<br></code></pre></div></td></tr></table></figure><h2 id=""></h2><p>csv<code>Pandas</code></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br>train_df = pd.read_csv(<span class="hljs-string">&#x27;./data/train_set.csv&#x27;</span>, sep=<span class="hljs-string">&#x27;\t&#x27;</span>, nrows=<span class="hljs-number">100</span>)<br></code></pre></div></td></tr></table></figure><p><code>read_csv</code></p><ul><li></li><li><code>sep</code><code>\t</code></li><li><code>nrows</code>100</li></ul><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">train_df.head()<br></code></pre></div></td></tr></table></figure><table><thead><tr class="header"><th style="text-align: left;">label</th><th style="text-align: left;">text</th><th></th></tr></thead><tbody><tr class="odd"><td style="text-align: left;">0</td><td style="text-align: left;">2</td><td>2967 6758 339 2021 1854 3731 4109 3792 4149 15...</td></tr><tr class="even"><td style="text-align: left;">1</td><td style="text-align: left;">11</td><td>4464 486 6352 5619 2465 4802 1452 3137 5778 54...</td></tr><tr class="odd"><td style="text-align: left;">2</td><td style="text-align: left;">3</td><td>7346 4068 5074 3747 5681 6093 1777 2226 7354 6...</td></tr><tr class="even"><td style="text-align: left;">3</td><td style="text-align: left;">2</td><td>7159 948 4866 2109 5520 2490 211 3956 5520 549...</td></tr><tr class="odd"><td style="text-align: left;">4</td><td style="text-align: left;">3</td><td>3646 3055 3055 2490 4659 6065 3370 5814 2465 5...</td></tr></tbody></table><p></p><h1 id=""></h1><p></p><p></p><ul><li></li><li></li><li></li></ul><h2 id=""></h2><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">%pylab inline<br>train_df[<span class="hljs-string">&#x27;text_len&#x27;</span>] = train_df[<span class="hljs-string">&#x27;text&#x27;</span>].apply(<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">len</span>(x.split(<span class="hljs-string">&#x27; &#x27;</span>)))<br><span class="hljs-built_in">print</span>(train_df[<span class="hljs-string">&#x27;text_len&#x27;</span>].describe())<br></code></pre></div></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">opulating the interactive namespace from numpy and matplotlib<br>count     100.000000<br>mean      872.320000<br>std       923.138191<br>min        64.000000<br><span class="hljs-meta prompt_">25% </span><span class="language-bash">      359.500000</span><br><span class="hljs-meta prompt_">50% </span><span class="language-bash">      598.000000</span><br><span class="hljs-meta prompt_">75% </span><span class="language-bash">     1058.000000</span><br>max      7125.000000<br>Name: text_len, dtype: float64<br></code></pre></div></td></tr></table></figure><p>907257921</p><h2 id=""></h2><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">train_df[<span class="hljs-string">&#x27;label&#x27;</span>].value_counts().plot(kind=<span class="hljs-string">&#x27;bar&#x27;</span>)<br>plt.title(<span class="hljs-string">&#x27;News class count&#x27;</span>)<br>plt.xlabel(<span class="hljs-string">&quot;category&quot;</span>)<br></code></pre></div></td></tr></table></figure><figure class="highlight stylus"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs stylus"><span class="hljs-function"><span class="hljs-title">Text</span><span class="hljs-params">(<span class="hljs-number">0.5</span>, <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;category&#x27;</span>)</span></span><br></code></pre></div></td></tr></table></figure><p><img src="/img/nlp//1.png" /></p><p>{'': 0, '': 1, '': 2,'': 3, '': 4, '': 5, '': 6, '': 7, '': 8,'': 9, '': 10, '': 11, '': 12, '': 13}</p><p></p><h2 id=""></h2><p></p><p>686937505034</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> Counter<br>all_lines = <span class="hljs-string">&#x27; &#x27;</span>.join(<span class="hljs-built_in">list</span>(train_df[<span class="hljs-string">&#x27;text&#x27;</span>]))<br>word_count = Counter(all_lines.split(<span class="hljs-string">&quot; &quot;</span>))<br>word_count = <span class="hljs-built_in">sorted</span>(word_count.items(), key=<span class="hljs-keyword">lambda</span> d:d[<span class="hljs-number">1</span>], reverse = <span class="hljs-literal">True</span>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(word_count))<br><br><span class="hljs-built_in">print</span>(word_count[<span class="hljs-number">0</span>])<br><br><span class="hljs-built_in">print</span>(word_count[-<span class="hljs-number">1</span>])<br></code></pre></div></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">2405<br>(&#x27;3750&#x27;, 3702)<br>(&#x27;5034&#x27;, 1)<br></code></pre></div></td></tr></table></figure><h2 id=""></h2><p></p><ol type="1"><li>1000</li><li>4w1k</li><li>7000-8000</li></ol><p></p><ol type="1"><li></li><li></li></ol><h1 id=""></h1><h2 id=""><strong></strong></h2><ul><li>TF-IDF</li><li>sklearn</li></ul><h2 id=""></h2><h3 id="one-hot">One-hot</h3><p>One-hot/</p><p>One-hot</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-number">1</span>      <br><span class="hljs-number">2</span>    <br></code></pre></div></td></tr></table></figure><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">&#123;<br>    <span class="hljs-string">&#x27;&#x27;</span>: <span class="hljs-number">1</span>, <span class="hljs-string">&#x27;&#x27;</span>: <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;&#x27;</span>: <span class="hljs-number">3</span>, <span class="hljs-string">&#x27;&#x27;</span>: <span class="hljs-number">4</span>, <span class="hljs-string">&#x27;&#x27;</span>: <span class="hljs-number">5</span>,<br>  <span class="hljs-string">&#x27;&#x27;</span>: <span class="hljs-number">6</span>, <span class="hljs-string">&#x27;&#x27;</span>: <span class="hljs-number">7</span>, <span class="hljs-string">&#x27;&#x27;</span>: <span class="hljs-number">8</span>, <span class="hljs-string">&#x27;&#x27;</span>: <span class="hljs-number">9</span>, <span class="hljs-string">&#x27;&#x27;</span>: <span class="hljs-number">10</span>, <span class="hljs-string">&#x27;&#x27;</span>: <span class="hljs-number">11</span><br>&#125;<br></code></pre></div></td></tr></table></figure><p>1111</p><figure class="highlight prolog"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs prolog">[<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]<br>[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]<br>...<br>[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>]<br></code></pre></div></td></tr></table></figure><h3 id="bag-of-words">Bag of Words</h3><p>Bag of WordsCountVectors/</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-number">1</span>      <br><span class="hljs-number">2</span>    <br></code></pre></div></td></tr></table></figure><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-number">1</span>      <br> [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]<br><br><span class="hljs-number">2</span>    <br> [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]<br></code></pre></div></td></tr></table></figure><p>sklearn<code>CountVectorizer</code></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">from</span> sklearn.feature_extraction.text <span class="hljs-keyword">import</span> CountVectorizer<br>corpus = [<br>    <span class="hljs-string">&#x27;This is the first document.&#x27;</span>,<br>    <span class="hljs-string">&#x27;This document is the second document.&#x27;</span>,<br>    <span class="hljs-string">&#x27;And this is the third one.&#x27;</span>,<br>    <span class="hljs-string">&#x27;Is this the first document?&#x27;</span>,<br>]<br>vectorizer = CountVectorizer()<br>vectorizer.fit_transform(corpus).toarray()<br></code></pre></div></td></tr></table></figure><h3 id="n-gram">N-gram</h3><p>N-gramCountVectors</p><p>N212</p><figure class="highlight"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs">1     <br>2   <br></code></pre></div></td></tr></table></figure><h3 id="tf-idf">TF-IDF</h3><p>TF-IDF <strong></strong>TermFrequency<strong></strong>Inverse DocumentFrequency</p><figure class="highlight stylus"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs stylus"><span class="hljs-function"><span class="hljs-title">TF</span><span class="hljs-params">(t)</span></span>=  / <br><span class="hljs-function"><span class="hljs-title">IDF</span><span class="hljs-params">(t)</span></span>= log_e / <br></code></pre></div></td></tr></table></figure><h2 id="-1"></h2><p>F1</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># Count Vectors + RidgeClassifier</span><br><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br><span class="hljs-keyword">from</span> sklearn.feature_extraction.text <span class="hljs-keyword">import</span> CountVectorizer<br><span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> RidgeClassifier<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> f1_score<br><br>train_df = pd.read_csv(<span class="hljs-string">&#x27;./data/train_set.csv&#x27;</span>, sep=<span class="hljs-string">&#x27;\t&#x27;</span>, nrows=<span class="hljs-number">15000</span>)<br><br>vectorizer = CountVectorizer(max_features=<span class="hljs-number">3000</span>)<br>train_test = vectorizer.fit_transform(train_df[<span class="hljs-string">&#x27;text&#x27;</span>])<br><br>clf = RidgeClassifier()<br>clf.fit(train_test[:<span class="hljs-number">10000</span>], train_df[<span class="hljs-string">&#x27;label&#x27;</span>].values[:<span class="hljs-number">10000</span>])<br><br>val_pred = clf.predict(train_test[<span class="hljs-number">10000</span>:])<br><span class="hljs-built_in">print</span>(f1_score(train_df[<span class="hljs-string">&#x27;label&#x27;</span>].values[<span class="hljs-number">10000</span>:], val_pred, average=<span class="hljs-string">&#x27;macro&#x27;</span>))<br></code></pre></div></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">0.741494277019762<br></code></pre></div></td></tr></table></figure><h1id="-word2vec">-Word2Vec</h1><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">import</span> logging<br><span class="hljs-keyword">import</span> random<br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch<br><br>logging.basicConfig(level=logging.INFO, <span class="hljs-built_in">format</span>=<span class="hljs-string">&#x27;%(asctime)-15s %(levelname)s: %(message)s&#x27;</span>)<br><br><span class="hljs-comment"># set seed</span><br>seed = <span class="hljs-number">666</span><br>random.seed(seed)<br>np.random.seed(seed)<br>torch.cuda.manual_seed(seed)<br>torch.manual_seed(seed)<br></code></pre></div></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># split data to 10 fold</span><br>fold_num = <span class="hljs-number">10</span><br>data_file = <span class="hljs-string">&#x27;./data/train_set.csv&#x27;</span><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">all_data2fold</span>(<span class="hljs-params">fold_num, num=<span class="hljs-number">10000</span></span>):<br>    fold_data = []<br>    f = pd.read_csv(data_file, sep=<span class="hljs-string">&#x27;\t&#x27;</span>, encoding=<span class="hljs-string">&#x27;UTF-8&#x27;</span>)<br>    <span class="hljs-comment"># texts: [&#x27;2967 6758 339 2021 1854 3731 4109 3792 4149 1519 ...]</span><br>    texts = f[<span class="hljs-string">&#x27;text&#x27;</span>].tolist()[:num]<br>    <span class="hljs-comment"># labels: [2, 11, 3, 2, 3, 9, 3, 10, 12, 3, 0, 7, 4, 0, 0 ...]</span><br>    labels = f[<span class="hljs-string">&#x27;label&#x27;</span>].tolist()[:num]<br><br>    total = <span class="hljs-built_in">len</span>(labels)<br><br>    <span class="hljs-comment"># indexall_textsall_labels</span><br>    index = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(total))<br>    <span class="hljs-comment"># index: [3447, 966, 593, 5029, 4382, 2345, 974, 3786, 2249, ...]</span><br>    np.random.shuffle(index)<br><br>    all_texts = []<br>    all_labels = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> index:<br>        all_texts.append(texts[i])<br>        all_labels.append(labels[i])<br>    <span class="hljs-comment"># all_texts: [&#x27;600 3373 2828 2515 5026 245 3743 26 2396 6122 3720 14 ...]</span><br>    <span class="hljs-comment"># all_labels: [2, 4, 8, 7, 0, 0, 2, 1, 12, 0, ...]</span><br><br>    <span class="hljs-comment"># key:valuekeylabel,valuelabelindex</span><br>    label2id = &#123;&#125;<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(total):<br>        label = <span class="hljs-built_in">str</span>(all_labels[i])<br>        <span class="hljs-keyword">if</span> label <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> label2id:<br>            label2id[label] = [i]<br>        <span class="hljs-keyword">else</span>:<br>            label2id[label].append(i)<br>    <span class="hljs-comment"># label2id: &#123;&#x27;2&#x27;: [0, 6, 14, 21, 27, 28, 32, 39, ...], &#x27;4&#x27;: [...], ...&#125;</span><br><br>    <span class="hljs-comment"># label10</span><br>    all_index = [[] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(fold_num)]<br>    <span class="hljs-keyword">for</span> label, data <span class="hljs-keyword">in</span> label2id.items():<br>        <span class="hljs-comment"># print(label, len(data))</span><br>        <span class="hljs-comment"># data = 105</span><br>        <span class="hljs-comment"># fold_num = 10</span><br>        <span class="hljs-comment"># batch_size = 10</span><br>        <span class="hljs-comment"># other = 5</span><br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        i=0, cur_batch_size = 11, datch_data = [data[0], data[1], ... , data[10]]</span><br><span class="hljs-string">        i=1, cur_batch_size = 11, datch_data = [data[10], data[11], ... , data[20]]</span><br><span class="hljs-string">        ......</span><br><span class="hljs-string">        i=5, cur_batch_size = 10, datch_data = [data[50], data[51], ... , data[59]]</span><br><span class="hljs-string">        i=6, cur_batch_size = 10, datch_data = [data[60], data[61], ... , data[69]]</span><br><span class="hljs-string">        ......</span><br><span class="hljs-string">        i=9, cur_batch_size = 10, datch_data = [data[90], data[91], ... , data[99]]</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-comment"># print(label, len(data))</span><br>        batch_size = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">len</span>(data) / fold_num)<br>        other = <span class="hljs-built_in">len</span>(data) - batch_size * fold_num<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(fold_num):<br>            cur_batch_size = batch_size + <span class="hljs-number">1</span> <span class="hljs-keyword">if</span> i &lt; other <span class="hljs-keyword">else</span> batch_size<br>            <span class="hljs-comment"># print(cur_batch_size)</span><br>            batch_data = [data[i * batch_size + b] <span class="hljs-keyword">for</span> b <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(cur_batch_size)]<br>            all_index[i].extend(batch_data)<br><br>    batch_size = <span class="hljs-built_in">int</span>(total / fold_num)<br>    other_texts = []<br>    other_labels = []<br>    other_num = <span class="hljs-number">0</span><br>    start = <span class="hljs-number">0</span><br>    <span class="hljs-comment"># 10all_indexindex</span><br>    <span class="hljs-keyword">for</span> fold <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(fold_num):<br>        num = <span class="hljs-built_in">len</span>(all_index[fold])<br>        texts = [all_texts[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> all_index[fold]]<br>        labels = [all_labels[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> all_index[fold]]<br><br>        <span class="hljs-comment"># &gt;10batch_size,other_texts,fold_labels</span><br>        <span class="hljs-keyword">if</span> num &gt; batch_size:<br>            fold_texts = texts[:batch_size]<br>            other_texts.extend(texts[batch_size:])<br>            fold_labels = labels[:batch_size]<br>            other_labels.extend(labels[batch_size:])<br>            other_num += num - batch_size<br>        <span class="hljs-comment"># &lt;10other_sizebatch_size-numfold_labels</span><br>        <span class="hljs-keyword">elif</span> num &lt; batch_size:<br>            end = start + batch_size - num<br>            fold_texts = texts + other_texts[start: end]<br>            fold_labels = labels + other_labels[start: end]<br>            start = end<br>        <span class="hljs-comment"># </span><br>        <span class="hljs-keyword">else</span>:<br>            fold_texts = texts<br>            fold_labels = labels<br><br>        <span class="hljs-keyword">assert</span> batch_size == <span class="hljs-built_in">len</span>(fold_labels)<br><br>        <span class="hljs-comment"># shuffle10</span><br>        index = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(batch_size))<br>        np.random.shuffle(index)<br><br>        shuffle_fold_texts = []<br>        shuffle_fold_labels = []<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> index:<br>            shuffle_fold_texts.append(fold_texts[i])<br>            shuffle_fold_labels.append(fold_labels[i])<br><br>        data = &#123;<span class="hljs-string">&#x27;label&#x27;</span>: shuffle_fold_labels, <span class="hljs-string">&#x27;text&#x27;</span>: shuffle_fold_texts&#125;<br>        fold_data.append(data)<br><br>    logging.info(<span class="hljs-string">&quot;Fold lens %s&quot;</span>, <span class="hljs-built_in">str</span>([<span class="hljs-built_in">len</span>(data[<span class="hljs-string">&#x27;label&#x27;</span>]) <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> fold_data]))<br><br>    <span class="hljs-keyword">return</span> fold_data<br><br><br>fold_data = all_data2fold(<span class="hljs-number">10</span>)<br></code></pre></div></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># build train data for word2vec</span><br>fold_id = <span class="hljs-number">9</span><br><br>train_texts = []<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, fold_id):<br>    data = fold_data[i]<br>    train_texts.extend(data[<span class="hljs-string">&#x27;text&#x27;</span>])<br>    <br>logging.info(<span class="hljs-string">&#x27;Total %d docs.&#x27;</span> % <span class="hljs-built_in">len</span>(train_texts))<br></code></pre></div></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">logging.info(<span class="hljs-string">&#x27;Start training...&#x27;</span>)<br><span class="hljs-keyword">from</span> gensim.models.word2vec <span class="hljs-keyword">import</span> Word2Vec<br><br>num_features = <span class="hljs-number">100</span>     <span class="hljs-comment"># Word vector dimensionality</span><br>num_workers = <span class="hljs-number">8</span>       <span class="hljs-comment"># Number of threads to run in parallel</span><br><br>train_texts = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">list</span>(x.split()), train_texts))<br>model = Word2Vec(train_texts, workers=num_workers, size=num_features)<br>model.init_sims(replace=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># save model</span><br>model.save(<span class="hljs-string">&quot;./save/word2vec.bin&quot;</span>)<br></code></pre></div></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># load model</span><br>model = Word2Vec.load(<span class="hljs-string">&quot;./save/word2vec.bin&quot;</span>)<br><br><span class="hljs-comment"># convert format</span><br>model.wv.save_word2vec_format(<span class="hljs-string">&#x27;./save/word2vec.txt&#x27;</span>, binary=<span class="hljs-literal">False</span>)<br></code></pre></div></td></tr></table></figure><h1id="-textrnn">-TextRNN</h1><p>TextRNNRNNLSTMTextRNNLSTM</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">import</span> logging<br><span class="hljs-keyword">import</span> random<br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch<br><br>logging.basicConfig(level=logging.INFO, <span class="hljs-built_in">format</span>=<span class="hljs-string">&#x27;%(asctime)-15s %(levelname)s: %(message)s&#x27;</span>)<br><br><span class="hljs-comment"># set seed</span><br>seed = <span class="hljs-number">666</span><br>random.seed(seed)<br>np.random.seed(seed)<br>torch.cuda.manual_seed(seed)<br>torch.manual_seed(seed)<br><br><span class="hljs-comment"># set cuda</span><br>gpu = <span class="hljs-number">0</span><br>use_cuda = gpu &gt;= <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> torch.cuda.is_available()<br><span class="hljs-keyword">if</span> use_cuda:<br>    torch.cuda.set_device(gpu)<br>    device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span>, gpu)<br><span class="hljs-keyword">else</span>:<br>    device = torch.device(<span class="hljs-string">&quot;cpu&quot;</span>)<br>logging.info(<span class="hljs-string">&quot;Use cuda: %s, gpu id: %d.&quot;</span>, use_cuda, gpu)<br></code></pre></div></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># split data to 10 fold</span><br>fold_num = <span class="hljs-number">10</span><br>data_file = <span class="hljs-string">&#x27;../data/train_set.csv&#x27;</span><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">all_data2fold</span>(<span class="hljs-params">fold_num, num=<span class="hljs-number">1000</span></span>):<br>    fold_data = []<br>    f = pd.read_csv(data_file, sep=<span class="hljs-string">&#x27;\t&#x27;</span>, encoding=<span class="hljs-string">&#x27;UTF-8&#x27;</span>)<br>    texts = f[<span class="hljs-string">&#x27;text&#x27;</span>].tolist()[:num]<br>    labels = f[<span class="hljs-string">&#x27;label&#x27;</span>].tolist()[:num]<br><br>    total = <span class="hljs-built_in">len</span>(labels)<br><br>    index = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(total))<br>    np.random.shuffle(index)<br><br>    all_texts = []<br>    all_labels = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> index:<br>        all_texts.append(texts[i])<br>        all_labels.append(labels[i])<br><br>    label2id = &#123;&#125;<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(total):<br>        label = <span class="hljs-built_in">str</span>(all_labels[i])<br>        <span class="hljs-keyword">if</span> label <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> label2id:<br>            label2id[label] = [i]<br>        <span class="hljs-keyword">else</span>:<br>            label2id[label].append(i)<br><br>    all_index = [[] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(fold_num)]<br>    <span class="hljs-keyword">for</span> label, data <span class="hljs-keyword">in</span> label2id.items():<br>        <span class="hljs-comment"># print(label, len(data))</span><br>        batch_size = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">len</span>(data) / fold_num)<br>        other = <span class="hljs-built_in">len</span>(data) - batch_size * fold_num<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(fold_num):<br>            cur_batch_size = batch_size + <span class="hljs-number">1</span> <span class="hljs-keyword">if</span> i &lt; other <span class="hljs-keyword">else</span> batch_size<br>            <span class="hljs-comment"># print(cur_batch_size)</span><br>            batch_data = [data[i * batch_size + b] <span class="hljs-keyword">for</span> b <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(cur_batch_size)]<br>            all_index[i].extend(batch_data)<br><br>    batch_size = <span class="hljs-built_in">int</span>(total / fold_num)<br>    other_texts = []<br>    other_labels = []<br>    other_num = <span class="hljs-number">0</span><br>    start = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> fold <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(fold_num):<br>        num = <span class="hljs-built_in">len</span>(all_index[fold])<br>        texts = [all_texts[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> all_index[fold]]<br>        labels = [all_labels[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> all_index[fold]]<br><br>        <span class="hljs-keyword">if</span> num &gt; batch_size:<br>            fold_texts = texts[:batch_size]<br>            other_texts.extend(texts[batch_size:])<br>            fold_labels = labels[:batch_size]<br>            other_labels.extend(labels[batch_size:])<br>            other_num += num - batch_size<br>        <span class="hljs-keyword">elif</span> num &lt; batch_size:<br>            end = start + batch_size - num<br>            fold_texts = texts + other_texts[start: end]<br>            fold_labels = labels + other_labels[start: end]<br>            start = end<br>        <span class="hljs-keyword">else</span>:<br>            fold_texts = texts<br>            fold_labels = labels<br><br>        <span class="hljs-keyword">assert</span> batch_size == <span class="hljs-built_in">len</span>(fold_labels)<br><br>        <span class="hljs-comment"># shuffle</span><br>        index = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(batch_size))<br>        np.random.shuffle(index)<br><br>        shuffle_fold_texts = []<br>        shuffle_fold_labels = []<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> index:<br>            shuffle_fold_texts.append(fold_texts[i])<br>            shuffle_fold_labels.append(fold_labels[i])<br><br>        data = &#123;<span class="hljs-string">&#x27;label&#x27;</span>: shuffle_fold_labels, <span class="hljs-string">&#x27;text&#x27;</span>: shuffle_fold_texts&#125;<br>        fold_data.append(data)<br><br>    logging.info(<span class="hljs-string">&quot;Fold lens %s&quot;</span>, <span class="hljs-built_in">str</span>([<span class="hljs-built_in">len</span>(data[<span class="hljs-string">&#x27;label&#x27;</span>]) <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> fold_data]))<br><br>    <span class="hljs-keyword">return</span> fold_data<br><br><br>fold_data = all_data2fold(<span class="hljs-number">10</span>)<br></code></pre></div></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># build vocab</span><br><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> Counter<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BasicTokenizer<br><br>basic_tokenizer = BasicTokenizer()<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Vocab</span>():<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, train_data</span>):<br>        self.min_count = <span class="hljs-number">5</span><br>        self.pad = <span class="hljs-number">0</span><br>        self.unk = <span class="hljs-number">1</span><br>        self._id2word = [<span class="hljs-string">&#x27;[PAD]&#x27;</span>, <span class="hljs-string">&#x27;[UNK]&#x27;</span>]<br>        self._id2extword = [<span class="hljs-string">&#x27;[PAD]&#x27;</span>, <span class="hljs-string">&#x27;[UNK]&#x27;</span>]<br><br>        self._id2label = []<br>        self.target_names = []<br><br>        self.build_vocab(train_data)<br><br>        reverse = <span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(x, <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(x))))<br>        <br>        <span class="hljs-comment"># _word2id = &#123;&#x27;[PAD]&#x27;: 0, &#x27;[UNK]&#x27;: 1&#125;</span><br>        self._word2id = reverse(self._id2word)<br>        self._label2id = reverse(self._id2label)<br><br>        logging.info(<span class="hljs-string">&quot;Build vocab: words %d, labels %d.&quot;</span> % (self.word_size, self.label_size))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">build_vocab</span>(<span class="hljs-params">self, data</span>):<br>        self.word_counter = Counter()<br><br>        <span class="hljs-keyword">for</span> text <span class="hljs-keyword">in</span> data[<span class="hljs-string">&#x27;text&#x27;</span>]:<br>            words = text.split()<br>            <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> words:<br>                self.word_counter[word] += <span class="hljs-number">1</span><br><br>        <span class="hljs-keyword">for</span> word, count <span class="hljs-keyword">in</span> self.word_counter.most_common():<br>            <span class="hljs-keyword">if</span> count &gt;= self.min_count:<br>                self._id2word.append(word)<br><br>        label2name = &#123;<span class="hljs-number">0</span>: <span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-number">1</span>: <span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-number">2</span>: <span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-number">3</span>: <span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-number">4</span>: <span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-number">5</span>: <span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-number">6</span>: <span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-number">7</span>: <span class="hljs-string">&#x27;&#x27;</span>,<br>                      <span class="hljs-number">8</span>: <span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-number">9</span>: <span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-number">10</span>: <span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-number">11</span>: <span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-number">12</span>: <span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-number">13</span>: <span class="hljs-string">&#x27;&#x27;</span>&#125;<br><br>        self.label_counter = Counter(data[<span class="hljs-string">&#x27;label&#x27;</span>])<br><br>        <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(self.label_counter)):<br>            count = self.label_counter[label]<br>            self._id2label.append(label)<br>            self.target_names.append(label2name[label])<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">load_pretrained_embs</span>(<span class="hljs-params">self, embfile</span>):<br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(embfile, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>            lines = f.readlines()<br>            items = lines[<span class="hljs-number">0</span>].split()<br>            word_count, embedding_dim = <span class="hljs-built_in">int</span>(items[<span class="hljs-number">0</span>]), <span class="hljs-built_in">int</span>(items[<span class="hljs-number">1</span>])<br><br>        index = <span class="hljs-built_in">len</span>(self._id2extword)<br>        embeddings = np.zeros((word_count + index, embedding_dim))<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> lines[<span class="hljs-number">1</span>:]:<br>            values = line.split()<br>            self._id2extword.append(values[<span class="hljs-number">0</span>])<br>            vector = np.array(values[<span class="hljs-number">1</span>:], dtype=<span class="hljs-string">&#x27;float64&#x27;</span>)<br>            embeddings[self.unk] += vector<br>            embeddings[index] = vector<br>            index += <span class="hljs-number">1</span><br><br>        embeddings[self.unk] = embeddings[self.unk] / word_count<br>        embeddings = embeddings / np.std(embeddings)<br><br>        reverse = <span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(x, <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(x))))<br>        self._extword2id = reverse(self._id2extword)<br><br>        <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(<span class="hljs-built_in">set</span>(self._id2extword)) == <span class="hljs-built_in">len</span>(self._id2extword)<br><br>        <span class="hljs-keyword">return</span> embeddings<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">word2id</span>(<span class="hljs-params">self, xs</span>):<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(xs, <span class="hljs-built_in">list</span>):<br>            <span class="hljs-keyword">return</span> [self._word2id.get(x, self.unk) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> xs]<br>        <span class="hljs-keyword">return</span> self._word2id.get(xs, self.unk)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">extword2id</span>(<span class="hljs-params">self, xs</span>):<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(xs, <span class="hljs-built_in">list</span>):<br>            <span class="hljs-keyword">return</span> [self._extword2id.get(x, self.unk) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> xs]<br>        <span class="hljs-keyword">return</span> self._extword2id.get(xs, self.unk)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">label2id</span>(<span class="hljs-params">self, xs</span>):<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(xs, <span class="hljs-built_in">list</span>):<br>            <span class="hljs-keyword">return</span> [self._label2id.get(x, self.unk) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> xs]<br>        <span class="hljs-keyword">return</span> self._label2id.get(xs, self.unk)<br><br><span class="hljs-meta">    @property</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">word_size</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self._id2word)<br><br><span class="hljs-meta">    @property</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">extword_size</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self._id2extword)<br><br><span class="hljs-meta">    @property</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">label_size</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self._id2label)<br><br><br>vocab = Vocab(train_data)<br></code></pre></div></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># build module</span><br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Attention</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, hidden_size</span>):<br>        <span class="hljs-built_in">super</span>(Attention, self).__init__()<br>        self.weight = nn.Parameter(torch.Tensor(hidden_size, hidden_size))<br>        self.weight.data.normal_(mean=<span class="hljs-number">0.0</span>, std=<span class="hljs-number">0.05</span>)<br><br>        self.bias = nn.Parameter(torch.Tensor(hidden_size))<br>        b = np.zeros(hidden_size, dtype=np.float32)<br>        self.bias.data.copy_(torch.from_numpy(b))<br><br>        self.query = nn.Parameter(torch.Tensor(hidden_size))<br>        self.query.data.normal_(mean=<span class="hljs-number">0.0</span>, std=<span class="hljs-number">0.05</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, batch_hidden, batch_masks</span>):<br>        <span class="hljs-comment"># batch_hidden: b x len x hidden_size (2 * hidden_size of lstm)</span><br>        <span class="hljs-comment"># batch_masks:  b x len</span><br><br>        <span class="hljs-comment"># linear</span><br>        key = torch.matmul(batch_hidden, self.weight) + self.bias  <span class="hljs-comment"># b x len x hidden</span><br><br>        <span class="hljs-comment"># compute attention</span><br>        outputs = torch.matmul(key, self.query)  <span class="hljs-comment"># b x len</span><br><br>        masked_outputs = outputs.masked_fill((<span class="hljs-number">1</span> - batch_masks).<span class="hljs-built_in">bool</span>(), <span class="hljs-built_in">float</span>(-<span class="hljs-number">1e32</span>))<br><br>        attn_scores = F.softmax(masked_outputs, dim=<span class="hljs-number">1</span>)  <span class="hljs-comment"># b x len</span><br><br>        <span class="hljs-comment"># -1e32 1/len, -infnan, 0</span><br>        masked_attn_scores = attn_scores.masked_fill((<span class="hljs-number">1</span> - batch_masks).<span class="hljs-built_in">bool</span>(), <span class="hljs-number">0.0</span>)<br><br>        <span class="hljs-comment"># sum weighted sources</span><br>        batch_outputs = torch.bmm(masked_attn_scores.unsqueeze(<span class="hljs-number">1</span>), key).squeeze(<span class="hljs-number">1</span>)  <span class="hljs-comment"># b x hidden</span><br><br>        <span class="hljs-keyword">return</span> batch_outputs, attn_scores<br><br><br><span class="hljs-comment"># build word encoder</span><br>word2vec_path = <span class="hljs-string">&#x27;../emb/word2vec.txt&#x27;</span><br>dropout = <span class="hljs-number">0.15</span><br>word_hidden_size = <span class="hljs-number">128</span><br>word_num_layers = <span class="hljs-number">2</span><br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">WordLSTMEncoder</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, vocab</span>):<br>        <span class="hljs-built_in">super</span>(WordLSTMEncoder, self).__init__()<br>        self.dropout = nn.Dropout(dropout)<br>        self.word_dims = <span class="hljs-number">100</span><br><br>        self.word_embed = nn.Embedding(vocab.word_size, self.word_dims, padding_idx=<span class="hljs-number">0</span>)<br><br>        extword_embed = vocab.load_pretrained_embs(word2vec_path)<br>        extword_size, word_dims = extword_embed.shape<br>        logging.info(<span class="hljs-string">&quot;Load extword embed: words %d, dims %d.&quot;</span> % (extword_size, word_dims))<br><br>        self.extword_embed = nn.Embedding(extword_size, word_dims, padding_idx=<span class="hljs-number">0</span>)<br>        self.extword_embed.weight.data.copy_(torch.from_numpy(extword_embed))<br>        self.extword_embed.weight.requires_grad = <span class="hljs-literal">False</span><br><br>        input_size = self.word_dims<br><br>        self.word_lstm = nn.LSTM(<br>            input_size=input_size,<br>            hidden_size=word_hidden_size,<br>            num_layers=word_num_layers,<br>            batch_first=<span class="hljs-literal">True</span>,<br>            bidirectional=<span class="hljs-literal">True</span><br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, word_ids, extword_ids, batch_masks</span>):<br>        <span class="hljs-comment"># word_ids: sen_num x sent_len</span><br>        <span class="hljs-comment"># extword_ids: sen_num x sent_len</span><br>        <span class="hljs-comment"># batch_masks   sen_num x sent_len</span><br><br>        word_embed = self.word_embed(word_ids)  <span class="hljs-comment"># sen_num x sent_len x 100</span><br>        extword_embed = self.extword_embed(extword_ids)<br>        batch_embed = word_embed + extword_embed<br><br>        <span class="hljs-keyword">if</span> self.training:<br>            batch_embed = self.dropout(batch_embed)<br><br>        hiddens, _ = self.word_lstm(batch_embed)  <span class="hljs-comment"># sen_num x sent_len x  hidden*2</span><br>        hiddens = hiddens * batch_masks.unsqueeze(<span class="hljs-number">2</span>)<br><br>        <span class="hljs-keyword">if</span> self.training:<br>            hiddens = self.dropout(hiddens)<br><br>        <span class="hljs-keyword">return</span> hiddens<br><br><br><span class="hljs-comment"># build sent encoder</span><br>sent_hidden_size = <span class="hljs-number">256</span><br>sent_num_layers = <span class="hljs-number">2</span><br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SentEncoder</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, sent_rep_size</span>):<br>        <span class="hljs-built_in">super</span>(SentEncoder, self).__init__()<br>        self.dropout = nn.Dropout(dropout)<br><br>        self.sent_lstm = nn.LSTM(<br>            input_size=sent_rep_size,<br>            hidden_size=sent_hidden_size,<br>            num_layers=sent_num_layers,<br>            batch_first=<span class="hljs-literal">True</span>,<br>            bidirectional=<span class="hljs-literal">True</span><br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, sent_reps, sent_masks</span>):<br>        <span class="hljs-comment"># sent_reps:  b x doc_len x sent_rep_size</span><br>        <span class="hljs-comment"># sent_masks: b x doc_len</span><br><br>        sent_hiddens, _ = self.sent_lstm(sent_reps)  <span class="hljs-comment"># b x doc_len x hidden*2</span><br>        sent_hiddens = sent_hiddens * sent_masks.unsqueeze(<span class="hljs-number">2</span>)<br><br>        <span class="hljs-keyword">if</span> self.training:<br>            sent_hiddens = self.dropout(sent_hiddens)<br><br>        <span class="hljs-keyword">return</span> sent_hiddens<br></code></pre></div></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># build model</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Model</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, vocab</span>):<br>        <span class="hljs-built_in">super</span>(Model, self).__init__()<br>        self.sent_rep_size = word_hidden_size * <span class="hljs-number">2</span><br>        self.doc_rep_size = sent_hidden_size * <span class="hljs-number">2</span><br>        self.all_parameters = &#123;&#125;<br>        parameters = []<br>        self.word_encoder = WordLSTMEncoder(vocab)<br>        self.word_attention = Attention(self.sent_rep_size)<br>        parameters.extend(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> p: p.requires_grad, self.word_encoder.parameters())))<br>        parameters.extend(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> p: p.requires_grad, self.word_attention.parameters())))<br><br>        self.sent_encoder = SentEncoder(self.sent_rep_size)<br>        self.sent_attention = Attention(self.doc_rep_size)<br>        parameters.extend(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> p: p.requires_grad, self.sent_encoder.parameters())))<br>        parameters.extend(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> p: p.requires_grad, self.sent_attention.parameters())))<br><br>        self.out = nn.Linear(self.doc_rep_size, vocab.label_size, bias=<span class="hljs-literal">True</span>)<br>        parameters.extend(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> p: p.requires_grad, self.out.parameters())))<br><br>        <span class="hljs-keyword">if</span> use_cuda:<br>            self.to(device)<br><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(parameters) &gt; <span class="hljs-number">0</span>:<br>            self.all_parameters[<span class="hljs-string">&quot;basic_parameters&quot;</span>] = parameters<br><br>        logging.info(<span class="hljs-string">&#x27;Build model with lstm word encoder, lstm sent encoder.&#x27;</span>)<br><br>        para_num = <span class="hljs-built_in">sum</span>([np.prod(<span class="hljs-built_in">list</span>(p.size())) <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> self.parameters()])<br>        logging.info(<span class="hljs-string">&#x27;Model param num: %.2f M.&#x27;</span> % (para_num / <span class="hljs-number">1e6</span>))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, batch_inputs</span>):<br>        <span class="hljs-comment"># batch_inputs(batch_inputs1, batch_inputs2): b x doc_len x sent_len</span><br>        <span class="hljs-comment"># batch_masks : b x doc_len x sent_len</span><br>        batch_inputs1, batch_inputs2, batch_masks = batch_inputs<br>        batch_size, max_doc_len, max_sent_len = batch_inputs1.shape[<span class="hljs-number">0</span>], batch_inputs1.shape[<span class="hljs-number">1</span>], batch_inputs1.shape[<span class="hljs-number">2</span>]<br>        batch_inputs1 = batch_inputs1.view(batch_size * max_doc_len, max_sent_len)  <span class="hljs-comment"># sen_num x sent_len</span><br>        batch_inputs2 = batch_inputs2.view(batch_size * max_doc_len, max_sent_len)  <span class="hljs-comment"># sen_num x sent_len</span><br>        batch_masks = batch_masks.view(batch_size * max_doc_len, max_sent_len)  <span class="hljs-comment"># sen_num x sent_len</span><br><br>        batch_hiddens = self.word_encoder(batch_inputs1, batch_inputs2,<br>                                          batch_masks)  <span class="hljs-comment"># sen_num x sent_len x sent_rep_size</span><br>        sent_reps, atten_scores = self.word_attention(batch_hiddens, batch_masks)  <span class="hljs-comment"># sen_num x sent_rep_size</span><br><br>        sent_reps = sent_reps.view(batch_size, max_doc_len, self.sent_rep_size)  <span class="hljs-comment"># b x doc_len x sent_rep_size</span><br>        batch_masks = batch_masks.view(batch_size, max_doc_len, max_sent_len)  <span class="hljs-comment"># b x doc_len x max_sent_len</span><br>        sent_masks = batch_masks.<span class="hljs-built_in">bool</span>().<span class="hljs-built_in">any</span>(<span class="hljs-number">2</span>).<span class="hljs-built_in">float</span>()  <span class="hljs-comment"># b x doc_len</span><br><br>        sent_hiddens = self.sent_encoder(sent_reps, sent_masks)  <span class="hljs-comment"># b x doc_len x doc_rep_size</span><br>        doc_reps, atten_scores = self.sent_attention(sent_hiddens, sent_masks)  <span class="hljs-comment"># b x doc_rep_size</span><br><br>        batch_outputs = self.out(doc_reps)  <span class="hljs-comment"># b x num_labels</span><br><br>        <span class="hljs-keyword">return</span> batch_outputs<br><br><br>model = Model(vocab)<br></code></pre></div></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># build optimizer</span><br>learning_rate = <span class="hljs-number">2e-4</span><br>decay = <span class="hljs-number">.75</span><br>decay_step = <span class="hljs-number">1000</span><br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Optimizer</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, model_parameters</span>):<br>        self.all_params = []<br>        self.optims = []<br>        self.schedulers = []<br><br>        <span class="hljs-keyword">for</span> name, parameters <span class="hljs-keyword">in</span> model_parameters.items():<br>            <span class="hljs-keyword">if</span> name.startswith(<span class="hljs-string">&quot;basic&quot;</span>):<br>                optim = torch.optim.Adam(parameters, lr=learning_rate)<br>                self.optims.append(optim)<br><br>                l = <span class="hljs-keyword">lambda</span> step: decay ** (step // decay_step)<br>                scheduler = torch.optim.lr_scheduler.LambdaLR(optim, lr_lambda=l)<br>                self.schedulers.append(scheduler)<br>                self.all_params.extend(parameters)<br><br>            <span class="hljs-keyword">else</span>:<br>                Exception(<span class="hljs-string">&quot;no nameed parameters.&quot;</span>)<br><br>        self.num = <span class="hljs-built_in">len</span>(self.optims)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">step</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">for</span> optim, scheduler <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(self.optims, self.schedulers):<br>            optim.step()<br>            scheduler.step()<br>            optim.zero_grad()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">zero_grad</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">for</span> optim <span class="hljs-keyword">in</span> self.optims:<br>            optim.zero_grad()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_lr</span>(<span class="hljs-params">self</span>):<br>        lrs = <span class="hljs-built_in">tuple</span>(<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x: x.get_lr()[-<span class="hljs-number">1</span>], self.schedulers))<br>        lr = <span class="hljs-string">&#x27; %.5f&#x27;</span> * self.num<br>        res = lr % lrs<br>        <span class="hljs-keyword">return</span> res<br></code></pre></div></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># build dataset</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">sentence_split</span>(<span class="hljs-params">text, vocab, max_sent_len=<span class="hljs-number">256</span>, max_segment=<span class="hljs-number">16</span></span>):<br>    words = text.strip().split()<br>    document_len = <span class="hljs-built_in">len</span>(words)<br><br>    index = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, document_len, max_sent_len))<br>    index.append(document_len)<br><br>    segments = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(index) - <span class="hljs-number">1</span>):<br>        segment = words[index[i]: index[i + <span class="hljs-number">1</span>]]<br>        <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(segment) &gt; <span class="hljs-number">0</span><br>        segment = [word <span class="hljs-keyword">if</span> word <span class="hljs-keyword">in</span> vocab._id2word <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;&lt;UNK&gt;&#x27;</span> <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> segment]<br>        segments.append([<span class="hljs-built_in">len</span>(segment), segment])<br><br>    <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(segments) &gt; <span class="hljs-number">0</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(segments) &gt; max_segment:<br>        segment_ = <span class="hljs-built_in">int</span>(max_segment / <span class="hljs-number">2</span>)<br>        <span class="hljs-keyword">return</span> segments[:segment_] + segments[-segment_:]<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> segments<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_examples</span>(<span class="hljs-params">data, vocab, max_sent_len=<span class="hljs-number">256</span>, max_segment=<span class="hljs-number">8</span></span>):<br>    label2id = vocab.label2id<br>    examples = []<br><br>    <span class="hljs-keyword">for</span> text, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(data[<span class="hljs-string">&#x27;text&#x27;</span>], data[<span class="hljs-string">&#x27;label&#x27;</span>]):<br>        <span class="hljs-comment"># label</span><br>        <span class="hljs-built_in">id</span> = label2id(label)<br><br>        <span class="hljs-comment"># words</span><br>        sents_words = sentence_split(text, vocab, max_sent_len, max_segment)<br>        doc = []<br>        <span class="hljs-keyword">for</span> sent_len, sent_words <span class="hljs-keyword">in</span> sents_words:<br>            word_ids = vocab.word2id(sent_words)<br>            extword_ids = vocab.extword2id(sent_words)<br>            doc.append([sent_len, word_ids, extword_ids])<br>        examples.append([<span class="hljs-built_in">id</span>, <span class="hljs-built_in">len</span>(doc), doc])<br><br>    logging.info(<span class="hljs-string">&#x27;Total %d docs.&#x27;</span> % <span class="hljs-built_in">len</span>(examples))<br>    <span class="hljs-keyword">return</span> examples<br></code></pre></div></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># build loader</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">batch_slice</span>(<span class="hljs-params">data, batch_size</span>):<br>    batch_num = <span class="hljs-built_in">int</span>(np.ceil(<span class="hljs-built_in">len</span>(data) / <span class="hljs-built_in">float</span>(batch_size)))<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(batch_num):<br>        cur_batch_size = batch_size <span class="hljs-keyword">if</span> i &lt; batch_num - <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-built_in">len</span>(data) - batch_size * i<br>        docs = [data[i * batch_size + b] <span class="hljs-keyword">for</span> b <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(cur_batch_size)]<br><br>        <span class="hljs-keyword">yield</span> docs<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">data_iter</span>(<span class="hljs-params">data, batch_size, shuffle=<span class="hljs-literal">True</span>, noise=<span class="hljs-number">1.0</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    randomly permute data, then sort by source length, and partition into batches</span><br><span class="hljs-string">    ensure that the length of  sentences in each batch</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    batched_data = []<br>    <span class="hljs-keyword">if</span> shuffle:<br>        np.random.shuffle(data)<br><br>    lengths = [example[<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> example <span class="hljs-keyword">in</span> data]<br>    noisy_lengths = [- (l + np.random.uniform(- noise, noise)) <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> lengths]<br>    sorted_indices = np.argsort(noisy_lengths).tolist()<br>    sorted_data = [data[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> sorted_indices]<br><br>    batched_data.extend(<span class="hljs-built_in">list</span>(batch_slice(sorted_data, batch_size)))<br><br>    <span class="hljs-keyword">if</span> shuffle:<br>        np.random.shuffle(batched_data)<br><br>    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> batched_data:<br>        <span class="hljs-keyword">yield</span> batch<br></code></pre></div></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># some function</span><br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> f1_score, precision_score, recall_score<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_score</span>(<span class="hljs-params">y_ture, y_pred</span>):<br>    y_ture = np.array(y_ture)<br>    y_pred = np.array(y_pred)<br>    f1 = f1_score(y_ture, y_pred, average=<span class="hljs-string">&#x27;macro&#x27;</span>) * <span class="hljs-number">100</span><br>    p = precision_score(y_ture, y_pred, average=<span class="hljs-string">&#x27;macro&#x27;</span>) * <span class="hljs-number">100</span><br>    r = recall_score(y_ture, y_pred, average=<span class="hljs-string">&#x27;macro&#x27;</span>) * <span class="hljs-number">100</span><br><br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">str</span>((reformat(p, <span class="hljs-number">2</span>), reformat(r, <span class="hljs-number">2</span>), reformat(f1, <span class="hljs-number">2</span>))), reformat(f1, <span class="hljs-number">2</span>)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">reformat</span>(<span class="hljs-params">num, n</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">float</span>(<span class="hljs-built_in">format</span>(num, <span class="hljs-string">&#x27;0.&#x27;</span> + <span class="hljs-built_in">str</span>(n) + <span class="hljs-string">&#x27;f&#x27;</span>))<br></code></pre></div></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># build trainer</span><br><br><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> classification_report<br><br>clip = <span class="hljs-number">5.0</span><br>epochs = <span class="hljs-number">1</span><br>early_stops = <span class="hljs-number">3</span><br>log_interval = <span class="hljs-number">200</span><br><br>test_batch_size = <span class="hljs-number">16</span><br>train_batch_size = <span class="hljs-number">16</span><br><br>save_model = <span class="hljs-string">&#x27;../save/rnn.bin&#x27;</span><br>save_test = <span class="hljs-string">&#x27;../save/rnn.csv&#x27;</span><br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Trainer</span>():<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, model, vocab</span>):<br>        self.model = model<br>        self.report = <span class="hljs-literal">True</span><br><br>        self.train_data = get_examples(train_data, vocab)<br>        self.batch_num = <span class="hljs-built_in">int</span>(np.ceil(<span class="hljs-built_in">len</span>(self.train_data) / <span class="hljs-built_in">float</span>(train_batch_size)))<br>        self.dev_data = get_examples(dev_data, vocab)<br>        self.test_data = get_examples(test_data, vocab)<br><br>        <span class="hljs-comment"># criterion</span><br>        self.criterion = nn.CrossEntropyLoss()<br><br>        <span class="hljs-comment"># label name</span><br>        self.target_names = vocab.target_names<br><br>        <span class="hljs-comment"># optimizer</span><br>        self.optimizer = Optimizer(model.all_parameters)<br><br>        <span class="hljs-comment"># count</span><br>        self.step = <span class="hljs-number">0</span><br>        self.early_stop = -<span class="hljs-number">1</span><br>        self.best_train_f1, self.best_dev_f1 = <span class="hljs-number">0</span>, <span class="hljs-number">0</span><br>        self.last_epoch = epochs<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">self</span>):<br>        logging.info(<span class="hljs-string">&#x27;Start training...&#x27;</span>)<br>        <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, epochs + <span class="hljs-number">1</span>):<br>            train_f1 = self._train(epoch)<br><br>            dev_f1 = self._<span class="hljs-built_in">eval</span>(epoch)<br><br>            <span class="hljs-keyword">if</span> self.best_dev_f1 &lt;= dev_f1:<br>                logging.info(<br>                    <span class="hljs-string">&quot;Exceed history dev = %.2f, current dev = %.2f&quot;</span> % (self.best_dev_f1, dev_f1))<br>                torch.save(self.model.state_dict(), save_model)<br><br>                self.best_train_f1 = train_f1<br>                self.best_dev_f1 = dev_f1<br>                self.early_stop = <span class="hljs-number">0</span><br>            <span class="hljs-keyword">else</span>:<br>                self.early_stop += <span class="hljs-number">1</span><br>                <span class="hljs-keyword">if</span> self.early_stop == early_stops:<br>                    logging.info(<br>                        <span class="hljs-string">&quot;Eearly stop in epoch %d, best train: %.2f, dev: %.2f&quot;</span> % (<br>                            epoch - early_stops, self.best_train_f1, self.best_dev_f1))<br>                    self.last_epoch = epoch<br>                    <span class="hljs-keyword">break</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>(<span class="hljs-params">self</span>):<br>        self.model.load_state_dict(torch.load(save_model))<br>        self._<span class="hljs-built_in">eval</span>(self.last_epoch + <span class="hljs-number">1</span>, test=<span class="hljs-literal">True</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_train</span>(<span class="hljs-params">self, epoch</span>):<br>        self.optimizer.zero_grad()<br>        self.model.train()<br><br>        start_time = time.time()<br>        epoch_start_time = time.time()<br>        overall_losses = <span class="hljs-number">0</span><br>        losses = <span class="hljs-number">0</span><br>        batch_idx = <span class="hljs-number">1</span><br>        y_pred = []<br>        y_true = []<br>        <span class="hljs-keyword">for</span> batch_data <span class="hljs-keyword">in</span> data_iter(self.train_data, train_batch_size, shuffle=<span class="hljs-literal">True</span>):<br>            torch.cuda.empty_cache()<br>            batch_inputs, batch_labels = self.batch2tensor(batch_data)<br>            batch_outputs = self.model(batch_inputs)<br>            loss = self.criterion(batch_outputs, batch_labels)<br>            loss.backward()<br><br>            loss_value = loss.detach().cpu().item()<br>            losses += loss_value<br>            overall_losses += loss_value<br><br>            y_pred.extend(torch.<span class="hljs-built_in">max</span>(batch_outputs, dim=<span class="hljs-number">1</span>)[<span class="hljs-number">1</span>].cpu().numpy().tolist())<br>            y_true.extend(batch_labels.cpu().numpy().tolist())<br><br>            nn.utils.clip_grad_norm_(self.optimizer.all_params, max_norm=clip)<br>            <span class="hljs-keyword">for</span> optimizer, scheduler <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(self.optimizer.optims, self.optimizer.schedulers):<br>                optimizer.step()<br>                scheduler.step()<br>            self.optimizer.zero_grad()<br><br>            self.step += <span class="hljs-number">1</span><br><br>            <span class="hljs-keyword">if</span> batch_idx % log_interval == <span class="hljs-number">0</span>:<br>                elapsed = time.time() - start_time<br><br>                lrs = self.optimizer.get_lr()<br>                logging.info(<br>                    <span class="hljs-string">&#x27;| epoch &#123;:3d&#125; | step &#123;:3d&#125; | batch &#123;:3d&#125;/&#123;:3d&#125; | lr&#123;&#125; | loss &#123;:.4f&#125; | s/batch &#123;:.2f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(<br>                        epoch, self.step, batch_idx, self.batch_num, lrs,<br>                        losses / log_interval,<br>                        elapsed / log_interval))<br><br>                losses = <span class="hljs-number">0</span><br>                start_time = time.time()<br><br>            batch_idx += <span class="hljs-number">1</span><br><br>        overall_losses /= self.batch_num<br>        during_time = time.time() - epoch_start_time<br><br>        <span class="hljs-comment"># reformat</span><br>        overall_losses = reformat(overall_losses, <span class="hljs-number">4</span>)<br>        score, f1 = get_score(y_true, y_pred)<br><br>        logging.info(<br>            <span class="hljs-string">&#x27;| epoch &#123;:3d&#125; | score &#123;&#125; | f1 &#123;&#125; | loss &#123;:.4f&#125; | time &#123;:.2f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(epoch, score, f1,<br>                                                                                  overall_losses,<br>                                                                                  during_time))<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">set</span>(y_true) == <span class="hljs-built_in">set</span>(y_pred) <span class="hljs-keyword">and</span> self.report:<br>            report = classification_report(y_true, y_pred, digits=<span class="hljs-number">4</span>, target_names=self.target_names)<br>            logging.info(<span class="hljs-string">&#x27;\n&#x27;</span> + report)<br><br>        <span class="hljs-keyword">return</span> f1<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_eval</span>(<span class="hljs-params">self, epoch, test=<span class="hljs-literal">False</span></span>):<br>        self.model.<span class="hljs-built_in">eval</span>()<br>        start_time = time.time()<br><br>        y_pred = []<br>        y_true = []<br>        <span class="hljs-keyword">with</span> torch.no_grad():<br>            <span class="hljs-keyword">for</span> batch_data <span class="hljs-keyword">in</span> data_iter(self.dev_data, test_batch_size, shuffle=<span class="hljs-literal">False</span>):<br>                torch.cuda.empty_cache()<br>                batch_inputs, batch_labels = self.batch2tensor(batch_data)<br>                batch_outputs = self.model(batch_inputs)<br>                y_pred.extend(torch.<span class="hljs-built_in">max</span>(batch_outputs, dim=<span class="hljs-number">1</span>)[<span class="hljs-number">1</span>].cpu().numpy().tolist())<br>                y_true.extend(batch_labels.cpu().numpy().tolist())<br><br>            score, f1 = get_score(y_true, y_pred)<br><br>            during_time = time.time() - start_time<br>            <br>            <span class="hljs-keyword">if</span> test:<br>                df = pd.DataFrame(&#123;<span class="hljs-string">&#x27;label&#x27;</span>: y_pred&#125;)<br>                df.to_csv(save_test, index=<span class="hljs-literal">False</span>, sep=<span class="hljs-string">&#x27;,&#x27;</span>)<br>            <span class="hljs-keyword">else</span>:<br>                logging.info(<br>                    <span class="hljs-string">&#x27;| epoch &#123;:3d&#125; | dev | score &#123;&#125; | f1 &#123;&#125; | time &#123;:.2f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(epoch, score, f1,<br>                                                                              during_time))<br>                <span class="hljs-keyword">if</span> <span class="hljs-built_in">set</span>(y_true) == <span class="hljs-built_in">set</span>(y_pred) <span class="hljs-keyword">and</span> self.report:<br>                    report = classification_report(y_true, y_pred, digits=<span class="hljs-number">4</span>, target_names=self.target_names)<br>                    logging.info(<span class="hljs-string">&#x27;\n&#x27;</span> + report)<br><br>        <span class="hljs-keyword">return</span> f1<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">batch2tensor</span>(<span class="hljs-params">self, batch_data</span>):<br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">            [[label, doc_len, [[sent_len, [sent_id0, ...], [sent_id1, ...]], ...]]</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        batch_size = <span class="hljs-built_in">len</span>(batch_data)<br>        doc_labels = []<br>        doc_lens = []<br>        doc_max_sent_len = []<br>        <span class="hljs-keyword">for</span> doc_data <span class="hljs-keyword">in</span> batch_data:<br>            doc_labels.append(doc_data[<span class="hljs-number">0</span>])<br>            doc_lens.append(doc_data[<span class="hljs-number">1</span>])<br>            sent_lens = [sent_data[<span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> sent_data <span class="hljs-keyword">in</span> doc_data[<span class="hljs-number">2</span>]]<br>            max_sent_len = <span class="hljs-built_in">max</span>(sent_lens)<br>            doc_max_sent_len.append(max_sent_len)<br><br>        max_doc_len = <span class="hljs-built_in">max</span>(doc_lens)<br>        max_sent_len = <span class="hljs-built_in">max</span>(doc_max_sent_len)<br><br>        batch_inputs1 = torch.zeros((batch_size, max_doc_len, max_sent_len), dtype=torch.int64)<br>        batch_inputs2 = torch.zeros((batch_size, max_doc_len, max_sent_len), dtype=torch.int64)<br>        batch_masks = torch.zeros((batch_size, max_doc_len, max_sent_len), dtype=torch.float32)<br>        batch_labels = torch.LongTensor(doc_labels)<br><br>        <span class="hljs-keyword">for</span> b <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(batch_size):<br>            <span class="hljs-keyword">for</span> sent_idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(doc_lens[b]):<br>                sent_data = batch_data[b][<span class="hljs-number">2</span>][sent_idx]<br>                <span class="hljs-keyword">for</span> word_idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(sent_data[<span class="hljs-number">0</span>]):<br>                    batch_inputs1[b, sent_idx, word_idx] = sent_data[<span class="hljs-number">1</span>][word_idx]<br>                    batch_inputs2[b, sent_idx, word_idx] = sent_data[<span class="hljs-number">2</span>][word_idx]<br>                    batch_masks[b, sent_idx, word_idx] = <span class="hljs-number">1</span><br><br>        <span class="hljs-keyword">if</span> use_cuda:<br>            batch_inputs1 = batch_inputs1.to(device)<br>            batch_inputs2 = batch_inputs2.to(device)<br>            batch_masks = batch_masks.to(device)<br>            batch_labels = batch_labels.to(device)<br><br>        <span class="hljs-keyword">return</span> (batch_inputs1, batch_inputs2, batch_masks), batch_labels<br></code></pre></div></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># train</span><br>trainer = Trainer(model, vocab)<br>trainer.train()<br></code></pre></div></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># test</span><br>trainer.test()<br></code></pre></div></td></tr></table></figure><h1 id="-bert">-BERT</h1><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br><span class="line">445</span><br><span class="line">446</span><br><span class="line">447</span><br><span class="line">448</span><br><span class="line">449</span><br><span class="line">450</span><br><span class="line">451</span><br><span class="line">452</span><br><span class="line">453</span><br><span class="line">454</span><br><span class="line">455</span><br><span class="line">456</span><br><span class="line">457</span><br><span class="line">458</span><br><span class="line">459</span><br><span class="line">460</span><br><span class="line">461</span><br><span class="line">462</span><br><span class="line">463</span><br><span class="line">464</span><br><span class="line">465</span><br><span class="line">466</span><br><span class="line">467</span><br><span class="line">468</span><br><span class="line">469</span><br><span class="line">470</span><br><span class="line">471</span><br><span class="line">472</span><br><span class="line">473</span><br><span class="line">474</span><br><span class="line">475</span><br><span class="line">476</span><br><span class="line">477</span><br><span class="line">478</span><br><span class="line">479</span><br><span class="line">480</span><br><span class="line">481</span><br><span class="line">482</span><br><span class="line">483</span><br><span class="line">484</span><br><span class="line">485</span><br><span class="line">486</span><br><span class="line">487</span><br><span class="line">488</span><br><span class="line">489</span><br><span class="line">490</span><br><span class="line">491</span><br><span class="line">492</span><br><span class="line">493</span><br><span class="line">494</span><br><span class="line">495</span><br><span class="line">496</span><br><span class="line">497</span><br><span class="line">498</span><br><span class="line">499</span><br><span class="line">500</span><br><span class="line">501</span><br><span class="line">502</span><br><span class="line">503</span><br><span class="line">504</span><br><span class="line">505</span><br><span class="line">506</span><br><span class="line">507</span><br><span class="line">508</span><br><span class="line">509</span><br><span class="line">510</span><br><span class="line">511</span><br><span class="line">512</span><br><span class="line">513</span><br><span class="line">514</span><br><span class="line">515</span><br><span class="line">516</span><br><span class="line">517</span><br><span class="line">518</span><br><span class="line">519</span><br><span class="line">520</span><br><span class="line">521</span><br><span class="line">522</span><br><span class="line">523</span><br><span class="line">524</span><br><span class="line">525</span><br><span class="line">526</span><br><span class="line">527</span><br><span class="line">528</span><br><span class="line">529</span><br><span class="line">530</span><br><span class="line">531</span><br><span class="line">532</span><br><span class="line">533</span><br><span class="line">534</span><br><span class="line">535</span><br><span class="line">536</span><br><span class="line">537</span><br><span class="line">538</span><br><span class="line">539</span><br><span class="line">540</span><br><span class="line">541</span><br><span class="line">542</span><br><span class="line">543</span><br><span class="line">544</span><br><span class="line">545</span><br><span class="line">546</span><br><span class="line">547</span><br><span class="line">548</span><br><span class="line">549</span><br><span class="line">550</span><br><span class="line">551</span><br><span class="line">552</span><br><span class="line">553</span><br><span class="line">554</span><br><span class="line">555</span><br><span class="line">556</span><br><span class="line">557</span><br><span class="line">558</span><br><span class="line">559</span><br><span class="line">560</span><br><span class="line">561</span><br><span class="line">562</span><br><span class="line">563</span><br><span class="line">564</span><br><span class="line">565</span><br><span class="line">566</span><br><span class="line">567</span><br><span class="line">568</span><br><span class="line">569</span><br><span class="line">570</span><br><span class="line">571</span><br><span class="line">572</span><br><span class="line">573</span><br><span class="line">574</span><br><span class="line">575</span><br><span class="line">576</span><br><span class="line">577</span><br><span class="line">578</span><br><span class="line">579</span><br><span class="line">580</span><br><span class="line">581</span><br><span class="line">582</span><br><span class="line">583</span><br><span class="line">584</span><br><span class="line">585</span><br><span class="line">586</span><br><span class="line">587</span><br><span class="line">588</span><br><span class="line">589</span><br><span class="line">590</span><br><span class="line">591</span><br><span class="line">592</span><br><span class="line">593</span><br><span class="line">594</span><br><span class="line">595</span><br><span class="line">596</span><br><span class="line">597</span><br><span class="line">598</span><br><span class="line">599</span><br><span class="line">600</span><br><span class="line">601</span><br><span class="line">602</span><br><span class="line">603</span><br><span class="line">604</span><br><span class="line">605</span><br><span class="line">606</span><br><span class="line">607</span><br><span class="line">608</span><br><span class="line">609</span><br><span class="line">610</span><br><span class="line">611</span><br><span class="line">612</span><br><span class="line">613</span><br><span class="line">614</span><br><span class="line">615</span><br><span class="line">616</span><br><span class="line">617</span><br><span class="line">618</span><br><span class="line">619</span><br><span class="line">620</span><br><span class="line">621</span><br><span class="line">622</span><br><span class="line">623</span><br><span class="line">624</span><br><span class="line">625</span><br><span class="line">626</span><br><span class="line">627</span><br><span class="line">628</span><br><span class="line">629</span><br><span class="line">630</span><br><span class="line">631</span><br><span class="line">632</span><br><span class="line">633</span><br><span class="line">634</span><br><span class="line">635</span><br><span class="line">636</span><br><span class="line">637</span><br><span class="line">638</span><br><span class="line">639</span><br><span class="line">640</span><br><span class="line">641</span><br><span class="line">642</span><br><span class="line">643</span><br><span class="line">644</span><br><span class="line">645</span><br><span class="line">646</span><br><span class="line">647</span><br><span class="line">648</span><br><span class="line">649</span><br><span class="line">650</span><br><span class="line">651</span><br><span class="line">652</span><br><span class="line">653</span><br><span class="line">654</span><br><span class="line">655</span><br><span class="line">656</span><br><span class="line">657</span><br><span class="line">658</span><br><span class="line">659</span><br><span class="line">660</span><br><span class="line">661</span><br><span class="line">662</span><br><span class="line">663</span><br><span class="line">664</span><br><span class="line">665</span><br><span class="line">666</span><br><span class="line">667</span><br><span class="line">668</span><br><span class="line">669</span><br><span class="line">670</span><br><span class="line">671</span><br><span class="line">672</span><br><span class="line">673</span><br><span class="line">674</span><br><span class="line">675</span><br><span class="line">676</span><br><span class="line">677</span><br><span class="line">678</span><br><span class="line">679</span><br><span class="line">680</span><br><span class="line">681</span><br><span class="line">682</span><br><span class="line">683</span><br><span class="line">684</span><br><span class="line">685</span><br><span class="line">686</span><br><span class="line">687</span><br><span class="line">688</span><br><span class="line">689</span><br><span class="line">690</span><br><span class="line">691</span><br><span class="line">692</span><br><span class="line">693</span><br><span class="line">694</span><br><span class="line">695</span><br><span class="line">696</span><br><span class="line">697</span><br><span class="line">698</span><br><span class="line">699</span><br><span class="line">700</span><br><span class="line">701</span><br><span class="line">702</span><br><span class="line">703</span><br><span class="line">704</span><br><span class="line">705</span><br><span class="line">706</span><br><span class="line">707</span><br><span class="line">708</span><br><span class="line">709</span><br><span class="line">710</span><br><span class="line">711</span><br><span class="line">712</span><br><span class="line">713</span><br><span class="line">714</span><br><span class="line">715</span><br><span class="line">716</span><br><span class="line">717</span><br><span class="line">718</span><br><span class="line">719</span><br><span class="line">720</span><br><span class="line">721</span><br><span class="line">722</span><br><span class="line">723</span><br><span class="line">724</span><br><span class="line">725</span><br><span class="line">726</span><br><span class="line">727</span><br><span class="line">728</span><br><span class="line">729</span><br><span class="line">730</span><br><span class="line">731</span><br><span class="line">732</span><br><span class="line">733</span><br><span class="line">734</span><br><span class="line">735</span><br><span class="line">736</span><br><span class="line">737</span><br><span class="line">738</span><br><span class="line">739</span><br><span class="line">740</span><br><span class="line">741</span><br><span class="line">742</span><br><span class="line">743</span><br><span class="line">744</span><br><span class="line">745</span><br><span class="line">746</span><br><span class="line">747</span><br><span class="line">748</span><br><span class="line">749</span><br><span class="line">750</span><br><span class="line">751</span><br><span class="line">752</span><br><span class="line">753</span><br><span class="line">754</span><br><span class="line">755</span><br><span class="line">756</span><br><span class="line">757</span><br><span class="line">758</span><br><span class="line">759</span><br><span class="line">760</span><br><span class="line">761</span><br><span class="line">762</span><br><span class="line">763</span><br><span class="line">764</span><br><span class="line">765</span><br><span class="line">766</span><br><span class="line">767</span><br><span class="line">768</span><br><span class="line">769</span><br><span class="line">770</span><br><span class="line">771</span><br><span class="line">772</span><br><span class="line">773</span><br><span class="line">774</span><br><span class="line">775</span><br><span class="line">776</span><br><span class="line">777</span><br><span class="line">778</span><br><span class="line">779</span><br><span class="line">780</span><br><span class="line">781</span><br><span class="line">782</span><br><span class="line">783</span><br><span class="line">784</span><br><span class="line">785</span><br><span class="line">786</span><br><span class="line">787</span><br><span class="line">788</span><br><span class="line">789</span><br><span class="line">790</span><br><span class="line">791</span><br><span class="line">792</span><br><span class="line">793</span><br><span class="line">794</span><br><span class="line">795</span><br><span class="line">796</span><br><span class="line">797</span><br><span class="line">798</span><br><span class="line">799</span><br><span class="line">800</span><br><span class="line">801</span><br><span class="line">802</span><br><span class="line">803</span><br><span class="line">804</span><br><span class="line">805</span><br><span class="line">806</span><br><span class="line">807</span><br><span class="line">808</span><br><span class="line">809</span><br><span class="line">810</span><br><span class="line">811</span><br><span class="line">812</span><br><span class="line">813</span><br><span class="line">814</span><br><span class="line">815</span><br><span class="line">816</span><br><span class="line">817</span><br><span class="line">818</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">import</span> logging<br><span class="hljs-keyword">import</span> random<br><br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> torch<br><br>logging.basicConfig(level=logging.INFO, <span class="hljs-built_in">format</span>=<span class="hljs-string">&#x27;%(asctime)-15s %(levelname)s: %(message)s&#x27;</span>)<br><br><span class="hljs-comment"># set seed</span><br>seed = <span class="hljs-number">666</span><br>random.seed(seed)<br>np.random.seed(seed)<br>torch.cuda.manual_seed(seed)<br>torch.manual_seed(seed)<br><br><span class="hljs-comment"># set cuda</span><br>gpu = <span class="hljs-number">0</span><br>use_cuda = gpu &gt;= <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> torch.cuda.is_available()<br><span class="hljs-keyword">if</span> use_cuda:<br>    torch.cuda.set_device(gpu)<br>    device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span>, gpu)<br><span class="hljs-keyword">else</span>:<br>    device = torch.device(<span class="hljs-string">&quot;cpu&quot;</span>)<br>logging.info(<span class="hljs-string">&quot;Use cuda: %s, gpu id: %d.&quot;</span>, use_cuda, gpu)<br><br><span class="hljs-comment"># split data to 10 fold</span><br>fold_num = <span class="hljs-number">10</span><br>data_file = <span class="hljs-string">&#x27;../data/train_set.csv&#x27;</span><br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">all_data2fold</span>(<span class="hljs-params">fold_num, num=<span class="hljs-number">10000</span></span>):<br>    fold_data = []<br>    f = pd.read_csv(data_file, sep=<span class="hljs-string">&#x27;\t&#x27;</span>, encoding=<span class="hljs-string">&#x27;UTF-8&#x27;</span>)<br>    texts = f[<span class="hljs-string">&#x27;text&#x27;</span>].tolist()[:num]<br>    labels = f[<span class="hljs-string">&#x27;label&#x27;</span>].tolist()[:num]<br><br>    total = <span class="hljs-built_in">len</span>(labels)<br><br>    index = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(total))<br>    np.random.shuffle(index)<br><br>    all_texts = []<br>    all_labels = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> index:<br>        all_texts.append(texts[i])<br>        all_labels.append(labels[i])<br><br>    label2id = &#123;&#125;<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(total):<br>        label = <span class="hljs-built_in">str</span>(all_labels[i])<br>        <span class="hljs-keyword">if</span> label <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> label2id:<br>            label2id[label] = [i]<br>        <span class="hljs-keyword">else</span>:<br>            label2id[label].append(i)<br><br>    all_index = [[] <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(fold_num)]<br>    <span class="hljs-keyword">for</span> label, data <span class="hljs-keyword">in</span> label2id.items():<br>        <span class="hljs-comment"># print(label, len(data))</span><br>        batch_size = <span class="hljs-built_in">int</span>(<span class="hljs-built_in">len</span>(data) / fold_num)<br>        other = <span class="hljs-built_in">len</span>(data) - batch_size * fold_num<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(fold_num):<br>            cur_batch_size = batch_size + <span class="hljs-number">1</span> <span class="hljs-keyword">if</span> i &lt; other <span class="hljs-keyword">else</span> batch_size<br>            <span class="hljs-comment"># print(cur_batch_size)</span><br>            batch_data = [data[i * batch_size + b] <span class="hljs-keyword">for</span> b <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(cur_batch_size)]<br>            all_index[i].extend(batch_data)<br><br>    batch_size = <span class="hljs-built_in">int</span>(total / fold_num)<br>    other_texts = []<br>    other_labels = []<br>    other_num = <span class="hljs-number">0</span><br>    start = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> fold <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(fold_num):<br>        num = <span class="hljs-built_in">len</span>(all_index[fold])<br>        texts = [all_texts[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> all_index[fold]]<br>        labels = [all_labels[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> all_index[fold]]<br><br>        <span class="hljs-keyword">if</span> num &gt; batch_size:<br>            fold_texts = texts[:batch_size]<br>            other_texts.extend(texts[batch_size:])<br>            fold_labels = labels[:batch_size]<br>            other_labels.extend(labels[batch_size:])<br>            other_num += num - batch_size<br>        <span class="hljs-keyword">elif</span> num &lt; batch_size:<br>            end = start + batch_size - num<br>            fold_texts = texts + other_texts[start: end]<br>            fold_labels = labels + other_labels[start: end]<br>            start = end<br>        <span class="hljs-keyword">else</span>:<br>            fold_texts = texts<br>            fold_labels = labels<br><br>        <span class="hljs-keyword">assert</span> batch_size == <span class="hljs-built_in">len</span>(fold_labels)<br><br>        <span class="hljs-comment"># shuffle</span><br>        index = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(batch_size))<br>        np.random.shuffle(index)<br><br>        shuffle_fold_texts = []<br>        shuffle_fold_labels = []<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> index:<br>            shuffle_fold_texts.append(fold_texts[i])<br>            shuffle_fold_labels.append(fold_labels[i])<br><br>        data = &#123;<span class="hljs-string">&#x27;label&#x27;</span>: shuffle_fold_labels, <span class="hljs-string">&#x27;text&#x27;</span>: shuffle_fold_texts&#125;<br>        fold_data.append(data)<br><br>    logging.info(<span class="hljs-string">&quot;Fold lens %s&quot;</span>, <span class="hljs-built_in">str</span>([<span class="hljs-built_in">len</span>(data[<span class="hljs-string">&#x27;label&#x27;</span>]) <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> fold_data]))<br><br>    <span class="hljs-keyword">return</span> fold_data<br><br><br>fold_data = all_data2fold(<span class="hljs-number">10</span>)<br><br><span class="hljs-comment"># build train, dev, test data</span><br>fold_id = <span class="hljs-number">9</span><br><br><span class="hljs-comment"># dev</span><br>dev_data = fold_data[fold_id]<br><br><span class="hljs-comment"># train</span><br>train_texts = []<br>train_labels = []<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, fold_id):<br>    data = fold_data[i]<br>    train_texts.extend(data[<span class="hljs-string">&#x27;text&#x27;</span>])<br>    train_labels.extend(data[<span class="hljs-string">&#x27;label&#x27;</span>])<br><br>train_data = &#123;<span class="hljs-string">&#x27;label&#x27;</span>: train_labels, <span class="hljs-string">&#x27;text&#x27;</span>: train_texts&#125;<br><br><span class="hljs-comment"># test</span><br>test_data_file = <span class="hljs-string">&#x27;../data/test_a.csv&#x27;</span><br>f = pd.read_csv(test_data_file, sep=<span class="hljs-string">&#x27;\t&#x27;</span>, encoding=<span class="hljs-string">&#x27;UTF-8&#x27;</span>)<br>texts = f[<span class="hljs-string">&#x27;text&#x27;</span>].tolist()<br>test_data = &#123;<span class="hljs-string">&#x27;label&#x27;</span>: [<span class="hljs-number">0</span>] * <span class="hljs-built_in">len</span>(texts), <span class="hljs-string">&#x27;text&#x27;</span>: texts&#125;<br><br><span class="hljs-comment"># build vocab</span><br><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> Counter<br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BasicTokenizer<br><br><span class="hljs-comment"># </span><br>basic_tokenizer = BasicTokenizer()<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Vocab</span>():<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, train_data</span>):<br>        self.min_count = <span class="hljs-number">5</span><br>        self.pad = <span class="hljs-number">0</span><br>        self.unk = <span class="hljs-number">1</span><br>        self._id2word = [<span class="hljs-string">&#x27;[PAD]&#x27;</span>, <span class="hljs-string">&#x27;[UNK]&#x27;</span>]<br>        self._id2extword = [<span class="hljs-string">&#x27;[PAD]&#x27;</span>, <span class="hljs-string">&#x27;[UNK]&#x27;</span>]<br><br>        self._id2label = []<br>        self.target_names = []<br><br>        self.build_vocab(train_data)<br><br>        reverse = <span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(x, <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(x))))<br>        self._word2id = reverse(self._id2word)<br>        self._label2id = reverse(self._id2label)<br><br>        logging.info(<span class="hljs-string">&quot;Build vocab: words %d, labels %d.&quot;</span> % (self.word_size, self.label_size))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">build_vocab</span>(<span class="hljs-params">self, data</span>):<br>        self.word_counter = Counter()<br><br>        <span class="hljs-keyword">for</span> text <span class="hljs-keyword">in</span> data[<span class="hljs-string">&#x27;text&#x27;</span>]:<br>            words = text.split()<br>            <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> words:<br>                self.word_counter[word] += <span class="hljs-number">1</span><br><br>        <span class="hljs-keyword">for</span> word, count <span class="hljs-keyword">in</span> self.word_counter.most_common():<br>            <span class="hljs-keyword">if</span> count &gt;= self.min_count:<br>                self._id2word.append(word)<br><br>        label2name = &#123;<span class="hljs-number">0</span>: <span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-number">1</span>: <span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-number">2</span>: <span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-number">3</span>: <span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-number">4</span>: <span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-number">5</span>: <span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-number">6</span>: <span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-number">7</span>: <span class="hljs-string">&#x27;&#x27;</span>,<br>                      <span class="hljs-number">8</span>: <span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-number">9</span>: <span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-number">10</span>: <span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-number">11</span>: <span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-number">12</span>: <span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-number">13</span>: <span class="hljs-string">&#x27;&#x27;</span>&#125;<br><br>        self.label_counter = Counter(data[<span class="hljs-string">&#x27;label&#x27;</span>])<br><br>        <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(self.label_counter)):<br>            count = self.label_counter[label]<br>            self._id2label.append(label)<br>            self.target_names.append(label2name[label])<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">load_pretrained_embs</span>(<span class="hljs-params">self, embfile</span>):<br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(embfile, encoding=<span class="hljs-string">&#x27;utf-8&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>            lines = f.readlines()<br>            items = lines[<span class="hljs-number">0</span>].split()<br>            word_count, embedding_dim = <span class="hljs-built_in">int</span>(items[<span class="hljs-number">0</span>]), <span class="hljs-built_in">int</span>(items[<span class="hljs-number">1</span>])<br><br>        index = <span class="hljs-built_in">len</span>(self._id2extword)<br>        embeddings = np.zeros((word_count + index, embedding_dim))<br>        <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> lines[<span class="hljs-number">1</span>:]:<br>            values = line.split()<br>            self._id2extword.append(values[<span class="hljs-number">0</span>])<br>            vector = np.array(values[<span class="hljs-number">1</span>:], dtype=<span class="hljs-string">&#x27;float64&#x27;</span>)<br>            embeddings[self.unk] += vector<br>            embeddings[index] = vector<br>            index += <span class="hljs-number">1</span><br><br>        embeddings[self.unk] = embeddings[self.unk] / word_count<br>        embeddings = embeddings / np.std(embeddings)<br><br>        reverse = <span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(x, <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(x))))<br>        self._extword2id = reverse(self._id2extword)<br><br>        <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(<span class="hljs-built_in">set</span>(self._id2extword)) == <span class="hljs-built_in">len</span>(self._id2extword)<br><br>        <span class="hljs-keyword">return</span> embeddings<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">word2id</span>(<span class="hljs-params">self, xs</span>):<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(xs, <span class="hljs-built_in">list</span>):<br>            <span class="hljs-keyword">return</span> [self._word2id.get(x, self.unk) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> xs]<br>        <span class="hljs-keyword">return</span> self._word2id.get(xs, self.unk)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">extword2id</span>(<span class="hljs-params">self, xs</span>):<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(xs, <span class="hljs-built_in">list</span>):<br>            <span class="hljs-keyword">return</span> [self._extword2id.get(x, self.unk) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> xs]<br>        <span class="hljs-keyword">return</span> self._extword2id.get(xs, self.unk)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">label2id</span>(<span class="hljs-params">self, xs</span>):<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(xs, <span class="hljs-built_in">list</span>):<br>            <span class="hljs-keyword">return</span> [self._label2id.get(x, self.unk) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> xs]<br>        <span class="hljs-keyword">return</span> self._label2id.get(xs, self.unk)<br><br><span class="hljs-meta">    @property</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">word_size</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self._id2word)<br><br><span class="hljs-meta">    @property</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">extword_size</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self._id2extword)<br><br><span class="hljs-meta">    @property</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">label_size</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self._id2label)<br><br><br>vocab = Vocab(train_data)<br><br><span class="hljs-comment"># build module</span><br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Attention</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, hidden_size</span>):<br>        <span class="hljs-built_in">super</span>(Attention, self).__init__()<br>        self.weight = nn.Parameter(torch.Tensor(hidden_size, hidden_size))<br>        self.weight.data.normal_(mean=<span class="hljs-number">0.0</span>, std=<span class="hljs-number">0.05</span>)<br><br>        self.bias = nn.Parameter(torch.Tensor(hidden_size))<br>        b = np.zeros(hidden_size, dtype=np.float32)<br>        self.bias.data.copy_(torch.from_numpy(b))<br><br>        self.query = nn.Parameter(torch.Tensor(hidden_size))<br>        self.query.data.normal_(mean=<span class="hljs-number">0.0</span>, std=<span class="hljs-number">0.05</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, batch_hidden, batch_masks</span>):<br>        <span class="hljs-comment"># batch_hidden: b x len x hidden_size (2 * hidden_size of lstm)</span><br>        <span class="hljs-comment"># batch_masks:  b x len</span><br><br>        <span class="hljs-comment"># linear</span><br>        key = torch.matmul(batch_hidden, self.weight) + self.bias  <span class="hljs-comment"># b x len x hidden</span><br><br>        <span class="hljs-comment"># compute attention</span><br>        outputs = torch.matmul(key, self.query)  <span class="hljs-comment"># b x len</span><br><br>        masked_outputs = outputs.masked_fill((<span class="hljs-number">1</span> - batch_masks).<span class="hljs-built_in">bool</span>(), <span class="hljs-built_in">float</span>(-<span class="hljs-number">1e32</span>))<br><br>        attn_scores = F.softmax(masked_outputs, dim=<span class="hljs-number">1</span>)  <span class="hljs-comment"># b x len</span><br><br>        <span class="hljs-comment"># -1e32 1/len, -infnan, 0</span><br>        masked_attn_scores = attn_scores.masked_fill((<span class="hljs-number">1</span> - batch_masks).<span class="hljs-built_in">bool</span>(), <span class="hljs-number">0.0</span>)<br><br>        <span class="hljs-comment"># sum weighted sources</span><br>        batch_outputs = torch.bmm(masked_attn_scores.unsqueeze(<span class="hljs-number">1</span>), key).squeeze(<span class="hljs-number">1</span>)  <span class="hljs-comment"># b x hidden</span><br><br>        <span class="hljs-keyword">return</span> batch_outputs, attn_scores<br><br><br><span class="hljs-comment"># build word encoder</span><br>bert_path = <span class="hljs-string">&#x27;./emb/bert-mini/&#x27;</span><br>dropout = <span class="hljs-number">0.15</span><br><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertModel<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">WordBertEncoder</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(WordBertEncoder, self).__init__()<br>        self.dropout = nn.Dropout(dropout)<br><br>        self.tokenizer = WhitespaceTokenizer()<br>        self.bert = BertModel.from_pretrained(bert_path)<br><br>        self.pooled = <span class="hljs-literal">False</span><br>        logging.info(<span class="hljs-string">&#x27;Build Bert encoder with pooled &#123;&#125;.&#x27;</span>.<span class="hljs-built_in">format</span>(self.pooled))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">encode</span>(<span class="hljs-params">self, tokens</span>):<br>        tokens = self.tokenizer.tokenize(tokens)<br>        <span class="hljs-keyword">return</span> tokens<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_bert_parameters</span>(<span class="hljs-params">self</span>):<br>        no_decay = [<span class="hljs-string">&#x27;bias&#x27;</span>, <span class="hljs-string">&#x27;LayerNorm.weight&#x27;</span>]<br>        optimizer_parameters = [<br>            &#123;<span class="hljs-string">&#x27;params&#x27;</span>: [p <span class="hljs-keyword">for</span> n, p <span class="hljs-keyword">in</span> self.bert.named_parameters() <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">any</span>(nd <span class="hljs-keyword">in</span> n <span class="hljs-keyword">for</span> nd <span class="hljs-keyword">in</span> no_decay)],<br>             <span class="hljs-string">&#x27;weight_decay&#x27;</span>: <span class="hljs-number">0.01</span>&#125;,<br>            &#123;<span class="hljs-string">&#x27;params&#x27;</span>: [p <span class="hljs-keyword">for</span> n, p <span class="hljs-keyword">in</span> self.bert.named_parameters() <span class="hljs-keyword">if</span> <span class="hljs-built_in">any</span>(nd <span class="hljs-keyword">in</span> n <span class="hljs-keyword">for</span> nd <span class="hljs-keyword">in</span> no_decay)],<br>             <span class="hljs-string">&#x27;weight_decay&#x27;</span>: <span class="hljs-number">0.0</span>&#125;<br>        ]<br>        <span class="hljs-keyword">return</span> optimizer_parameters<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, input_ids, token_type_ids</span>):<br>        <span class="hljs-comment"># input_ids: sen_num x bert_len</span><br>        <span class="hljs-comment"># token_type_ids: sen_num  x bert_len</span><br><br>        <span class="hljs-comment"># sen_num x bert_len x 256, sen_num x 256</span><br>        sequence_output, pooled_output = self.bert(input_ids=input_ids, token_type_ids=token_type_ids)<br><br>        <span class="hljs-keyword">if</span> self.pooled:<br>            reps = pooled_output<br>        <span class="hljs-keyword">else</span>:<br>            reps = sequence_output[:, <span class="hljs-number">0</span>, :]  <span class="hljs-comment"># sen_num x 256</span><br><br>        <span class="hljs-keyword">if</span> self.training:<br>            reps = self.dropout(reps)<br><br>        <span class="hljs-keyword">return</span> reps<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">WhitespaceTokenizer</span>():<br>    <span class="hljs-string">&quot;&quot;&quot;WhitespaceTokenizer with vocab.&quot;&quot;&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        vocab_file = bert_path + <span class="hljs-string">&#x27;vocab.txt&#x27;</span><br>        self._token2id = self.load_vocab(vocab_file)<br>        self._id2token = &#123;v: k <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> self._token2id.items()&#125;<br>        self.max_len = <span class="hljs-number">256</span><br>        self.unk = <span class="hljs-number">1</span><br><br>        logging.info(<span class="hljs-string">&quot;Build Bert vocab with size %d.&quot;</span> % (self.vocab_size))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">load_vocab</span>(<span class="hljs-params">self, vocab_file</span>):<br>        f = <span class="hljs-built_in">open</span>(vocab_file, <span class="hljs-string">&#x27;r&#x27;</span>)<br>        lines = f.readlines()<br>        lines = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x: x.strip(), lines))<br>        vocab = <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(lines, <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(lines))))<br>        <span class="hljs-keyword">return</span> vocab<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize</span>(<span class="hljs-params">self, tokens</span>):<br>        <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(tokens) &lt;= self.max_len - <span class="hljs-number">2</span><br>        tokens = [<span class="hljs-string">&quot;[CLS]&quot;</span>] + tokens + [<span class="hljs-string">&quot;[SEP]&quot;</span>]<br>        output_tokens = self.token2id(tokens)<br>        <span class="hljs-keyword">return</span> output_tokens<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">token2id</span>(<span class="hljs-params">self, xs</span>):<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(xs, <span class="hljs-built_in">list</span>):<br>            <span class="hljs-keyword">return</span> [self._token2id.get(x, self.unk) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> xs]<br>        <span class="hljs-keyword">return</span> self._token2id.get(xs, self.unk)<br><br><span class="hljs-meta">    @property</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">vocab_size</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self._id2token)<br><br><br><span class="hljs-comment"># build sent encoder</span><br>sent_hidden_size = <span class="hljs-number">256</span><br>sent_num_layers = <span class="hljs-number">2</span><br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">SentEncoder</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, sent_rep_size</span>):<br>        <span class="hljs-built_in">super</span>(SentEncoder, self).__init__()<br>        self.dropout = nn.Dropout(dropout)<br><br>        self.sent_lstm = nn.LSTM(<br>            input_size=sent_rep_size,<br>            hidden_size=sent_hidden_size,<br>            num_layers=sent_num_layers,<br>            batch_first=<span class="hljs-literal">True</span>,<br>            bidirectional=<span class="hljs-literal">True</span><br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, sent_reps, sent_masks</span>):<br>        <span class="hljs-comment"># sent_reps:  b x doc_len x sent_rep_size</span><br>        <span class="hljs-comment"># sent_masks: b x doc_len</span><br><br>        sent_hiddens, _ = self.sent_lstm(sent_reps)  <span class="hljs-comment"># b x doc_len x hidden*2</span><br>        sent_hiddens = sent_hiddens * sent_masks.unsqueeze(<span class="hljs-number">2</span>)<br><br>        <span class="hljs-keyword">if</span> self.training:<br>            sent_hiddens = self.dropout(sent_hiddens)<br><br>        <span class="hljs-keyword">return</span> sent_hiddens<br><br><br><span class="hljs-comment"># build model</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Model</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, vocab</span>):<br>        <span class="hljs-built_in">super</span>(Model, self).__init__()<br>        self.sent_rep_size = <span class="hljs-number">256</span><br>        self.doc_rep_size = sent_hidden_size * <span class="hljs-number">2</span><br>        self.all_parameters = &#123;&#125;<br>        parameters = []<br>        self.word_encoder = WordBertEncoder()<br>        bert_parameters = self.word_encoder.get_bert_parameters()<br><br>        self.sent_encoder = SentEncoder(self.sent_rep_size)<br>        self.sent_attention = Attention(self.doc_rep_size)<br>        parameters.extend(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> p: p.requires_grad, self.sent_encoder.parameters())))<br>        parameters.extend(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> p: p.requires_grad, self.sent_attention.parameters())))<br><br>        self.out = nn.Linear(self.doc_rep_size, vocab.label_size, bias=<span class="hljs-literal">True</span>)<br>        parameters.extend(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> p: p.requires_grad, self.out.parameters())))<br><br>        <span class="hljs-keyword">if</span> use_cuda:<br>            self.to(device)<br><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(parameters) &gt; <span class="hljs-number">0</span>:<br>            self.all_parameters[<span class="hljs-string">&quot;basic_parameters&quot;</span>] = parameters<br>        self.all_parameters[<span class="hljs-string">&quot;bert_parameters&quot;</span>] = bert_parameters<br><br>        logging.info(<span class="hljs-string">&#x27;Build model with bert word encoder, lstm sent encoder.&#x27;</span>)<br><br>        para_num = <span class="hljs-built_in">sum</span>([np.prod(<span class="hljs-built_in">list</span>(p.size())) <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> self.parameters()])<br>        logging.info(<span class="hljs-string">&#x27;Model param num: %.2f M.&#x27;</span> % (para_num / <span class="hljs-number">1e6</span>))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, batch_inputs</span>):<br>        <span class="hljs-comment"># batch_inputs(batch_inputs1, batch_inputs2): b x doc_len x sent_len</span><br>        <span class="hljs-comment"># batch_masks : b x doc_len x sent_len</span><br>        batch_inputs1, batch_inputs2, batch_masks = batch_inputs<br>        batch_size, max_doc_len, max_sent_len = batch_inputs1.shape[<span class="hljs-number">0</span>], batch_inputs1.shape[<span class="hljs-number">1</span>], batch_inputs1.shape[<span class="hljs-number">2</span>]<br>        batch_inputs1 = batch_inputs1.view(batch_size * max_doc_len, max_sent_len)  <span class="hljs-comment"># sen_num x sent_len</span><br>        batch_inputs2 = batch_inputs2.view(batch_size * max_doc_len, max_sent_len)  <span class="hljs-comment"># sen_num x sent_len</span><br>        batch_masks = batch_masks.view(batch_size * max_doc_len, max_sent_len)  <span class="hljs-comment"># sen_num x sent_len</span><br><br>        sent_reps = self.word_encoder(batch_inputs1, batch_inputs2)  <span class="hljs-comment"># sen_num x sent_rep_size</span><br><br>        sent_reps = sent_reps.view(batch_size, max_doc_len, self.sent_rep_size)  <span class="hljs-comment"># b x doc_len x sent_rep_size</span><br>        batch_masks = batch_masks.view(batch_size, max_doc_len, max_sent_len)  <span class="hljs-comment"># b x doc_len x max_sent_len</span><br>        sent_masks = batch_masks.<span class="hljs-built_in">bool</span>().<span class="hljs-built_in">any</span>(<span class="hljs-number">2</span>).<span class="hljs-built_in">float</span>()  <span class="hljs-comment"># b x doc_len</span><br><br>        sent_hiddens = self.sent_encoder(sent_reps, sent_masks)  <span class="hljs-comment"># b x doc_len x doc_rep_size</span><br>        doc_reps, atten_scores = self.sent_attention(sent_hiddens, sent_masks)  <span class="hljs-comment"># b x doc_rep_size</span><br><br>        batch_outputs = self.out(doc_reps)  <span class="hljs-comment"># b x num_labels</span><br><br>        <span class="hljs-keyword">return</span> batch_outputs<br><br><br>model = Model(vocab)<br><br><span class="hljs-comment"># build optimizer</span><br>learning_rate = <span class="hljs-number">2e-4</span><br>bert_lr = <span class="hljs-number">5e-5</span><br>decay = <span class="hljs-number">.75</span><br>decay_step = <span class="hljs-number">1000</span><br><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AdamW, get_linear_schedule_with_warmup<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Optimizer</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, model_parameters, steps</span>):<br>        self.all_params = []<br>        self.optims = []<br>        self.schedulers = []<br><br>        <span class="hljs-keyword">for</span> name, parameters <span class="hljs-keyword">in</span> model_parameters.items():<br>            <span class="hljs-keyword">if</span> name.startswith(<span class="hljs-string">&quot;basic&quot;</span>):<br>                optim = torch.optim.Adam(parameters, lr=learning_rate)<br>                self.optims.append(optim)<br><br>                l = <span class="hljs-keyword">lambda</span> step: decay ** (step // decay_step)<br>                scheduler = torch.optim.lr_scheduler.LambdaLR(optim, lr_lambda=l)<br>                self.schedulers.append(scheduler)<br>                self.all_params.extend(parameters)<br>            <span class="hljs-keyword">elif</span> name.startswith(<span class="hljs-string">&quot;bert&quot;</span>):<br>                optim_bert = AdamW(parameters, bert_lr, eps=<span class="hljs-number">1e-8</span>)<br>                self.optims.append(optim_bert)<br><br>                scheduler_bert = get_linear_schedule_with_warmup(optim_bert, <span class="hljs-number">0</span>, steps)<br>                self.schedulers.append(scheduler_bert)<br><br>                <span class="hljs-keyword">for</span> group <span class="hljs-keyword">in</span> parameters:<br>                    <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> group[<span class="hljs-string">&#x27;params&#x27;</span>]:<br>                        self.all_params.append(p)<br>            <span class="hljs-keyword">else</span>:<br>                Exception(<span class="hljs-string">&quot;no nameed parameters.&quot;</span>)<br><br>        self.num = <span class="hljs-built_in">len</span>(self.optims)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">step</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">for</span> optim, scheduler <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(self.optims, self.schedulers):<br>            optim.step()<br>            scheduler.step()<br>            optim.zero_grad()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">zero_grad</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">for</span> optim <span class="hljs-keyword">in</span> self.optims:<br>            optim.zero_grad()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_lr</span>(<span class="hljs-params">self</span>):<br>        lrs = <span class="hljs-built_in">tuple</span>(<span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> x: x.get_lr()[-<span class="hljs-number">1</span>], self.schedulers))<br>        lr = <span class="hljs-string">&#x27; %.5f&#x27;</span> * self.num<br>        res = lr % lrs<br>        <span class="hljs-keyword">return</span> res<br><br><span class="hljs-comment"># build dataset</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">sentence_split</span>(<span class="hljs-params">text, vocab, max_sent_len=<span class="hljs-number">256</span>, max_segment=<span class="hljs-number">16</span></span>):<br>    words = text.strip().split()<br>    document_len = <span class="hljs-built_in">len</span>(words)<br><br>    index = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, document_len, max_sent_len))<br>    index.append(document_len)<br><br>    segments = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(index) - <span class="hljs-number">1</span>):<br>        segment = words[index[i]: index[i + <span class="hljs-number">1</span>]]<br>        <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(segment) &gt; <span class="hljs-number">0</span><br>        segment = [word <span class="hljs-keyword">if</span> word <span class="hljs-keyword">in</span> vocab._id2word <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;&lt;UNK&gt;&#x27;</span> <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> segment]<br>        segments.append([<span class="hljs-built_in">len</span>(segment), segment])<br><br>    <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(segments) &gt; <span class="hljs-number">0</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(segments) &gt; max_segment:<br>        segment_ = <span class="hljs-built_in">int</span>(max_segment / <span class="hljs-number">2</span>)<br>        <span class="hljs-keyword">return</span> segments[:segment_] + segments[-segment_:]<br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> segments<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_examples</span>(<span class="hljs-params">data, word_encoder, vocab, max_sent_len=<span class="hljs-number">256</span>, max_segment=<span class="hljs-number">8</span></span>):<br>    label2id = vocab.label2id<br>    examples = []<br><br>    <span class="hljs-keyword">for</span> text, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(data[<span class="hljs-string">&#x27;text&#x27;</span>], data[<span class="hljs-string">&#x27;label&#x27;</span>]):<br>        <span class="hljs-comment"># label</span><br>        <span class="hljs-built_in">id</span> = label2id(label)<br><br>        <span class="hljs-comment"># words</span><br>        sents_words = sentence_split(text, vocab, max_sent_len-<span class="hljs-number">2</span>, max_segment)<br>        doc = []<br>        <span class="hljs-keyword">for</span> sent_len, sent_words <span class="hljs-keyword">in</span> sents_words:<br>            token_ids = word_encoder.encode(sent_words)<br>            sent_len = <span class="hljs-built_in">len</span>(token_ids)<br>            token_type_ids = [<span class="hljs-number">0</span>] * sent_len<br>            doc.append([sent_len, token_ids, token_type_ids])<br>        examples.append([<span class="hljs-built_in">id</span>, <span class="hljs-built_in">len</span>(doc), doc])<br><br>    logging.info(<span class="hljs-string">&#x27;Total %d docs.&#x27;</span> % <span class="hljs-built_in">len</span>(examples))<br>    <span class="hljs-keyword">return</span> examples<br><br><br><span class="hljs-comment"># build loader</span><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">batch_slice</span>(<span class="hljs-params">data, batch_size</span>):<br>    batch_num = <span class="hljs-built_in">int</span>(np.ceil(<span class="hljs-built_in">len</span>(data) / <span class="hljs-built_in">float</span>(batch_size)))<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(batch_num):<br>        cur_batch_size = batch_size <span class="hljs-keyword">if</span> i &lt; batch_num - <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-built_in">len</span>(data) - batch_size * i<br>        docs = [data[i * batch_size + b] <span class="hljs-keyword">for</span> b <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(cur_batch_size)]<br><br>        <span class="hljs-keyword">yield</span> docs<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">data_iter</span>(<span class="hljs-params">data, batch_size, shuffle=<span class="hljs-literal">True</span>, noise=<span class="hljs-number">1.0</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    randomly permute data, then sort by source length, and partition into batches</span><br><span class="hljs-string">    ensure that the length of  sentences in each batch</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    batched_data = []<br>    <span class="hljs-keyword">if</span> shuffle:<br>        np.random.shuffle(data)<br><br>        lengths = [example[<span class="hljs-number">1</span>] <span class="hljs-keyword">for</span> example <span class="hljs-keyword">in</span> data]<br>        noisy_lengths = [- (l + np.random.uniform(- noise, noise)) <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> lengths]<br>        sorted_indices = np.argsort(noisy_lengths).tolist()<br>        sorted_data = [data[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> sorted_indices]<br>    <span class="hljs-keyword">else</span>:<br>        sorted_data = data<br><br>    batched_data.extend(<span class="hljs-built_in">list</span>(batch_slice(sorted_data, batch_size)))<br><br>    <span class="hljs-keyword">if</span> shuffle:<br>        np.random.shuffle(batched_data)<br><br>    <span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> batched_data:<br>        <span class="hljs-keyword">yield</span> batch<br><br><span class="hljs-comment"># some function</span><br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> f1_score, precision_score, recall_score<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_score</span>(<span class="hljs-params">y_ture, y_pred</span>):<br>    y_ture = np.array(y_ture)<br>    y_pred = np.array(y_pred)<br>    f1 = f1_score(y_ture, y_pred, average=<span class="hljs-string">&#x27;macro&#x27;</span>) * <span class="hljs-number">100</span><br>    p = precision_score(y_ture, y_pred, average=<span class="hljs-string">&#x27;macro&#x27;</span>) * <span class="hljs-number">100</span><br>    r = recall_score(y_ture, y_pred, average=<span class="hljs-string">&#x27;macro&#x27;</span>) * <span class="hljs-number">100</span><br><br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">str</span>((reformat(p, <span class="hljs-number">2</span>), reformat(r, <span class="hljs-number">2</span>), reformat(f1, <span class="hljs-number">2</span>))), reformat(f1, <span class="hljs-number">2</span>)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">reformat</span>(<span class="hljs-params">num, n</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">float</span>(<span class="hljs-built_in">format</span>(num, <span class="hljs-string">&#x27;0.&#x27;</span> + <span class="hljs-built_in">str</span>(n) + <span class="hljs-string">&#x27;f&#x27;</span>))<br><br><br><span class="hljs-comment"># build trainer</span><br><br><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">from</span> sklearn.metrics <span class="hljs-keyword">import</span> classification_report<br><br>clip = <span class="hljs-number">5.0</span><br>epochs = <span class="hljs-number">1</span><br>early_stops = <span class="hljs-number">3</span><br>log_interval = <span class="hljs-number">50</span><br><br>test_batch_size = <span class="hljs-number">16</span><br>train_batch_size = <span class="hljs-number">16</span><br><br>save_model = <span class="hljs-string">&#x27;./bert.bin&#x27;</span><br>save_test = <span class="hljs-string">&#x27;./bert.csv&#x27;</span><br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Trainer</span>():<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, model, vocab</span>):<br>        self.model = model<br>        self.report = <span class="hljs-literal">True</span><br><br>        self.train_data = get_examples(train_data, model.word_encoder, vocab)<br>        self.batch_num = <span class="hljs-built_in">int</span>(np.ceil(<span class="hljs-built_in">len</span>(self.train_data) / <span class="hljs-built_in">float</span>(train_batch_size)))<br>        self.dev_data = get_examples(dev_data, model.word_encoder, vocab)<br>        self.test_data = get_examples(test_data, model.word_encoder, vocab)<br><br>        <span class="hljs-comment"># criterion</span><br>        self.criterion = nn.CrossEntropyLoss()<br><br>        <span class="hljs-comment"># label name</span><br>        self.target_names = vocab.target_names<br><br>        <span class="hljs-comment"># optimizer</span><br>        self.optimizer = Optimizer(model.all_parameters, steps=self.batch_num * epochs)<br><br>        <span class="hljs-comment"># count</span><br>        self.step = <span class="hljs-number">0</span><br>        self.early_stop = -<span class="hljs-number">1</span><br>        self.best_train_f1, self.best_dev_f1 = <span class="hljs-number">0</span>, <span class="hljs-number">0</span><br>        self.last_epoch = epochs<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">train</span>(<span class="hljs-params">self</span>):<br>        logging.info(<span class="hljs-string">&#x27;Start training...&#x27;</span>)<br>        <span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, epochs + <span class="hljs-number">1</span>):<br>            train_f1 = self._train(epoch)<br><br>            dev_f1 = self._<span class="hljs-built_in">eval</span>(epoch)<br><br>            <span class="hljs-keyword">if</span> self.best_dev_f1 &lt;= dev_f1:<br>                logging.info(<br>                    <span class="hljs-string">&quot;Exceed history dev = %.2f, current dev = %.2f&quot;</span> % (self.best_dev_f1, dev_f1))<br>                torch.save(self.model.state_dict(), save_model)<br><br>                self.best_train_f1 = train_f1<br>                self.best_dev_f1 = dev_f1<br>                self.early_stop = <span class="hljs-number">0</span><br>            <span class="hljs-keyword">else</span>:<br>                self.early_stop += <span class="hljs-number">1</span><br>                <span class="hljs-keyword">if</span> self.early_stop == early_stops:<br>                    logging.info(<br>                        <span class="hljs-string">&quot;Eearly stop in epoch %d, best train: %.2f, dev: %.2f&quot;</span> % (<br>                            epoch - early_stops, self.best_train_f1, self.best_dev_f1))<br>                    self.last_epoch = epoch<br>                    <span class="hljs-keyword">break</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>(<span class="hljs-params">self</span>):<br>        self.model.load_state_dict(torch.load(save_model))<br>        self._<span class="hljs-built_in">eval</span>(self.last_epoch + <span class="hljs-number">1</span>, test=<span class="hljs-literal">True</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_train</span>(<span class="hljs-params">self, epoch</span>):<br>        self.optimizer.zero_grad()<br>        self.model.train()<br><br>        start_time = time.time()<br>        epoch_start_time = time.time()<br>        overall_losses = <span class="hljs-number">0</span><br>        losses = <span class="hljs-number">0</span><br>        batch_idx = <span class="hljs-number">1</span><br>        y_pred = []<br>        y_true = []<br>        <span class="hljs-keyword">for</span> batch_data <span class="hljs-keyword">in</span> data_iter(self.train_data, train_batch_size, shuffle=<span class="hljs-literal">True</span>):<br>            torch.cuda.empty_cache()<br>            batch_inputs, batch_labels = self.batch2tensor(batch_data)<br>            batch_outputs = self.model(batch_inputs)<br>            loss = self.criterion(batch_outputs, batch_labels)<br>            loss.backward()<br><br>            loss_value = loss.detach().cpu().item()<br>            losses += loss_value<br>            overall_losses += loss_value<br><br>            y_pred.extend(torch.<span class="hljs-built_in">max</span>(batch_outputs, dim=<span class="hljs-number">1</span>)[<span class="hljs-number">1</span>].cpu().numpy().tolist())<br>            y_true.extend(batch_labels.cpu().numpy().tolist())<br><br>            nn.utils.clip_grad_norm_(self.optimizer.all_params, max_norm=clip)<br>            <span class="hljs-keyword">for</span> optimizer, scheduler <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(self.optimizer.optims, self.optimizer.schedulers):<br>                optimizer.step()<br>                scheduler.step()<br>            self.optimizer.zero_grad()<br><br>            self.step += <span class="hljs-number">1</span><br><br>            <span class="hljs-keyword">if</span> batch_idx % log_interval == <span class="hljs-number">0</span>:<br>                elapsed = time.time() - start_time<br><br>                lrs = self.optimizer.get_lr()<br>                logging.info(<br>                    <span class="hljs-string">&#x27;| epoch &#123;:3d&#125; | step &#123;:3d&#125; | batch &#123;:3d&#125;/&#123;:3d&#125; | lr&#123;&#125; | loss &#123;:.4f&#125; | s/batch &#123;:.2f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(<br>                        epoch, self.step, batch_idx, self.batch_num, lrs,<br>                        losses / log_interval,<br>                        elapsed / log_interval))<br><br>                losses = <span class="hljs-number">0</span><br>                start_time = time.time()<br><br>            batch_idx += <span class="hljs-number">1</span><br><br>        overall_losses /= self.batch_num<br>        during_time = time.time() - epoch_start_time<br><br>        <span class="hljs-comment"># reformat</span><br>        overall_losses = reformat(overall_losses, <span class="hljs-number">4</span>)<br>        score, f1 = get_score(y_true, y_pred)<br><br>        logging.info(<br>            <span class="hljs-string">&#x27;| epoch &#123;:3d&#125; | score &#123;&#125; | f1 &#123;&#125; | loss &#123;:.4f&#125; | time &#123;:.2f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(epoch, score, f1,<br>                                                                                  overall_losses,<br>                                                                                  during_time))<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">set</span>(y_true) == <span class="hljs-built_in">set</span>(y_pred) <span class="hljs-keyword">and</span> self.report:<br>            report = classification_report(y_true, y_pred, digits=<span class="hljs-number">4</span>, target_names=self.target_names)<br>            logging.info(<span class="hljs-string">&#x27;\n&#x27;</span> + report)<br><br>        <span class="hljs-keyword">return</span> f1<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_eval</span>(<span class="hljs-params">self, epoch, test=<span class="hljs-literal">False</span></span>):<br>        self.model.<span class="hljs-built_in">eval</span>()<br>        start_time = time.time()<br>        data = self.test_data <span class="hljs-keyword">if</span> test <span class="hljs-keyword">else</span> self.dev_data<br>        y_pred = []<br>        y_true = []<br>        <span class="hljs-keyword">with</span> torch.no_grad():<br>            <span class="hljs-keyword">for</span> batch_data <span class="hljs-keyword">in</span> data_iter(data, test_batch_size, shuffle=<span class="hljs-literal">False</span>):<br>                torch.cuda.empty_cache()<br>                batch_inputs, batch_labels = self.batch2tensor(batch_data)<br>                batch_outputs = self.model(batch_inputs)<br>                y_pred.extend(torch.<span class="hljs-built_in">max</span>(batch_outputs, dim=<span class="hljs-number">1</span>)[<span class="hljs-number">1</span>].cpu().numpy().tolist())<br>                y_true.extend(batch_labels.cpu().numpy().tolist())<br><br>            score, f1 = get_score(y_true, y_pred)<br><br>            during_time = time.time() - start_time<br><br>            <span class="hljs-keyword">if</span> test:<br>                df = pd.DataFrame(&#123;<span class="hljs-string">&#x27;label&#x27;</span>: y_pred&#125;)<br>                df.to_csv(save_test, index=<span class="hljs-literal">False</span>, sep=<span class="hljs-string">&#x27;,&#x27;</span>)<br>            <span class="hljs-keyword">else</span>:<br>                logging.info(<br>                    <span class="hljs-string">&#x27;| epoch &#123;:3d&#125; | dev | score &#123;&#125; | f1 &#123;&#125; | time &#123;:.2f&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(epoch, score, f1,<br>                                                                                  during_time))<br>                <span class="hljs-keyword">if</span> <span class="hljs-built_in">set</span>(y_true) == <span class="hljs-built_in">set</span>(y_pred) <span class="hljs-keyword">and</span> self.report:<br>                    report = classification_report(y_true, y_pred, digits=<span class="hljs-number">4</span>, target_names=self.target_names)<br>                    logging.info(<span class="hljs-string">&#x27;\n&#x27;</span> + report)<br><br>        <span class="hljs-keyword">return</span> f1<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">batch2tensor</span>(<span class="hljs-params">self, batch_data</span>):<br>        <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">            [[label, doc_len, [[sent_len, [sent_id0, ...], [sent_id1, ...]], ...]]</span><br><span class="hljs-string">        &#x27;&#x27;&#x27;</span><br>        batch_size = <span class="hljs-built_in">len</span>(batch_data)<br>        doc_labels = []<br>        doc_lens = []<br>        doc_max_sent_len = []<br>        <span class="hljs-keyword">for</span> doc_data <span class="hljs-keyword">in</span> batch_data:<br>            doc_labels.append(doc_data[<span class="hljs-number">0</span>])<br>            doc_lens.append(doc_data[<span class="hljs-number">1</span>])<br>            sent_lens = [sent_data[<span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> sent_data <span class="hljs-keyword">in</span> doc_data[<span class="hljs-number">2</span>]]<br>            max_sent_len = <span class="hljs-built_in">max</span>(sent_lens)<br>            doc_max_sent_len.append(max_sent_len)<br><br>        max_doc_len = <span class="hljs-built_in">max</span>(doc_lens)<br>        max_sent_len = <span class="hljs-built_in">max</span>(doc_max_sent_len)<br><br>        batch_inputs1 = torch.zeros((batch_size, max_doc_len, max_sent_len), dtype=torch.int64)<br>        batch_inputs2 = torch.zeros((batch_size, max_doc_len, max_sent_len), dtype=torch.int64)<br>        batch_masks = torch.zeros((batch_size, max_doc_len, max_sent_len), dtype=torch.float32)<br>        batch_labels = torch.LongTensor(doc_labels)<br><br>        <span class="hljs-keyword">for</span> b <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(batch_size):<br>            <span class="hljs-keyword">for</span> sent_idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(doc_lens[b]):<br>                sent_data = batch_data[b][<span class="hljs-number">2</span>][sent_idx]<br>                <span class="hljs-keyword">for</span> word_idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(sent_data[<span class="hljs-number">0</span>]):<br>                    batch_inputs1[b, sent_idx, word_idx] = sent_data[<span class="hljs-number">1</span>][word_idx]<br>                    batch_inputs2[b, sent_idx, word_idx] = sent_data[<span class="hljs-number">2</span>][word_idx]<br>                    batch_masks[b, sent_idx, word_idx] = <span class="hljs-number">1</span><br><br>        <span class="hljs-keyword">if</span> use_cuda:<br>            batch_inputs1 = batch_inputs1.to(device)<br>            batch_inputs2 = batch_inputs2.to(device)<br>            batch_masks = batch_masks.to(device)<br>            batch_labels = batch_labels.to(device)<br><br>        <span class="hljs-keyword">return</span> (batch_inputs1, batch_inputs2, batch_masks), batch_labels<br><br><span class="hljs-comment"># train</span><br>trainer = Trainer(model, vocab)<br>trainer.train()<br><br><span class="hljs-comment"># test</span><br>trainer.test()<br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>NLP</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>NLP-Assignment4</title>
    <link href="/2022/05/15/NLP-Assignment4/"/>
    <url>/2022/05/15/NLP-Assignment4/</url>
    
    <content type="html"><![CDATA[<h1 id="assignment4">Assignment4</h1><h2 id="rnn">RNN</h2><p>Seq2SeqNMTNMTLSTMencoderLSTMdecoder</p><p><img src="http://ww1.sinaimg.cn/large/0060yMmAly1gsjzdzvwbaj30pv0hzjuy.jpg" referrerpolicy="no-referrer"/></p><p>msource <spanclass="math inline">\(x_1, x_2, , x_m \in R^{e \times1}\)</span><spanclass="math inline">\(e\)</span>EncoderLSTM<span class="math inline">\(i\)</span>  <spanclass="math inline">\(h_i^{enc}\)</span>  <spanclass="math inline">\(c_i^{enc}\)</span>  <spanclass="math display">\[\mathbf{h}_{i}^{\text {enc }}=\left[\overleftarrow{\mathbf{h}_{i}^{\text{enc }}} ; \overrightarrow{\mathbf{h}_{i}^{\text {enc }}}\right] \text {where } \mathbf{h}_{i}^{\text {enc }} \in \mathbb{R}^{2 h \times 1},\overleftarrow{\mathbf{h}_{i}^{\text {enc }}},\overrightarrow{\mathbf{h}_{i}^{\text {en }}} \in \mathbb{R}^{h \times1} \quad 1 \leq i \leq m\]</span></p><p><span class="math display">\[\mathbf{c}_{i}^{\text {enc }}=\left[\overleftarrow{\mathbf{c}_{i}^{\text{enc }}} ; \overrightarrow{\mathbf{c}_{i}^{\text {enc }}}\right] \text {where } \mathbf{c}_{i}^{\text {enc }} \in \mathbb{R}^{2 h \times 1},\overleftarrow{\mathbf{c}_{i}^{\text {enc }}},\overrightarrow{\mathbf{c}_{i}^{\text {en }}} \in \mathbb{R}^{h \times1} \quad 1 \leq i \leq m\]</span></p><p>Decoder <spanclass="math display">\[\mathbf{h}_{0}^{\text {dec}}=\mathbf{W}_{h}\left[\overleftarrow{\mathbf{h}_{1}^{\text {enc }}} ;\overrightarrow{\mathbf{h}_{m}^{\text {enc }}}\right] \text { where }\mathbf{h}_{0}^{\text {dec }} \in \mathbb{R}^{h \times 1},\mathbf{W}_{h} \in \mathbb{R}^{h \times 2 h}\]</span></p><p><span class="math display">\[\mathbf{c}_{0}^{\text {dec}}=\mathbf{W}_{c}\left[\overleftarrow{\mathbf{c}_{1}^{\text {enc }}} ;\overrightarrow{\mathbf{c}_{m}^{\text {enc }}}\right] \text { where }\mathbf{c}_{0}^{\text {dec }} \in \mathbb{R}^{h \times 1},\mathbf{W}_{c} \in \mathbb{R}^{h \times 2 h}\]</span></p><p>Decoder<span class="math inline">\(t\)</span>  <spanclass="math inline">\(\bar{y}_t\)</span>  <spanclass="math inline">\(y_t\)</span><spanclass="math inline">\(o_{t-1}\)</span><spanclass="math inline">\(o_0\)</span>0 <spanclass="math inline">\(\bar{y}_t \in R^{(e + h) \times 1}\)</span> <spanclass="math display">\[\mathbf{h}_{t}^{\mathrm{dec}},\mathbf{c}_{t}^{\mathrm{dec}}=\operatorname{Decoder}\left(\overline{\mathbf{y}_{t}},\mathbf{h}_{t-1}^{\mathrm{dec}}, \mathbf{c}_{t-1}^{\mathrm{dec}}\right)\text { where } \mathbf{h}_{t}^{\mathrm{dec}} \in \mathbb{R}^{h \times1}, \mathbf{c}_{t}^{\mathrm{dec}} \in \mathbb{R}^{h \times 1}\]</span>  <span class="math inline">\(h^{dec}_t\)</span> <span class="math inline">\(h^{enc}_0, h^{enc}_1, ,h^{enc}_m\)</span> multiplicative attention <spanclass="math display">\[\begin{array}{c}\mathbf{e}_{t, i}=\left(\mathbf{h}_{t}^{\mathrm{dec}}\right)^{T}\mathbf{W}_{\text {attProj }} \mathbf{h}_{i}^{\text {enc }} \text {where } \mathbf{e}_{t} \in \mathbb{R}^{m \times 1}, \mathbf{W}_{\text{attProj }} \in \mathbb{R}^{h \times 2 h} \quad 1 \leq i \leq m \\\alpha_{t}=\operatorname{softmax}\left(\mathbf{e}_{t}\right) \text {where } \alpha_{t} \in \mathbb{R}^{m \times 1} \\\mathbf{a}_{t}=\sum_{i=1}^{m} \alpha_{t, i} \mathbf{h}_{i}^{\text {enc}} \text { where } \mathbf{a}_{t} \in \mathbb{R}^{2 h \times 1}\end{array}\]</span>  <span class="math inline">\(a_t\)</span> <span class="math inline">\(h^{dec}_t\)</span> <em>combined-output</em>  <spanclass="math inline">\(o_t\)</span> <span class="math display">\[\begin{array}{r}\mathbf{u}_{t}=\left[\mathbf{a}_{t} ;\mathbf{h}_{t}^{\mathrm{dec}}\right] \text { where } \mathbf{u}_{t} \in\mathbb{R}^{3 h \times 1} \\\mathbf{v}_{t}=\mathbf{W}_{u} \mathbf{u}_{t} \text { where }\mathbf{v}_{t} \in \mathbb{R}^{h \times 1}, \mathbf{W}_{u} \in\mathbb{R}^{h \times 3 h} \\\mathbf{o}_{t}=\operatorname{Dropout}\left(\tanh\left(\mathbf{v}_{t}\right)\right) \text { where } \mathbf{o}_{t} \in\mathbb{R}^{h \times 1}\end{array}\]</span>  <span class="math display">\[\mathbf{P}_{t}=\operatorname{softmax}\left(\mathbf{W}_{\text {vocab }}\mathbf{o}_{t}\right) \text { where } \mathbf{P}_{t} \in\mathbb{R}^{V_{t} \times 1}, \mathbf{W}_{\text {vocab }} \in\mathbb{R}^{V_{t} \times h}\]</span>  <span class="math display">\[J_{t}(\theta)=\text { CrossEntropy }\left(\mathbf{P}_{t},\mathbf{g}_{t}\right)\]</span></p><p></p><h2 id="part1-">part1</h2><h3 id="a-pad_sents">(a) pad_sents</h3><p>In order to apply tensor operations, we must ensure that thesentences in a given batch are of the same length. Thus, we mustidentify the longest sentence in a batch and pad others to be the samelength. Implement the pad sents function in utils.py, which shallproduce these padded sentences.</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">pad_sents</span>(<span class="hljs-params">sents, pad_token</span>):<br>    <span class="hljs-string">&quot;&quot;&quot; Pad list of sentences according to the longest sentence in the batch.</span><br><span class="hljs-string">    @param sents (list[list[str]]): list of sentences, where each sentence</span><br><span class="hljs-string">                                    is represented as a list of words</span><br><span class="hljs-string">    @param pad_token (str): padding token</span><br><span class="hljs-string">    @returns sents_padded (list[list[str]]): list of sentences where sentences shorter</span><br><span class="hljs-string">        than the max length sentence are padded out with the pad_token, such that</span><br><span class="hljs-string">        each sentences in the batch now has equal length.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    sents_padded = []<br><br>    <span class="hljs-comment"># YOUR CODE HERE (~6 Lines)</span><br>    corpus_size = <span class="hljs-built_in">len</span>(sents)<br>    lens = [<span class="hljs-built_in">len</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> sents]  <span class="hljs-comment"># every sentence&#x27;s length</span><br>    max_lens = <span class="hljs-built_in">max</span>(lens)<br>    sents_padded = [sents[i] + [pad_token] * (max_lens - lens[i]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(corpus_size)]      <span class="hljs-comment"># shape N x max_lens</span><br>    <span class="hljs-comment"># END YOUR CODE</span><br><br>    <span class="hljs-keyword">return</span> sents_padded<br></code></pre></div></td></tr></table></figure><h3 id="b-modelembeddings">(b) ModelEmbeddings</h3><p>Implement the <code>__init__</code> function in model embeddings.pyto initialize the necessary source and target embeddings.</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ModelEmbeddings</span>(nn.Module): <br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Class that converts input words to their embeddings.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, embed_size, vocab</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Init the Embedding layers.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        @param embed_size (int): Embedding size (dimensionality)</span><br><span class="hljs-string">        @param vocab (Vocab): Vocabulary object containing src and tgt languages</span><br><span class="hljs-string">                              See vocab.py for documentation.</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>(ModelEmbeddings, self).__init__()<br>        self.embed_size = embed_size<br><br>        <span class="hljs-comment"># default values</span><br>        self.source = <span class="hljs-literal">None</span><br>        self.target = <span class="hljs-literal">None</span><br><br>        src_pad_token_idx = vocab.src[<span class="hljs-string">&#x27;&lt;pad&gt;&#x27;</span>]<br>        tgt_pad_token_idx = vocab.tgt[<span class="hljs-string">&#x27;&lt;pad&gt;&#x27;</span>]<br><br>        <span class="hljs-comment"># YOUR CODE HERE (~2 Lines)</span><br>        <span class="hljs-comment"># TODO - Initialize the following variables:</span><br>        <span class="hljs-comment">#     self.source (Embedding Layer for source language)</span><br>        <span class="hljs-comment">#     self.target (Embedding Layer for target langauge)</span><br>        <span class="hljs-comment">#</span><br>        <span class="hljs-comment"># Note:</span><br>        <span class="hljs-comment">#     1. `vocab` object contains two vocabularies:</span><br>        <span class="hljs-comment">#            `vocab.src` for source</span><br>        <span class="hljs-comment">#            `vocab.tgt` for target</span><br>        <span class="hljs-comment">#     2. You can get the length of a specific vocabulary by running:</span><br>        <span class="hljs-comment">#             `len(vocab.&lt;specific_vocabulary&gt;)`</span><br>        <span class="hljs-comment">#     3. Remember to include the padding token for the specific vocabulary</span><br>        <span class="hljs-comment">#        when creating your Embedding.</span><br>        <span class="hljs-comment">#</span><br>        <span class="hljs-comment"># Use the following docs to properly initialize these variables:</span><br>        <span class="hljs-comment">#     Embedding Layer:</span><br>        <span class="hljs-comment">#         https://pytorch.org/docs/stable/nn.html#torch.nn.Embedding</span><br><br>        self.source = nn.Embedding(<span class="hljs-built_in">len</span>(vocab.src), embed_size, padding_idx=src_pad_token_idx)<br>        self.target = nn.Embedding(<span class="hljs-built_in">len</span>(vocab.tgt), embed_size, padding_idx=tgt_pad_token_idx)<br><br>        <span class="hljs-comment"># END YOUR CODE</span><br></code></pre></div></td></tr></table></figure><h3 id="c-nmt">(c) NMT</h3><p>Implement the <code>__init__</code> function in nmt model.py toinitialize the necessary model embeddings (using the ModelEmbeddingsclass from model embeddings.py) and layers (LSTM, projection, anddropout) for the NMT system</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">NMT</span>(nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot; Simple Neural Machine Translation Model:</span><br><span class="hljs-string">        - Bidrectional LSTM Encoder</span><br><span class="hljs-string">        - Unidirection LSTM Decoder</span><br><span class="hljs-string">        - Global Attention Model (Luong, et al. 2015)</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, embed_size, hidden_size, vocab, dropout_rate=<span class="hljs-number">0.2</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot; Init NMT Model.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        @param embed_size (int): Embedding size (dimensionality)</span><br><span class="hljs-string">        @param hidden_size (int): Hidden Size (dimensionality)</span><br><span class="hljs-string">        @param vocab (Vocab): Vocabulary object containing src and tgt languages</span><br><span class="hljs-string">                              See vocab.py for documentation.</span><br><span class="hljs-string">        @param dropout_rate (float): Dropout probability, for attention</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>(NMT, self).__init__()<br>        self.model_embeddings = ModelEmbeddings(embed_size, vocab)<br>        self.hidden_size = hidden_size<br>        self.dropout_rate = dropout_rate<br>        self.vocab = vocab<br><br>        <span class="hljs-comment"># default values</span><br>        self.encoder = <span class="hljs-literal">None</span> <br>        self.decoder = <span class="hljs-literal">None</span><br>        self.h_projection = <span class="hljs-literal">None</span><br>        self.c_projection = <span class="hljs-literal">None</span><br>        self.att_projection = <span class="hljs-literal">None</span><br>        self.combined_output_projection = <span class="hljs-literal">None</span><br>        self.target_vocab_projection = <span class="hljs-literal">None</span><br>        self.dropout = <span class="hljs-literal">None</span><br><br>        <span class="hljs-comment"># YOUR CODE HERE (~8 Lines)</span><br>        <span class="hljs-comment"># TODO - Initialize the following variables:</span><br>        <span class="hljs-comment">#     self.encoder (Bidirectional LSTM with bias)</span><br>        <span class="hljs-comment">#     self.decoder (LSTM Cell with bias)</span><br>        <span class="hljs-comment">#     self.h_projection (Linear Layer with no bias), called W_&#123;h&#125; in the PDF.</span><br>        <span class="hljs-comment">#     self.c_projection (Linear Layer with no bias), called W_&#123;c&#125; in the PDF.</span><br>        <span class="hljs-comment">#     self.att_projection (Linear Layer with no bias), called W_&#123;attProj&#125; in the PDF.</span><br>        <span class="hljs-comment">#     self.combined_output_projection (Linear Layer with no bias), called W_&#123;u&#125; in the PDF.</span><br>        <span class="hljs-comment">#     self.target_vocab_projection (Linear Layer with no bias), called W_&#123;vocab&#125; in the PDF.</span><br>        <span class="hljs-comment">#     self.dropout (Dropout Layer)</span><br>        <span class="hljs-comment">#</span><br>        <span class="hljs-comment"># Use the following docs to properly initialize these variables:</span><br>        <span class="hljs-comment">#     LSTM:</span><br>        <span class="hljs-comment">#         https://pytorch.org/docs/stable/nn.html#torch.nn.LSTM</span><br>        <span class="hljs-comment">#     LSTM Cell:</span><br>        <span class="hljs-comment">#         https://pytorch.org/docs/stable/nn.html#torch.nn.LSTMCell</span><br>        <span class="hljs-comment">#     Linear Layer:</span><br>        <span class="hljs-comment">#         https://pytorch.org/docs/stable/nn.html#torch.nn.Linear</span><br>        <span class="hljs-comment">#     Dropout Layer:</span><br>        <span class="hljs-comment">#         https://pytorch.org/docs/stable/nn.html#torch.nn.Dropout</span><br><br>        self.encoder = nn.LSTM(embed_size, hidden_size, bias=<span class="hljs-literal">True</span>, bidirectional=<span class="hljs-literal">True</span>)<br>        self.decoder = nn.LSTMCell(embed_size + hidden_size, hidden_size, bias=<span class="hljs-literal">True</span>)<br>        self.h_projection = nn.Linear(hidden_size * <span class="hljs-number">2</span>, hidden_size, bias=<span class="hljs-literal">False</span>) <span class="hljs-comment"># prj output of last h_state of encode (R^2h) to R^h</span><br>        self.c_projection = nn.Linear(hidden_size * <span class="hljs-number">2</span>, hidden_size, bias=<span class="hljs-literal">False</span>)<br>        self.att_projection = nn.Linear(hidden_size * <span class="hljs-number">2</span>, hidden_size, bias=<span class="hljs-literal">False</span>) <span class="hljs-comment"># 1 x 2h (h_encode_i) * 2h x h (W) * h * 1 (h_decode_t) = 1 x 1 = e_t,i</span><br>        self.combined_output_projection = nn.Linear(hidden_size * <span class="hljs-number">3</span>, hidden_size, bias=<span class="hljs-literal">False</span>) <span class="hljs-comment"># use after combined attention output and h_decode</span><br>        self.target_vocab_projection    = nn.Linear(hidden_size, <span class="hljs-built_in">len</span>(vocab.tgt), bias=<span class="hljs-literal">False</span>) <span class="hljs-comment"># for softmax of last</span><br>        self.dropout = nn.Dropout(self.dropout_rate)<br>        <span class="hljs-comment"># END YOUR CODE</span><br><br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, source: <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]], target: <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]]</span>) -&gt; torch.Tensor:<br>        <span class="hljs-string">&quot;&quot;&quot; Take a mini-batch of source and target sentences, compute the log-likelihood of</span><br><span class="hljs-string">        target sentences under the language models learned by the NMT system.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        @param source (List[List[str]]): list of source sentence tokens</span><br><span class="hljs-string">        @param target (List[List[str]]): list of target sentence tokens, wrapped by `&lt;s&gt;` and `&lt;/s&gt;`</span><br><span class="hljs-string"></span><br><span class="hljs-string">        @returns scores (Tensor): a variable/tensor of shape (b, ) representing the</span><br><span class="hljs-string">                                    log-likelihood of generating the gold-standard target sentence for</span><br><span class="hljs-string">                                    each example in the input batch. Here b = batch size.</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-comment"># Compute sentence lengths</span><br>        source_lengths = [<span class="hljs-built_in">len</span>(s) <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> source]<br><br>        <span class="hljs-comment"># Convert list of lists into tensors</span><br>        source_padded = self.vocab.src.to_input_tensor(source, device=self.device)   <span class="hljs-comment"># Tensor: (src_len, b)</span><br>        target_padded = self.vocab.tgt.to_input_tensor(target, device=self.device)   <span class="hljs-comment"># Tensor: (tgt_len, b)</span><br><br>        <span class="hljs-comment">#     Run the network forward:</span><br>        <span class="hljs-comment">#     1. Apply the encoder to `source_padded` by calling `self.encode()`</span><br>        <span class="hljs-comment">#     2. Generate sentence masks for `source_padded` by calling `self.generate_sent_masks()`</span><br>        <span class="hljs-comment">#     3. Apply the decoder to compute combined-output by calling `self.decode()`</span><br>        <span class="hljs-comment">#     4. Compute log probability distribution over the target vocabulary using the</span><br>        <span class="hljs-comment">#        combined_outputs returned by the `self.decode()` function.</span><br><br>        enc_hiddens, dec_init_state = self.encode(source_padded, source_lengths)<br>        enc_masks = self.generate_sent_masks(enc_hiddens, source_lengths)<br>        combined_outputs = self.decode(enc_hiddens, enc_masks, dec_init_state, target_padded)<br>        P = F.log_softmax(self.target_vocab_projection(combined_outputs), dim=-<span class="hljs-number">1</span>)<br><br>        <span class="hljs-comment"># Zero out, probabilities for which we have nothing in the target text</span><br>        target_masks = (target_padded != self.vocab.tgt[<span class="hljs-string">&#x27;&lt;pad&gt;&#x27;</span>]).<span class="hljs-built_in">float</span>()<br>        <br>        <span class="hljs-comment"># Compute log probability of generating true target words</span><br>        target_gold_words_log_prob = torch.gather(P, index=target_padded[<span class="hljs-number">1</span>:].unsqueeze(-<span class="hljs-number">1</span>), dim=-<span class="hljs-number">1</span>).squeeze(-<span class="hljs-number">1</span>) * target_masks[<span class="hljs-number">1</span>:]<br>        scores = target_gold_words_log_prob.<span class="hljs-built_in">sum</span>(dim=<span class="hljs-number">0</span>)<br>        <span class="hljs-keyword">return</span> scores<br></code></pre></div></td></tr></table></figure><h3 id="d-encode">(d) encode</h3><p>Implement the <code>encode</code> function in nmt model.py. Thisfunction converts the padded source sentences into the tensor<spanclass="math inline">\(X\)</span>, generates<spanclass="math inline">\(h^{enc}_1,...,h^{enc}_m\)</span> , and computesthe initial state<span class="math inline">\(\ h^{dec}_0\)</span>andinitial cell<span class="math inline">\(\ c^{dec}_0\)</span>for theDecoder. You can run a non-comprehensive sanity check byexecuting:<code>python sanity_check.py 1d</code></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">encode</span>(<span class="hljs-params">self, source_padded: torch.Tensor, source_lengths: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-type">Tuple</span>[torch.Tensor, <span class="hljs-type">Tuple</span>[torch.Tensor, torch.Tensor]]:<br>   <span class="hljs-string">&quot;&quot;&quot; Apply the encoder to source sentences to obtain encoder hidden states.</span><br><span class="hljs-string">       Additionally, take the final states of the encoder and project them to obtain initial states for decoder.</span><br><span class="hljs-string"></span><br><span class="hljs-string">   @param source_padded (Tensor): Tensor of padded source sentences with shape (src_len, b), where</span><br><span class="hljs-string">                                   b = batch_size, src_len = maximum source sentence length. Note that </span><br><span class="hljs-string">                                  these have already been sorted in order of longest to shortest sentence.</span><br><span class="hljs-string">   @param source_lengths (List[int]): List of actual lengths for each of the source sentences in the batch</span><br><span class="hljs-string">   @returns enc_hiddens (Tensor): Tensor of hidden units with shape (b, src_len, h*2), where</span><br><span class="hljs-string">                                   b = batch size, src_len = maximum source sentence length, h = hidden size.</span><br><span class="hljs-string">   @returns dec_init_state (tuple(Tensor, Tensor)): Tuple of tensors representing the decoder&#x27;s initial</span><br><span class="hljs-string">                                           hidden state and cell.</span><br><span class="hljs-string">   &quot;&quot;&quot;</span><br>   enc_hiddens, dec_init_state = <span class="hljs-literal">None</span>, <span class="hljs-literal">None</span><br><br>   <span class="hljs-comment"># YOUR CODE HERE (~ 8 Lines)</span><br>   <span class="hljs-comment"># <span class="hljs-doctag">TODO:</span></span><br>   <span class="hljs-comment">#     1. Construct Tensor `X` of source sentences with shape (src_len, b, e) using the source model embeddings.</span><br>   <span class="hljs-comment">#         src_len = maximum source sentence length, b = batch size, e = embedding size. Note</span><br>   <span class="hljs-comment">#         that there is no initial hidden state or cell for the decoder.</span><br>   <span class="hljs-comment">#     2. Compute `enc_hiddens`, `last_hidden`, `last_cell` by applying the encoder to `X`.</span><br>   <span class="hljs-comment">#         - Before you can apply the encoder, you need to apply the `pack_padded_sequence` function to X.</span><br>   <span class="hljs-comment">#         - After you apply the encoder, you need to apply the `pad_packed_sequence` function to enc_hiddens.</span><br>   <span class="hljs-comment">#         - Note that the shape of the tensor returned by the encoder is (src_len b, h*2) and we want to</span><br>   <span class="hljs-comment">#           return a tensor of shape (b, src_len, h*2) as `enc_hiddens`.</span><br>   <span class="hljs-comment">#     3. Compute `dec_init_state` = (init_decoder_hidden, init_decoder_cell):</span><br>   <span class="hljs-comment">#         - `init_decoder_hidden`:</span><br>   <span class="hljs-comment">#             `last_hidden` is a tensor shape (2, b, h). The first dimension corresponds to forwards and backwards.</span><br>   <span class="hljs-comment">#             Concatenate the forwards and backwards tensors to obtain a tensor shape (b, 2*h).</span><br>   <span class="hljs-comment">#             Apply the h_projection layer to this in order to compute init_decoder_hidden.</span><br>   <span class="hljs-comment">#             This is h_0^&#123;dec&#125; in the PDF. Here b = batch size, h = hidden size</span><br>   <span class="hljs-comment">#         - `init_decoder_cell`:</span><br>   <span class="hljs-comment">#             `last_cell` is a tensor shape (2, b, h). The first dimension corresponds to forwards and backwards.</span><br>   <span class="hljs-comment">#             Concatenate the forwards and backwards tensors to obtain a tensor shape (b, 2*h).</span><br>   <span class="hljs-comment">#             Apply the c_projection layer to this in order to compute init_decoder_cell.</span><br>   <span class="hljs-comment">#             This is c_0^&#123;dec&#125; in the PDF. Here b = batch size, h = hidden size</span><br>   <span class="hljs-comment">#</span><br>   <span class="hljs-comment"># See the following docs, as you may need to use some of the following functions in your implementation:</span><br>   <span class="hljs-comment">#     Pack the padded sequence X before passing to the encoder:</span><br>   <span class="hljs-comment">#         https://pytorch.org/docs/stable/nn.html#torch.nn.utils.rnn.pack_padded_sequence</span><br>   <span class="hljs-comment">#     Pad the packed sequence, enc_hiddens, returned by the encoder:</span><br>   <span class="hljs-comment">#         https://pytorch.org/docs/stable/nn.html#torch.nn.utils.rnn.pad_packed_sequence</span><br>   <span class="hljs-comment">#     Tensor Concatenation:</span><br>   <span class="hljs-comment">#         https://pytorch.org/docs/stable/torch.html#torch.cat</span><br>   <span class="hljs-comment">#     Tensor Permute:</span><br>   <span class="hljs-comment">#         https://pytorch.org/docs/stable/tensors.html#torch.Tensor.permute</span><br>   X = self.model_embeddings.source(source_padded) <span class="hljs-comment"># (src_len, b, e)</span><br>   X = pack_padded_sequence(X, lengths=source_lengths) <span class="hljs-comment"># if feed pack to RNN, it will not calculate output for pad element</span><br>   <span class="hljs-comment"># pack_padded_sequence and pad_packed_sequence example:</span><br>   <span class="hljs-comment"># https://github.com/HarshTrivedi/packing-unpacking-pytorch-minimal-tutorial</span><br>   <span class="hljs-comment"># PackedSequence: Named Tuple with 2 attribute data &amp; batch_size</span><br>   <span class="hljs-comment"># data: shape (batch_sum_len x embed_dim)</span><br>   <span class="hljs-comment"># batch_size: each columns when feed to lstm (max = batch_size (start word of all sentence), min = 1 (only one word in this column))</span><br><br>   <span class="hljs-comment"># After feed PackedSequence to LSTM, return PackedSequence with the same attributes : data &amp; batch_size</span><br>   enc_hiddens, (last_hidden, last_cell) = self.encoder(X)<br>   <span class="hljs-comment"># pad_packed_sequence will unpack PackedSequence, which transform (data &amp; batch_size) -&gt; (max_len, b, h * 2)</span><br>   <span class="hljs-comment"># padded indice will be 0s</span><br>   enc_hiddens, _ = pad_packed_sequence(enc_hiddens)<br>   enc_hiddens = enc_hiddens.transpose(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>)<span class="hljs-comment"># (b, max_len, h* 2) </span><br><br>   last_hidden = torch.cat((last_hidden[<span class="hljs-number">0</span>], last_hidden[<span class="hljs-number">1</span>]), <span class="hljs-number">1</span>)<span class="hljs-comment"># (2, b, h) -&gt; (b, h * 2)</span><br>   init_decoder_hidden = self.h_projection(last_hidden)<br><br>   last_cell = torch.cat((last_cell[<span class="hljs-number">0</span>], last_cell[<span class="hljs-number">1</span>]), <span class="hljs-number">1</span>)<br>   init_decoder_cell = self.c_projection(last_cell)<br><br>   dec_init_state = (init_decoder_hidden, init_decoder_cell)<br>   <span class="hljs-comment"># END YOUR CODE</span><br><br>   <span class="hljs-keyword">return</span> enc_hiddens, dec_init_state<br></code></pre></div></td></tr></table></figure><h3 id="e-decode">(e) decode</h3><p>Implement the <code>decode</code> function in nmt model.py. Thisfunction constructs y and runs the step function over every timestepfor the input. You can run a non-comprehensive sanity check byexecuting:<code>python sanity_check.py 1e</code></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">decode</span>(<span class="hljs-params">self, enc_hiddens: torch.Tensor, enc_masks: torch.Tensor,</span><br><span class="hljs-params">            dec_init_state: <span class="hljs-type">Tuple</span>[torch.Tensor, torch.Tensor], target_padded: torch.Tensor</span>) -&gt; torch.Tensor:<br>    <span class="hljs-string">&quot;&quot;&quot;Compute combined output vectors for a batch.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    @param enc_hiddens (Tensor): Hidden states (b, src_len, h*2), where</span><br><span class="hljs-string">                                 b = batch size, src_len = maximum source sentence length, h = hidden size.</span><br><span class="hljs-string">    @param enc_masks (Tensor): Tensor of sentence masks (b, src_len), where</span><br><span class="hljs-string">                                 b = batch size, src_len = maximum source sentence length.</span><br><span class="hljs-string">    @param dec_init_state (tuple(Tensor, Tensor)): Initial state and cell for decoder</span><br><span class="hljs-string">    @param target_padded (Tensor): Gold-standard padded target sentences (tgt_len, b), where</span><br><span class="hljs-string">                                   tgt_len = maximum target sentence length, b = batch size. </span><br><span class="hljs-string"></span><br><span class="hljs-string">    @returns combined_outputs (Tensor): combined output tensor  (tgt_len, b,  h), where</span><br><span class="hljs-string">                                    tgt_len = maximum target sentence length, b = batch_size,  h = hidden size</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># Chop of the &lt;END&gt; token for max length sentences.</span><br>    target_padded = target_padded[:-<span class="hljs-number">1</span>]<br><br>    <span class="hljs-comment"># Initialize the decoder state (hidden and cell)</span><br>    dec_state = dec_init_state<br><br>    <span class="hljs-comment"># Initialize previous combined output vector o_&#123;t-1&#125; as zero</span><br>    batch_size = enc_hiddens.size(<span class="hljs-number">0</span>)<br>    o_prev = torch.zeros(batch_size, self.hidden_size, device=self.device)<br><br>    <span class="hljs-comment"># Initialize a list we will use to collect the combined output o_t on each step</span><br>    combined_outputs = []<br><br>    <span class="hljs-comment"># YOUR CODE HERE (~9 Lines)</span><br>    <span class="hljs-comment"># <span class="hljs-doctag">TODO:</span></span><br>    <span class="hljs-comment">#     1. Apply the attention projection layer to `enc_hiddens` to obtain `enc_hiddens_proj`,</span><br>    <span class="hljs-comment">#         which should be shape (b, src_len, h),</span><br>    <span class="hljs-comment">#         where b = batch size, src_len = maximum source length, h = hidden size.</span><br>    <span class="hljs-comment">#         This is applying W_&#123;attProj&#125; to h^enc, as described in the PDF.</span><br>    <span class="hljs-comment">#     2. Construct tensor `Y` of target sentences with shape (tgt_len, b, e) using the target model embeddings.</span><br>    <span class="hljs-comment">#         where tgt_len = maximum target sentence length, b = batch size, e = embedding size.</span><br>    <span class="hljs-comment">#     3. Use the torch.split function to iterate over the time dimension of Y.</span><br>    <span class="hljs-comment">#         Within the loop, this will give you Y_t of shape (1, b, e) where b = batch size, e = embedding size.</span><br>    <span class="hljs-comment">#             - Squeeze Y_t into a tensor of dimension (b, e).</span><br>    <span class="hljs-comment">#             - Construct Ybar_t by concatenating Y_t with o_prev.</span><br>    <span class="hljs-comment">#             - Use the step function to compute the the Decoder&#x27;s next (cell, state) values</span><br>    <span class="hljs-comment">#               as well as the new combined output o_t.</span><br>    <span class="hljs-comment">#             - Append o_t to combined_outputs</span><br>    <span class="hljs-comment">#             - Update o_prev to the new o_t.</span><br>    <span class="hljs-comment">#     4. Use torch.stack to convert combined_outputs from a list length tgt_len of</span><br>    <span class="hljs-comment">#         tensors shape (b, h), to a single tensor shape (tgt_len, b, h)</span><br>    <span class="hljs-comment">#         where tgt_len = maximum target sentence length, b = batch size, h = hidden size.</span><br>    <span class="hljs-comment">#</span><br>    <span class="hljs-comment"># Note:</span><br>    <span class="hljs-comment">#    - When using the squeeze() function make sure to specify the dimension you want to squeeze</span><br>    <span class="hljs-comment">#      over. Otherwise, you will remove the batch dimension accidentally, if batch_size = 1.</span><br>    <span class="hljs-comment">#</span><br>    <span class="hljs-comment"># Use the following docs to implement this functionality:</span><br>    <span class="hljs-comment">#     Zeros Tensor:</span><br>    <span class="hljs-comment">#         https://pytorch.org/docs/stable/torch.html#torch.zeros</span><br>    <span class="hljs-comment">#     Tensor Splitting (iteration):</span><br>    <span class="hljs-comment">#         https://pytorch.org/docs/stable/torch.html#torch.split</span><br>    <span class="hljs-comment">#     Tensor Dimension Squeezing:</span><br>    <span class="hljs-comment">#         https://pytorch.org/docs/stable/torch.html#torch.squeeze</span><br>    <span class="hljs-comment">#     Tensor Concatenation:</span><br>    <span class="hljs-comment">#         https://pytorch.org/docs/stable/torch.html#torch.cat</span><br>    <span class="hljs-comment">#     Tensor Stacking:</span><br>    <span class="hljs-comment">#         https://pytorch.org/docs/stable/torch.html#torch.stack</span><br><br>    <span class="hljs-comment"># 1,</span><br>    enc_hiddens_proj = self.att_projection(enc_hiddens) <span class="hljs-comment"># enc_hiddens: (b, l, h * 2)  dot (h * 2, h) -&gt; b, l, h</span><br>    <span class="hljs-comment"># 2,</span><br>    Y = self.model_embeddings.target(target_padded) <span class="hljs-comment"># (tgt_len, b, h)</span><br>    <span class="hljs-comment"># 3,</span><br>    <span class="hljs-keyword">for</span> Y_t <span class="hljs-keyword">in</span> torch.split(Y, <span class="hljs-number">1</span>, dim=<span class="hljs-number">0</span>):<br>        squeezed = torch.squeeze(Y_t) <span class="hljs-comment"># shape (b, e)</span><br>        Ybar_t = torch.cat((squeezed, o_prev), dim=<span class="hljs-number">1</span>) <span class="hljs-comment"># shape (b, e + h)</span><br>        dec_state, o_t, _ = self.step(Ybar_t, dec_state, enc_hiddens, enc_hiddens_proj, enc_masks)<br>        combined_outputs.append(o_t)<br>        o_prev = o_t<br>    <span class="hljs-comment"># 4,</span><br>    combined_outputs = torch.stack(combined_outputs, dim=<span class="hljs-number">0</span>)<br>    <span class="hljs-comment"># END YOUR CODE</span><br><br>    <span class="hljs-keyword">return</span> combined_outputs<br></code></pre></div></td></tr></table></figure><h3 id="f-step">(f) step</h3><p>Implement the <code>step</code> function in nmt model.py. Thisfunction applies the Decoders LSTM cell for a single timestep,computing the encoding of the target word h dec t , the attention scoreset, attention distribution t, the attention output at, and finally thecombined output ot. You can run a non-comprehensive sanity check byexecuting:<code>python sanity_check.py 1f</code></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">step</span>(<span class="hljs-params">self, Ybar_t: torch.Tensor,</span><br><span class="hljs-params">        dec_state: <span class="hljs-type">Tuple</span>[torch.Tensor, torch.Tensor],</span><br><span class="hljs-params">        enc_hiddens: torch.Tensor,</span><br><span class="hljs-params">        enc_hiddens_proj: torch.Tensor,</span><br><span class="hljs-params">        enc_masks: torch.Tensor</span>) -&gt; <span class="hljs-type">Tuple</span>[<span class="hljs-type">Tuple</span>, torch.Tensor, torch.Tensor]:<br>    <span class="hljs-string">&quot;&quot;&quot; Compute one forward step of the LSTM decoder, including the attention computation.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    @param Ybar_t (Tensor): Concatenated Tensor of [Y_t o_prev], with shape (b, e + h). The input for the decoder,</span><br><span class="hljs-string">                            where b = batch size, e = embedding size, h = hidden size.</span><br><span class="hljs-string">    @param dec_state (tuple(Tensor, Tensor)): Tuple of tensors both with shape (b, h), where b = batch size, h = hidden size.</span><br><span class="hljs-string">            First tensor is decoder&#x27;s prev hidden state, second tensor is decoder&#x27;s prev cell.</span><br><span class="hljs-string">    @param enc_hiddens (Tensor): Encoder hidden states Tensor, with shape (b, src_len, h * 2), where b = batch size,</span><br><span class="hljs-string">                                src_len = maximum source length, h = hidden size.</span><br><span class="hljs-string">    @param enc_hiddens_proj (Tensor): Encoder hidden states Tensor, projected from (h * 2) to h. Tensor is with shape (b, src_len, h),</span><br><span class="hljs-string">                                where b = batch size, src_len = maximum source length, h = hidden size.</span><br><span class="hljs-string">    @param enc_masks (Tensor): Tensor of sentence masks shape (b, src_len),</span><br><span class="hljs-string">                                where b = batch size, src_len is maximum source length. </span><br><span class="hljs-string"></span><br><span class="hljs-string">    @returns dec_state (tuple (Tensor, Tensor)): Tuple of tensors both shape (b, h), where b = batch size, h = hidden size.</span><br><span class="hljs-string">            First tensor is decoder&#x27;s new hidden state, second tensor is decoder&#x27;s new cell.</span><br><span class="hljs-string">    @returns combined_output (Tensor): Combined output Tensor at timestep t, shape (b, h), where b = batch size, h = hidden size.</span><br><span class="hljs-string">    @returns e_t (Tensor): Tensor of shape (b, src_len). It is attention scores distribution.</span><br><span class="hljs-string">                            Note: You will not use this outside of this function.</span><br><span class="hljs-string">                                  We are simply returning this value so that we can sanity check</span><br><span class="hljs-string">                                  your implementation.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    combined_output = <span class="hljs-literal">None</span><br><br>    <span class="hljs-comment"># YOUR CODE HERE (~3 Lines)</span><br>    <span class="hljs-comment"># <span class="hljs-doctag">TODO:</span></span><br>    <span class="hljs-comment">#     1. Apply the decoder to `Ybar_t` and `dec_state`to obtain the new dec_state.</span><br>    <span class="hljs-comment">#     2. Split dec_state into its two parts (dec_hidden, dec_cell)</span><br>    <span class="hljs-comment">#     3. Compute the attention scores e_t, a Tensor shape (b, src_len).</span><br>    <span class="hljs-comment">#        Note: b = batch_size, src_len = maximum source length, h = hidden size.</span><br>    <span class="hljs-comment">#</span><br>    <span class="hljs-comment">#       Hints:</span><br>    <span class="hljs-comment">#         - dec_hidden is shape (b, h) and corresponds to h^dec_t in the PDF (batched)</span><br>    <span class="hljs-comment">#         - enc_hiddens_proj is shape (b, src_len, h) and corresponds to W_&#123;attProj&#125; h^enc (batched).</span><br>    <span class="hljs-comment">#         - Use batched matrix multiplication (torch.bmm) to compute e_t.</span><br>    <span class="hljs-comment">#         - To get the tensors into the right shapes for bmm, you will need to do some squeezing and unsqueezing.</span><br>    <span class="hljs-comment">#         - When using the squeeze() function make sure to specify the dimension you want to squeeze</span><br>    <span class="hljs-comment">#             over. Otherwise, you will remove the batch dimension accidentally, if batch_size = 1.</span><br>    <span class="hljs-comment">#</span><br>    <span class="hljs-comment"># Use the following docs to implement this functionality:</span><br>    <span class="hljs-comment">#     Batch Multiplication:</span><br>    <span class="hljs-comment">#        https://pytorch.org/docs/stable/torch.html#torch.bmm</span><br>    <span class="hljs-comment">#     Tensor Unsqueeze:</span><br>    <span class="hljs-comment">#         https://pytorch.org/docs/stable/torch.html#torch.unsqueeze</span><br>    <span class="hljs-comment">#     Tensor Squeeze:</span><br>    <span class="hljs-comment">#         https://pytorch.org/docs/stable/torch.html#torch.squeeze</span><br><br>    <span class="hljs-comment"># 1,</span><br>    dec_state = self.decoder(Ybar_t, dec_state)<br>    (dec_hidden, dec_cell) = dec_state<br>    <span class="hljs-comment"># 3, (b, src_len, h) .dot(b, h, 1) -&gt; (b, src_len, 1) -&gt; (b, src_len)</span><br>    e_t = enc_hiddens_proj.bmm(dec_hidden.unsqueeze(<span class="hljs-number">2</span>)).squeeze(<span class="hljs-number">2</span>)<br>    <span class="hljs-comment">### END YOUR CODE</span><br><br>    <span class="hljs-comment"># Set e_t to -inf where enc_masks has 1</span><br>    <span class="hljs-keyword">if</span> enc_masks <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        e_t.data.masked_fill_(enc_masks.byte(), -<span class="hljs-built_in">float</span>(<span class="hljs-string">&#x27;inf&#x27;</span>)) <span class="hljs-comment"># mask the 0s with -inf, so e^x = 0</span><br><br>    <span class="hljs-comment"># YOUR CODE HERE (~6 Lines)</span><br>    <span class="hljs-comment"># <span class="hljs-doctag">TODO:</span></span><br>    <span class="hljs-comment">#     1. Apply softmax to e_t to yield alpha_t</span><br>    <span class="hljs-comment">#     2. Use batched matrix multiplication between alpha_t and enc_hiddens to obtain the</span><br>    <span class="hljs-comment">#         attention output vector, a_t.</span><br>    <span class="hljs-comment">#     Hints:</span><br>    <span class="hljs-comment">#           - alpha_t is shape (b, src_len)</span><br>    <span class="hljs-comment">#           - enc_hiddens is shape (b, src_len, 2h)</span><br>    <span class="hljs-comment">#           - a_t should be shape (b, 2h)</span><br>    <span class="hljs-comment">#           - You will need to do some squeezing and unsqueezing.</span><br>    <span class="hljs-comment">#     Note: b = batch size, src_len = maximum source length, h = hidden size.</span><br>    <span class="hljs-comment">#</span><br>    <span class="hljs-comment">#     3. Concatenate dec_hidden with a_t to compute tensor U_t</span><br>    <span class="hljs-comment">#     4. Apply the combined output projection layer to U_t to compute tensor V_t</span><br>    <span class="hljs-comment">#     5. Compute tensor O_t by first applying the Tanh function and then the dropout layer.</span><br>    <span class="hljs-comment">#</span><br>    <span class="hljs-comment"># Use the following docs to implement this functionality:</span><br>    <span class="hljs-comment">#     Softmax:</span><br>    <span class="hljs-comment">#         https://pytorch.org/docs/stable/nn.html#torch.nn.functional.softmax</span><br>    <span class="hljs-comment">#     Batch Multiplication:</span><br>    <span class="hljs-comment">#        https://pytorch.org/docs/stable/torch.html#torch.bmm</span><br>    <span class="hljs-comment">#     Tensor View:</span><br>    <span class="hljs-comment">#         https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view</span><br>    <span class="hljs-comment">#     Tensor Concatenation:</span><br>    <span class="hljs-comment">#         https://pytorch.org/docs/stable/torch.html#torch.cat</span><br>    <span class="hljs-comment">#     Tanh:</span><br>    <span class="hljs-comment">#         https://pytorch.org/docs/stable/torch.html#torch.tanh</span><br><br>    <span class="hljs-comment"># 1, apply softmax to e_t</span><br>    alpha_t = F.softmax(e_t, dim=<span class="hljs-number">1</span>) <span class="hljs-comment"># (b, src_len)</span><br>    <span class="hljs-comment"># 2, (b, 1, src_len) x (b, src_len, 2h) = (b, 1, 2h) -&gt; (b, 2h)</span><br>    <span class="hljs-comment"># a_t = e_t.unsqueeze(1).bmm(enc_hiddens).squeeze(1)</span><br>    att_view = (alpha_t.size(<span class="hljs-number">0</span>), <span class="hljs-number">1</span>, alpha_t.size(<span class="hljs-number">1</span>))<br>    a_t = torch.bmm(alpha_t.view(*att_view), enc_hiddens).squeeze(<span class="hljs-number">1</span>)<br><br>    <span class="hljs-comment"># 3, concate a_t (b, 2h) and dec_hidden (b, h) to U_t (b, 3h)</span><br>    U_t = torch.cat((a_t, dec_hidden), dim=<span class="hljs-number">1</span>)<br>    <span class="hljs-comment"># 4, apply combined output to U_T -&gt; V_t, shape (b, h)</span><br>    V_t = self.combined_output_projection(U_t)<br>    O_t = self.dropout(torch.tanh(V_t))<br><br>    <span class="hljs-comment"># END YOUR CODE</span><br><br>    combined_output = O_t<br>    <span class="hljs-keyword">return</span> dec_state, combined_output, e_t<br></code></pre></div></td></tr></table></figure><h3 id="g-generate_sent_masks">(g) generate_sent_masks</h3><p>The generate sent masks() function in nmt model.py produces a tensorcalled enc masks. It has shape (batch size, max source sentence length)and contains 1s in positions corresponding to pad tokens in the input,and 0s for non-pad tokens. Look at how the masks are used during theattention computation in the step() function (lines 295-296). Firstexplain (in around three sentences) what effect the masks have on theentire attention computation. Then explain (in one or two sentences) whyit is necessary to use the masks in this way.</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_sent_masks</span>(<span class="hljs-params">self, enc_hiddens: torch.Tensor, source_lengths: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; torch.Tensor:<br>    <span class="hljs-string">&quot;&quot;&quot; Generate sentence masks for encoder hidden states.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    @param enc_hiddens (Tensor): encodings of shape (b, src_len, 2*h), where b = batch size,</span><br><span class="hljs-string">                                 src_len = max source length, h = hidden size. </span><br><span class="hljs-string">    @param source_lengths (List[int]): List of actual lengths for each of the sentences in the batch.</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    @returns enc_masks (Tensor): Tensor of sentence masks of shape (b, src_len),</span><br><span class="hljs-string">                                where src_len = max source length, h = hidden size.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    enc_masks = torch.zeros(enc_hiddens.size(<span class="hljs-number">0</span>), enc_hiddens.size(<span class="hljs-number">1</span>), dtype=torch.<span class="hljs-built_in">float</span>)<br>    <span class="hljs-keyword">for</span> e_id, src_len <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(source_lengths):<br>        enc_masks[e_id, src_len:] = <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> enc_masks.to(self.device)<br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>NLP</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>-seq2seq</title>
    <link href="/2022/05/14/%E7%AC%AC%E5%85%AB%E8%AE%B2-%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E3%80%81seq2seq%E4%B8%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/"/>
    <url>/2022/05/14/%E7%AC%AC%E5%85%AB%E8%AE%B2-%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E3%80%81seq2seq%E4%B8%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/</url>
    
    <content type="html"><![CDATA[<h1 id="smt">1.SMT</h1><h2 id="">1.1 </h2><p>(MT)<spanclass="math inline">\(x\)</span>(<strong></strong>)(<strong></strong>)<spanclass="math inline">\(y\)</span></p><h2 id="s">1.2 1950s</h2><p>2050</p><ul><li>  ()</li><li><strong></strong></li></ul><h2 id="s-2010s">1.3 1990s-2010s</h2><p><strong></strong><strong></strong><strong></strong></p><p>  <spanclass="math inline">\(x\)</span><strong></strong><spanclass="math inline">\(y\  argmax_yP(y|x)\)</span>Bayes<strong></strong><span class="math display">\[argmaxx_yP(x|y)P(y)\]</span></p><ul><li><span class="math inline">\(P(x|y)\)</span><strong>TranslationModel / </strong><ul><li>()</li><li></li></ul></li><li><span class="math inline">\(P(y)\)</span><strong>Language Model /</strong><ul><li>()</li><li></li></ul></li></ul><h2 id="s-2010s-1">1.4 1990s-2010s</h2><p><strong></strong><spanclass="math inline">\(P(x|y)\)</span></p><p><strong></strong>(/)</p><h2 id="smt">1.5SMT</h2><p><strong></strong><spanclass="math inline">\(P(x|y)\)</span></p><p></p><p><span class="math display">\[P(x,a|y)\]</span></p><ul><li><span class="math inline">\(a\)</span></li><li><span class="math inline">\(x\)</span><spanclass="math inline">\(y\)</span></li></ul><h2 id="">1.6 </h2><p></p><ul><li></li></ul><p><img src="/img/nlp//1.png" /></p><h2 id="">1.7 </h2><p></p><p><img src="/img/nlp//2.png" /></p><p></p><p><img src="/img/nlp//3.png" /></p><p></p><p><strong></strong>()</p><p></p><ul><li>()</li><li>()</li></ul><h2 id="smt-1">1.8 SMT</h2><ul><li>argmax<ul><li><spanclass="math inline">\(y\)</span> </li></ul></li><li><ul><li><strong></strong></li></ul></li></ul><h2 id="smt">1.9 SMT</h2><p><img src="/img/nlp//4.png" /></p><p><img src="/img/nlp//5.png" /></p><h2 id="s-2010s-2">1.10 1990s-2010s</h2><p>SMT<strong></strong></p><p></p><ul><li></li><li><strong></strong></li><li><ul><li></li></ul></li><li><ul><li></li></ul></li><li><ul><li></li></ul></li></ul><h1 id="">2.</h1><h2 id="neural-machine-translationnmt">2.1Neural Machine Translation(NMT)</h2><p><strong></strong>(NMT)</p><p> <strong>sequence-to-sequence</strong>(seq2seq)RNNs</p><ul><li>RNN</li><li>RNN</li><li>RNN</li><li><strong></strong> </li></ul><p><img src="/img/nlp//6.png" /></p><h2 id="sequence-to-sequence">2.2Sequence-to-sequence</h2><p></p><p>NLP</p><ul><li><strong></strong>(  )</li><li><strong></strong>(  )</li><li><strong></strong>(  )</li><li><strong></strong>(  Python)</li></ul><h2 id="nmt">2.3 (NMT)</h2><p><strong>sequence-to-sequence</strong></p><ul><li>(Language Model)<spanclass="math inline">\(y\)</span></li><li>(Conditional)<spanclass="math inline">\(x\)</span></li></ul><p>NMT<span class="math inline">\(P(y|x)\)</span> <spanclass="math display">\[P(y \mid x)=P\left(y_{1} \mid x\right) P\left(y_{2} \mid y_{1}, x\right)P\left(y_{3} \mid y_{1}, y_{2}, x\right) \ldots P\left(y_{T} \mid y_{1},\ldots, y_{T-1}, x\right)\]</span></p><ul><li><spanclass="math inline">\(x\)</span></li></ul><p><strong></strong>NMT</p><p><strong></strong></p><h2 id="">2.4 </h2><p>Seq2seq</p><p><img src="/img/nlp//7.png" /></p><h1 id="">3.</h1><h2 id="">3.1 </h2><p>()argmax</p><p><strong></strong>()</p><p><strong></strong></p><p><img src="/img/nlp//8.png" /></p><h2 id="">3.2 </h2><p></p><p><img src="/img/nlp//9.png" /></p><p></p><h2 id="">3.3 </h2><p>(<spanclass="math inline">\(T\)</span>)<spanclass="math inline">\(y\)</span> <span class="math display">\[\begin{aligned}P(y \mid x) &amp;=P\left(y_{1} \mid x\right) P\left(y_{2} \mid y_{1},x\right) P\left(y_{3} \mid y_{1}, y_{2}, x\right) \ldots, P\left(y_{T}\mid y_{1}, \ldots, y_{T-1}, x\right) \\&amp;=\prod_{t=1}^{T} P\left(y_{t} \mid y_{1}, \ldots, y_{t-1}, x\right)\end{aligned}\]</span></p><p> - <spanclass="math inline">\(t\)</span><spanclass="math inline">\(V^t\)</span><spanclass="math inline">\(V\)</span>vocab  - <spanclass="math inline">\(O(V^t)\)</span><strong></strong></p><h2 id="">3.4 </h2><ul><li>([hypotheses] )<ul><li><spanclass="math inline">\(k\)</span>Beam(510)</li></ul></li><li><spanclass="math inline">\(y_1,y_2,...,y_t\)</span><strong></strong></li></ul><p><span class="math display">\[\operatorname{score}\left(y_{1}, \ldots, y_{t}\right)=\logP_{\mathrm{LM}}\left(y_{1}, \ldots, y_{t} \mid x\right)=\sum_{i=1}^{t}\log P_{\mathrm{LM}}\left(y_{i} \mid y_{1}, \ldots, y_{i-1}, x\right)\]</span></p><ul><li><p></p></li><li><p> top k </p></li><li><p> <strong></strong> </p></li><li><p><strong></strong></p></li></ul><h2 id="">3.5 </h2><p>Beam size = k = 2 <span class="math display">\[\operatorname{score}\left(y_{1}, \ldots, y_{t}\right)=\sum_{i=1}^{t}\log P_{\mathrm{LM}}\left(y_{i} \mid y_{1}, \ldots, y_{i-1}, x\right)\]</span> <img src="/img/nlp//10.png" /></p><ul><li></li><li><ul><li><spanclass="math inline">\(k\)</span><spanclass="math inline">\(k\)</span></li><li><ul><li><span class="math inline">\(t=2\)</span><code>hit</code>  <code>was</code></li><li><span class="math inline">\(t=3\)</span><code>a</code>  <code>me</code></li><li><span class="math inline">\(t=4\)</span><code>pie</code>  <code>with</code></li><li><span class="math inline">\(t=5\)</span><code>a</code>  <code>one</code></li><li><span class="math inline">\(t=6\)</span><code>pie</code></li></ul></li></ul></li><li></li><li></li></ul><h2 id="">3.6 </h2><ul><li><ul><li> he hit me with a pie</li></ul></li><li><strong></strong><ul><li><strong></strong></li><li><strong></strong> Beam Search</li></ul></li><li> Beam Search <ul><li><span class="math inline">\(T\)</span>(<spanclass="math inline">\(T\)</span>)</li><li><spanclass="math inline">\(n\)</span>(<spanclass="math inline">\(n\)</span>)</li></ul></li></ul><h2 id="">3.7 </h2><p>,</p><p><spanclass="math inline">\(y_1,...,y_t\)</span> <spanclass="math display">\[\operatorname{score}\left(y_{1}, \ldots, y_{t}\right)=\logP_{\mathrm{LM}}\left(y_{1}, \ldots, y_{t} \mid x\right)=\sum_{i=1}^{t}\log P_{\mathrm{LM}}\left(y_{i} \mid y_{1}, \ldots, y_{i-1}, x\right)\]</span> <strong></strong> </p><p><strong></strong>top one <spanclass="math display">\[\frac{1}{t} \sum_{i=1}^{t} \log P_{\mathrm{LM}}\left(y_{i} \mid y_{1},\ldots, y_{i-1}, x\right)\]</span></p><h2 id="nmt">3.8 (NMT)</h2><p>SMTNMT<strong></strong></p><p></p><ul><li></li><li></li><li></li></ul><p></p><ul><li></li></ul><p></p><ul><li></li><li></li></ul><h2 id="nmt">3.9 (NMT)</h2><p>SMTNMT<strong></strong></p><p>NMT</p><ul><li></li></ul><p>NMT</p><ul><li></li><li></li></ul><h1 id="">4.</h1><h2 id="">4.1 </h2><p>BLEU(Bilingual Evaluation Understudy)</p><ul><li> Assignment 4 BLEU</li></ul><p>BLEU()</p><ul><li>n-gram  (n1-4)</li><li></li></ul><p>BLEU</p><ul><li></li><li><strong></strong>BLEUscoren-gram</li></ul><h2 id="">4.2 </h2><p></p><p></p><ul><li><strong></strong></li><li><strong></strong></li><li></li><li><strong></strong></li></ul><p></p><ul><li>NMT</li><li></li></ul><h1 id="">5.</h1><h2 id="sequence-to-sequence">5.1Sequence-to-sequence</h2><ul><li></li><li></li><li></li></ul><p><img src="/img/nlp//11.png" /></p><h2 id="">5.2 </h2><p><strong></strong></p><p><strong></strong><strong></strong><strong></strong></p><p>()</p><h2 id="">5.3</h2><ul><li>token  DotProduct </li></ul><p><img src="/img/nlp//15.png" /></p><p><img src="/img/nlp//16.png" /></p><ul><li>softmax</li><li>(he)</li></ul><p><img src="/img/nlp//17.png" /></p><ul><li><strong></strong><strong></strong></li><li><strong></strong><strong></strong></li></ul><p><img src="/img/nlp//18.png" /></p><p><strong></strong><strong></strong><span class="math inline">\(\hat{y_1}\)</span></p><p><img src="/img/nlp//19.png" /></p><p>()4</p><p><img src="/img/nlp//20.png" /></p><p><img src="/img/nlp//21.png" /></p><p><img src="/img/nlp//12.png" /></p><h2 id="">5.4 </h2><p><span class="math inline">\(h_{1}, \ldots, h_{N}\in \mathbb{R}^{h}\)</span></p><p><spanclass="math inline">\(t\)</span><spanclass="math inline">\(s_{t} \in \mathbb{R}^{h}\)</span></p><p> <span class="math display">\[e^{t}=\left[s_{t}^{T} \boldsymbol{h}_{1}, \ldots, \boldsymbol{s}_{t}^{T}\boldsymbol{h}_{N}\right] \in \mathbb{R}^{N}\]</span> softmax<spanclass="math inline">\(\alpha^t\)</span>(1) <spanclass="math display">\[\alpha^{t}=\operatorname{softmax}\left(e^{t}\right) \in \mathbb{R}^{N}\]</span> <spanclass="math inline">\(\alpha^t\)</span><spanclass="math inline">\(\alpha^{t} \boldsymbol{a}_{t}=\sum_{i=1}^{N}\alpha_{i}^{t} \boldsymbol{h}_{i} \in \mathbb{R}^{h}\)</span></p><p><spanclass="math inline">\(\alpha^t\)</span>seq2seq  <span class="math display">\[\left[\boldsymbol{a}_{t} ; \boldsymbol{s}_{t}\right] \in \mathbb{R}^{2h}\]</span></p><h2 id="">5.5 </h2><p>NMT</p><ul><li></li></ul><p></p><ul><li></li></ul><p></p><ul><li></li></ul><p></p><ul><li></li><li>()</li><li></li><li></li></ul><h2 id="">5.6</h2><p></p><p><strong></strong>(seq2seq)(MT)</p><p> <strong>query attends to the values</strong></p><p>seq2seq +attention()()</p><h2 id="-1">5.7</h2><p></p><ul><li><strong></strong><strong></strong></li></ul><p></p><ul><li><strong></strong></li><li><strong>()</strong>()</li></ul><h2 id="">5.8 </h2><p><img src="/img/nlp//13.png" /></p><p><img src="/img/nlp//14.png" /></p>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>NLP</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>-RNN</title>
    <link href="/2022/05/13/%E7%AC%AC%E4%B8%83%E8%AE%B2-%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E9%97%AE%E9%A2%98%E4%B8%8ERNN%E5%8F%98%E7%A7%8D/"/>
    <url>/2022/05/13/%E7%AC%AC%E4%B8%83%E8%AE%B2-%E6%A2%AF%E5%BA%A6%E6%B6%88%E5%A4%B1%E9%97%AE%E9%A2%98%E4%B8%8ERNN%E5%8F%98%E7%A7%8D/</url>
    
    <content type="html"><![CDATA[<h1 id="">1.</h1><h2 id="">1.1 </h2><p></p><p><img src="/img/nlp//1.png" /></p><h2 id="">1.2 </h2><p><span class="math display">\[\boldsymbol{h}^{(t)}=\sigma\left(\boldsymbol{W}_{h}\boldsymbol{h}^{(t-1)}+\boldsymbol{W}_{x}\boldsymbol{x}^{(t)}+\boldsymbol{b}_{1}\right)\]</span></p><p><strong></strong> <span class="math display">\[\frac{\partial \boldsymbol{h}^{(t)}}{\partial\boldsymbol{h}^{(t-1)}}=\operatorname{diag}\left(\sigma^{\prime}\left(\boldsymbol{W}_{h}\boldsymbol{h}^{(t-1)}+\boldsymbol{W}_{x}\boldsymbol{x}^{(t)}+\boldsymbol{b}_{1}\right)\right) \boldsymbol{W}_{h}\]</span> <spanclass="math inline">\(i\)</span><spanclass="math inline">\(J^{(i)}(\theta)\)</span><spanclass="math inline">\(j\)</span><spanclass="math inline">\(h^{(j)}\)</span><spanclass="math inline">\(W_h\)</span><spanclass="math inline">\(i\)</span><spanclass="math inline">\(j\)</span></p><p> L2  <span class="math display">\[\left\|\frac{\partial J^{(i)}(\theta)}{\partial\boldsymbol{h}^{(j)}}\right\| \leq\left\|\frac{\partialJ^{(i)}(\theta)}{\partial\boldsymbol{h}^{(i)}}\right\|\left\|\boldsymbol{W}_{h}\right\|^{(i-j)}\prod_{j&lt;t \leqi}\left\|\operatorname{diag}\left(\sigma^{\prime}\left(\boldsymbol{W}_{h}\boldsymbol{h}^{(t-1)}+\boldsymbol{W}_{x}\boldsymbol{x}^{(t)}+\boldsymbol{b}_{1}\right)\right)\right\|\]</span> Pascanu et al <spanclass="math inline">\(W_h\)</span><strong></strong>&lt;1<spanclass="math inline">\(\left\|\frac{\partial J^{(i)}(\theta)}{\partial\boldsymbol{h}^{(j)}}\right\|\)</span><strong></strong></p><ul><li>1sigmoid</li></ul><p><strong></strong> &gt;1<strong></strong></p><h2 id="">1.3 </h2><p></p><p><img src="/img/nlp//2.png" /></p><p><strong></strong><strong></strong></p><p>(<spanclass="math inline">\(t\)</span><spanclass="math inline">\(t+n\)</span>)</p><ul><li><span class="math inline">\(t\)</span><spanclass="math inline">\(t+n\)</span><strong></strong></li><li><strong></strong><spanclass="math inline">\(t\)</span><spanclass="math inline">\(t+n\)</span></li></ul><h2 id="rnn">1.4RNN</h2><p><code>LM task: When she tried to print her tickets, she found that the printer was out of toner. She went to the stationery store to buy more toner. It was very overpriced. After installing the toner into the printer, she finally printed her ________</code></p><p>RNN-LM7 <code>tickets</code> <code>tickets</code><strong></strong></p><p><strong></strong></p><ul><li><strong></strong></li></ul><p><img src="/img/nlp//3.png" /></p><p>Correct answer: The writer of the books <u>is</u> planning asequel</p><ul><li><strong></strong>The <u>writer</u> of the books <u>is</u></li><li><strong></strong>The writer of the <u>books</u> <u>is</u></li></ul><p>RNN-LMs<strong></strong><strong></strong>[Linzenet al . 2016]</p><h2 id="">1.5 </h2><p>RNNRNN<span class="math display">\[\boldsymbol{h}^{(t)}=\sigma\left(\boldsymbol{W}_{h}\boldsymbol{h}^{(t-1)}+\boldsymbol{W}_{x}\boldsymbol{x}^{(t)}+\boldsymbol{b}\right)\]</span> RNN</p><h1 id="">2.</h1><h2 id="">2.1 </h2><p>SGD<strong></strong>()</p><p> <strong>Inf</strong> <strong>NaN</strong>()</p><h2 id="">2.2</h2><p><strong></strong>SGD</p><p><img src="/img/nlp//4.png" /></p><p><strong></strong></p><p>RNN()</p><p><img src="/img/nlp//5.png" /></p><p><strong></strong>(<strong></strong>)</p><p></p><h1 id="lstm">3.(LSTM)</h1><h2 id="lstm">3.1 (LSTM)</h2><p>HochreiterSchmidhuber1997RNN</p><p><spanclass="math inline">\(t\)</span><strong></strong><spanclass="math inline">\(h^{(t)}\)</span><strong></strong><spanclass="math inline">\(c^{(t)}\)</span></p><ul><li><span class="math inline">\(n\)</span></li><li></li><li>LSTM<strong></strong><strong></strong><strong></strong></li></ul><p>  /  /  </p><ul><li><span class="math inline">\(n\)</span></li><li><strong></strong>(1)<strong></strong>(0)</li><li><strong></strong></li></ul><p><img src="/img/nlp//6.png" /></p><p><spanclass="math inline">\(x^{(t)}\)</span><spanclass="math inline">\(h^{(t)}\)</span><spanclass="math inline">\(c^{(t)}\)</span><spanclass="math inline">\(t\)</span></p><ul><li><p><strong></strong></p></li><li><p><strong></strong></p></li><li><p><strong></strong></p></li><li><p><strong></strong></p></li><li><p><strong></strong>()()</p></li><li><p><strong></strong>(output)</p></li><li><p><strong>Sigmoid</strong>01</p></li><li><p></p></li><li><p>(<spanclass="math inline">\(n\)</span>)</p></li></ul><p><img src="/img/nlp//7.png" /></p><p><img src="/img/nlp//8.png" /></p><h2 id="lstm">3.2 LSTM</h2><p>RNNLSTM</p><ul><li></li><li>RNN<spanclass="math inline">\(W_h\)</span></li></ul><p>LSTM<strong>/</strong></p><h2 id="lstms">3.3 LSTMs</h2><p>2013-2015LSTM</p><ul><li></li><li><strong>LSTM</strong></li></ul><p>(2019)(<strong>Transformers</strong>)</p><ul><li>WMT(a MT conference + competition)</li><li>2016WMTRNN44</li><li>2018WMTRNN9Transformers 63</li></ul><h1 id="gru">4.GRU</h1><h2 id="gated-recurrent-unitsgru">4.1 Gated Recurrent Units(GRU)</h2><p>Cho2014LSTM<spanclass="math inline">\(t\)</span><spanclass="math inline">\(x^{(t)}\)</span><spanclass="math inline">\(h^{(t)}\)</span>()</p><ul><li><p><strong></strong></p></li><li><p><strong></strong></p></li><li><p><strong></strong></p></li><li><p><strong></strong></p></li></ul><p></p><ul><li>LSTMGRU(updategate0)</li></ul><p><img src="/img/nlp//9.png" /></p><h2 id="lstm-vs-gru">4.2 LSTM vs GRU</h2><p>RNNLSTMGRU</p><p><strong>GRU</strong><strong>LSTM</strong><strong></strong>()</p><p><strong></strong>LSTMGRU</p><h2 id="rnn">4.3 /RNN</h2><p><strong>/RNN</strong></p><p>()</p><ul><li>/</li><li>()</li><li> /<strong></strong>()</li></ul><p></p><ul><li>ResNet,</li><li></li><li></li></ul><p></p><ul><li>DenseNet</li><li></li></ul><p></p><ul><li>Highway</li><li></li><li>LSTMs/</li></ul><p>/RNN[Bengioet al, 1994]</p><h2 id="rnn">4.4 RNN</h2><p><img src="/img/nlp//10.png" /></p><p>terribly</p><p>(the movie was)</p><p>?</p><ul><li>excitingterribly()</li></ul><p><img src="/img/nlp//11.png" /></p><p>terribly</p><p><img src="/img/nlp//12.png" /></p><p>RNNLSTMGRU</p><p>RNN</p><p>RNNs</p><p><img src="/img/nlp//13.png" /></p><p>+</p><p>RNNs</p><ul><li>LM</li></ul><p>()<strong></strong>()</p><p>BERT(transformer)</p><ul><li>BERT!</li></ul><h2 id="rnn">4.5 RNN</h2><p>RNNsdeep()</p><p><strong>RNN</strong>RNN</p><p><strong>RNN</strong><strong></strong><strong>RNN</strong><strong></strong></p><p>RNNRNN</p><p><img src="/img/nlp//14.png" /></p><p>RNN<span class="math inline">\(i\)</span>RNN<spanclass="math inline">\(i+1\)</span></p><h2 id="rnn">4.6 RNN</h2><p>RNNs()</p><p>2017Britz et al24RNN,4RNN</p><ul><li><strong>skip-connections</strong> /<strong>dense-connections</strong> RNNs(8)</li><li>RNN</li></ul><p>Transformer-based (BERT)24</p><ul><li>BERT skipping-like</li></ul><h2 id="">4.7 </h2><ul><li>LSTMGRU</li><li></li><li></li><li>RNN/</li></ul><p><img src="/img/nlp//15.png" /></p><p></p><p>http://www.showmeai.tech/article-detail/241</p>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>NLP</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>-</title>
    <link href="/2022/05/12/%E7%AC%AC%E5%85%AD%E8%AE%B2-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/"/>
    <url>/2022/05/12/%E7%AC%AC%E5%85%AD%E8%AE%B2-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="">1.</h1><h2 id="-1">1.1 </h2><p>1<strong></strong></p><p><spanclass="math inline">\(x^{(1)},x^{(2)},...,x^{(t)}\)</span><spanclass="math inline">\(x^{(t+1)}\)</span> <spanclass="math display">\[P(x^{(t+1)}| x^{(t)}, ..., x^{(1)})\]</span></p><ul><li><spanclass="math inline">\(x^{(t+1)}\)</span><spanclass="math inline">\(V={w_1,...,w_v}\)</span></li><li> Language Model </li></ul><p>2<strong></strong></p><p><spanclass="math inline">\(x^{(1)},x^{(2)},...,x^{(T)}\)</span>()<span class="math display">\[\begin{aligned}P\left(\boldsymbol{x}^{(1)}, \ldots, \boldsymbol{x}^{(T)}\right)&amp;=P\left(\boldsymbol{x}^{(1)}\right) \timesP\left(\boldsymbol{x}^{(2)} \mid \boldsymbol{x}^{(1)}\right) \times\cdots \times P\left(\boldsymbol{x}^{(T)} \mid \boldsymbol{x}^{(T-1)},\ldots, \boldsymbol{x}^{(1)}\right) \\&amp;=\prod_{t=1}^{T} P\left(\boldsymbol{x}^{(t)} \mid\boldsymbol{x}^{(t-1)}, \ldots, \boldsymbol{x}^{(1)}\right)\end{aligned}\]</span></p><ul><li><span class="math inline">\(\prod_{t=1}^{T}P\left(\boldsymbol{x}^{(t)} \mid \boldsymbol{x}^{(t-1)}, \ldots,\boldsymbol{x}^{(1)}\right)\)</span></li></ul><h2 id="n-gram-">1.2 n-gram </h2><figure class="highlight fortran"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs fortran">the students <span class="hljs-keyword">opened</span> their __<br></code></pre></div></td></tr></table></figure><p><strong></strong></p><p><strong></strong>() n-gram</p><p><strong></strong>n-gram<spanclass="math inline">\(n\)</span></p><ul><li><strong>uni</strong>grams: <code>the</code>, <code>students</code>,<code>opened</code>, <code>their</code></li><li><strong>bi</strong>grams: <code>the students</code>,<code>students opened</code>, <code>opened their</code></li><li><strong>tri</strong>grams: <code>the students opened</code>,<code>students opened their</code></li><li><strong>4-</strong>grams:<code>the students opened their</code></li></ul><p><strong></strong> n-gram</p><p><spanclass="math inline">\(x^{(t+1)}\)</span><spanclass="math inline">\(n-1\)</span> <span class="math display">\[P\left(\boldsymbol{x}^{(t+1)} \mid \boldsymbol{x}^{(t)}, \ldots,\boldsymbol{x}^{(1)}\right)=P(\boldsymbol{x}^{(t+1)} \mid\overbrace{\left.\boldsymbol{x}^{(t)}, \ldots,\boldsymbol{x}^{(t-n+2)}\right)}^{n-1 \text { words }}\]</span> <strong></strong>n-gram(n-1)-gram</p><p><strong></strong>()<span class="math display">\[\approx \frac{\operatorname{count}\left(\boldsymbol{x}^{(t+1)},\boldsymbol{x}^{(t)}, \ldots,\boldsymbol{x}^{(t-n+2)}\right)}{\operatorname{count}\left(\boldsymbol{x}^{(t)},\ldots, \boldsymbol{x}^{(t-n+2)}\right)}\]</span></p><h2 id="n-gram-">1.3 n-gram </h2><p> <strong>4-gram</strong> </p><p><code>as the proctor started the clock, the students opened their ____</code><code>students opened their _____</code></p><ul><li><ul><li><code>students opened their</code> 1000</li><li><code>students opened their books</code> 400</li></ul></li></ul><p><span class="math display">\[P(books|students \ opened \ their) = 0.4\]</span></p><ul><li><code>students opened their exams</code> 100</li></ul><p><span class="math display">\[P(exams|students \ opened \ their) = 0.1\]</span></p><ul><li>proctor<ul><li> <code>proctor</code><code>exams</code>  <code>books</code></li></ul></li></ul><h2 id="n-gram">1.4 n-gram</h2><p><strong>1</strong><code>students open their ww</code>0</p><ul><li>(Partial)<strong></strong><spanclass="math inline">\(w\in V\)</span><spanclass="math inline">\(\delta\)</span></li></ul><p><strong>2</strong><code>students open their</code><spanclass="math inline">\(w\)</span></p><ul><li><p>(Partial)<strong></strong><code>open their</code></p></li><li><p>Note/: <spanclass="math inline">\(n\)</span><spanclass="math inline">\(n\)</span>5</p></li></ul><h2 id="n-gram">1.5 n-gram</h2><p><strong></strong> n-grams</p><p><spanclass="math inline">\(n\)</span></p><h2 id="n-gram">1.6 n-gram</h2><ul><li><p></p></li><li><p>trigram</p></li><li><p><spanclass="math inline">\(n\)</span></p></li></ul><h2 id="">1.7 </h2><p></p><ul><li><strong></strong><span class="math inline">\(x^{(1)},x^{(2)}, ...,x^{(t)}\)</span></li><li><strong></strong><spanclass="math inline">\(P\left(\boldsymbol{x}^{(t+1)} \mid\boldsymbol{x}^{(t)}, \ldots, \boldsymbol{x}^{(1)}\right)\)</span></li></ul><p><img src="/img/nlp//1.png" /></p><h2 id="">1.8 </h2><p><img src="/img/nlp//2.png" /></p><p> n-gram <strong></strong></p><ul><li></li><li>n-grams</li></ul><p>NNLM<strong></strong></p><ul><li></li><li><spanclass="math inline">\(W\)</span></li><li></li><li><span class="math inline">\(x^{(1)}\)</span><spanclass="math inline">\(x^{(2)}\)</span></li></ul><p></p><h1 id="rnn">2.(RNN)</h1><h2 id="rnn-1">2.1 (RNN)</h2><p><img src="/img/nlp//3.png" /></p><p><img src="/img/nlp//4.png" /></p><ul><li>RNN<ul><li><strong></strong></li><li><spanclass="math inline">\(t\)</span>()<strong></strong></li><li><strong></strong><strong></strong></li><li><strong></strong></li></ul></li><li>RNN<ul><li></li><li></li></ul></li></ul><h2 id="rnn">2.2 RNN</h2><p><strong></strong></p><p>RNN-LM</p><ul><li></li></ul><p><spanclass="math inline">\(t\)</span><strong></strong><spanclass="math inline">\(\hat{y}^{(t)}\)</span><spanclass="math inline">\(y^{(t)}\)</span>(<spanclass="math inline">\(x^{(t+1)}\)</span>)<strong></strong><span class="math display">\[J^{(t)}(\theta)=C E\left(\boldsymbol{y}^{(t)},\hat{\boldsymbol{y}}^{(t)}\right)=-\sum_{w \in V}\boldsymbol{y}_{w}^{(t)} \log \hat{\boldsymbol{y}}_{w}^{(t)}=-\log\hat{\boldsymbol{y}}_{\boldsymbol{x}_{t+1}}^{(t)}\]</span> <strong></strong> <spanclass="math display">\[J(\theta)=\frac{1}{T} \sum_{t=1}^{T} J^{(t)}(\theta)=\frac{1}{T}\sum_{t=1}^{T}-\log \hat{\boldsymbol{y}}_{\boldsymbol{x}_{t+1}}^{(t)}\]</span> <img src="/img/nlp//5.png" /></p><p><spanclass="math inline">\(x^{(1)},...,x^{(T)}\)</span><spanclass="math inline">\(x^{(1)},...,x^{(T)}\)</span></p><p></p><p><spanclass="math inline">\(J(\theta)\)</span>()</p><h2 id="rnn">2.3 RNN</h2><p><strong></strong><spanclass="math inline">\(W_h\)</span><spanclass="math inline">\(J^{(t)}(\theta)\)</span></p><p><strong></strong> <spanclass="math display">\[\frac{\partial J^{(t)}}{\partial\boldsymbol{W}_{\boldsymbol{h}}}=\left.\sum_{i=1}^{t} \frac{\partialJ^{(t)}}{\partial \boldsymbol{W}_{\boldsymbol{h}}}\right|_{(i)}\]</span> <img src="/img/nlp//6.png" /></p><p><strong></strong></p><p><strong></strong><spanclass="math inline">\(i=t,...,0\)</span>backpropagation through time</p><h2 id="rnn">2.4 RNN</h2><p>n-gramRNN</p><p><img src="/img/nlp//7.png" /></p><h1 id="">3.</h1><h2 id="-1">3.1 </h2><p> perplexity <spanclass="math inline">\(J(\theta)\)</span> <spanclass="math display">\[=\prod_{t=1}^{T}\left(\frac{1}{\hat{y}_{x_{t+1}}^{(t)}}\right)^{1 /T}=\exp \left(\frac{1}{T} \sum_{t=1}^{T}-\log\hat{\boldsymbol{y}}_{\boldsymbol{x}_{t+1}}^{(t)}\right)=\exp(J(\theta))\]</span> </p><h2 id="rnn">3.2 RNN</h2><p></p><ul><li></li></ul><p>NLP</p><ul><li>/</li></ul><h2 id="">3.3 </h2><p><strong></strong>LM: LanguageModel</p><p></p><ul><li></li><li></li><li></li></ul><p><spanclass="math inline">\(\ne\)</span>RNNsLMRNNs!</p><h2 id="rnn">3.4 RNN</h2><p><img src="/img/nlp//8.png" /></p><h2 id="rnn">3.5 RNN</h2><p></p><p><strong></strong></p><p><img src="/img/nlp//9.png" /></p><p>EncoderNLP</p><p><img src="/img/nlp//10.png" /></p><h2 id="rnn">3.6 RNN</h2><p></p><p><img src="/img/nlp//11.png" /></p><p></p><p>http://www.showmeai.tech/article-detail/240</p>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>NLP</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>-</title>
    <link href="/2022/05/12/%E7%AC%AC%E4%BA%94%E8%AE%B2-%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90%E4%B8%8E%E4%BE%9D%E5%AD%98%E8%A7%A3%E6%9E%90/"/>
    <url>/2022/05/12/%E7%AC%AC%E4%BA%94%E8%AE%B2-%E5%8F%A5%E6%B3%95%E5%88%86%E6%9E%90%E4%B8%8E%E4%BE%9D%E5%AD%98%E8%A7%A3%E6%9E%90/</url>
    
    <content type="html"><![CDATA[<h1 id="">1.</h1><h2 id="">1.1</h2><p></p><ul><li>CFGcontext-free grammars </li></ul><p><strong></strong>part of speech = pos</p><ul><li>the, cat, cuddly, by, door</li><li>Det, N, Adj, P, N</li></ul><p><strong></strong><strong></strong></p><ul><li>the cuddly cat NP =&gt; Det Adj N</li><li>by the door PP =&gt;P N P</li></ul><p><strong></strong><strong></strong></p><ul><li>the cuddly cat by the door=&gt; NP  NP PP</li></ul><p></p><ul><li><strong>Det</strong> <code>Determiner</code> <strong></strong></li><li><strong>NP</strong> <code>Noun Phrase</code><strong></strong></li><li><strong>VP</strong> <code>Verb Phrase</code><strong></strong></li><li><strong>P</strong> <code>Preposition</code> <strong></strong></li><li><strong>PP</strong> <code>Prepositional Phrase</code><strong></strong></li></ul><p><img src="/img/nlp//1.png" /></p><h2 id="">1.2</h2><p>()</p><p><img src="/img/nlp//2.png" /></p><ul><li><p>looklookcrate(cratelook</p><ul><li><p><code>in</code><code>the</code><code>large</code> <code>crate</code> </p></li><li><p><code>in the kitchen</code>  <code>crate</code> </p></li><li><p><code>in</code><code>the</code>  <code>kitchen</code></p></li><li><p><code>by the door</code>  <code>crate</code> </p></li></ul></li></ul><h2 id="">1.3 </h2><p></p><p></p><p></p><h2 id="">1.4 </h2><p>1<code>San Jose cops kill man with knife</code></p><ul><li><ul><li><code>cops</code>  <code>kill</code>  <code>subject</code>(subject  <strong></strong>)</li><li><code>man</code>  <code>kill</code>  <code>object</code> (object <strong></strong>)</li><li><code>knife</code>  <code>kill</code>  <code>modifier</code>(modifier  <strong></strong>)</li></ul></li><li><ul><li><code>knife</code>  <code>man</code>  <code>modifier</code>( <code>nmod</code>)</li></ul></li></ul><p>2<code>Scientists count whales from space</code></p><ul><li><code>from space</code><code>count</code><code>whales</code>?<ul><li></li></ul></li></ul><h2 id="">1.5 </h2><p></p><ul><li></li></ul><p><code>The board approved [ its acquisition ] [ by Royal Trustco Ltd. ] [ of Toronto ] [ for $27 a share ] [ at its monthly meeting ].</code></p><ul><li><code>board</code>  <code>approved</code><code>acquisition</code>  <code>approved</code> </li><li><code>by Royal Trustco Ltd.</code>  <code>acquisition</code></li><li><code>of Toronto</code> <code>approved</code><code>acquisition</code><code>Royal Trustco Ltd.</code><code>Royal Trustco Ltd.</code></li><li><code>for $27 a share</code>  <code>acquisition</code></li><li><code>at its monthly meeting</code> <code>approved</code></li></ul><p>  <strong>/Catalan numbers</strong><span class="math display">\[C_{n}=(2 n) ! /[(n+1) ! n !]\]</span></p><h2 id="">1.6 </h2><p>1<code>Shuttle veteran and longtime NASA executive Fred Gregory appointed to board</code></p><ul><li><code>[[Shuttle veteran and longtime NASA executive] Fred Gregory] appointed to board</code></li><li><code>[Shuttle veteran] and [longtime NASA executive Fred Gregory] appointed to board</code></li></ul><p>2<code>Students get first hand job experience</code></p><ul><li><code>first hand</code><ul><li><code>first</code>  <code>hand</code> (amod)</li></ul></li><li><code>first</code>  <code>experience</code><code>hand</code> <code>job</code></li></ul><h2 id="vp">1.7 (VP)</h2><p><code>Mutilated body washes up on Rio beach to be used for Olympic beach volleyball</code></p><ul><li><code>to be used for Olympic beach volleyball</code>  (VP)</li><li> <code>body</code>  <code>beach</code></li></ul><h1 id="">2.</h1><h2 id="-">2.1 ##</h2><p><img src="/img/nlp//3.png" /></p><h2 id="">2.2 </h2><p>()<strong></strong></p><p><strong>Dependency Structure</strong></p><ol type="1"><li><p><strong></strong></p></li><li><p><strong>(Dependency TreeGraph)</strong></p></li></ol><ul><li>(type)(apposition)</li><li>(head)(regent)()</li><li>()</li></ul><h2 id="">2.3 /</h2><ul><li><ul><li>Paini(5)</li><li></li></ul></li><li>/<ul><li>20(R.S.Wells,1947; then Chomsky)</li></ul></li><li> L. Tesnire(1959)<ul><li>20()<ul><li></li></ul></li></ul></li><li>NLP<ul><li>David Hays(?)(Hays1962)</li></ul></li></ul><h2 id="">2.4 </h2><ul><li><ul><li>Tesnire </li></ul></li><li></li></ul><p><img src="/img/nlp//4.png" /></p><h2 id="">2.5</h2><p><img src="/img/nlp//5.png" /></p><h2 id="">2.6 </h2><ul><li><p><strong> treebank</strong></p></li><li><p> treebank </p><ul><li><ul><li></li><li></li></ul></li><li></li><li></li><li></li></ul></li></ul><h2 id="">2.7 </h2><p><strong></strong></p><p>1.<strong>Bilexical affinities</strong> () -[discussion  issues] </p><p>2.<strong>Dependency distance </strong> - </p><p>3.<strong>Intervening material </strong> -</p><p>4.<strong>Valency of heads</strong> - How many dependents on whichside are usual for a head?</p><p><img src="/img/nlp//6.png" /></p><h2 id="">2.8 </h2><ul><li><p>()</p></li><li><p></p><ul><li></li><li> ABBA</li></ul></li><li><p></p></li><li><p>( non-projective)</p><ul><li>non-projectice</li></ul></li></ul><p><img src="/img/nlp//7.png" /></p><h2 id="">2.9 </h2><ul><li><p></p></li><li><p>CFG</p><ul><li></li></ul></li><li><p></p><ul><li></li></ul></li></ul><h2 id="">2.10 </h2><p>1.<strong>Dynamic programming</strong></p><ul><li>Eisner(1996) O(n3)</li></ul><p>2.<strong>Graph algorithms</strong></p><ul><li></li><li>McDonald et al.s (2005) MSTParserML(MIRA)</li></ul><p>3.<strong>Constraint Satisfaction</strong></p><ul><li> Karlsson(1990), etc.</li></ul><p>4.<strong>Transition-based parsing or deterministic dependencyparsing</strong></p><ul><li> MaltParser(Nivreet al. 2008)</li></ul><h1 id="">3.</h1><h2 id="-greedy-transition-based-parsing-nivre-2003">3.1## Greedy transition-based parsing [Nivre 2003]</h2><ul><li></li><li><ul><li>shift-reduceshiftreducereduce</li></ul></li><li><ul><li><span class="math inline">\(\sigma\)</span> ROOT<span class="math inline">\(w_i\)</span></li><li><spanclass="math inline">\(\beta\)</span><spanclass="math inline">\(w_i\)</span></li><li><spanclass="math inline">\(A\)</span><spanclass="math inline">\((w_i,r,w_j)\)</span><spanclass="math inline">\(r\)</span></li><li></li></ul></li></ul><h2 id="">3.2</h2>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>NLP</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>-</title>
    <link href="/2022/05/08/%E7%AC%AC%E5%9B%9B%E8%AE%B2-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E4%B8%8E%E8%AE%A1%E7%AE%97%E5%9B%BE/"/>
    <url>/2022/05/08/%E7%AC%AC%E5%9B%9B%E8%AE%B2-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E4%B8%8E%E8%AE%A1%E7%AE%97%E5%9B%BE/</url>
    
    <content type="html"><![CDATA[<h1id="">1.</h1><h2 id="">1.1 </h2><ul><li><p><span class="math inline">\(\frac{\partials}{\partial W}\)</span></p></li><li><p>:</p></li><li><p><span class="math display">\[\frac{\partial s}{\partial W}=\frac{\partial s}{\partial h}\frac{\partial h}{\partial z} \frac{\partial z}{\partial W}\]</span></p></li><li><p><span class="math display">\[s=u^{T} h, \ \ \ h=f(z),\ \ \ z=Wx+b\]</span></p></li></ul><h2 id="">1.2 </h2><ul><li><p>()</p></li><li><p><span class="math display">\[\frac{\partial s}{\partial W}=\delta \frac{\partial z}{\partialW}=\delta \frac{\partial}{\partial W} W x+b\]</span></p></li><li><p><spanclass="math inline">\(W_{ij}\)</span></p></li><li><p><span class="math inline">\(W_{ij}\)</span><spanclass="math inline">\(z_i\)</span></p></li></ul><p><span class="math display">\[\begin{aligned}\frac{\partial z_{i}}{\partial W_{i j}} &amp;=\frac{\partial}{\partialW_{i j}} W_{i .} x+b_{i} \\&amp;=\frac{\partial}{\partial W_{i j}} \sum_{k=1}^{d} W_{i k}x_{k}=x_{j}\end{aligned}\]</span></p><p><img src="/img/nlp//1.png" /></p><ul><li><p><spanclass="math inline">\(W_{ij}\)</span></p></li><li><p><span class="math display">\[\frac{\partial s}{\partial W_{i j}}=\delta_{i} x_{j}\]</span></p></li><li><p><spanclass="math inline">\(W\)</span></p></li><li><p><strong></strong></p></li><li><p><span class="math display">\[\begin{aligned}\frac{\partial s}{\partial W} &amp;=\delta^{T} x^{T} \\{[n \times m] } &amp;=[n \times 1][1 \times m]\end{aligned}\]</span></p></li></ul><h2 id="">1.3 </h2><ul><li><p></p></li><li><p><span class="math inline">\(\nabla_{x} J=W^{T}\delta=\delta_{x_{\text {window }}}\)</span></p></li><li><p><span class="math inline">\(X_{\text {window}}=\left[\begin{array}{lllll} X_{\text {museums }} &amp; X_{\text {in }}&amp; X_{\text {Paris }} &amp; X_{\text {are }} &amp; X_{\text {amazing}} \end{array}\right]\)</span></p></li><li><p><span class="math inline">\(\delta_{\text {window}}=\left[\begin{array}{c} \nabla_{x_{\text {museums }}} \\\nabla_{x_{\text {in }}} \\ \nabla_{x_{\text {Pare }}} \\\nabla_{x_{\text {are }}} \\ \nabla_{x_{\text {amazing }}}\end{array}\right] \in \mathbb{R}^{5 d}\)</span></p></li><li><p></p></li></ul><h2 id="">1.4 </h2><ul><li>()</li><li><spanclass="math inline">\(x_{in}\)</span>Location</li></ul><h2 id="">1.5 </h2><ul><li><p><strong></strong></p></li><li><p><strong></strong>TVtelly</p></li><li><p><strong></strong>television</p></li><li><p><strong></strong></p><p><img src="/img/nlp//2.png" /></p></li><li><p><strong></strong></p></li><li><p></p><ul><li></li><li>TVtelly</li><li></li><li>television</li></ul></li></ul><p><img src="/img/nlp//3.png" /></p><h2 id="">1.6 </h2><ul><li><p><strong></strong></p></li><li><p></p><ul><li></li><li></li><li></li></ul></li><li><p><strong></strong>(finetune)</p></li><li><p></p><ul><li></li><li> train = update= fine-tune </li></ul></li></ul><h1 id="">2.</h1><h2 id="">2.1 </h2><ul><li><ul><li>()</li></ul></li><li></li></ul><h2 id="">2.2 </h2><ul><li><ul><li></li><li></li><li></li></ul></li></ul><p><span class="math display">\[\begin{array}{l}s=u^{T} h \\h=f(z) \\z=W x+b \\x \quad(\text { input) }\end{array}\]</span></p><p><img src="/img/nlp//4.png" /></p><h2 id="">2.3 </h2><ul><li><ul><li></li></ul></li><li> local gradient<ul><li></li></ul></li><li> = <spanclass="math inline">\(\times\)</span></li></ul><p><img src="/img/nlp//5.png" /></p><ul><li></li></ul><p><img src="/img/nlp//6.png" /></p><h2 id="">2.4 </h2><p><img src="D:\blog\source\img\nlp\\7.png" /></p><h2 id="">2.5 </h2><p><span class="math inline">\(\frac{\partial f}{\partialy}\)</span> <span class="math display">\[\begin{array}{c}a=x+y \\b=\max (y, z) \\f=a b \\\frac{\partial f}{\partial y}=\frac{\partial f}{\partial a}\frac{\partial a}{\partial y}+\frac{\partial f}{\partial b}\frac{\partial b}{\partial y}\end{array}\]</span></p><h2 id="">2.6 </h2>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>NLP</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>-</title>
    <link href="/2022/05/06/%E7%AC%AC%E4%B8%89%E8%AE%B2-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86/"/>
    <url>/2022/05/06/%E7%AC%AC%E4%B8%89%E8%AE%B2-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9F%A5%E8%AF%86/</url>
    
    <content type="html"><![CDATA[<h1 id="">1 </h1><h2 id="">1.1 </h2><p><strong></strong><strong></strong><span class="math display">\[\{x_i,y_i\}^N_{i=1}\]</span></p><ul><li><spanclass="math inline">\(x_i\)</span><strong></strong>()(d)</li><li><spanclass="math inline">\(y_i\)</span>(C)<ul><li>/</li><li></li><li>()</li></ul></li></ul><h2 id="">1.2 </h2><ul><li><p>2</p><ul><li>softmax / logistic</li><li></li></ul></li><li><p><strong>/</strong><spanclass="math inline">\(x_i\)</span> softmax/logistic<span class="math inline">\(W \in R^{C \timesd}\)</span>()</p></li><li><p><strong></strong><spanclass="math inline">\(x\)</span>:</p></li></ul><p><span class="math display">\[p(y \mid x)=\frac{\exp \left(W_{y} \cdot x\right)}{\sum_{c=1}^{C} \exp\left(W_{c} \cdot x\right)}\]</span></p><h2 id="softmax">1.3 softmax</h2><p><strong></strong></p><h3 id="wythx">1 <spanclass="math inline">\(W\)</span><spanclass="math inline">\(y^{th}\)</span><spanclass="math inline">\(x\)</span></h3><p><span class="math display">\[W_{y} \cdot x=\sum_{i=1}^{d} W_{y i} x_{i}=f_{y}\]</span></p><p>c=12...C<spanclass="math inline">\(f_y\)</span></p><h3 id="softmax">2softmax</h3><p><span class="math display">\[p(y \mid x)=\frac{\exp \left(f_{y}\right)}{\sum_{c=1}^{C} \exp\left(f_{c}\right)}=\operatorname{softmax}\left(f_{y}\right)\]</span></p><h2 id="softmax">1.4 softmax</h2><p>softmax</p><p><spanclass="math inline">\((x,y)\)</span><strong></strong><spanclass="math inline">\(y\)</span><strong></strong>:<span class="math display">\[-\log p(y \mid x)=-\log \left(\frac{\exp\left(f_{y}\right)}{\sum_{c=1}^{C} \exp \left(f_{c}\right)}\right)\]</span></p><h2 id="">1.5 </h2><ul><li></li><li><spanclass="math inline">\(p\)</span><spanclass="math inline">\(q\)</span></li><li></li></ul><p><span class="math display">\[H(p, q)=-\sum_{c=1}^{C} p(c) \log q(c)\]</span></p><ul><li>10</li></ul><p><span class="math display">\[p=[0,...,0,1,...,0]\]</span></p><ul><li>(one-hotvector)</li></ul><h2 id="">1.6 </h2><p><spanclass="math inline">\(\{x_i,y_i\}_{i=1}^N\)</span><span class="math display">\[J(\theta)=\frac{1}{N} \sum_{i=1}^{N}-\log\left(\frac{e^{f_{y_{i}}}}{\sum_{c=1}^{C} e^{f_{c}}}\right)\]</span>  <span class="math display">\[f_{y}=f_{y}(x)=W_{y} \cdot x=\sum_{j=1}^{d} W_{y j} x_{j}\]</span> <spanclass="math inline">\(f:f=W_x\)</span></p><h2 id="">1.7 </h2><p><spanclass="math inline">\(\theta\)</span><spanclass="math inline">\(W\)</span> <span class="math display">\[\theta=\left[\begin{array}{c}W_{\cdot 1} \\\vdots \\W_{\cdot d}\end{array}\right]=W(:) \in \mathbb{R}^{C d}\]</span> <strong></strong> <spanclass="math display">\[\nabla_{\theta} J(\theta)=\left[\begin{array}{c}\nabla_{W_{1}} \\\vdots \\\nabla_{W_{d}}\end{array}\right] \in \mathbb{R}^{C d}\]</span></p><h2 id="">1.8 </h2><ul><li>Softmax(  logistic)</li></ul><p><img src="/img/nlp//1.png" /></p><ul><li>Softmax<ul><li></li><li></li></ul></li></ul><h2 id="">1.9 </h2><ul><li><p></p></li><li><p>tip </p><ul><li></li><li></li></ul></li></ul><h2 id="">1.10 </h2><ul><li>NLP<ul><li><span class="math inline">\(W\)</span><spanclass="math inline">\(x\)</span></li><li></li><li>()softmax</li></ul></li><li></li></ul><p><span class="math display">\[\nabla_{\theta} J(\theta)=\left[\begin{array}{c}\nabla_{W_{1}} \\\vdots \\\nabla_{W_{\text {dardvark }}} \\\vdots \\\nabla_{x_{z e b r a}}\end{array}\right] \in \mathbb{R}^{C d+V d}\]</span></p><ul><li><span class="math inline">\(Vd\)</span></li></ul><h2 id="">1.11 </h2><ul><li>An artificial neuron<ul><li></li><li> softmax</li></ul></li><li>Neural computation</li><li>Neural selectivity</li><li>Hierarchy of neural processing</li></ul><h2 id="">1.12</h2><p><span class="math display">\[h_{w, b}(x)=f\left(w^{T} x+b\right)\]</span></p><p><span class="math display">\[f(z)=\frac{1}{1+e^{-z}}\]</span></p><ul><li><spanclass="math inline">\(b\)</span></li><li><span class="math inline">\(w\)</span><spanclass="math inline">\(b\)</span></li></ul><h2 id="">1.13</h2><ul><li></li><li></li></ul><p><img src="/img/nlp//2.png" /></p><ul><li>logistic</li><li></li></ul><p><img src="/img/nlp//3.png" /></p><p></p><p><img src="/img/nlp//4.png" /></p><h2 id="">1.14 </h2><p> <span class="math display">\[a_{1}=f\left(W_{11} x_{1}+W_{12} x_{2}+W_{13} x_{3}+b_{1}\right)\]</span></p><p><span class="math display">\[a_{2}=f\left(W_{21} x_{1}+W_{22} x_{2}+W_{23} x_{3}+b_{2}\right)\]</span></p><p> <span class="math display">\[z=Wx+b\]</span> <spanclass="math inline">\(f\)</span>element-wise <spanclass="math display">\[f\left(\left[z_{1}, z_{2},z_{3}\right]\right)=\left[f\left(z_{1}\right), f\left(z_{2}\right),f\left(z_{3}\right)\right]\]</span> <img src="/img/nlp//5.png" /></p><h2 id="">1.15 </h2><ul><li><ul><li></li><li><spanclass="math inline">\(W_1W_2x=Wx\)</span></li></ul></li><li></li><li></li></ul><h1 id="">2 </h1><h2 id="ner">2.1 (NER)</h2><ul><li><ul><li>()</li><li></li><li></li><li> slot-filling </li></ul></li><li>/</li></ul><h2 id="">2.2 </h2><p></p><p><img src="/img/nlp//6.png" /></p><h2 id="ner">2.3 NER</h2><ul><li><ul><li> First National Bank  National Bank</li></ul></li><li><ul><li>Future School </li></ul></li><li>/<ul><li>Zig Ziglar ? </li></ul></li><li><ul><li>Charles Schwab  PER  ORG</li></ul></li></ul><h1 id="">3.</h1><h2 id="-">3.1. -</h2><ul><li><ul><li></li></ul></li><li><ul><li></li></ul></li><li><ul><li></li></ul></li></ul><h2 id="softmax">3.2 softmax</h2><ul><li><p>softmax</p></li><li><p>Paris2</p></li><li><p><span class="math inline">\(x_{w i n d o w}=x \in R^{5d}\)</span></p></li></ul><h2 id="softmax">3.3 Softmax</h2><p><spanclass="math inline">\(x=x_{window}\)</span>softmax<span class="math display">\[\hat{y}_{y}=p(y \mid x)=\frac{\exp \left(\sqrt{W_{y} \cdotx}\right)}{\sum_{c=1}^{C} \exp \left(W_{c} \cdot x\right)}\]</span> <strong></strong></p><ul><li></li></ul><h2 id="">3.4 </h2><ul><li><p></p></li><li><p>word2vec</p><ul><li>NERLocation</li></ul></li></ul><h2 id="">3.5 </h2><p><spanclass="math inline">\(a\)</span> <spanclass="math display">\[\operatorname{score}(x)=U^{T} a \in \mathbb{R}\]</span> </p><ul><li>s = score(museums in Paris are amazing)</li></ul><p><img src="/img/nlp//7.png" /></p><h2 id="">3.6 </h2><p></p><p><img src="/img/nlp//8.png" /></p><p>museumin</p><h1 id="pytorch">4.pytorch</h1><h2 id="">4.1 </h2><p>()</p><ul><li><span class="math inline">\(s = score(museums\ in\ Paris\ are\amazing)\)</span></li><li><span class="math inline">\(s_c = socre(Not\ all\ museums\ in\Paris)\)</span></li></ul><p><strong></strong> <span class="math display">\[J=max(0,1-s-s_c)\]</span>   SGD</p><p><strong></strong></p><ul><li><spanclass="math inline">\(J=max(0,1-s-s_c)\)</span></li><li>NER1</li><li></li><li>word2vec</li></ul><h2 id="">4.2 </h2>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>NLP</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>NLP-Assignment2</title>
    <link href="/2022/05/06/NLP-Assignment2/"/>
    <url>/2022/05/06/NLP-Assignment2/</url>
    
    <content type="html"><![CDATA[<h1 id="assignment2">Assignment2</h1><h2 id="23">23</h2><p>word2veccenterword <em>c</em> <em>c</em> <em>c</em>outsidewordsbanking2turningintocrisesas</p><p><img src="/img/nlp/assignment2/1.jpg"/></p><p>Skip-gramword2veccbow<spanclass="math inline">\((|)\)</span><span class="math inline">\(o\)</span>  <spanclass="math inline">\(c\)</span>  <spanclass="math inline">\((=|=)\)</span> <spanclass="math inline">\(c\)</span>  <spanclass="math inline">\(o\)</span>  <spanclass="math inline">\(c\)</span> <spanclass="math inline">\(o\)</span> </p><p>word2vecdot-productsnaive-softmax<span class="math display">\[P(O=o \mid C=c)=\frac{\exp \left(\boldsymbol{u}_{o}^{\top}\boldsymbol{v}_{c}\right)}{\sum_{w \in \operatorname{Vocab}} \exp\left(\boldsymbol{u}_{w}^{\top} \boldsymbol{v}_{c}\right)}\]</span></p><p><span class="math inline">\(_o\)</span><spanclass="math inline">\(v_c\)</span><span class="math inline">\(\)</span>  <spanclass="math inline">\(\)</span>  <spanclass="math inline">\(\)</span>  <spanclass="math inline">\(V\)</span> <spanclass="math inline">\(w \in Vocabulary\)</span> </p><p> <span class="math inline">\(c\)</span>  <spanclass="math inline">\(o\)</span> <spanclass="math display">\[\boldsymbol{J}_{naive-softmax}(v_c, o, \boldsymbol{U}) = -log P(O=o \midC=c)\]</span></p><p> <spanclass="math inline">\(y\)</span>  <spanclass="math inline">\(\hat{y}\)</span>  <spanclass="math inline">\(y\)</span>kk10 <spanclass="math inline">\(\hat{y}\)</span>kk</p><h3 id="a-3">(a) (3)</h3><p>(2)naive-softmax <spanclass="math inline">\(y\)</span>  <spanclass="math inline">\(\hat{y}\)</span></p><p><span class="math display">\[-\sum_{w \in V o c a b} y_{w} \log\left(\hat{y}_{w}\right)=-\log \left(\hat{y}_{o}\right)\]</span></p><p><strong></strong> <span class="math inline">\(o\)</span> <span class="math inline">\(o\)</span></p><h3 id="b-5">(b) (5)</h3><p> <spanclass="math inline">\(\boldsymbol{J}_{naive-softmax}(v_c, o,\boldsymbol{U})\)</span>  <spanclass="math inline">\(v_c\)</span>  <spanclass="math inline">\(y\)</span> <spanclass="math inline">\(\hat{y}\)</span> <spanclass="math inline">\(\)</span> </p><p><strong></strong> <span class="math display">\[\begin{aligned}J_{\text {naive-softmax} }\left(\boldsymbol{v}_{c}, o,\boldsymbol{U}\right)&amp;=-\log P(O=o | C=c) \\&amp;= -\log \frac{\exp \left(\boldsymbol{u}_{o}^{\top}\boldsymbol{v}_{c}\right)}{\sum_{w \in \operatorname{Vocab} } \exp\left(\boldsymbol{u}_{\boldsymbol{w} }^{\top} \boldsymbol{v}_{c}\right)}\\&amp;= - {u}_{o}^{\top}{v}_{c} + \log \sum_{w \in \operatorname{Vocab} }\exp \left(\boldsymbol{u}_{\boldsymbol{w} }^{\top}\boldsymbol{v}_{c}\right)\end{aligned}\]</span></p><p><span class="math display">\[\begin{aligned}\frac{\partial J_{\text {naive-softmax} }\left(\boldsymbol{v}_{c}, o,\boldsymbol{U}\right)}{\partial  v_c}&amp;= -u_o + \sum_{o \in \operatorname{Vocab} }\frac{\exp(u_o^\topv_c)}{\sum_{w \in \operatorname{Vocab} } \exp\left(\boldsymbol{u}_{\boldsymbol{w} }^{\top} \boldsymbol{v}_{c}\right)}\frac{\partial (u_o^\top v_c)}{\partial v_c}\\&amp;=-u_o + \sum_{o \in \operatorname{Vocab} } P(O=o | C=c)  u_o \\&amp;=- U y + U \hat y \\&amp;= U(\hat y - y)\end{aligned}\]</span></p><h3 id="c-5">(c) (5)</h3><p> <spanclass="math inline">\(\boldsymbol{J}_{naive-softmax}(v_c, o,\boldsymbol{U})\)</span>  <spanclass="math inline">\(w\)</span>  <spanclass="math inline">\(w\)</span>  <spanclass="math inline">\(o\)</span> <spanclass="math inline">\(w\)</span>  <spanclass="math inline">\(o\)</span> <spanclass="math inline">\(y\)</span> <spanclass="math inline">\(\hat{y}\)</span> <spanclass="math inline">\(v_c\)</span> </p><p><strong></strong> <span class="math display">\[\begin{aligned}\frac{\partial J_{\text {naive-softmax} }\left(\boldsymbol{v}_{c}, o,\boldsymbol{U}\right)}{\partial  u_w}&amp;= -v_c 1_{\lbrace w=o \rbrace } + \frac{\exp(u_w^\top v_c)}{\sum_{w\in \operatorname{Vocab} } \exp \left(\boldsymbol{u}_{\boldsymbol{w}}^{\top} \boldsymbol{v}_{c}\right)}\frac{\partial (u_w^\top v_c)}{\partial u_w}\\&amp;=-v_c  1_{\lbrace w=o \rbrace } +  P(O=w | C=c)  v_c \\&amp;=v_c( \hat y_w -  y_w)\end{aligned}\]</span></p><h3 id="d-3">(d) (3)</h3><p>sigmoid <span class="math display">\[\sigma(\boldsymbol{x})=\frac{1}{1+e^{-\boldsymbol{x}}}=\frac{e^{\boldsymbol{x}}}{e^{\boldsymbol{x}}+1}\]</span>  <span class="math inline">\(x\)</span> <span class="math inline">\(x\)</span> </p><p><strong></strong></p><p> <span class="math display">\[\begin{aligned}\frac{\partial \sigma(x_i )}{\partial x_j }&amp;= \sigma (x_i) (1 -\sigma(x_i)) 1_{\lbrace i=j\rbrace  }\end{aligned}\]</span>  <span class="math display">\[\frac{\partial \sigma(x)}{\partial  x}=\text{diag}(\sigma(x) (1- \sigma(x)))\]</span></p><h3 id="e-4">(e) (4)</h3><p>K<spanclass="math inline">\(w_1, w_2, , w_K\)</span> <spanclass="math inline">\(u_1, u_2, , u_K\)</span> <spanclass="math inline">\(o \not\in {w_1, w_2, , w_K}\)</span><span class="math inline">\(o\)</span>  <spanclass="math inline">\(c\)</span>  <spanclass="math display">\[\boldsymbol{J}_{\text {neg-sample }}\left(\boldsymbol{v}_{c}, o,\boldsymbol{U}\right)=-\log \left(\sigma\left(\boldsymbol{u}_{o}^{\top}\boldsymbol{v}_{c}\right)\right)-\sum_{k=1}^{K} \log\left(\sigma\left(-\boldsymbol{u}_{k}^{\top}\boldsymbol{v}_{c}\right)\right)\]</span> (b)(c) <spanclass="math inline">\(\boldsymbol{u}_o\)</span><spanclass="math inline">\(\boldsymbol{v}_c\)</span><spanclass="math inline">\(\boldsymbol{u}_k\)</span> </p><p>naive-softmax</p><p>(d)</p><p><strong></strong> <span class="math display">\[\begin{aligned}\frac{\partial J_{\text {neg-sample} }\left(v_{c}, o,U\right)}{\partial  v_c}&amp;=-\frac{\sigma\left(\boldsymbol{u}_{o}^{\top}\boldsymbol{v}_{c}\right)\left(1- \sigma\left(\boldsymbol{u}_{o}^{\top}\boldsymbol{v}_{c}\right)\right)}{\sigma\left(\boldsymbol{u}_{o}^{\top}\boldsymbol{v}_{c}\right)}u _o-\sum_{k=1}^K\frac{\sigma\left(-\boldsymbol{u}_{k}^{\top}\boldsymbol{v}_{c}\right)\left(1- \sigma\left(-\boldsymbol{u}_{k}^{\top}\boldsymbol{v}_{c}\right)\right)}{\sigma\left(-\boldsymbol{u}_{k}^{\top}\boldsymbol{v}_{c}\right)}(-u_k)\\&amp;= -\left(1- \sigma\left(\boldsymbol{u}_{o}^{\top}\boldsymbol{v}_{c}\right)\right)u_o+ \sum_{k=1}^K  \left(1- \sigma\left(-\boldsymbol{u}_{k}^{\top}\boldsymbol{v}_{c}\right)\right)u_k\\\frac{\partial J_{\text {neg-sample} }\left(v_{c}, o,U\right)}{\partial  u_o}&amp;=-\frac{\sigma\left(\boldsymbol{u}_{o}^{\top}\boldsymbol{v}_{c}\right)\left(1- \sigma\left(\boldsymbol{u}_{o}^{\top}\boldsymbol{v}_{c}\right)\right)}{\sigma\left(\boldsymbol{u}_{o}^{\top}\boldsymbol{v}_{c}\right)}v _c\\&amp;= -\left(1- \sigma\left(\boldsymbol{u}_{o}^{\top}\boldsymbol{v}_{c}\right)\right)v_c \\\frac{\partial J_{\text {neg-sample} }\left(v_{c}, o,U\right)}{\partial  u_k}&amp;=-\frac{\sigma\left(-\boldsymbol{u}_{k}^{\top}\boldsymbol{v}_{c}\right)\left(1- \sigma\left(-\boldsymbol{u}_{k}^{\top}\boldsymbol{v}_{c}\right)\right)}{\sigma\left(-\boldsymbol{u}_{k}^{\top}\boldsymbol{v}_{c}\right)}(-v_c)\\&amp;= \left(1- \sigma\left(-\boldsymbol{u}_{k}^{\top}\boldsymbol{v}_{c}\right)\right)v_c\end{aligned}\]</span></p><ul><li><p></p></li><li><p>  K+1</p></li><li><p>sigmoid</p></li></ul><h3 id="f-3">(f) (3)</h3><p> <span class="math inline">\(c =w_t\)</span><span class="math inline">\([w_{t-m}, ,w_{t-1}, w_t, w_{t+1}, , w_{t+m}]\)</span><spanclass="math inline">\(m\)</span>skip-gramword2vec<span class="math display">\[\boldsymbol{J}_{\text {skip-gram }}\left(\boldsymbol{v}_{c}, w_{t-m},\ldots w_{t+m}, \boldsymbol{U}\right)=\sum_{-m \leq j \leq m \atop j\neq 0} \boldsymbol{J}\left(\boldsymbol{v}_{c}, w_{t+j},\boldsymbol{U}\right)\]</span> <spanclass="math inline">\(\boldsymbol{J}(\boldsymbol{v}_c, w_{t+j},\boldsymbol{U})\)</span><spanclass="math inline">\(w_{t+j}\)</span><spanclass="math inline">\(c=w_t\)</span>naive-softmaxneg-sample</p><p></p><ol type="i"><li><p> <span class="math inline">\(U\)</span></p></li><li><p> <span class="math inline">\(\boldsymbol{v}_c\)</span></p></li><li><p> <span class="math inline">\(\boldsymbol{v}_w\)</span></p></li></ol><strong></strong> $$<span class="math display">\[\begin{aligned}\partial \boldsymbol{J}_{\text {skip-gram } }\left(\boldsymbol{v}_{c},w_{t-m}, \dots w_{t+m}, \boldsymbol{U}\right) / \partial \boldsymbol{U}&amp;=\sum_{-m \leq j \leq m \atop j \neq 0} \partial\boldsymbol{J}\left(\boldsymbol{v}_{c}, w_{t+j}, \boldsymbol{U}\right) /\partial \boldsymbol{U} \\\partial \boldsymbol{J}_{\text {skip-gram } }\left(\boldsymbol{v}_{c},w_{t-m}, \dots w_{t+m}, \boldsymbol{U}\right) / \partial\boldsymbol{v_c}&amp;=\sum_{-m \leq j \leq m \atop j \neq 0} \partial\boldsymbol{J}\left(\boldsymbol{v}_{c}, w_{t+j}, \boldsymbol{U}\right) /\partial  \boldsymbol{v_c} \\\partial \boldsymbol{J}_{\text {skip-gram } }\left(\boldsymbol{v}_{c},w_{t-m}, \dots w_{t+m}, \boldsymbol{U}\right) / \partial\boldsymbol{v_w}&amp;=\sum_{-m \leq j \leq m \atop j \neq 0} \partial\boldsymbol{J}\left(\boldsymbol{v}_{c}, w_{t+j}, \boldsymbol{U}\right) /\partial  \boldsymbol{v_w} \\\end{aligned}\]</span><p>$$</p><h2 id="word2vec20">word2vec20</h2><p> <ahref="http://web.stanford.edu/class/cs224n/assignments/a2.zip"></a>python &gt;=3.5numpyconda</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">conda env create -f env.yml<br>conda activate a2<br></code></pre></div></td></tr></table></figure><p></p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">conda deactivate<br></code></pre></div></td></tr></table></figure><h3 id="a-12">(a) (12)</h3><p> word2vec.py sigmoid softmaxskip-grampythonword2vec.py</p><p><strong></strong></p><h4 id="sigmoid">sigmoid</h4><p>numpy</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">sigmoid</span>(<span class="hljs-params">x</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Compute the sigmoid function for the input here.</span><br><span class="hljs-string">    Arguments:</span><br><span class="hljs-string">    x -- A scalar or numpy array.</span><br><span class="hljs-string">    Return:</span><br><span class="hljs-string">    s -- sigmoid(x)</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-comment">### YOUR CODE HERE</span><br>    s = <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + np.exp(-x))<br><br>    <span class="hljs-comment">### END YOUR CODE</span><br><br>    <span class="hljs-keyword">return</span> s<br></code></pre></div></td></tr></table></figure><h4 id="naivesoftmaxlossandgradient">naiveSoftmaxLossAndGradient</h4><p></p><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment">### YOUR CODE HERE</span><br><br><span class="hljs-comment">### Please use the provided softmax function (imported earlier in this file)</span><br><span class="hljs-comment">### This numerically stable implementation helps you avoid issues pertaining</span><br><span class="hljs-comment">### to integer overflow. </span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    centerWordVec: 1 * d</span><br><span class="hljs-string">    outsideVectors: n * d</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br><span class="hljs-comment">#1 * n</span><br>vec = centerWordVec.dot(outsideVectors.T)<br><span class="hljs-comment">#1 * n</span><br>prob = softmax(vec)<br>loss = -np.log(prob[outsideWordIdx])<br><span class="hljs-comment">#1 * d</span><br>gradCenterVec = -outsideVectors[outsideWordIdx] + prob.dot(outsideVectors)<br><span class="hljs-comment">#n * d</span><br>gradOutsideVecs = prob.reshape(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>).dot(centerWordVec.reshape(<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>))<br><span class="hljs-comment">#n * d</span><br>gradOutsideVecs[outsideWordIdx] -= centerWordVec<br><span class="hljs-comment">### END YOUR CODE</span><br></code></pre></div></td></tr></table></figure><h4 id="negsamplinglossandgradient">negSamplingLossAndGradient</h4><p>native-softmax</p><ul><li>K1K+1</li><li>sigmoidsoftmax</li></ul><p>K+1<em></em> </p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment">### Please use your implementation of sigmoid in here.</span><br><br><span class="hljs-comment"># indices might have same index</span><br><span class="hljs-comment"># extract W</span><br>W = np.zeros((<span class="hljs-built_in">len</span>(indices), outsideVectors.shape[<span class="hljs-number">1</span>]))<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(indices)):<br>    W[i] = outsideVectors[indices[i]]<br><br><span class="hljs-comment"># forward</span><br>a = centerWordVec<br>a = a.reshape((a.shape[<span class="hljs-number">0</span>], <span class="hljs-number">1</span>))<br><br>z = np.dot(W, a) <span class="hljs-comment"># (K+1, 1)</span><br>preds = sigmoid(z)<br><br><span class="hljs-comment"># backprop</span><br>y = np.zeros((preds.shape[<span class="hljs-number">0</span>], <span class="hljs-number">1</span>))<br>y[<span class="hljs-number">0</span>] = <span class="hljs-number">1</span> <span class="hljs-comment"># index 0 is target</span><br><br>loss = -(y*np.log(preds) + (<span class="hljs-number">1</span> - y)*np.log(<span class="hljs-number">1</span> - preds)).<span class="hljs-built_in">sum</span>()<br><br>delta = preds - y<br>gradCenterVec = np.dot(W.T, delta) <span class="hljs-comment"># (V, 1)</span><br>gradW = np.dot(delta, a.T) <span class="hljs-comment"># (K+1, V)</span><br>gradCenterVec = gradCenterVec.flatten()<br><br><span class="hljs-comment"># apply gradW into gradOutsideVecs</span><br>gradOutsideVecs = np.zeros_like(outsideVectors)<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(indices)):<br>    oi = indices[i]<br>    gradOutsideVecs[oi] += gradW[i]<br></code></pre></div></td></tr></table></figure><h4 id="skipgram">skipgram</h4><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">ci = word2Ind[currentCenterWord]<br>vc = centerWordVectors[ci]<br><br><span class="hljs-keyword">for</span> o <span class="hljs-keyword">in</span> outsideWords:<br>    oi = word2Ind[o]<br>    loss_, gradVc, gradUo = word2vecLossAndGradient(vc, oi, outsideVectors, dataset)<br>    gradCenterVecs[ci] += gradVc<br>    gradOutsideVectors += gradUo<br>    loss += loss_<br></code></pre></div></td></tr></table></figure><h3 id="b-4">(b) (4)</h3><p>sgd.pySGDpython sgd.py</p><p><strong></strong></p><h4 id="sgd">sgd</h4><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment">### YOUR CODE HERE</span><br>loss, grad = f(x)<br>x -= step * grad<br><br><span class="hljs-comment">### END YOUR CODE</span><br></code></pre></div></td></tr></table></figure><h3 id="c-4">(c) (4)</h3><p>StanformSentimentTreebank(SST) shget_datasets.sh  python run.py</p><p></p><p>40,000 word_vectors.png </p><p><strong></strong></p><p><img src="http://ww1.sinaimg.cn/large/0060yMmAly1gsz2rwoc9sj30hs0dc3zy.jpg" referrerpolicy="no-referrer" /></p><ul><li>male-&gt;famale  king -&gt; queen</li><li>(women, famale)(enjoyable,annoying) </li></ul>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>NLP</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>NLP-Assignment1</title>
    <link href="/2022/05/05/NLP-Assignment1/"/>
    <url>/2022/05/05/NLP-Assignment1/</url>
    
    <content type="html"><![CDATA[<h1 id="assignment1">Assignment1</h1><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># All Import Statements Defined Here</span><br><span class="hljs-comment"># Note: Do not add to this list.</span><br><span class="hljs-comment"># ----------------</span><br><br><span class="hljs-keyword">import</span> sys<br><span class="hljs-keyword">assert</span> sys.version_info[<span class="hljs-number">0</span>]==<span class="hljs-number">3</span><br><span class="hljs-keyword">assert</span> sys.version_info[<span class="hljs-number">1</span>] &gt;= <span class="hljs-number">5</span><br><br><span class="hljs-keyword">from</span> gensim.models <span class="hljs-keyword">import</span> KeyedVectors<br><span class="hljs-keyword">from</span> gensim.test.utils <span class="hljs-keyword">import</span> datapath<br><span class="hljs-keyword">import</span> pprint<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br>plt.rcParams[<span class="hljs-string">&#x27;figure.figsize&#x27;</span>] = [<span class="hljs-number">10</span>, <span class="hljs-number">5</span>]<br><span class="hljs-keyword">import</span> nltk<br>nltk.download(<span class="hljs-string">&#x27;reuters&#x27;</span>)<br><span class="hljs-keyword">from</span> nltk.corpus <span class="hljs-keyword">import</span> reuters<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> random<br><span class="hljs-keyword">import</span> scipy <span class="hljs-keyword">as</span> sp<br><span class="hljs-keyword">from</span> sklearn.decomposition <span class="hljs-keyword">import</span> TruncatedSVD<br><span class="hljs-keyword">from</span> sklearn.decomposition <span class="hljs-keyword">import</span> PCA<br><br>START_TOKEN = <span class="hljs-string">&#x27;&lt;START&gt;&#x27;</span><br>END_TOKEN = <span class="hljs-string">&#x27;&lt;END&gt;&#x27;</span><br><br>np.random.seed(<span class="hljs-number">0</span>)<br>random.seed(<span class="hljs-number">0</span>)<br><span class="hljs-comment"># ----------------</span><br></code></pre></div></td></tr></table></figure><h2 id="part-1">Part 1</h2><p></p><p><strong>You shall know a word by the company it keeps (<ahref="https://en.wikipedia.org/wiki/John_Rupert_Firth">Firth, J. R.1957:11</a>)</strong></p><p> <em></em><em></em> ( <ahref="http://web.stanford.edu/class/cs124/lec/vectorsemantics.video.pdf"></a> <ahref="https://medium.com/data-science-group-iitr/word-embedding-2d05d270b285"></a>)</p><p></p><ul><li></li><li></li><li>SVD</li><li></li></ul><h3 id="1.1-dicintct_words">1.1 dicintct_words</h3><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">distinct_words</span>(<span class="hljs-params">corpus</span>):<br>    <span class="hljs-string">&quot;&quot;&quot; Determine a list of distinct words for the corpus.</span><br><span class="hljs-string">        Params:</span><br><span class="hljs-string">            corpus (list of list of strings): corpus of documents</span><br><span class="hljs-string">        Return:</span><br><span class="hljs-string">            corpus_words (list of strings): list of distinct words across the corpus, sorted (using python &#x27;sorted&#x27; function)</span><br><span class="hljs-string">            num_corpus_words (integer): number of distinct words across the corpus</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    corpus_words = []<br>    num_corpus_words = -<span class="hljs-number">1</span><br>    <br>    <span class="hljs-comment"># ------------------</span><br>    <span class="hljs-comment"># Write your implementation here.</span><br>    corpus_words =  <span class="hljs-built_in">sorted</span>(<span class="hljs-built_in">list</span>(<span class="hljs-built_in">set</span>([word <span class="hljs-keyword">for</span> sentence <span class="hljs-keyword">in</span> corpus <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> sentence])))<br>    num_corpus_words = <span class="hljs-built_in">len</span>(corpus_words)<br><br>    <span class="hljs-comment"># ------------------</span><br><br>    <span class="hljs-keyword">return</span> corpus_words, num_corpus_words<br></code></pre></div></td></tr></table></figure><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># ---------------------</span><br><span class="hljs-comment"># Run this sanity check</span><br><span class="hljs-comment"># Note that this not an exhaustive check for correctness.</span><br><span class="hljs-comment"># ---------------------</span><br><br><span class="hljs-comment"># Define toy corpus</span><br>test_corpus = [<span class="hljs-string">&quot;&#123;&#125; All that glitters isn&#x27;t gold &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(START_TOKEN, END_TOKEN).split(<span class="hljs-string">&quot; &quot;</span>), <span class="hljs-string">&quot;&#123;&#125; All&#x27;s well that ends well &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(START_TOKEN, END_TOKEN).split(<span class="hljs-string">&quot; &quot;</span>)]<br>test_corpus_words, num_corpus_words = distinct_words(test_corpus)<br><br><span class="hljs-comment"># Correct answers</span><br>ans_test_corpus_words = <span class="hljs-built_in">sorted</span>([START_TOKEN, <span class="hljs-string">&quot;All&quot;</span>, <span class="hljs-string">&quot;ends&quot;</span>, <span class="hljs-string">&quot;that&quot;</span>, <span class="hljs-string">&quot;gold&quot;</span>, <span class="hljs-string">&quot;All&#x27;s&quot;</span>, <span class="hljs-string">&quot;glitters&quot;</span>, <span class="hljs-string">&quot;isn&#x27;t&quot;</span>, <span class="hljs-string">&quot;well&quot;</span>, END_TOKEN])<br>ans_num_corpus_words = <span class="hljs-built_in">len</span>(ans_test_corpus_words)<br><br><span class="hljs-comment"># Test correct number of words</span><br><span class="hljs-keyword">assert</span>(num_corpus_words == ans_num_corpus_words), <span class="hljs-string">&quot;Incorrect number of distinct words. Correct: &#123;&#125;. Yours: &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(ans_num_corpus_words, num_corpus_words)<br><br><span class="hljs-comment"># Test correct words</span><br><span class="hljs-keyword">assert</span> (test_corpus_words == ans_test_corpus_words), <span class="hljs-string">&quot;Incorrect corpus_words.\nCorrect: &#123;&#125;\nYours:   &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(<span class="hljs-built_in">str</span>(ans_test_corpus_words), <span class="hljs-built_in">str</span>(test_corpus_words))<br><br><span class="hljs-comment"># Print Success</span><br><span class="hljs-built_in">print</span> (<span class="hljs-string">&quot;-&quot;</span> * <span class="hljs-number">80</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Passed All Tests!&quot;</span>)<br><span class="hljs-built_in">print</span> (<span class="hljs-string">&quot;-&quot;</span> * <span class="hljs-number">80</span>)<br></code></pre></div></td></tr></table></figure><h3id="1.2compute_co_occurrence_matrix">1.2compute_co_occurrence_matrix</h3><p><code>w</code> <code>window_size</code> </p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_co_occurrence_matrix</span>(<span class="hljs-params">corpus, window_size=<span class="hljs-number">4</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot; Compute co-occurrence matrix for the given corpus and window_size (default of 4).</span><br><span class="hljs-string">    </span><br><span class="hljs-string">        Note: Each word in a document should be at the center of a window. Words near edges will have a smaller</span><br><span class="hljs-string">              number of co-occurring words.</span><br><span class="hljs-string">              </span><br><span class="hljs-string">              For example, if we take the document &quot;START All that glitters is not gold END&quot; with window size of 4,</span><br><span class="hljs-string">              &quot;All&quot; will co-occur with &quot;START&quot;, &quot;that&quot;, &quot;glitters&quot;, &quot;is&quot;, and &quot;not&quot;.</span><br><span class="hljs-string">    </span><br><span class="hljs-string">        Params:</span><br><span class="hljs-string">            corpus (list of list of strings): corpus of documents</span><br><span class="hljs-string">            window_size (int): size of context window</span><br><span class="hljs-string">        Return:</span><br><span class="hljs-string">            M (numpy matrix of shape (number of corpus words, number of corpus words)): </span><br><span class="hljs-string">                Co-occurence matrix of word counts. </span><br><span class="hljs-string">                The ordering of the words in the rows/columns should be the same as the ordering of the words given by the distinct_words function.</span><br><span class="hljs-string">            word2Ind (dict): dictionary that maps word to index (i.e. row/column number) for matrix M.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    words, num_words = distinct_words(corpus)<br>    M = np.zeros((num_words, num_words))<br>    word2Ind = <span class="hljs-built_in">dict</span>([(word, index) <span class="hljs-keyword">for</span> index, word <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(words)])<br>    <br>    <span class="hljs-comment"># ------------------</span><br>    <span class="hljs-comment"># Write your implementation here.</span><br>    <span class="hljs-keyword">for</span> sentence <span class="hljs-keyword">in</span> corpus:<br>        current_index = <span class="hljs-number">0</span><br>        sentence_len = <span class="hljs-built_in">len</span>(sentence)<br>        indices = [word2Ind[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> sentence]<br>        <span class="hljs-keyword">while</span> current_index &lt; sentence_len:<br>            left  = <span class="hljs-built_in">max</span>(current_index - window_size, <span class="hljs-number">0</span>)<br>            right = <span class="hljs-built_in">min</span>(current_index + window_size + <span class="hljs-number">1</span>, sentence_len) <br>            current_word = sentence[current_index]<br>            current_word_index = word2Ind[current_word]<br>            words_around = indices[left:current_index] + indices[current_index+<span class="hljs-number">1</span>:right]<br>            <br>            <span class="hljs-keyword">for</span> ind <span class="hljs-keyword">in</span> words_around:<br>                M[current_word_index, ind] += <span class="hljs-number">1</span><br>            <br>            current_index += <span class="hljs-number">1</span><br><br>    <span class="hljs-comment"># ------------------</span><br><br>    <span class="hljs-keyword">return</span> M, word2Ind<br></code></pre></div></td></tr></table></figure><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># ---------------------</span><br><span class="hljs-comment"># Run this sanity check</span><br><span class="hljs-comment"># Note that this is not an exhaustive check for correctness.</span><br><span class="hljs-comment"># ---------------------</span><br><br><span class="hljs-comment"># Define toy corpus and get student&#x27;s co-occurrence matrix</span><br>test_corpus = [<span class="hljs-string">&quot;&#123;&#125; All that glitters isn&#x27;t gold &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(START_TOKEN, END_TOKEN).split(<span class="hljs-string">&quot; &quot;</span>), <span class="hljs-string">&quot;&#123;&#125; All&#x27;s well that ends well &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(START_TOKEN, END_TOKEN).split(<span class="hljs-string">&quot; &quot;</span>)]<br>M_test, word2ind_test = compute_co_occurrence_matrix(test_corpus, window_size=<span class="hljs-number">1</span>)<br><br><span class="hljs-comment"># Correct M and word2ind</span><br>M_test_ans = np.array( <br>    [[<span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>,],<br>     [<span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>,],<br>     [<span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>,],<br>     [<span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>,],<br>     [<span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>,],<br>     [<span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>,],<br>     [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>,],<br>     [<span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>,],<br>     [<span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>,],<br>     [<span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">0.</span>, <span class="hljs-number">1.</span>, <span class="hljs-number">0.</span>,]]<br>)<br>ans_test_corpus_words = <span class="hljs-built_in">sorted</span>([START_TOKEN, <span class="hljs-string">&quot;All&quot;</span>, <span class="hljs-string">&quot;ends&quot;</span>, <span class="hljs-string">&quot;that&quot;</span>, <span class="hljs-string">&quot;gold&quot;</span>, <span class="hljs-string">&quot;All&#x27;s&quot;</span>, <span class="hljs-string">&quot;glitters&quot;</span>, <span class="hljs-string">&quot;isn&#x27;t&quot;</span>, <span class="hljs-string">&quot;well&quot;</span>, END_TOKEN])<br>word2ind_ans = <span class="hljs-built_in">dict</span>(<span class="hljs-built_in">zip</span>(ans_test_corpus_words, <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(ans_test_corpus_words))))<br><br><span class="hljs-comment"># Test correct word2ind</span><br><span class="hljs-keyword">assert</span> (word2ind_ans == word2ind_test), <span class="hljs-string">&quot;Your word2ind is incorrect:\nCorrect: &#123;&#125;\nYours: &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(word2ind_ans, word2ind_test)<br><br><span class="hljs-comment"># Test correct M shape</span><br><span class="hljs-keyword">assert</span> (M_test.shape == M_test_ans.shape), <span class="hljs-string">&quot;M matrix has incorrect shape.\nCorrect: &#123;&#125;\nYours: &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(M_test.shape, M_test_ans.shape)<br><br><span class="hljs-comment"># Test correct M values</span><br><span class="hljs-keyword">for</span> w1 <span class="hljs-keyword">in</span> word2ind_ans.keys():<br>    idx1 = word2ind_ans[w1]<br>    <span class="hljs-keyword">for</span> w2 <span class="hljs-keyword">in</span> word2ind_ans.keys():<br>        idx2 = word2ind_ans[w2]<br>        student = M_test[idx1, idx2]<br>        correct = M_test_ans[idx1, idx2]<br>        <span class="hljs-keyword">if</span> student != correct:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Correct M:&quot;</span>)<br>            <span class="hljs-built_in">print</span>(M_test_ans)<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Your M: &quot;</span>)<br>            <span class="hljs-built_in">print</span>(M_test)<br>            <span class="hljs-keyword">raise</span> AssertionError(<span class="hljs-string">&quot;Incorrect count at index (&#123;&#125;, &#123;&#125;)=(&#123;&#125;, &#123;&#125;) in matrix M. Yours has &#123;&#125; but should have &#123;&#125;.&quot;</span>.<span class="hljs-built_in">format</span>(idx1, idx2, w1, w2, student, correct))<br><br><span class="hljs-comment"># Print Success</span><br><span class="hljs-built_in">print</span> (<span class="hljs-string">&quot;-&quot;</span> * <span class="hljs-number">80</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Passed All Tests!&quot;</span>)<br><span class="hljs-built_in">print</span> (<span class="hljs-string">&quot;-&quot;</span> * <span class="hljs-number">80</span>)<br></code></pre></div></td></tr></table></figure><h3 id="1.3-reduce_to_k_dim">1.3 reduce_to_k_dim</h3><p>1.2N xNNscikit-learnSVDkNx k </p><p><strong></strong>numpyscipyscikit-learnSVDscipysklearnTruncatedSVDsklearnSVDrandomized<ahref="https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html">sklearn.decomposition.TruncatedSVD</a></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">reduce_to_k_dim</span>(<span class="hljs-params">M, k=<span class="hljs-number">2</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot; Reduce a co-occurence count matrix of dimensionality (num_corpus_words, num_corpus_words)</span><br><span class="hljs-string">        to a matrix of dimensionality (num_corpus_words, k) using the following SVD function from Scikit-Learn:</span><br><span class="hljs-string">            - http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html</span><br><span class="hljs-string">    </span><br><span class="hljs-string">        Params:</span><br><span class="hljs-string">            M (numpy matrix of shape (number of corpus words, number of corpus words)): co-occurence matrix of word counts</span><br><span class="hljs-string">            k (int): embedding size of each word after dimension reduction</span><br><span class="hljs-string">        Return:</span><br><span class="hljs-string">            M_reduced (numpy matrix of shape (number of corpus words, k)): matrix of k-dimensioal word embeddings.</span><br><span class="hljs-string">                    In terms of the SVD from math class, this actually returns U * S</span><br><span class="hljs-string">    &quot;&quot;&quot;</span>    <br>    n_iters = <span class="hljs-number">10</span>     <span class="hljs-comment"># Use this parameter in your call to `TruncatedSVD`</span><br>    M_reduced = <span class="hljs-literal">None</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Running Truncated SVD over %i words...&quot;</span> % (M.shape[<span class="hljs-number">0</span>]))<br>    <br>    <span class="hljs-comment"># ------------------</span><br>    <span class="hljs-comment"># Write your implementation here.</span><br>    TSVD = TruncatedSVD(n_components=k, n_iter=n_iters)<br>    M_reduced = TSVD.fit_transform(M)<br><br>    <span class="hljs-comment"># ------------------</span><br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Done.&quot;</span>)<br>    <span class="hljs-keyword">return</span> M_reduced<br></code></pre></div></td></tr></table></figure><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># ---------------------</span><br><span class="hljs-comment"># Run this sanity check</span><br><span class="hljs-comment"># Note that this is not an exhaustive check for correctness </span><br><span class="hljs-comment"># In fact we only check that your M_reduced has the right dimensions.</span><br><span class="hljs-comment"># ---------------------</span><br><br><span class="hljs-comment"># Define toy corpus and run student code</span><br>test_corpus = [<span class="hljs-string">&quot;&#123;&#125; All that glitters isn&#x27;t gold &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(START_TOKEN, END_TOKEN).split(<span class="hljs-string">&quot; &quot;</span>), <span class="hljs-string">&quot;&#123;&#125; All&#x27;s well that ends well &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(START_TOKEN, END_TOKEN).split(<span class="hljs-string">&quot; &quot;</span>)]<br>M_test, word2ind_test = compute_co_occurrence_matrix(test_corpus, window_size=<span class="hljs-number">1</span>)<br>M_test_reduced = reduce_to_k_dim(M_test, k=<span class="hljs-number">2</span>)<br><br><span class="hljs-comment"># Test proper dimensions</span><br><span class="hljs-keyword">assert</span> (M_test_reduced.shape[<span class="hljs-number">0</span>] == <span class="hljs-number">10</span>), <span class="hljs-string">&quot;M_reduced has &#123;&#125; rows; should have &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(M_test_reduced.shape[<span class="hljs-number">0</span>], <span class="hljs-number">10</span>)<br><span class="hljs-keyword">assert</span> (M_test_reduced.shape[<span class="hljs-number">1</span>] == <span class="hljs-number">2</span>), <span class="hljs-string">&quot;M_reduced has &#123;&#125; columns; should have &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(M_test_reduced.shape[<span class="hljs-number">1</span>], <span class="hljs-number">2</span>)<br><br><span class="hljs-comment"># Print Success</span><br><span class="hljs-built_in">print</span> (<span class="hljs-string">&quot;-&quot;</span> * <span class="hljs-number">80</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Passed All Tests!&quot;</span>)<br><span class="hljs-built_in">print</span> (<span class="hljs-string">&quot;-&quot;</span> * <span class="hljs-number">80</span>)<br></code></pre></div></td></tr></table></figure><h3 id="1.4--plot_embeddings">1.4  plot_embeddings</h3><p>matplotlib<code>scatter</code>   <code>text</code></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">plot_embeddings</span>(<span class="hljs-params">M_reduced, word2Ind, words</span>):<br>    <span class="hljs-string">&quot;&quot;&quot; Plot in a scatterplot the embeddings of the words specified in the list &quot;words&quot;.</span><br><span class="hljs-string">        NOTE: do not plot all the words listed in M_reduced / word2Ind.</span><br><span class="hljs-string">        Include a label next to each point.</span><br><span class="hljs-string">        </span><br><span class="hljs-string">        Params:</span><br><span class="hljs-string">            M_reduced (numpy matrix of shape (number of unique words in the corpus , k)): matrix of k-dimensioal word embeddings</span><br><span class="hljs-string">            word2Ind (dict): dictionary that maps word to indices for matrix M</span><br><span class="hljs-string">            words (list of strings): words whose embeddings we want to visualize</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-comment"># ------------------</span><br>    <span class="hljs-comment"># Write your implementation here.</span><br>    <br>    <span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> words:<br>        index = word2Ind[w]<br>        embedding = M_reduced[index]<br>        x, y  = embedding[<span class="hljs-number">0</span>], embedding[<span class="hljs-number">1</span>]<br>        plt.scatter(x, y, marker=<span class="hljs-string">&#x27;x&#x27;</span>, color=<span class="hljs-string">&#x27;red&#x27;</span>)<br>        plt.text(x, y, word, fontsize=<span class="hljs-number">9</span>)<br>    plt.show()<br>    <span class="hljs-comment"># ------------------</span><br></code></pre></div></td></tr></table></figure><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># ---------------------</span><br><span class="hljs-comment"># Run this sanity check</span><br><span class="hljs-comment"># Note that this is not an exhaustive check for correctness.</span><br><span class="hljs-comment"># The plot produced should look like the &quot;test solution plot&quot; depicted below. </span><br><span class="hljs-comment"># ---------------------</span><br><br><span class="hljs-built_in">print</span> (<span class="hljs-string">&quot;-&quot;</span> * <span class="hljs-number">80</span>)<br><span class="hljs-built_in">print</span> (<span class="hljs-string">&quot;Outputted Plot:&quot;</span>)<br><br>M_reduced_plot_test = np.array([[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>], [-<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>], [<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>], [-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>], [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>]])<br>word2ind_plot_test = &#123;<span class="hljs-string">&#x27;test1&#x27;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;test2&#x27;</span>: <span class="hljs-number">1</span>, <span class="hljs-string">&#x27;test3&#x27;</span>: <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;test4&#x27;</span>: <span class="hljs-number">3</span>, <span class="hljs-string">&#x27;test5&#x27;</span>: <span class="hljs-number">4</span>&#125;<br>words = [<span class="hljs-string">&#x27;test1&#x27;</span>, <span class="hljs-string">&#x27;test2&#x27;</span>, <span class="hljs-string">&#x27;test3&#x27;</span>, <span class="hljs-string">&#x27;test4&#x27;</span>, <span class="hljs-string">&#x27;test5&#x27;</span>]<br>plot_embeddings(M_reduced_plot_test, word2ind_plot_test, words)<br><br><span class="hljs-built_in">print</span> (<span class="hljs-string">&quot;-&quot;</span> * <span class="hljs-number">80</span>)<br></code></pre></div></td></tr></table></figure><p></p><p><img src="/img/nlp/assignment1/1.jpg"/></p><h3 id="1.5">1.5</h3><p>2</p><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># -----------------------------</span><br><span class="hljs-comment"># Run This Cell to Produce Your Plot</span><br><span class="hljs-comment"># ------------------------------</span><br>reuters_corpus = read_corpus()<br>M_co_occurrence, word2ind_co_occurrence = compute_co_occurrence_matrix(reuters_corpus)<br>M_reduced_co_occurrence = reduce_to_k_dim(M_co_occurrence, k=<span class="hljs-number">2</span>)<br><br><span class="hljs-comment"># Rescale (normalize) the rows to make them each of unit-length</span><br>M_lengths = np.linalg.norm(M_reduced_co_occurrence, axis=<span class="hljs-number">1</span>)<br>M_normalized = M_reduced_co_occurrence / M_lengths[:, np.newaxis] <span class="hljs-comment"># broadcasting</span><br><br>words = [<span class="hljs-string">&#x27;barrels&#x27;</span>, <span class="hljs-string">&#x27;bpd&#x27;</span>, <span class="hljs-string">&#x27;ecuador&#x27;</span>, <span class="hljs-string">&#x27;energy&#x27;</span>, <span class="hljs-string">&#x27;industry&#x27;</span>, <span class="hljs-string">&#x27;kuwait&#x27;</span>, <span class="hljs-string">&#x27;oil&#x27;</span>, <span class="hljs-string">&#x27;output&#x27;</span>, <span class="hljs-string">&#x27;petroleum&#x27;</span>, <span class="hljs-string">&#x27;iraq&#x27;</span>]<br><br>plot_embeddings(M_normalized, word2ind_co_occurrence, words)<br></code></pre></div></td></tr></table></figure><p><img src="/img/nlp/assignment1/2.jpg"/></p><h2 id="part-2">Part 2</h2><p>word2vecword2vec<ahref="https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf"></a></p><p>gensimword2vec300google</p><p>SVD3002</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">load_embedding_model</span>():<br>    <span class="hljs-string">&quot;&quot;&quot; Load GloVe Vectors</span><br><span class="hljs-string">        Return:</span><br><span class="hljs-string">            wv_from_bin: All 400000 embeddings, each lengh 200</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">import</span> gensim.downloader <span class="hljs-keyword">as</span> api<br>    wv_from_bin = api.load(<span class="hljs-string">&quot;glove-wiki-gigaword-200&quot;</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Loaded vocab size %i&quot;</span> % <span class="hljs-built_in">len</span>(wv_from_bin.vocab.keys()))<br>    <span class="hljs-keyword">return</span> wv_from_bin<br></code></pre></div></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># -----------------------------------</span><br><span class="hljs-comment"># Run Cell to Load Word Vectors</span><br><span class="hljs-comment"># Note: This will take a couple minutes</span><br><span class="hljs-comment"># -----------------------------------</span><br>wv_from_bin = load_embedding_model()<br></code></pre></div></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_matrix_of_vectors</span>(<span class="hljs-params">wv_from_bin, required_words=[<span class="hljs-string">&#x27;barrels&#x27;</span>, <span class="hljs-string">&#x27;bpd&#x27;</span>, <span class="hljs-string">&#x27;ecuador&#x27;</span>, <span class="hljs-string">&#x27;energy&#x27;</span>, <span class="hljs-string">&#x27;industry&#x27;</span>, <span class="hljs-string">&#x27;kuwait&#x27;</span>, <span class="hljs-string">&#x27;oil&#x27;</span>, <span class="hljs-string">&#x27;output&#x27;</span>, <span class="hljs-string">&#x27;petroleum&#x27;</span>, <span class="hljs-string">&#x27;iraq&#x27;</span>]</span>):<br>    <span class="hljs-string">&quot;&quot;&quot; Put the GloVe vectors into a matrix M.</span><br><span class="hljs-string">        Param:</span><br><span class="hljs-string">            wv_from_bin: KeyedVectors object; the 400000 GloVe vectors loaded from file</span><br><span class="hljs-string">        Return:</span><br><span class="hljs-string">            M: numpy matrix shape (num words, 200) containing the vectors</span><br><span class="hljs-string">            word2ind: dictionary mapping each word to its row number in M</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">import</span> random<br>    words = <span class="hljs-built_in">list</span>(wv_from_bin.vocab.keys())<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Shuffling words ...&quot;</span>)<br>    random.seed(<span class="hljs-number">224</span>)<br>    random.shuffle(words)<br>    words = words[:<span class="hljs-number">10000</span>]<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Putting %i words into word2ind and matrix M...&quot;</span> % <span class="hljs-built_in">len</span>(words))<br>    word2ind = &#123;&#125;<br>    M = []<br>    curInd = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> words:<br>        <span class="hljs-keyword">try</span>:<br>            M.append(wv_from_bin.word_vec(w))<br>            word2ind[w] = curInd<br>            curInd += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">except</span> KeyError:<br>            <span class="hljs-keyword">continue</span><br>    <span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> required_words:<br>        <span class="hljs-keyword">if</span> w <span class="hljs-keyword">in</span> words:<br>            <span class="hljs-keyword">continue</span><br>        <span class="hljs-keyword">try</span>:<br>            M.append(wv_from_bin.word_vec(w))<br>            word2ind[w] = curInd<br>            curInd += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">except</span> KeyError:<br>            <span class="hljs-keyword">continue</span><br>    M = np.stack(M)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Done.&quot;</span>)<br>    <span class="hljs-keyword">return</span> M, word2ind<br></code></pre></div></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># -----------------------------------------------------------------</span><br><span class="hljs-comment"># Run Cell to Reduce 200-Dimensional Word Embeddings to k Dimensions</span><br><span class="hljs-comment"># Note: This should be quick to run</span><br><span class="hljs-comment"># -----------------------------------------------------------------</span><br>M, word2ind = get_matrix_of_vectors(wv_from_bin)<br>M_reduced = reduce_to_k_dim(M, k=<span class="hljs-number">2</span>)<br><br><span class="hljs-comment"># Rescale (normalize) the rows to make them each of unit-length</span><br>M_lengths = np.linalg.norm(M_reduced, axis=<span class="hljs-number">1</span>)<br>M_reduced_normalized = M_reduced / M_lengths[:, np.newaxis] <span class="hljs-comment"># broadcasting</span><br></code></pre></div></td></tr></table></figure><h3 id="2.1word2vec">2.1word2vec</h3><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">words = [<span class="hljs-string">&#x27;barrels&#x27;</span>, <span class="hljs-string">&#x27;bpd&#x27;</span>, <span class="hljs-string">&#x27;ecuador&#x27;</span>, <span class="hljs-string">&#x27;energy&#x27;</span>, <span class="hljs-string">&#x27;industry&#x27;</span>, <span class="hljs-string">&#x27;kuwait&#x27;</span>, <span class="hljs-string">&#x27;oil&#x27;</span>, <span class="hljs-string">&#x27;output&#x27;</span>, <span class="hljs-string">&#x27;petroleum&#x27;</span>, <span class="hljs-string">&#x27;iraq&#x27;</span>]<br>plot_embeddings(M_reduced_normalized, word2ind, words)<br></code></pre></div></td></tr></table></figure><p>1.5</p><h3 id="2.2">2.2</h3><p>leavesscooptop-10leavestop-10vanishesstalks</p><p><strong>Note</strong>: You should use the<code>wv_from_bin.most_similar(word)</code> function to get the top 10similar words. This function ranks all other words in the vocabularywith respect to their cosine similarity to the given word. For furtherassistance, please check the <strong><ahref="https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.FastTextKeyedVectors.most_similar">GenSimdocumentation</a></strong>.</p><p>columntop-10columnistarticle</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># ------------------</span><br><span class="hljs-comment"># Write your polysemous word exploration code here.</span><br><br>wv_from_bin.most_similar(<span class="hljs-string">&quot;column&quot;</span>)<br><br><span class="hljs-comment"># ------------------</span><br></code></pre></div></td></tr></table></figure><p></p><figure class="highlight scheme"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs scheme">[(<span class="hljs-symbol">&#x27;columns</span>&#x27;, <span class="hljs-number">0.767943263053894</span>),<br> (<span class="hljs-symbol">&#x27;columnist</span>&#x27;, <span class="hljs-number">0.6541407108306885</span>),<br> (<span class="hljs-symbol">&#x27;article</span>&#x27;, <span class="hljs-number">0.651928186416626</span>),<br> (<span class="hljs-symbol">&#x27;columnists</span>&#x27;, <span class="hljs-number">0.617466926574707</span>),<br> (<span class="hljs-symbol">&#x27;syndicated_column</span>&#x27;, <span class="hljs-number">0.599014401435852</span>),<br> (<span class="hljs-symbol">&#x27;op_ed</span>&#x27;, <span class="hljs-number">0.588202714920044</span>),<br> (<span class="hljs-symbol">&#x27;Op_Ed</span>&#x27;, <span class="hljs-number">0.5801560282707214</span>),<br> (<span class="hljs-symbol">&#x27;op_ed_column</span>&#x27;, <span class="hljs-number">0.5779396891593933</span>),<br> (<span class="hljs-symbol">&#x27;nationally_syndicated_column</span>&#x27;, <span class="hljs-number">0.572504997253418</span>),<br> (<span class="hljs-symbol">&#x27;colum</span>&#x27;, <span class="hljs-number">0.5595961213111877</span>)]<br></code></pre></div></td></tr></table></figure><h3 id="2.3">2.3</h3><p>(w1, w2,w3)w1w2w1w3w1w3&lt;w1w2w1=happyw2=cheerfulw3=sad</p><p>You should use the the <code>wv_from_bin.distance(w1, w2)</code>function here in order to compute the cosine distance between two words.Please see the <strong><ahref="https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.FastTextKeyedVectors.distance">GenSimdocumentation</a></strong> for further assistance.</p><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># ------------------</span><br><span class="hljs-comment"># Write your synonym &amp; antonym exploration code here.</span><br><br>w1 = <span class="hljs-string">&quot;love&quot;</span><br>w2 = <span class="hljs-string">&quot;like&quot;</span><br>w3 = <span class="hljs-string">&quot;hate&quot;</span><br>w1_w2_dist = wv_from_bin.distance(w1, w2)<br>w1_w3_dist = wv_from_bin.distance(w1, w3)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Synonyms &#123;&#125;, &#123;&#125; have cosine distance: &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(w1, w2, w1_w2_dist))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Antonyms &#123;&#125;, &#123;&#125; have cosine distance: &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(w1, w3, w1_w3_dist))<br><br><span class="hljs-comment"># ------------------</span><br></code></pre></div></td></tr></table></figure><p></p><figure class="highlight apache"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs apache"><span class="hljs-attribute">Synonyms</span> love, like have cosine distance: <span class="hljs-number">0</span>.<span class="hljs-number">6328612565994263</span><br><span class="hljs-attribute">Antonyms</span> love, hate have cosine distance: <span class="hljs-number">0</span>.<span class="hljs-number">39960432052612305</span><br></code></pre></div></td></tr></table></figure><h3 id="2.4">2.4</h3><p>man kingwoman___word2vecmost_similar<ahref="https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.FastTextKeyedVectors.most_similar">GenSim</a></p><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># ------------------</span><br><span class="hljs-comment"># Write your analogy exploration code here.</span><br><span class="hljs-comment"># man : him :: woman : her</span><br>pprint.pprint(wv_from_bin.most_similar(positive=[<span class="hljs-string">&#x27;woman&#x27;</span>, <span class="hljs-string">&#x27;him&#x27;</span>], negative=[<span class="hljs-string">&#x27;man&#x27;</span>]))<br><br><span class="hljs-comment"># ------------------</span><br></code></pre></div></td></tr></table></figure><p></p><figure class="highlight scheme"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs scheme">[(<span class="hljs-symbol">&#x27;her</span>&#x27;, <span class="hljs-number">0.694490909576416</span>),<br> (<span class="hljs-symbol">&#x27;she</span>&#x27;, <span class="hljs-number">0.6385233402252197</span>),<br> (<span class="hljs-symbol">&#x27;me</span>&#x27;, <span class="hljs-number">0.628451406955719</span>),<br> (<span class="hljs-symbol">&#x27;herself</span>&#x27;, <span class="hljs-number">0.6239798665046692</span>),<br> (<span class="hljs-symbol">&#x27;them</span>&#x27;, <span class="hljs-number">0.5843966007232666</span>),<br> (<span class="hljs-symbol">&#x27;She</span>&#x27;, <span class="hljs-number">0.5237804651260376</span>),<br> (<span class="hljs-symbol">&#x27;myself</span>&#x27;, <span class="hljs-number">0.4885627031326294</span>),<br> (<span class="hljs-symbol">&#x27;saidshe</span>&#x27;, <span class="hljs-number">0.48337966203689575</span>),<br> (<span class="hljs-symbol">&#x27;he</span>&#x27;, <span class="hljs-number">0.48184287548065186</span>),<br> (<span class="hljs-symbol">&#x27;Gail_Quets</span>&#x27;, <span class="hljs-number">0.4784894585609436</span>)]<br></code></pre></div></td></tr></table></figure><p>her</p><h3 id="2.5">2.5</h3><p> </p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># ------------------</span><br><span class="hljs-comment"># Write your incorrect analogy exploration code here.</span><br><span class="hljs-comment"># tree : leaf :: flower : petal</span><br>pprint.pprint(wv_from_bin.most_similar(positive=[<span class="hljs-string">&#x27;leaf&#x27;</span>, <span class="hljs-string">&#x27;flower&#x27;</span>], negative=[<span class="hljs-string">&#x27;tree&#x27;</span>]))<br><br><span class="hljs-comment"># ------------------</span><br></code></pre></div></td></tr></table></figure><p></p><figure class="highlight scheme"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs scheme">[(<span class="hljs-symbol">&#x27;floral</span>&#x27;, <span class="hljs-number">0.5532568693161011</span>),<br> (<span class="hljs-symbol">&#x27;marigold</span>&#x27;, <span class="hljs-number">0.5291938185691833</span>),<br> (<span class="hljs-symbol">&#x27;tulip</span>&#x27;, <span class="hljs-number">0.521312952041626</span>),<br> (<span class="hljs-symbol">&#x27;rooted_cuttings</span>&#x27;, <span class="hljs-number">0.5189826488494873</span>),<br> (<span class="hljs-symbol">&#x27;variegation</span>&#x27;, <span class="hljs-number">0.5136324763298035</span>),<br> (<span class="hljs-symbol">&#x27;Asiatic_lilies</span>&#x27;, <span class="hljs-number">0.5132641792297363</span>),<br> (<span class="hljs-symbol">&#x27;gerberas</span>&#x27;, <span class="hljs-number">0.5106234550476074</span>),<br> (<span class="hljs-symbol">&#x27;gerbera_daisies</span>&#x27;, <span class="hljs-number">0.5101010203361511</span>),<br> (<span class="hljs-symbol">&#x27;Verbena_bonariensis</span>&#x27;, <span class="hljs-number">0.5070016980171204</span>),<br> (<span class="hljs-symbol">&#x27;violet</span>&#x27;, <span class="hljs-number">0.5058108568191528</span>)]<br></code></pre></div></td></tr></table></figure><p></p><h3 id="2.6">2.6</h3><p></p><ol type="a"><li><p>womanbossman?</p></li><li><p>manbosswoman?</p></li></ol><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># Run this cell</span><br><span class="hljs-comment"># Here `positive` indicates the list of words to be similar to and `negative` indicates the list of words to be</span><br><span class="hljs-comment"># most dissimilar from.</span><br>pprint.pprint(wv_from_bin.most_similar(positive=[<span class="hljs-string">&#x27;woman&#x27;</span>, <span class="hljs-string">&#x27;boss&#x27;</span>], negative=[<span class="hljs-string">&#x27;man&#x27;</span>]))<br><span class="hljs-built_in">print</span>()<br>pprint.pprint(wv_from_bin.most_similar(positive=[<span class="hljs-string">&#x27;man&#x27;</span>, <span class="hljs-string">&#x27;boss&#x27;</span>], negative=[<span class="hljs-string">&#x27;woman&#x27;</span>]))<br></code></pre></div></td></tr></table></figure><p></p><figure class="highlight scheme"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs scheme">[(<span class="hljs-symbol">&#x27;bosses</span>&#x27;, <span class="hljs-number">0.5522644519805908</span>),<br> (<span class="hljs-symbol">&#x27;manageress</span>&#x27;, <span class="hljs-number">0.49151360988616943</span>),<br> (<span class="hljs-symbol">&#x27;exec</span>&#x27;, <span class="hljs-number">0.45940813422203064</span>),<br> (<span class="hljs-symbol">&#x27;Manageress</span>&#x27;, <span class="hljs-number">0.45598435401916504</span>),<br> (<span class="hljs-symbol">&#x27;receptionist</span>&#x27;, <span class="hljs-number">0.4474116563796997</span>),<br> (<span class="hljs-symbol">&#x27;Jane_Danson</span>&#x27;, <span class="hljs-number">0.44480544328689575</span>),<br> (<span class="hljs-symbol">&#x27;Fiz_Jennie_McAlpine</span>&#x27;, <span class="hljs-number">0.44275766611099243</span>),<br> (<span class="hljs-symbol">&#x27;Coronation_Street_actress</span>&#x27;, <span class="hljs-number">0.44275566935539246</span>),<br> (<span class="hljs-symbol">&#x27;supremo</span>&#x27;, <span class="hljs-number">0.4409853219985962</span>),<br> (<span class="hljs-symbol">&#x27;coworker</span>&#x27;, <span class="hljs-number">0.43986251950263977</span>)]<br><br>[(<span class="hljs-symbol">&#x27;supremo</span>&#x27;, <span class="hljs-number">0.6097398400306702</span>),<br> (<span class="hljs-symbol">&#x27;MOTHERWELL_boss</span>&#x27;, <span class="hljs-number">0.5489562153816223</span>),<br> (<span class="hljs-symbol">&#x27;CARETAKER_boss</span>&#x27;, <span class="hljs-number">0.5375303626060486</span>),<br> (<span class="hljs-symbol">&#x27;Bully_Wee_boss</span>&#x27;, <span class="hljs-number">0.5333974361419678</span>),<br> (<span class="hljs-symbol">&#x27;YEOVIL_Town_boss</span>&#x27;, <span class="hljs-number">0.5321705341339111</span>),<br> (<span class="hljs-symbol">&#x27;head_honcho</span>&#x27;, <span class="hljs-number">0.5281980037689209</span>),<br> (<span class="hljs-symbol">&#x27;manager_Stan_Ternent</span>&#x27;, <span class="hljs-number">0.525971531867981</span>),<br> (<span class="hljs-symbol">&#x27;Viv_Busby</span>&#x27;, <span class="hljs-number">0.5256162881851196</span>),<br> (<span class="hljs-symbol">&#x27;striker_Gabby_Agbonlahor</span>&#x27;, <span class="hljs-number">0.5250812768936157</span>),<br> (<span class="hljs-symbol">&#x27;BARNSLEY_boss</span>&#x27;, <span class="hljs-number">0.5238943099975586</span>)]<br></code></pre></div></td></tr></table></figure><p> : :::___landladytop-10manageressreceptionist</p><p> : :: :___/</p><h3 id="2.7">2.7</h3><p></p><ul><li>: :: :___</li><li>: :: :___</li></ul><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># ------------------</span><br><span class="hljs-comment"># Write your bias exploration code here.</span><br><br>pprint.pprint(wv_from_bin.most_similar(positive=[<span class="hljs-string">&#x27;woman&#x27;</span>, <span class="hljs-string">&#x27;doctor&#x27;</span>], negative=[<span class="hljs-string">&#x27;man&#x27;</span>]))<br><span class="hljs-built_in">print</span>()<br>pprint.pprint(wv_from_bin.most_similar(positive=[<span class="hljs-string">&#x27;man&#x27;</span>, <span class="hljs-string">&#x27;doctor&#x27;</span>], negative=[<span class="hljs-string">&#x27;woman&#x27;</span>]))<br><br><span class="hljs-comment"># ------------------</span><br></code></pre></div></td></tr></table></figure><p></p><figure class="highlight scheme"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs scheme">[(<span class="hljs-symbol">&#x27;gynecologist</span>&#x27;, <span class="hljs-number">0.7093892097473145</span>),<br> (<span class="hljs-symbol">&#x27;nurse</span>&#x27;, <span class="hljs-number">0.647728681564331</span>),<br> (<span class="hljs-symbol">&#x27;doctors</span>&#x27;, <span class="hljs-number">0.6471461057662964</span>),<br> (<span class="hljs-symbol">&#x27;physician</span>&#x27;, <span class="hljs-number">0.64389967918396</span>),<br> (<span class="hljs-symbol">&#x27;pediatrician</span>&#x27;, <span class="hljs-number">0.6249487996101379</span>),<br> (<span class="hljs-symbol">&#x27;nurse_practitioner</span>&#x27;, <span class="hljs-number">0.6218312978744507</span>),<br> (<span class="hljs-symbol">&#x27;obstetrician</span>&#x27;, <span class="hljs-number">0.6072014570236206</span>),<br> (<span class="hljs-symbol">&#x27;ob_gyn</span>&#x27;, <span class="hljs-number">0.5986712574958801</span>),<br> (<span class="hljs-symbol">&#x27;midwife</span>&#x27;, <span class="hljs-number">0.5927063226699829</span>),<br> (<span class="hljs-symbol">&#x27;dermatologist</span>&#x27;, <span class="hljs-number">0.5739566683769226</span>)]<br><br>[(<span class="hljs-symbol">&#x27;physician</span>&#x27;, <span class="hljs-number">0.6463665962219238</span>),<br> (<span class="hljs-symbol">&#x27;doctors</span>&#x27;, <span class="hljs-number">0.5858404040336609</span>),<br> (<span class="hljs-symbol">&#x27;surgeon</span>&#x27;, <span class="hljs-number">0.5723941326141357</span>),<br> (<span class="hljs-symbol">&#x27;dentist</span>&#x27;, <span class="hljs-number">0.552364706993103</span>),<br> (<span class="hljs-symbol">&#x27;cardiologist</span>&#x27;, <span class="hljs-number">0.5413815975189209</span>),<br> (<span class="hljs-symbol">&#x27;neurologist</span>&#x27;, <span class="hljs-number">0.5271126627922058</span>),<br> (<span class="hljs-symbol">&#x27;neurosurgeon</span>&#x27;, <span class="hljs-number">0.5249835848808289</span>),<br> (<span class="hljs-symbol">&#x27;urologist</span>&#x27;, <span class="hljs-number">0.5247740149497986</span>),<br> (<span class="hljs-symbol">&#x27;Doctor</span>&#x27;, <span class="hljs-number">0.5240625143051147</span>),<br> (<span class="hljs-symbol">&#x27;internist</span>&#x27;, <span class="hljs-number">0.5183224081993103</span>)]<br></code></pre></div></td></tr></table></figure><p>nurse</p><h3 id="2.8">2.8</h3><p></p><p></p><h2 id=""></h2><p>[1] CS224n: Natural Language Processing with Deep Learning,2019-03-12. http://web.stanford.edu/class/cs224n.</p><p>[2]https://github.com/ShowMeAI-Hub/awesome-AI-courses-notes-cheatsheets/tree/main/CS224n-Natural-Language-Processing-with-Deep-Learning/assignment-solutions/Assignment1</p>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>NLP</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>-</title>
    <link href="/2022/05/05/%E7%AC%AC%E4%BA%8C%E8%AE%B2-%E8%AF%8D%E5%90%91%E9%87%8F%E8%BF%9B%E9%98%B6/"/>
    <url>/2022/05/05/%E7%AC%AC%E4%BA%8C%E8%AE%B2-%E8%AF%8D%E5%90%91%E9%87%8F%E8%BF%9B%E9%98%B6/</url>
    
    <content type="html"><![CDATA[<h1 id="">1 </h1><h2 id="">1.1 </h2><p><spanclass="math inline">\(J(\theta)\)</span>()</p><ul><li></li><li></li></ul><p> Stochastic Gradient DescentSGD</p><ul><li></li></ul><p><strong>mini-batchgradient descent</strong></p><h2 id="">1.2 </h2><ul><li></li><li><spanclass="math inline">\(2m+1\)</span><spanclass="math inline">\(\nabla_{\theta}J_{t}(\theta)\)</span></li></ul><p><span class="math display">\[\nabla_{\theta} J_{t}(\theta)=\left[\begin{array}{l}0 \\\vdots \\\nabla_{v_{\text {like }}} \\\vdots \\0 \\\nabla_{u_{I}} \\\vdots \\\nabla_{u_{\text {learning }}} \\\vdots\end{array}\right] \in \mathbb{R}^{2 d V}\]</span></p><p><strong></strong></p><ul><li><spanclass="math inline">\(U\)</span><spanclass="math inline">\(V\)</span></li><li>/</li></ul><p></p><h2 id="word2vec">1.3 Word2vec</h2><p>word2vec</p><ul><li>1.Skip-grams (SG)</li><li>2.Continuous Bag of Words(CBOW)</li></ul><p>naivesoftmax()</p><h2 id="skip-gram2">1.4skip-gram2</h2><p>softmax</p><ul><li>2 negative sampling/ skip-gram</li><li> true pair () noise pair() </li></ul><p>()<spanclass="math inline">\(J(\theta)=\frac{1}{T} \sum_{t=1}^{T}J_{t}(\theta)\)</span> <span class="math display">\[J_{t}(\theta)=\log \sigma\left(u_{o}^{T} v_{c}\right)+\sum_{i=1}^{k}\mathbb{E}_{j \sim P(w)}\left[\log \sigma\left(-u_{j}^{T}v_{c}\right)\right]\]</span></p><ul><li>sigmoid()</li><li>2</li></ul><p>: <span class="math display">\[J_{n e g-s a m p l e}\left(\boldsymbol{o}, \boldsymbol{v}_{c},\boldsymbol{U}\right)=-\log \left(\sigma\left(\boldsymbol{u}_{o}^{\top}\boldsymbol{v}_{c}\right)\right)-\sum_{k=1}^{K} \log\left(\sigma\left(-\boldsymbol{u}_{k}^{\top}\boldsymbol{v}_{c}\right)\right)\]</span></p><ul><li><span class="math inline">\(K\)</span></li><li></li><li><span class="math inline">\(P(w)=U(w)^{3 / 4} /Z\)</span><spanclass="math inline">\(U(w)\)</span> unigram </li><li> 3/4 </li><li><span class="math inline">\(Z\)</span></li></ul><h1 id="">2 </h1><h2 id="">2.1 </h2><p><strong></strong><spanclass="math inline">\(X\)</span>windowfulldocument)</p><ul><li><strong>Window</strong>word2vecWindow(POS)</li><li><strong>Word-document</strong><spanclass="math inline">\(i\)</span><spanclass="math inline">\(j\)</span><spanclass="math inline">\(X_{ij}\)</span><spanclass="math inline">\(X\)</span><spanclass="math inline">\(|V| \times M\)</span><spanclass="math inline">\(|V|\)</span><spanclass="math inline">\(M\)</span>co-occurrencematrixLatent SemanticAnalysis</li></ul><h2 id="">2.2 </h2><p>(5-10)</p><p>1</p><ul><li>I like deep learning.</li><li>I like NLP.</li><li>I enjoy flying.</li></ul><p>word-word co-occurrence matrix</p><p><img src="/img/nlp//1.png" /></p><h2 id="">2.3</h2><p></p><ul><li></li><li></li><li></li></ul><h2 id="">2.4 </h2><p></p><ul><li>(25-1000)word2vec</li></ul><p></p><h2 id="1x1">2.5 1X1</h2><p>SVD<spanclass="math inline">\(X\)</span><span class="math inline">\(U\Sigma V^{T}\)</span></p><ul><li><spanclass="math inline">\(\Sigma\)</span></li><li><span class="math inline">\(U\)</span><spanclass="math inline">\(V\)</span></li></ul><p><spanclass="math inline">\(k\)</span><spanclass="math inline">\(U\)</span><spanclass="math inline">\(V\)</span></p><ul><li></li></ul><h2 id="svdpython">2.6SVDpython</h2><p><img src="/img/nlp//2.png" /></p><p></p><p><img src="/img/nlp//3.png" /></p><h2 id="">2.7 </h2><h3 id="hacks-to-x-several-used-in-rohde-et-al.-2005">Hacks to X(several used in Rohde et al. 2005)</h3><p> counts </p><ul><li>()<ul><li>log</li><li><span class="math inline">\(\min (X, t), t \approx 100\)</span></li><li></li></ul></li><li>window</li><li>Person</li></ul><h2 id="">2.8 </h2><p></p><ul><li><span class="math inline">\(dirve \to deriver\)</span></li><li><span class="math inline">\(swim \to swimmer\)</span></li><li><span class="math inline">\(teach \to teacher\)</span></li></ul><p></p><h2 id="-vs.-">2.9  VS. </h2><p></p><p><strong></strong></p><ul><li><strong></strong></li><li><strong></strong></li></ul><p><strong></strong></p><ul><li><strong></strong></li><li><strong></strong></li></ul><h1 id="glove">3 GloVe</h1><h2 id="-1">3.1 </h2><h3 id="encoding-meaning-in-vector-differences">3.1.1 Encoding meaningin vector differences</h3><p>GloVemeaningcomponent</p><p><img src="/img/nlp//4.png" /></p><p>icesteamsolidicesteamsolidicegaswatericesteamfashion1</p><h3id="combining-the-best-of-both-worlds-glove-pennington-et-al.-emnlp-2014">3.1.2Combining the best of both worlds GloVe [Pennington et al., EMNLP2014]</h3><p><span class="math display">\[w_i \cdot w_j = \log P(i|j)\]</span></p><p><span class="math display">\[J=\sum_{i, j=1}^{V} f\left(X_{i j}\right)\left(w_{i}^{T}\tilde{w}_{j}+b_{i}+\tilde{b}_{j}-\log X_{i j}\right)^{2}\]</span></p><ul><li></li><li></li><li></li></ul><h2 id="glove">3.2 GloVe</h2><p>GloVeGloVefrog</p><p><img src="/img/nlp//5.png" /></p><h1 id="">4 </h1><h2 id="">4.1 </h2><p></p><ul><li><strong></strong><ul><li>/</li><li></li><li></li><li></li></ul></li><li><strong></strong><ul><li>NLP</li><li></li><li></li><li></li></ul></li></ul><h2 id="">4.2 </h2><p><strong></strong>a,bcd<span class="math display">\[a: b:: c: ? \rightarrow d=\arg \max _{i}\frac{\left(x_{b}-x_{a}+x_{c}\right)^{T}x_{i}}{\left\|x_{b}-x_{a}+x_{c}\right\|}\]</span></p><ul><li></li><li></li><li>:</li></ul><h2 id="glove">4.3 Glove</h2><p>GloVe</p><p>brother  sister, man  woman, king - queen</p><p><img src="/img/nlp//6.png" /></p><h2 id="">4.4 </h2><p><img src="/img/nlp//7.png" /></p><p><img src="/img/nlp//8.png" /></p><ul><li></li><li>300</li></ul><h2 id="">4.5 </h2><p><img src="/img/nlp//9.png" /></p><h2 id="">4.6 </h2><h3 id="section"><img src="/img/nlp//10.png" /></h3><h1 id="word-senses">5 word senses</h1><h2 id="">5.1 </h2><p></p><ul><li></li><li></li></ul><p>pike</p><p></p><h2 id="pike">5.2 pike</h2><p><img src="/img/nlp//11.png" /></p><h2 id="-2">5.3 </h2><h3id="improving-word-representations-via-global-context-and-multiple-word-prototypes-huang-et-al.-2012">5.3.1Improving Word Representations Via Global Context And Multiple WordPrototypes (Huang et al. 2012)</h3><p><img src="/img/nlp//12.png" /></p><p>bank1bank2</p><h3id="linear-algebraic-structure-of-word-senses-with-applications-to-polysemy">5.3.2Linear Algebraic Structure of Word Senses, with Applications toPolysemy</h3><ul><li>(word2vec)()</li></ul><p><span class="math display">\[v_{pike} = \alpha_1 v_{pike_1} + \alpha_2 v_{pike_2} + \alpha_3v_{pike_3}\]</span></p><ul><li><span class="math inline">\(\alpha =\frac{f_{1}}{f_{1}+f_{2}+f_{3}}\)</span></li></ul><p></p><ul><li></li><li>()</li></ul><h2 id="">5.4 </h2><ul><li>NLP</li><li></li></ul><p><img src="/img/nlp//13.png" /></p>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>NLP</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2022/05/03/%E5%9B%9E%E6%BA%AF/"/>
    <url>/2022/05/03/%E5%9B%9E%E6%BA%AF/</url>
    
    <content type="html"><![CDATA[<h2 id="">17</h2><p><img src="/img/LeetCode//17.png" /></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">letterCombinations</span>(<span class="hljs-params">self, digits: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]:<br>        <span class="hljs-keyword">if</span> digits == <span class="hljs-string">&#x27;&#x27;</span>:<br>            <span class="hljs-keyword">return</span> []<br><br>        phoneMap = &#123;<br>        <span class="hljs-string">&#x27;2&#x27;</span>: <span class="hljs-string">&#x27;abc&#x27;</span>,<br>        <span class="hljs-string">&#x27;3&#x27;</span>: <span class="hljs-string">&#x27;def&#x27;</span>,<br>        <span class="hljs-string">&#x27;4&#x27;</span>: <span class="hljs-string">&#x27;ghi&#x27;</span>,<br>        <span class="hljs-string">&#x27;5&#x27;</span>: <span class="hljs-string">&#x27;jkl&#x27;</span>,<br>        <span class="hljs-string">&#x27;6&#x27;</span>: <span class="hljs-string">&#x27;mno&#x27;</span>,<br>        <span class="hljs-string">&#x27;7&#x27;</span>: <span class="hljs-string">&#x27;pqrs&#x27;</span>,<br>        <span class="hljs-string">&#x27;8&#x27;</span>: <span class="hljs-string">&#x27;tuv&#x27;</span>,<br>        <span class="hljs-string">&#x27;9&#x27;</span>: <span class="hljs-string">&#x27;wxyz&#x27;</span>,   <br>        &#125;<br>        <br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">backtrack</span>(<span class="hljs-params">index: <span class="hljs-built_in">int</span></span>):<span class="hljs-comment"># </span><br>            <span class="hljs-keyword">if</span> index == <span class="hljs-built_in">len</span>(digits):<br>                combinations.append(<span class="hljs-string">&#x27;&#x27;</span>.join(combination))<br>            <span class="hljs-keyword">else</span>:<br>                digit = digits[index]<br>                <span class="hljs-keyword">for</span> ch <span class="hljs-keyword">in</span> phoneMap[digit]:<br>                    combination.append(ch)<br>                    backtrack(index + <span class="hljs-number">1</span>)<br>                    combination.pop()<br><br>        combination = <span class="hljs-built_in">list</span>()<br>        combinations = <span class="hljs-built_in">list</span>()<br>        backtrack(<span class="hljs-number">0</span>)<br><br>        <span class="hljs-keyword">return</span> combinations<br></code></pre></div></td></tr></table></figure><h2 id="">22</h2><p><img src="/img/LeetCode//22.png" /></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">generateParenthesis</span>(<span class="hljs-params">self, n: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]:<br>        ans = []<br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">backtrack</span>(<span class="hljs-params">S, left, right</span>):<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(S) == <span class="hljs-number">2</span> * n:<br>                ans.append(<span class="hljs-string">&#x27;&#x27;</span>.join(S))<br>                <span class="hljs-keyword">return</span><br>            <span class="hljs-keyword">if</span> left &lt; n:<br>                S.append(<span class="hljs-string">&#x27;(&#x27;</span>)<br>                backtrack(S, left + <span class="hljs-number">1</span>, right)<br>                S.pop()<br>            <span class="hljs-keyword">if</span> right &lt; left:<br>                S.append(<span class="hljs-string">&#x27;)&#x27;</span>)<br>                backtrack(S, left, right + <span class="hljs-number">1</span>)<br>                S.pop()<br>        backtrack([], <span class="hljs-number">0</span>, <span class="hljs-number">0</span>)<br>        <span class="hljs-keyword">return</span> ans<br></code></pre></div></td></tr></table></figure><h2 id="">39</h2><p><img src="/img/LeetCode//39.png" /></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">combinationSum</span>(<span class="hljs-params">self, candidates: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], target: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]]:<br>        candidates.sort()<br>        n = <span class="hljs-built_in">len</span>(candidates)<br>        res = []<br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">backtrack</span>(<span class="hljs-params">i, tmp_sum, tmp</span>):<br>            <span class="hljs-keyword">if</span>  tmp_sum &gt; target <span class="hljs-keyword">or</span> i == n:<br>                <span class="hljs-keyword">return</span> <br>            <span class="hljs-keyword">if</span> tmp_sum == target:<br>                res.append(tmp)<br>                <span class="hljs-keyword">return</span> <br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(i, n):<br>                <span class="hljs-keyword">if</span> tmp_sum + candidates[j] &gt; target:<br>                    <span class="hljs-keyword">break</span><br>                backtrack(j, tmp_sum+candidates[j], tmp+[candidates[j]])<br>        backtrack(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, [])<br>        <span class="hljs-keyword">return</span> res<br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>LeetCode</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>-NLP</title>
    <link href="/2022/05/01/%E7%AC%AC%E4%B8%80%E8%AE%B2-NLP%E4%BB%8B%E7%BB%8D%E4%B8%8E%E8%AF%8D%E5%90%91%E9%87%8F%E5%88%9D%E6%AD%A5/"/>
    <url>/2022/05/01/%E7%AC%AC%E4%B8%80%E8%AE%B2-NLP%E4%BB%8B%E7%BB%8D%E4%B8%8E%E8%AF%8D%E5%90%91%E9%87%8F%E5%88%9D%E6%AD%A5/</url>
    
    <content type="html"><![CDATA[<h1 id="">1 </h1><h2 id="">1.1 </h2><p><strong>WordNet</strong>(isa)wordnetNLTK python</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">from</span> nltk.corpus <span class="hljs-keyword">import</span> wordnet <span class="hljs-keyword">as</span> wn<br>poses = &#123; <span class="hljs-string">&#x27;n&#x27;</span>:<span class="hljs-string">&#x27;noun&#x27;</span>, <span class="hljs-string">&#x27;v&#x27;</span>:<span class="hljs-string">&#x27;verb&#x27;</span>, <span class="hljs-string">&#x27;s&#x27;</span>:<span class="hljs-string">&#x27;adj (s)&#x27;</span>, <span class="hljs-string">&#x27;a&#x27;</span>:<span class="hljs-string">&#x27;adj&#x27;</span>, <span class="hljs-string">&#x27;r&#x27;</span>:<span class="hljs-string">&#x27;adv&#x27;</span>&#125;<br><span class="hljs-keyword">for</span> synset <span class="hljs-keyword">in</span> wn.synsets(<span class="hljs-string">&quot;good&quot;</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&#123;&#125;: &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(poses[synset.pos()], <span class="hljs-string">&quot;, &quot;</span>.join([l.name() <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> synset.lemmas()])))<br>        <br><span class="hljs-keyword">from</span> nltk.corpus <span class="hljs-keyword">import</span> wordnet <span class="hljs-keyword">as</span> wn<br>panda = wn.synset(<span class="hljs-string">&quot;panda.n.01&quot;</span>)<br>hyper = <span class="hljs-keyword">lambda</span> s: s.hypernyms()<br><span class="hljs-built_in">list</span>(panda.closure(hyper))<br></code></pre></div></td></tr></table></figure><p></p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">noun: good<br>noun: good, goodness<br>noun: good, goodness<br>noun: commodity, trade_good, good<br>adj: good<br>adj (sat): full, good<br>adj: good<br>adj (sat): estimable, good, honorable, respectable<br>adj (sat): beneficial, good<br>adj (sat): good<br>adj (sat): good, just, upright<br><br>adverb: well, good<br>adverb: thoroughly, soundly, good<br></code></pre></div></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">[Synset(&#x27;procyonid.n.01&#x27;),<br>Synset(&#x27;carnivore.n.01&#x27;),<br>Synset(&#x27;placental.n.01&#x27;),<br>Synset(&#x27;mammal.n.01&#x27;),<br>Synset(&#x27;vertebrate.n.01&#x27;),<br>Synset(&#x27;chordate.n.01&#x27;),<br>Synset(&#x27;animal.n.01&#x27;),<br>Synset(&#x27;organism.n.01&#x27;),<br>Synset(&#x27;living_thing.n.01&#x27;),<br>Synset(&#x27;whole.n.02&#x27;),<br>Synset(&#x27;object.n.01&#x27;),<br>Synset(&#x27;physical_entity.n.01&#x27;),<br>Synset(&#x27;entity.n.01&#x27;)]<br></code></pre></div></td></tr></table></figure><h2 id="wordnet">1.2 WordNet</h2><ul><li><p>proficientgood</p></li><li><p></p></li><li><p></p></li></ul><h2 id="">1.3 ()</h2><p>hotelconferencemotel</p><p>one-hot vector1one-hotvector <span class="math display">\[\text { motel }=\left[\begin{array}{lllllllllllllll}0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp;0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0\end{array}\right]\]</span></p><p><span class="math display">\[\text { hotel }=\left[\begin{array}{lllllllllllllll}0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp;0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\end{array}\right]\]</span></p><p>one-hot vector = 500000</p><h2 id="">1.4 </h2><p></p><p></p><ul><li>WordNet</li><li> </li></ul><h2 id="">1.5 </h2><p><strong></strong><strong></strong></p><p>NLP</p><ul><li><spanclass="math inline">\(w\)</span>()</li><li><spanclass="math inline">\(w\)</span><spanclass="math inline">\(w\)</span></li></ul><h1 id="word-vectors">2 Word Vectors</h1><h2 id="">2.1 </h2><p><strong>Word2vec</strong> (Mikolov et al.2013)</p><ul><li><strong></strong><ul><li></li><li></li><li><spanclass="math inline">\(t\)</span><spanclass="math inline">\(c\)</span>()<spanclass="math inline">\(o\)</span></li><li><span class="math inline">\(c\)</span><spanclass="math inline">\(o\)</span><spanclass="math inline">\(P(o|c)\)</span></li><li></li></ul></li></ul><p><img src="/img/nlp/3.png" /></p><h1 id="word2vec-">3 Word2vec </h1><h2 id="">3.1 </h2><p>t = 1,  , T, <spanclass="math inline">\(m\)</span><spanclass="math inline">\(w_j\)</span> <spanclass="math display">\[Likelihood = L(\theta) = \prod_{t=1}^{T} \prod_{\substack{-m \leq j \leqm \\ j \neq 0}}P(w_{t+j}|w_t;\theta)\]</span></p><p><spanclass="math inline">\(\theta\)</span></p><h2 id="">3.2 </h2><p><spanclass="math inline">\(J(\theta)\)</span>() <spanclass="math display">\[Likelihood=-\frac1T \log L(\theta)=-\frac1T \sum_{t=1}^{T}\sum_{\substack{-m \leq j \leq m \\ j \neq 0}} \logP(w_{t+j}|w_t;\theta)\]</span></p><p></p><ul><li><spanclass="math inline">\(J(\theta)\)</span><strong></strong><strong></strong></li><li>/<strong></strong></li></ul><p><spanclass="math inline">\(P(w_{t+j}|w_t;\theta)\)</span>?</p><p><span class="math inline">\(w\)</span></p><ul><li><spanclass="math inline">\(w\)</span><spanclass="math inline">\(v_w\)</span></li><li><spanclass="math inline">\(w\)</span><spanclass="math inline">\(u_w\)</span></li></ul><p><spanclass="math inline">\(c\)</span><spanclass="math inline">\(o\)</span> <spanclass="math display">\[P(o \mid c)=\frac{\exp \left(u_{o}^{T} v_{c}\right)}{\sum_{w \in V} \exp\left(u_{w}^{T} v_{c}\right)}\]</span></p><ul><li><spanclass="math inline">\(u_o^Tv_c\)</span></li><li></li><li>Score</li></ul><h1 id="word2vec">4 Word2vec</h1><p>softmax function(<spanclass="math inline">\(R^n\Rightarrow(0,1)^n\)</span>)<spanclass="math inline">\(x_i\)</span><spanclass="math inline">\(p_i\)</span> <span class="math display">\[\operatorname{softmax}\left(x_{i}\right)=\frac{\exp\left(x_{i}\right)}{\sum_{j=1}^{n} \exp \left(x_{j}\right)}=p_{i}\]</span> loss</p><ul><li><p>Recall<spanclass="math inline">\(\theta\)</span></p></li><li><p>dV</p></li><li><p><span class="math display">\[\theta=\left[\begin{array}{l}v_{\text {aardvark }} \\v_{a} \\\vdots \\v_{z e b r a} \\u_{a a r d v a r k} \\u_{a} \\\vdots \\u_{z e b r a}\end{array}\right] \in \mathbb{R}^{2 d V}\]</span></p></li><li><p></p></li></ul><p>loss</p>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
      <category>NLP</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2022/05/01/%E5%8F%8C%E6%8C%87%E9%92%88/"/>
    <url>/2022/05/01/%E5%8F%8C%E6%8C%87%E9%92%88/</url>
    
    <content type="html"><![CDATA[<h2 id="">11</h2><p><img src="/img/LeetCode//3.png" /></p><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">maxArea</span>(<span class="hljs-params">self, height: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">int</span>:<br>        n = <span class="hljs-built_in">len</span>(height)<br>        left = <span class="hljs-number">0</span>    <span class="hljs-comment"># </span><br>        right = n - <span class="hljs-number">1</span>   <span class="hljs-comment"># </span><br>        max_s = <span class="hljs-number">0</span>   <span class="hljs-comment"># </span><br>        s = <span class="hljs-number">0</span>   <span class="hljs-comment"># </span><br>        l = <span class="hljs-number">0</span>   <span class="hljs-comment"># </span><br>        <span class="hljs-keyword">while</span> right &gt; left:<br>            <span class="hljs-keyword">if</span> height[left] &gt; height[right]:<br>                l = height[right]<br>            <span class="hljs-keyword">else</span>:<br>                l = height[left]<br>            s = (right - left) * l<br>            <span class="hljs-keyword">if</span> s &gt; max_s:<br>                max_s = s<br>            <span class="hljs-keyword">if</span> height[left] &gt; height[right]:<br>                right = right - <span class="hljs-number">1</span><br>            <span class="hljs-keyword">else</span>:<br>                left = left + <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> max_s<br></code></pre></div></td></tr></table></figure><h2 id="">15</h2><p><img src="/img/LeetCode//15.png" /></p><p>00</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">threeSum</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]]:<br>        nums.sort()<br>        n = <span class="hljs-built_in">len</span>(nums)<br>        ans = <span class="hljs-built_in">list</span>()<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<span class="hljs-comment"># </span><br>            <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> nums[i] != nums[i - <span class="hljs-number">1</span>]:<br>                k = n - <span class="hljs-number">1</span><br>                j = i + <span class="hljs-number">1</span><br>                <span class="hljs-keyword">while</span> k &gt; j:<span class="hljs-comment"># </span><br>                    <span class="hljs-keyword">if</span> k != n - <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> nums[k] == nums[k + <span class="hljs-number">1</span>]:<span class="hljs-comment"># </span><br>                        k = k - <span class="hljs-number">1</span><br>                        <span class="hljs-keyword">continue</span><br>                    <span class="hljs-keyword">if</span> j != i + <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> nums[j] == nums[j - <span class="hljs-number">1</span>]:<span class="hljs-comment"># </span><br>                        j = j + <span class="hljs-number">1</span><br>                        <span class="hljs-keyword">continue</span><br>                    s = nums[i] + nums[j] + nums[k]<br>                    <span class="hljs-keyword">if</span> s == <span class="hljs-number">0</span>:<br>                        ans.append([nums[i], nums[j], nums[k]])<br>                        k = k - <span class="hljs-number">1</span><br>                        j = j + <span class="hljs-number">1</span><br>                    <span class="hljs-keyword">elif</span> s &gt; <span class="hljs-number">0</span>:<br>                        k = k - <span class="hljs-number">1</span><br>                    <span class="hljs-keyword">elif</span> s &lt; <span class="hljs-number">0</span>:<br>                        j = j + <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> ans<br></code></pre></div></td></tr></table></figure><h2 id="">16</h2><p><img src="/img/LeetCode//16.png" /></p><p>target</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">threeSumClosest</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], target: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:<br>        n = <span class="hljs-built_in">len</span>(nums)<br>        nums.sort()<br>        min_num = <span class="hljs-number">10</span>**<span class="hljs-number">9</span><br>        ans = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>            <span class="hljs-keyword">if</span> i != <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> nums[i] == nums[i - <span class="hljs-number">1</span>]:<br>                <span class="hljs-keyword">continue</span><br>            k = n - <span class="hljs-number">1</span><br>            j = i + <span class="hljs-number">1</span><br>            <span class="hljs-keyword">while</span> k &gt; j:<br>                s = nums[i] + nums[j] + nums[k]<br>                <span class="hljs-keyword">if</span> s == target:<br>                    <span class="hljs-keyword">return</span> s<br>                <span class="hljs-keyword">if</span> s &gt; target:<br>                    <span class="hljs-keyword">if</span> s - target &lt; min_num:<br>                        min_num = s - target<br>                        ans = s<br>                    k = k - <span class="hljs-number">1</span><br>                <span class="hljs-keyword">elif</span> s &lt; target:<br>                    <span class="hljs-keyword">if</span> target - s &lt; min_num:<br>                        min_num = target - s<br>                        ans = s<br>                    j = j + <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> ans<br></code></pre></div></td></tr></table></figure><h2 id="">18</h2><p><img src="/img/LeetCode//18.png" /></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">fourSum</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], target: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]]:<br>        n = <span class="hljs-built_in">len</span>(nums)<br>        <span class="hljs-keyword">if</span> nums == [] <span class="hljs-keyword">or</span> n &lt; <span class="hljs-number">4</span>:<br>            <span class="hljs-keyword">return</span> []<br>        nums.sort()<br>        ans = <span class="hljs-built_in">list</span>()<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n - <span class="hljs-number">3</span>):<br>            <span class="hljs-keyword">if</span> i != <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> nums[i] == nums[i - <span class="hljs-number">1</span>]:<br>                <span class="hljs-keyword">continue</span><br>            <span class="hljs-keyword">if</span> nums[i] + nums[i + <span class="hljs-number">1</span>] + nums[i + <span class="hljs-number">2</span>] + nums[i + <span class="hljs-number">3</span>] &gt; target:<br>                <span class="hljs-keyword">break</span><br>            <span class="hljs-keyword">if</span> nums[i] + nums[n - <span class="hljs-number">1</span>] + nums[n - <span class="hljs-number">2</span>] + nums[n - <span class="hljs-number">3</span>] &lt; target:<br>                <span class="hljs-keyword">continue</span><br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(i + <span class="hljs-number">1</span>, n - <span class="hljs-number">2</span>):<br>                <span class="hljs-keyword">if</span> j != i + <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> nums[j] == nums[j - <span class="hljs-number">1</span>]:<br>                    <span class="hljs-keyword">continue</span><br>                <span class="hljs-keyword">if</span> nums[i] + nums[j] + nums[j + <span class="hljs-number">1</span>] + nums[j + <span class="hljs-number">2</span>] &gt; target:<br>                    <span class="hljs-keyword">break</span><br>                <span class="hljs-keyword">if</span> nums[i] + nums[n - <span class="hljs-number">1</span>] + nums[n - <span class="hljs-number">2</span>] + nums[n - <span class="hljs-number">3</span>] &lt; target:<br>                    <span class="hljs-keyword">continue</span><br>                k = j + <span class="hljs-number">1</span><br>                l = n - <span class="hljs-number">1</span><br>                <span class="hljs-keyword">while</span> k &lt; l:<br>                    <span class="hljs-built_in">sum</span> = nums[i] + nums[j] + nums[k] + nums[l]<br>                    <span class="hljs-keyword">if</span> <span class="hljs-built_in">sum</span> &lt; target:<br>                        k = k + <span class="hljs-number">1</span><br>                    <span class="hljs-keyword">elif</span> <span class="hljs-built_in">sum</span> &gt; target:<br>                        l = l - <span class="hljs-number">1</span><br>                    <span class="hljs-keyword">elif</span> <span class="hljs-built_in">sum</span> == target:<br>                        ans.append([nums[i], nums[j], nums[k], nums[l]])<br>                        <span class="hljs-keyword">while</span> k &lt; l <span class="hljs-keyword">and</span> nums[k] == nums[k + <span class="hljs-number">1</span>]:<br>                            k = k + <span class="hljs-number">1</span><br>                        k = k + <span class="hljs-number">1</span><br>                        <span class="hljs-keyword">while</span> k &lt; l <span class="hljs-keyword">and</span> nums[l] == nums[l - <span class="hljs-number">1</span>]:<br>                            l = l - <span class="hljs-number">1</span><br>                        l = l - <span class="hljs-number">1</span> <br><br>        <span class="hljs-keyword">return</span> ans<br></code></pre></div></td></tr></table></figure><h2 id="n">19N</h2><p><img src="/img/LeetCode//19.png" /></p><p>nn</p><p>ifn</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># Definition for singly-linked list.</span><br><span class="hljs-comment"># class ListNode:</span><br><span class="hljs-comment">#     def __init__(self, val=0, next=None):</span><br><span class="hljs-comment">#         self.val = val</span><br><span class="hljs-comment">#         self.next = next</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">removeNthFromEnd</span>(<span class="hljs-params">self, head: ListNode, n: <span class="hljs-built_in">int</span></span>) -&gt; ListNode:<br>        right = head<br>        left = head<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>            right = right.<span class="hljs-built_in">next</span><br>        <span class="hljs-keyword">if</span> right == <span class="hljs-literal">None</span>:<span class="hljs-comment"># </span><br>            left = left.<span class="hljs-built_in">next</span><br>            <span class="hljs-keyword">return</span> left<br>        <span class="hljs-keyword">while</span> right.<span class="hljs-built_in">next</span> != <span class="hljs-literal">None</span>:<br>            left = left.<span class="hljs-built_in">next</span><br>            right = right.<span class="hljs-built_in">next</span><br>        left.<span class="hljs-built_in">next</span> = left.<span class="hljs-built_in">next</span>.<span class="hljs-built_in">next</span><br>        <span class="hljs-keyword">return</span> head<br></code></pre></div></td></tr></table></figure><h2 id="">26</h2><p><img src="/img/LeetCode//26.png" /></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">removeDuplicates</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">int</span>:<br>        <span class="hljs-keyword">if</span> nums == []:<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>        n = <span class="hljs-built_in">len</span>(nums)<br>        left, right = <span class="hljs-number">1</span>, <span class="hljs-number">1</span><br>        <span class="hljs-keyword">while</span> right &lt; n:<br>            <span class="hljs-keyword">if</span> nums[right] != nums[right - <span class="hljs-number">1</span>]:<br>                nums[left] = nums[right]<br>                left = left + <span class="hljs-number">1</span><br>            right = right + <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> left<br></code></pre></div></td></tr></table></figure><h1 id="-ii---">167 II - </h1><p><img src="/img/LeetCode/image-20221123105007573.png" /></p><p></p><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">twoSum</span>(<span class="hljs-params">self, numbers: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], target: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]:<br>        n = <span class="hljs-built_in">len</span>(numbers)<br>        l, r = <span class="hljs-number">0</span>, n - <span class="hljs-number">1</span><br>        <span class="hljs-keyword">while</span> l &lt; r:<br>            <span class="hljs-keyword">if</span> numbers[l] + numbers[r] == target:<br>                res = [l + <span class="hljs-number">1</span>, r + <span class="hljs-number">1</span>]<br>                <span class="hljs-keyword">break</span><br>            <span class="hljs-keyword">elif</span> numbers[l] + numbers[r] &lt; target:<br>                l += <span class="hljs-number">1</span><br>            <span class="hljs-keyword">elif</span> numbers[l] + numbers[r] &gt; target:<br>                r -= <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> res<br></code></pre></div></td></tr></table></figure><h1 id="">88 </h1><p><img src="/img/LeetCode/image-20221123150408473.png" /></p><p>nums1  m  1  nums2  n  1  nums1  nums1</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">merge</span>(<span class="hljs-params">self, nums1: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], m: <span class="hljs-built_in">int</span>, nums2: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], n: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-literal">None</span>:<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Do not return anything, modify nums1 in-place instead.</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        i = m - <span class="hljs-number">1</span><br>        j = n - <span class="hljs-number">1</span><br>        k = m + n - <span class="hljs-number">1</span><br>        <span class="hljs-keyword">while</span> i &gt;= <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> j &gt;= <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">if</span> nums1[i] &gt;= nums2[j]:<br>                nums1[k] = nums1[i]<br>                i -= <span class="hljs-number">1</span><br>                k -= <span class="hljs-number">1</span><br>            <span class="hljs-keyword">else</span>:<br>                nums1[k] = nums2[j]<br>                j -= <span class="hljs-number">1</span><br>                k -= <span class="hljs-number">1</span><br>        <span class="hljs-keyword">if</span> i &gt;= <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">while</span> i &gt;= <span class="hljs-number">0</span>:<br>                nums1[k] = nums1[i]<br>                i -= <span class="hljs-number">1</span><br>                k -= <span class="hljs-number">1</span><br>        <span class="hljs-keyword">if</span> j &gt;= <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">while</span> j &gt;= <span class="hljs-number">0</span>:<br>                nums1[k] = nums2[j]<br>                j -= <span class="hljs-number">1</span><br>                k -= <span class="hljs-number">1</span>      <br></code></pre></div></td></tr></table></figure><h1 id="">142</h1><p><img src="/img/LeetCode/image-20221123152641208.png" /></p><p>Floyd  slow fast fast slow  fast fast  slow  fast slow  fast  fast  slow  fast  slow  fast</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># Definition for singly-linked list.</span><br><span class="hljs-comment"># class ListNode:</span><br><span class="hljs-comment">#     def __init__(self, x):</span><br><span class="hljs-comment">#         self.val = x</span><br><span class="hljs-comment">#         self.next = None</span><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">detectCycle</span>(<span class="hljs-params">self, head: <span class="hljs-type">Optional</span>[ListNode]</span>) -&gt; <span class="hljs-type">Optional</span>[ListNode]:<br>        slow, fast = head, head<br>        <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> fast <span class="hljs-keyword">or</span> <span class="hljs-keyword">not</span> fast.<span class="hljs-built_in">next</span>:<br>                <span class="hljs-keyword">return</span><br>            slow = slow.<span class="hljs-built_in">next</span><br>            fast = fast.<span class="hljs-built_in">next</span>.<span class="hljs-built_in">next</span><br>            <span class="hljs-keyword">if</span> slow == fast:<br>                <span class="hljs-keyword">break</span><br>        fast = head<br>        <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>            <span class="hljs-keyword">if</span> slow == fast:<br>                <span class="hljs-keyword">return</span> fast<br>            slow = slow.<span class="hljs-built_in">next</span><br>            fast = fast.<span class="hljs-built_in">next</span><br></code></pre></div></td></tr></table></figure><h1 id="">76</h1><p><img src="/img/LeetCode/image-20221129163110444.png" /></p><p> start  end start  end for  while while  start  startO(n)t_disktwindow_disk</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">minWindow</span>(<span class="hljs-params">self, s: <span class="hljs-built_in">str</span>, t: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">str</span>:<br>        t_disk, window_disk = &#123;&#125;, &#123;&#125;<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(t)):<br>            <span class="hljs-keyword">if</span> t[i] <span class="hljs-keyword">in</span> t_disk:<br>                t_disk[t[i]] += <span class="hljs-number">1</span><br>            <span class="hljs-keyword">else</span>:<br>                t_disk[t[i]] = <span class="hljs-number">1</span><br>        <br>        <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> t_disk:<br>            window_disk[key] = <span class="hljs-number">0</span><br><br>        start, res, min_len = <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;&#x27;</span>, <span class="hljs-built_in">float</span>(<span class="hljs-string">&#x27;inf&#x27;</span>)<br><br>        <span class="hljs-keyword">for</span> end <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(s)):<br>            <span class="hljs-keyword">if</span> s[end] <span class="hljs-keyword">in</span> window_disk:<br>                window_disk[s[end]] += <span class="hljs-number">1</span><br>            <span class="hljs-keyword">else</span>:<br>                window_disk[s[end]] = <span class="hljs-number">1</span><br><br>            <span class="hljs-keyword">while</span> self.check_windows(t_disk, window_disk):<br>                <span class="hljs-keyword">if</span> min_len &gt; end - start + <span class="hljs-number">1</span>:<br>                    min_len = end - start + <span class="hljs-number">1</span><br>                    res = s[start: end + <span class="hljs-number">1</span>]<br>                window_disk[s[start]] -= <span class="hljs-number">1</span><br>                start += <span class="hljs-number">1</span><br><br>        <span class="hljs-keyword">return</span> res<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">check_windows</span>(<span class="hljs-params">self, s, t</span>):<br>        <span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> s:<br>            <span class="hljs-keyword">if</span> s[key] &gt; t[key]:<br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span><br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>LeetCode</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2022/04/29/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"/>
    <url>/2022/04/29/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/</url>
    
    <content type="html"><![CDATA[<h2 id="">4</h2><p><img src="/img/LeetCode//2.png" /></p><p>s[i+1:j-1]<em>s</em>[<em>i</em>+1:<em>j</em>1] s<em>s</em>  i<em>i</em>  j<em>j</em>s[i:j]<em>s</em>[<em>i</em>:<em>j</em>] </p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">longestPalindrome</span>(<span class="hljs-params">self, s: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">str</span>:<br>        n = <span class="hljs-built_in">len</span>(s)<br>        <span class="hljs-keyword">if</span> n &lt; <span class="hljs-number">2</span>:  <span class="hljs-comment"># 1</span><br>            <span class="hljs-keyword">return</span> s<br>        <br>        <span class="hljs-built_in">max</span> = <span class="hljs-number">1</span><br>        left = <span class="hljs-number">0</span><br>        <span class="hljs-comment"># dp[i][j]s[i...j]</span><br>        dp = [[<span class="hljs-literal">False</span>] * n <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n)]<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>            dp[i][i] = <span class="hljs-literal">True</span><br><br>        <span class="hljs-keyword">for</span> L <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>, n + <span class="hljs-number">1</span>):<br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>                right = L + i - <span class="hljs-number">1</span><br>                <span class="hljs-keyword">if</span> right &gt;= n:<br>                    <span class="hljs-keyword">break</span><br>                <br>                <span class="hljs-keyword">if</span> s[i] != s[right]:<br>                    dp[i][right] = <span class="hljs-literal">False</span><br>                <span class="hljs-keyword">else</span>:<br>                    <span class="hljs-keyword">if</span> right - i &lt; <span class="hljs-number">3</span>:<br>                        dp[i][right] = <span class="hljs-literal">True</span><br>                    <span class="hljs-keyword">else</span>:<br>                        dp[i][right] = dp[i + <span class="hljs-number">1</span>][right - <span class="hljs-number">1</span>]<br><br>                <span class="hljs-keyword">if</span> dp[i][right] <span class="hljs-keyword">and</span> L &gt; <span class="hljs-built_in">max</span>:<br>                    <span class="hljs-built_in">max</span> = L<br>                    left = i<br>        <span class="hljs-keyword">return</span> s[left:left+<span class="hljs-built_in">max</span>]<br></code></pre></div></td></tr></table></figure><h2 id="">53</h2><p><img src="/img/LeetCode//53.png" /></p><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">maxSubArray</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">int</span>:<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(nums)):<br>            nums[i] += <span class="hljs-built_in">max</span>(nums[i - <span class="hljs-number">1</span>], <span class="hljs-number">0</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">max</span>(nums)<br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>LeetCode</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2022/04/29/%E5%AD%97%E7%AC%A6%E4%B8%B2/"/>
    <url>/2022/04/29/%E5%AD%97%E7%AC%A6%E4%B8%B2/</url>
    
    <content type="html"><![CDATA[<h2 id="">3</h2><p><img src="/img/LeetCode//1.png" /></p><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">lengthOfLongestSubstring</span>(<span class="hljs-params">self, s: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">int</span>:<br>        occ = <span class="hljs-built_in">set</span>()<br>        n = <span class="hljs-built_in">len</span>(s)<br>        <span class="hljs-comment"># rkans</span><br>        rk, ans = -<span class="hljs-number">1</span>, <span class="hljs-number">0</span><br>        flag = <span class="hljs-number">0</span>    <span class="hljs-comment"># </span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>            rk = i<br>            flag = <span class="hljs-number">0</span><br>            <span class="hljs-keyword">while</span> rk &lt; n <span class="hljs-keyword">and</span> s[rk] <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> occ:<br>                occ.add(s[rk])<br>                flag = flag + <span class="hljs-number">1</span><br>                rk = rk + <span class="hljs-number">1</span><br>            ans = flag <span class="hljs-keyword">if</span> flag &gt; ans <span class="hljs-keyword">else</span> ans<br>            occ.clear()<br>        <span class="hljs-keyword">return</span> ans<br></code></pre></div></td></tr></table></figure><p></p><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">lengthOfLongestSubstring</span>(<span class="hljs-params">self, s: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">int</span>:<br>        occ = <span class="hljs-built_in">set</span>()<br>        n = <span class="hljs-built_in">len</span>(s)<br>        <span class="hljs-comment"># rkans</span><br>        rk, ans = <span class="hljs-number">0</span>, <span class="hljs-number">0</span><br>        flag = <span class="hljs-number">0</span>    <span class="hljs-comment"># </span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>            <span class="hljs-keyword">if</span> i &gt; <span class="hljs-number">0</span>:<br>                occ.remove(s[i - <span class="hljs-number">1</span>])<br>                flag = flag - <span class="hljs-number">1</span><br>            <span class="hljs-keyword">while</span> rk &lt; n <span class="hljs-keyword">and</span> s[rk] <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> occ:<br>                occ.add(s[rk])<br>                rk = rk + <span class="hljs-number">1</span><br>                flag = flag + <span class="hljs-number">1</span><br>            ans = flag <span class="hljs-keyword">if</span> flag &gt; ans <span class="hljs-keyword">else</span> ans<br>        <span class="hljs-keyword">return</span> ans<br></code></pre></div></td></tr></table></figure><h2 id="">4</h2><p><img src="/img/LeetCode//2.png" /></p><p>s[i+1:j-1]<em>s</em>[<em>i</em>+1:<em>j</em>1] s<em>s</em>  i<em>i</em>  j<em>j</em>s[i:j]<em>s</em>[<em>i</em>:<em>j</em>] </p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">longestPalindrome</span>(<span class="hljs-params">self, s: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">str</span>:<br>        n = <span class="hljs-built_in">len</span>(s)<br>        <span class="hljs-keyword">if</span> n &lt; <span class="hljs-number">2</span>:  <span class="hljs-comment"># 1</span><br>            <span class="hljs-keyword">return</span> s<br>        <br>        <span class="hljs-built_in">max</span> = <span class="hljs-number">1</span><br>        left = <span class="hljs-number">0</span><br>        <span class="hljs-comment"># dp[i][j]s[i...j]</span><br>        dp = [[<span class="hljs-literal">False</span>] * n <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n)]<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>            dp[i][i] = <span class="hljs-literal">True</span><br><br>        <span class="hljs-keyword">for</span> L <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>, n + <span class="hljs-number">1</span>):<br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>                right = L + i - <span class="hljs-number">1</span><br>                <span class="hljs-keyword">if</span> right &gt;= n:<br>                    <span class="hljs-keyword">break</span><br>                <br>                <span class="hljs-keyword">if</span> s[i] != s[right]:<br>                    dp[i][right] = <span class="hljs-literal">False</span><br>                <span class="hljs-keyword">else</span>:<br>                    <span class="hljs-keyword">if</span> right - i &lt; <span class="hljs-number">3</span>:<br>                        dp[i][right] = <span class="hljs-literal">True</span><br>                    <span class="hljs-keyword">else</span>:<br>                        dp[i][right] = dp[i + <span class="hljs-number">1</span>][right - <span class="hljs-number">1</span>]<br><br>                <span class="hljs-keyword">if</span> dp[i][right] <span class="hljs-keyword">and</span> L &gt; <span class="hljs-built_in">max</span>:<br>                    <span class="hljs-built_in">max</span> = L<br>                    left = i<br>        <span class="hljs-keyword">return</span> s[left:left+<span class="hljs-built_in">max</span>]<br></code></pre></div></td></tr></table></figure><h2 id="z">6Z</h2><p><img src="/img/LeetCode//3.png" /></p><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">convert</span>(<span class="hljs-params">self, s: <span class="hljs-built_in">str</span>, numRows: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">str</span>:<br>        n = <span class="hljs-built_in">len</span>(s)<br>        <span class="hljs-keyword">if</span> numRows == <span class="hljs-number">1</span> <span class="hljs-keyword">or</span> numRows &gt;= n:<br>            <span class="hljs-keyword">return</span> s<br>        t = <span class="hljs-number">2</span> * numRows - <span class="hljs-number">2</span><br>        col = (n + t - <span class="hljs-number">1</span>) // t * (numRows - <span class="hljs-number">1</span>)<br>        matrix = [[<span class="hljs-string">&#x27;&#x27;</span>] * col <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(numRows)]<br>        x, y = <span class="hljs-number">0</span>, <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> i, ch <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(s):<br>            matrix[x][y] = ch<br>            <span class="hljs-keyword">if</span> i % t &lt; numRows - <span class="hljs-number">1</span>:<br>                x = x + <span class="hljs-number">1</span><br>            <span class="hljs-keyword">else</span>:<br>                x = x - <span class="hljs-number">1</span><br>                y = y + <span class="hljs-number">1</span><br>        ans = <span class="hljs-string">&#x27;&#x27;</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(numRows):<br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(col):<br>                <span class="hljs-keyword">if</span> matrix[i][j]:<br>                    ans = ans + matrix[i][j]<br><br>        <span class="hljs-keyword">return</span> ans<br></code></pre></div></td></tr></table></figure><h2 id="">7</h2><p><img src="/img/LeetCode//4.png" /></p><p><img src="/img/LeetCode//5.png" /></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">myAtoi</span>(<span class="hljs-params">self, s: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">int</span>:<br>        flag = <span class="hljs-literal">False</span><br>        <span class="hljs-keyword">if</span> s == <span class="hljs-string">&#x27;&#x27;</span>:<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> i, ch <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(s):<br>            <span class="hljs-keyword">if</span> ch != <span class="hljs-string">&#x27; &#x27;</span>:<br>                s = s[i:]<br>                <span class="hljs-keyword">break</span><br><br>        <span class="hljs-keyword">if</span> s[<span class="hljs-number">0</span>] == <span class="hljs-string">&#x27;-&#x27;</span>:<br>            flag = <span class="hljs-literal">True</span><br>            s = s[<span class="hljs-number">1</span>:]<br>        <span class="hljs-keyword">elif</span> s[<span class="hljs-number">0</span>] == <span class="hljs-string">&#x27;+&#x27;</span>:<br>            s = s[<span class="hljs-number">1</span>:]<br>        a = <span class="hljs-number">0</span><br>        ans = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> i, ch <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(s):<br>            <span class="hljs-keyword">if</span> ch.isdigit() == <span class="hljs-literal">False</span>:<br>                <span class="hljs-keyword">break</span><br>            a = <span class="hljs-built_in">int</span>(ch)<br>            ans = ans * <span class="hljs-number">10</span> + a<br>        <span class="hljs-keyword">if</span> flag:<br>            ans = -<span class="hljs-number">1</span> * ans<br>        <span class="hljs-keyword">if</span> ans &gt; <span class="hljs-number">2</span> ** <span class="hljs-number">31</span> - <span class="hljs-number">1</span>:<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">2</span> ** <span class="hljs-number">31</span> - <span class="hljs-number">1</span><br>        <span class="hljs-keyword">elif</span> ans &lt; -(<span class="hljs-number">2</span> ** <span class="hljs-number">31</span>):<br>            <span class="hljs-keyword">return</span> -(<span class="hljs-number">2</span> ** <span class="hljs-number">31</span>)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">return</span> ans<br></code></pre></div></td></tr></table></figure><h2 id="">14</h2><p><img src="/img/LeetCode//6.png" /></p><p>x</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">longestCommonPrefix</span>(<span class="hljs-params">self, strs: <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]</span>) -&gt; <span class="hljs-built_in">str</span>:<br>        flag = strs[<span class="hljs-number">0</span>]<span class="hljs-comment"># </span><br>        a = <span class="hljs-string">&quot;&quot;</span><span class="hljs-comment"># flag</span><br>        ans = <span class="hljs-string">&quot;&quot;</span><br>        n = <span class="hljs-built_in">len</span>(strs)<br>        <span class="hljs-keyword">if</span> n == <span class="hljs-number">1</span>:<span class="hljs-comment"># </span><br>            <span class="hljs-keyword">return</span> strs[<span class="hljs-number">0</span>]<br>        <span class="hljs-keyword">for</span> i, s <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(strs):<br>            <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span>:<span class="hljs-comment"># </span><br>                <span class="hljs-keyword">continue</span><br>            <span class="hljs-keyword">for</span> j, ch <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(s):<span class="hljs-comment"># flag</span><br>                <span class="hljs-keyword">if</span> j &lt; <span class="hljs-built_in">len</span>(flag) <span class="hljs-keyword">and</span> ch == flag[j]:<br>                    a = a + ch<br>                <span class="hljs-keyword">else</span>:<br>                    <span class="hljs-keyword">break</span><br>            flag = a<br>            a = <span class="hljs-string">&quot;&quot;</span><br>            <span class="hljs-keyword">if</span> i == n - <span class="hljs-number">1</span>:<span class="hljs-comment"># </span><br>                ans = flag<br>        <span class="hljs-keyword">return</span> ans<br></code></pre></div></td></tr></table></figure><h2 id="">17</h2><p><img src="/img/LeetCode//17.png" /></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">letterCombinations</span>(<span class="hljs-params">self, digits: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]:<br>        <span class="hljs-keyword">if</span> digits == <span class="hljs-string">&#x27;&#x27;</span>:<br>            <span class="hljs-keyword">return</span> []<br><br>        phoneMap = &#123;<br>        <span class="hljs-string">&#x27;2&#x27;</span>: <span class="hljs-string">&#x27;abc&#x27;</span>,<br>        <span class="hljs-string">&#x27;3&#x27;</span>: <span class="hljs-string">&#x27;def&#x27;</span>,<br>        <span class="hljs-string">&#x27;4&#x27;</span>: <span class="hljs-string">&#x27;ghi&#x27;</span>,<br>        <span class="hljs-string">&#x27;5&#x27;</span>: <span class="hljs-string">&#x27;jkl&#x27;</span>,<br>        <span class="hljs-string">&#x27;6&#x27;</span>: <span class="hljs-string">&#x27;mno&#x27;</span>,<br>        <span class="hljs-string">&#x27;7&#x27;</span>: <span class="hljs-string">&#x27;pqrs&#x27;</span>,<br>        <span class="hljs-string">&#x27;8&#x27;</span>: <span class="hljs-string">&#x27;tuv&#x27;</span>,<br>        <span class="hljs-string">&#x27;9&#x27;</span>: <span class="hljs-string">&#x27;wxyz&#x27;</span>,   <br>        &#125;<br>        <br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">backtrack</span>(<span class="hljs-params">index: <span class="hljs-built_in">int</span></span>):<span class="hljs-comment"># </span><br>            <span class="hljs-keyword">if</span> index == <span class="hljs-built_in">len</span>(digits):<br>                combinations.append(<span class="hljs-string">&#x27;&#x27;</span>.join(combination))<br>            <span class="hljs-keyword">else</span>:<br>                digit = digits[index]<br>                <span class="hljs-keyword">for</span> ch <span class="hljs-keyword">in</span> phoneMap[digit]:<br>                    combination.append(ch)<br>                    backtrack(index + <span class="hljs-number">1</span>)<br>                    combination.pop()<br><br>        combination = <span class="hljs-built_in">list</span>()<br>        combinations = <span class="hljs-built_in">list</span>()<br>        backtrack(<span class="hljs-number">0</span>)<br><br>        <span class="hljs-keyword">return</span> combinations<br></code></pre></div></td></tr></table></figure><h2 id="">20</h2><p><img src="/img/LeetCode//20.png" /></p><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">isValid</span>(<span class="hljs-params">self, s: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">bool</span>:<br>        stack = <span class="hljs-built_in">list</span>()<br>        <span class="hljs-keyword">for</span> ch <span class="hljs-keyword">in</span> s:<br>            <span class="hljs-keyword">if</span> ch == <span class="hljs-string">&#x27;)&#x27;</span>:<br>                <span class="hljs-keyword">if</span> stack == []:<br>                    <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br>                temp = stack.pop()<br>                <span class="hljs-keyword">if</span> temp != <span class="hljs-string">&#x27;(&#x27;</span>:<br>                    <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br>            <span class="hljs-keyword">elif</span> ch == <span class="hljs-string">&#x27;&#125;&#x27;</span>:<br>                <span class="hljs-keyword">if</span> stack == []:<br>                    <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br>                temp = stack.pop()<br>                <span class="hljs-keyword">if</span> temp != <span class="hljs-string">&#x27;&#123;&#x27;</span>:<br>                    <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br>            <span class="hljs-keyword">elif</span> ch == <span class="hljs-string">&#x27;]&#x27;</span>:<br>                <span class="hljs-keyword">if</span> stack == []:<br>                    <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br>                temp = stack.pop()<br>                <span class="hljs-keyword">if</span> temp != <span class="hljs-string">&#x27;[&#x27;</span>:<br>                    <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br>            <span class="hljs-keyword">else</span>:<br>                stack.append(ch)<br>        <span class="hljs-keyword">if</span> stack:<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span><br></code></pre></div></td></tr></table></figure><h2 id="">21</h2><p><img src="/img/LeetCode//21.png" /></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># Definition for singly-linked list.</span><br><span class="hljs-comment"># class ListNode:</span><br><span class="hljs-comment">#     def __init__(self, val=0, next=None):</span><br><span class="hljs-comment">#         self.val = val</span><br><span class="hljs-comment">#         self.next = next</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">mergeTwoLists</span>(<span class="hljs-params">self, list1: <span class="hljs-type">Optional</span>[ListNode], list2: <span class="hljs-type">Optional</span>[ListNode]</span>) -&gt; <span class="hljs-type">Optional</span>[ListNode]:<br>        head = ListNode(<span class="hljs-number">0</span>, <span class="hljs-literal">None</span>)<br>        temp = head<br>        first = list1<br>        second = list2<br>        <span class="hljs-keyword">while</span> first <span class="hljs-keyword">and</span> second:<br>            <span class="hljs-keyword">if</span> first.val &lt;= second.val:<br>                temp.<span class="hljs-built_in">next</span> = first<br>                temp = temp.<span class="hljs-built_in">next</span><br>                first = first.<span class="hljs-built_in">next</span><br>            <span class="hljs-keyword">elif</span> first.val &gt; second.val:<br>                temp.<span class="hljs-built_in">next</span> = second<br>                temp = temp.<span class="hljs-built_in">next</span><br>                second = second.<span class="hljs-built_in">next</span><br>        <br>        temp.<span class="hljs-built_in">next</span> = first <span class="hljs-keyword">if</span> first <span class="hljs-keyword">else</span> second<br>        <br>        <span class="hljs-keyword">return</span> head.<span class="hljs-built_in">next</span><br></code></pre></div></td></tr></table></figure><h2 id="">22</h2><p><img src="/img/LeetCode//22.png" /></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">generateParenthesis</span>(<span class="hljs-params">self, n: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]:<br>        ans = []<br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">backtrack</span>(<span class="hljs-params">S, left, right</span>):<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(S) == <span class="hljs-number">2</span> * n:<br>                ans.append(<span class="hljs-string">&#x27;&#x27;</span>.join(S))<br>                <span class="hljs-keyword">return</span><br>            <span class="hljs-keyword">if</span> left &lt; n:<br>                S.append(<span class="hljs-string">&#x27;(&#x27;</span>)<br>                backtrack(S, left + <span class="hljs-number">1</span>, right)<br>                S.pop()<br>            <span class="hljs-keyword">if</span> right &lt; left:<br>                S.append(<span class="hljs-string">&#x27;)&#x27;</span>)<br>                backtrack(S, left, right + <span class="hljs-number">1</span>)<br>                S.pop()<br>        backtrack([], <span class="hljs-number">0</span>, <span class="hljs-number">0</span>)<br>        <span class="hljs-keyword">return</span> ans<br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>LeetCode</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2022/04/28/%E5%93%88%E5%B8%8C%E8%A1%A8/"/>
    <url>/2022/04/28/%E5%93%88%E5%B8%8C%E8%A1%A8/</url>
    
    <content type="html"><![CDATA[<h2 id="">1</h2><p><img src="/img/LeetCode//1.png" /></p><p><code>x</code><code>target - x</code> <code>x</code> <code>x</code> </p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">twoSum</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], target: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]:<br>        hashtable = <span class="hljs-built_in">dict</span>()<br>        <span class="hljs-keyword">for</span> i, num <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(nums):<br>            <span class="hljs-keyword">if</span> target - num <span class="hljs-keyword">in</span> hashtable:<br>                <span class="hljs-keyword">return</span> [hashtable[target - num], i]<br>            <span class="hljs-keyword">else</span>:<br>                hashtable[num] = i<br>        <span class="hljs-keyword">return</span> []<br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>LeetCode</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2022/04/28/%E9%93%BE%E8%A1%A8/"/>
    <url>/2022/04/28/%E9%93%BE%E8%A1%A8/</url>
    
    <content type="html"><![CDATA[<h2 id="">2</h2><p><img src="/img/LeetCode//2.png" /></p><p>1</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># Definition for singly-linked list.</span><br><span class="hljs-comment"># class ListNode:</span><br><span class="hljs-comment">#     def __init__(self, val=0, next=None):</span><br><span class="hljs-comment">#         self.val = val</span><br><span class="hljs-comment">#         self.next = next</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">addTwoNumbers</span>(<span class="hljs-params">self, l1: <span class="hljs-type">Optional</span>[ListNode], l2: <span class="hljs-type">Optional</span>[ListNode], carryflag = <span class="hljs-number">0</span></span>) -&gt; <span class="hljs-type">Optional</span>[ListNode]:<br>        n1, n2 = l1.val <span class="hljs-keyword">if</span> l1 <span class="hljs-keyword">else</span> <span class="hljs-number">0</span>, l2.val <span class="hljs-keyword">if</span> l2 <span class="hljs-keyword">else</span> <span class="hljs-number">0</span><br>        s = n1 + n2 + carryflag<br>        val, carry_flag = s % <span class="hljs-number">10</span>, <span class="hljs-number">1</span> <span class="hljs-keyword">if</span> s &gt; <span class="hljs-number">9</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span><br>        next1, next2 = l1.<span class="hljs-built_in">next</span> <span class="hljs-keyword">if</span> l1 <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span>, l2.<span class="hljs-built_in">next</span> <span class="hljs-keyword">if</span> l2 <span class="hljs-keyword">else</span> <span class="hljs-literal">None</span><br>        <span class="hljs-keyword">if</span> next1 <span class="hljs-keyword">or</span> next2 <span class="hljs-keyword">or</span> carry_flag:<br>            <span class="hljs-keyword">return</span> ListNode(val, self.addTwoNumbers(next1, next2, carry_flag))<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">return</span> ListNode(val)<br></code></pre></div></td></tr></table></figure><h2 id="n">19N</h2><p><img src="/img/LeetCode//19.png" /></p><p>nn</p><p>ifn</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># Definition for singly-linked list.</span><br><span class="hljs-comment"># class ListNode:</span><br><span class="hljs-comment">#     def __init__(self, val=0, next=None):</span><br><span class="hljs-comment">#         self.val = val</span><br><span class="hljs-comment">#         self.next = next</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">removeNthFromEnd</span>(<span class="hljs-params">self, head: ListNode, n: <span class="hljs-built_in">int</span></span>) -&gt; ListNode:<br>        right = head<br>        left = head<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>            right = right.<span class="hljs-built_in">next</span><br>        <span class="hljs-keyword">if</span> right == <span class="hljs-literal">None</span>:<span class="hljs-comment"># </span><br>            left = left.<span class="hljs-built_in">next</span><br>            <span class="hljs-keyword">return</span> left<br>        <span class="hljs-keyword">while</span> right.<span class="hljs-built_in">next</span> != <span class="hljs-literal">None</span>:<br>            left = left.<span class="hljs-built_in">next</span><br>            right = right.<span class="hljs-built_in">next</span><br>        left.<span class="hljs-built_in">next</span> = left.<span class="hljs-built_in">next</span>.<span class="hljs-built_in">next</span><br>        <span class="hljs-keyword">return</span> head<br></code></pre></div></td></tr></table></figure><h2 id="">24</h2><p><img src="/img/LeetCode//24.png" /></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># Definition for singly-linked list.</span><br><span class="hljs-comment"># class ListNode:</span><br><span class="hljs-comment">#     def __init__(self, val=0, next=None):</span><br><span class="hljs-comment">#         self.val = val</span><br><span class="hljs-comment">#         self.next = next</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">swapPairs</span>(<span class="hljs-params">self, head: ListNode</span>) -&gt; ListNode:<br>        <span class="hljs-keyword">if</span> head == <span class="hljs-literal">None</span>:<br>            <span class="hljs-keyword">return</span> head<br>        temp = ListNode(<span class="hljs-number">0</span>, head)<br>        first = temp<br>        second = temp.<span class="hljs-built_in">next</span><br><br>        <span class="hljs-keyword">while</span> second <span class="hljs-keyword">and</span> second.<span class="hljs-built_in">next</span>:<br>            first.<span class="hljs-built_in">next</span> = second.<span class="hljs-built_in">next</span><br>            second.<span class="hljs-built_in">next</span> = second.<span class="hljs-built_in">next</span>.<span class="hljs-built_in">next</span><br>            first.<span class="hljs-built_in">next</span>.<span class="hljs-built_in">next</span> = second<br>            <br>            first = second<br>            second = second.<span class="hljs-built_in">next</span><br>        <span class="hljs-keyword">return</span> temp.<span class="hljs-built_in">next</span><br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>LeetCode</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2022/04/28/%E6%95%B0%E7%BB%84%E5%8F%8A%E6%95%B0%E5%AD%A6/"/>
    <url>/2022/04/28/%E6%95%B0%E7%BB%84%E5%8F%8A%E6%95%B0%E5%AD%A6/</url>
    
    <content type="html"><![CDATA[<h2 id="">7</h2><p><img src="/img/LeetCode//1.png" /></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">reverse</span>(<span class="hljs-params">self, x: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:<br>        ans = <span class="hljs-number">0</span><br>        flag = <span class="hljs-literal">False</span><br>        <span class="hljs-keyword">if</span> x &lt; <span class="hljs-number">0</span>:<br>            flag = <span class="hljs-literal">True</span><br>            x = -<span class="hljs-number">1</span> * x<br>        a = <span class="hljs-number">0</span>   <span class="hljs-comment"># </span><br>        <span class="hljs-keyword">while</span> x != <span class="hljs-number">0</span>:<br>            a = x % <span class="hljs-number">10</span><br>            x = x // <span class="hljs-number">10</span><br>            ans = ans * <span class="hljs-number">10</span> + a<br>        <span class="hljs-keyword">if</span> flag:<br>            ans = -<span class="hljs-number">1</span> * ans<br>        <span class="hljs-keyword">if</span> ans &gt; <span class="hljs-number">2</span> ** <span class="hljs-number">31</span> - <span class="hljs-number">1</span> <span class="hljs-keyword">or</span> ans &lt; -(<span class="hljs-number">2</span> ** <span class="hljs-number">31</span>):<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">return</span> ans<br></code></pre></div></td></tr></table></figure><h2 id="">9</h2><p><img src="/img/LeetCode//2.png" /></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">isPalindrome</span>(<span class="hljs-params">self, x: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">bool</span>:<br>        <span class="hljs-keyword">if</span> x &lt; <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br>        a = self.reverse(x) <span class="hljs-comment"># </span><br>        <span class="hljs-keyword">if</span> a == x:<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">reverse</span>(<span class="hljs-params">self, x: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:<br>        ans = <span class="hljs-number">0</span><br>        a = <span class="hljs-number">0</span>   <span class="hljs-comment"># </span><br>        <span class="hljs-keyword">while</span> x != <span class="hljs-number">0</span>:<br>            a = x % <span class="hljs-number">10</span><br>            x = x // <span class="hljs-number">10</span><br>            ans = ans * <span class="hljs-number">10</span> + a<br>        <span class="hljs-keyword">return</span> ans<br></code></pre></div></td></tr></table></figure><h2 id="">11</h2><p><img src="/img/LeetCode//3.png" /></p><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">maxArea</span>(<span class="hljs-params">self, height: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">int</span>:<br>        n = <span class="hljs-built_in">len</span>(height)<br>        left = <span class="hljs-number">0</span>    <span class="hljs-comment"># </span><br>        right = n - <span class="hljs-number">1</span>   <span class="hljs-comment"># </span><br>        max_s = <span class="hljs-number">0</span>   <span class="hljs-comment"># </span><br>        s = <span class="hljs-number">0</span>   <span class="hljs-comment"># </span><br>        l = <span class="hljs-number">0</span>   <span class="hljs-comment"># </span><br>        <span class="hljs-keyword">while</span> right &gt; left:<br>            <span class="hljs-keyword">if</span> height[left] &gt; height[right]:<br>                l = height[right]<br>            <span class="hljs-keyword">else</span>:<br>                l = height[left]<br>            s = (right - left) * l<br>            <span class="hljs-keyword">if</span> s &gt; max_s:<br>                max_s = s<br>            <span class="hljs-keyword">if</span> height[left] &gt; height[right]:<br>                right = right - <span class="hljs-number">1</span><br>            <span class="hljs-keyword">else</span>:<br>                left = left + <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> max_s<br></code></pre></div></td></tr></table></figure><h2 id="">12</h2><p><img src="/img/LeetCode//4.png" /></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    A = [<br>        (<span class="hljs-number">1000</span>, <span class="hljs-string">&quot;M&quot;</span>),<br>        (<span class="hljs-number">900</span>, <span class="hljs-string">&quot;CM&quot;</span>),<br>        (<span class="hljs-number">500</span>, <span class="hljs-string">&quot;D&quot;</span>),<br>        (<span class="hljs-number">400</span>, <span class="hljs-string">&quot;CD&quot;</span>),<br>        (<span class="hljs-number">100</span>, <span class="hljs-string">&quot;C&quot;</span>),<br>        (<span class="hljs-number">90</span>, <span class="hljs-string">&quot;XC&quot;</span>),<br>        (<span class="hljs-number">50</span>, <span class="hljs-string">&quot;L&quot;</span>),<br>        (<span class="hljs-number">40</span>, <span class="hljs-string">&quot;XL&quot;</span>),<br>        (<span class="hljs-number">10</span>, <span class="hljs-string">&quot;X&quot;</span>),<br>        (<span class="hljs-number">9</span>, <span class="hljs-string">&quot;IX&quot;</span>),<br>        (<span class="hljs-number">5</span>, <span class="hljs-string">&quot;V&quot;</span>),<br>        (<span class="hljs-number">4</span>, <span class="hljs-string">&quot;IV&quot;</span>),<br>        (<span class="hljs-number">1</span>, <span class="hljs-string">&quot;I&quot;</span>),<br>    ]<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">intToRoman</span>(<span class="hljs-params">self, num: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">str</span>:<br>        ans = <span class="hljs-string">&quot;&quot;</span><br>        <span class="hljs-keyword">for</span> value, s <span class="hljs-keyword">in</span> self.A:<br>            <span class="hljs-keyword">while</span> num &gt;= value:<br>                num = num - value<br>                ans = ans + s<br>            <span class="hljs-keyword">if</span> num == <span class="hljs-number">0</span>:<br>                <span class="hljs-keyword">break</span><br>        <br>        <span class="hljs-keyword">return</span> ans<br></code></pre></div></td></tr></table></figure><h2 id="">13</h2><p><img src="/img/LeetCode//5.png" /></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    A = &#123;<br>        <span class="hljs-string">&#x27;I&#x27;</span>: <span class="hljs-number">1</span>,<br>        <span class="hljs-string">&#x27;V&#x27;</span>: <span class="hljs-number">5</span>,<br>        <span class="hljs-string">&#x27;X&#x27;</span>: <span class="hljs-number">10</span>,<br>        <span class="hljs-string">&#x27;L&#x27;</span>: <span class="hljs-number">50</span>,<br>        <span class="hljs-string">&#x27;C&#x27;</span>: <span class="hljs-number">100</span>,<br>        <span class="hljs-string">&#x27;D&#x27;</span>: <span class="hljs-number">500</span>,<br>        <span class="hljs-string">&#x27;M&#x27;</span>: <span class="hljs-number">1000</span>,<br>    &#125;<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">romanToInt</span>(<span class="hljs-params">self, s: <span class="hljs-built_in">str</span></span>) -&gt; <span class="hljs-built_in">int</span>:<br>        ans = <span class="hljs-number">0</span><br>        n = <span class="hljs-built_in">len</span>(s)<br>        <span class="hljs-keyword">for</span> i, ch <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(s):<br>            <span class="hljs-keyword">if</span> i &lt; n - <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> self.A[ch] &lt; self.A[s[i+<span class="hljs-number">1</span>]]:<br>                ans = ans - self.A[ch]<br>            <span class="hljs-keyword">else</span>:<br>                ans = ans + self.A[ch]<br>        <span class="hljs-keyword">return</span> ans<br></code></pre></div></td></tr></table></figure><h2 id="">15</h2><p><img src="/img/LeetCode//15.png" /></p><p>00</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">threeSum</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]]:<br>        nums.sort()<br>        n = <span class="hljs-built_in">len</span>(nums)<br>        ans = <span class="hljs-built_in">list</span>()<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<span class="hljs-comment"># </span><br>            <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> nums[i] != nums[i - <span class="hljs-number">1</span>]:<br>                k = n - <span class="hljs-number">1</span><br>                j = i + <span class="hljs-number">1</span><br>                <span class="hljs-keyword">while</span> k &gt; j:<span class="hljs-comment"># </span><br>                    <span class="hljs-keyword">if</span> k != n - <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> nums[k] == nums[k + <span class="hljs-number">1</span>]:<span class="hljs-comment"># </span><br>                        k = k - <span class="hljs-number">1</span><br>                        <span class="hljs-keyword">continue</span><br>                    <span class="hljs-keyword">if</span> j != i + <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> nums[j] == nums[j - <span class="hljs-number">1</span>]:<span class="hljs-comment"># </span><br>                        j = j + <span class="hljs-number">1</span><br>                        <span class="hljs-keyword">continue</span><br>                    s = nums[i] + nums[j] + nums[k]<br>                    <span class="hljs-keyword">if</span> s == <span class="hljs-number">0</span>:<br>                        ans.append([nums[i], nums[j], nums[k]])<br>                        k = k - <span class="hljs-number">1</span><br>                        j = j + <span class="hljs-number">1</span><br>                    <span class="hljs-keyword">elif</span> s &gt; <span class="hljs-number">0</span>:<br>                        k = k - <span class="hljs-number">1</span><br>                    <span class="hljs-keyword">elif</span> s &lt; <span class="hljs-number">0</span>:<br>                        j = j + <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> ans<br></code></pre></div></td></tr></table></figure><h2 id="">16</h2><p><img src="/img/LeetCode//16.png" /></p><p>target</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">threeSumClosest</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], target: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:<br>        n = <span class="hljs-built_in">len</span>(nums)<br>        nums.sort()<br>        min_num = <span class="hljs-number">10</span>**<span class="hljs-number">9</span><br>        ans = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>            <span class="hljs-keyword">if</span> i != <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> nums[i] == nums[i - <span class="hljs-number">1</span>]:<br>                <span class="hljs-keyword">continue</span><br>            k = n - <span class="hljs-number">1</span><br>            j = i + <span class="hljs-number">1</span><br>            <span class="hljs-keyword">while</span> k &gt; j:<br>                s = nums[i] + nums[j] + nums[k]<br>                <span class="hljs-keyword">if</span> s == target:<br>                    <span class="hljs-keyword">return</span> s<br>                <span class="hljs-keyword">if</span> s &gt; target:<br>                    <span class="hljs-keyword">if</span> s - target &lt; min_num:<br>                        min_num = s - target<br>                        ans = s<br>                    k = k - <span class="hljs-number">1</span><br>                <span class="hljs-keyword">elif</span> s &lt; target:<br>                    <span class="hljs-keyword">if</span> target - s &lt; min_num:<br>                        min_num = target - s<br>                        ans = s<br>                    j = j + <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> ans<br></code></pre></div></td></tr></table></figure><h2 id="">18</h2><p><img src="/img/LeetCode//18.png" /></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">fourSum</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], target: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]]:<br>        n = <span class="hljs-built_in">len</span>(nums)<br>        <span class="hljs-keyword">if</span> nums == [] <span class="hljs-keyword">or</span> n &lt; <span class="hljs-number">4</span>:<br>            <span class="hljs-keyword">return</span> []<br>        nums.sort()<br>        ans = <span class="hljs-built_in">list</span>()<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n - <span class="hljs-number">3</span>):<br>            <span class="hljs-keyword">if</span> i != <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> nums[i] == nums[i - <span class="hljs-number">1</span>]:<br>                <span class="hljs-keyword">continue</span><br>            <span class="hljs-keyword">if</span> nums[i] + nums[i + <span class="hljs-number">1</span>] + nums[i + <span class="hljs-number">2</span>] + nums[i + <span class="hljs-number">3</span>] &gt; target:<br>                <span class="hljs-keyword">break</span><br>            <span class="hljs-keyword">if</span> nums[i] + nums[n - <span class="hljs-number">1</span>] + nums[n - <span class="hljs-number">2</span>] + nums[n - <span class="hljs-number">3</span>] &lt; target:<br>                <span class="hljs-keyword">continue</span><br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(i + <span class="hljs-number">1</span>, n - <span class="hljs-number">2</span>):<br>                <span class="hljs-keyword">if</span> j != i + <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> nums[j] == nums[j - <span class="hljs-number">1</span>]:<br>                    <span class="hljs-keyword">continue</span><br>                <span class="hljs-keyword">if</span> nums[i] + nums[j] + nums[j + <span class="hljs-number">1</span>] + nums[j + <span class="hljs-number">2</span>] &gt; target:<br>                    <span class="hljs-keyword">break</span><br>                <span class="hljs-keyword">if</span> nums[i] + nums[n - <span class="hljs-number">1</span>] + nums[n - <span class="hljs-number">2</span>] + nums[n - <span class="hljs-number">3</span>] &lt; target:<br>                    <span class="hljs-keyword">continue</span><br>                k = j + <span class="hljs-number">1</span><br>                l = n - <span class="hljs-number">1</span><br>                <span class="hljs-keyword">while</span> k &lt; l:<br>                    <span class="hljs-built_in">sum</span> = nums[i] + nums[j] + nums[k] + nums[l]<br>                    <span class="hljs-keyword">if</span> <span class="hljs-built_in">sum</span> &lt; target:<br>                        k = k + <span class="hljs-number">1</span><br>                    <span class="hljs-keyword">elif</span> <span class="hljs-built_in">sum</span> &gt; target:<br>                        l = l - <span class="hljs-number">1</span><br>                    <span class="hljs-keyword">elif</span> <span class="hljs-built_in">sum</span> == target:<br>                        ans.append([nums[i], nums[j], nums[k], nums[l]])<br>                        <span class="hljs-keyword">while</span> k &lt; l <span class="hljs-keyword">and</span> nums[k] == nums[k + <span class="hljs-number">1</span>]:<br>                            k = k + <span class="hljs-number">1</span><br>                        k = k + <span class="hljs-number">1</span><br>                        <span class="hljs-keyword">while</span> k &lt; l <span class="hljs-keyword">and</span> nums[l] == nums[l - <span class="hljs-number">1</span>]:<br>                            l = l - <span class="hljs-number">1</span><br>                        l = l - <span class="hljs-number">1</span> <br><br>        <span class="hljs-keyword">return</span> ans<br></code></pre></div></td></tr></table></figure><h2 id="">26</h2><p><img src="/img/LeetCode//26.png" /></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">removeDuplicates</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">int</span>:<br>        <span class="hljs-keyword">if</span> nums == []:<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>        n = <span class="hljs-built_in">len</span>(nums)<br>        left, right = <span class="hljs-number">1</span>, <span class="hljs-number">1</span><br>        <span class="hljs-keyword">while</span> right &lt; n:<br>            <span class="hljs-keyword">if</span> nums[right] != nums[right - <span class="hljs-number">1</span>]:<br>                nums[left] = nums[right]<br>                left = left + <span class="hljs-number">1</span><br>            right = right + <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> left<br></code></pre></div></td></tr></table></figure><h2 id="">31</h2><p><img src="/img/LeetCode//31.png" /></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">nextPermutation</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-literal">None</span>:<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Do not return anything, modify nums in-place instead.</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        i = <span class="hljs-built_in">len</span>(nums) - <span class="hljs-number">2</span><br>        <span class="hljs-keyword">while</span> i &gt;= <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> nums[i] &gt;= nums[i + <span class="hljs-number">1</span>]:<br>            i -= <span class="hljs-number">1</span><br>        j = <span class="hljs-built_in">len</span>(nums) - <span class="hljs-number">1</span><br>        <span class="hljs-keyword">if</span> i &gt;= <span class="hljs-number">0</span>:<br>            <span class="hljs-keyword">while</span> j &gt;= <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> nums[i] &gt;= nums[j]:<br>                j -= <span class="hljs-number">1</span><br>            nums[i], nums[j] = nums[j], nums[i]<br>        left, right = i + <span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(nums) - <span class="hljs-number">1</span><br>        <span class="hljs-keyword">while</span> left &lt; right:<br>            nums[left], nums[right] = nums[right], nums[left]<br>            left += <span class="hljs-number">1</span><br>            right -= <span class="hljs-number">1</span><br></code></pre></div></td></tr></table></figure><h2 id="">33</h2><p><img src="/img/LeetCode//33.png" /></p><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">search</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], target: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">int</span>:<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> nums:<br>            <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span><br>        i = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">if</span> nums[<span class="hljs-number">0</span>] &gt; nums[<span class="hljs-built_in">len</span>(nums) - <span class="hljs-number">1</span>]:<br>            <span class="hljs-keyword">while</span> i &lt; <span class="hljs-built_in">len</span>(nums) - <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> nums[i] &lt; nums[i + <span class="hljs-number">1</span>]:<br>             i += <span class="hljs-number">1</span><br>            <span class="hljs-keyword">if</span> target &gt; nums[<span class="hljs-built_in">len</span>(nums) - <span class="hljs-number">1</span>]:<br>                left = <span class="hljs-number">0</span><br>                right = i<br>            <span class="hljs-keyword">elif</span> target &lt; nums[<span class="hljs-built_in">len</span>(nums) - <span class="hljs-number">1</span>]:<br>                left = i + <span class="hljs-number">1</span><br>                right = <span class="hljs-built_in">len</span>(nums) - <span class="hljs-number">1</span><br>            <span class="hljs-keyword">elif</span> target == nums[<span class="hljs-built_in">len</span>(nums) -<span class="hljs-number">1</span>]:<br>                <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(nums) - <span class="hljs-number">1</span><br>        <span class="hljs-keyword">else</span>:<br>            left, right = <span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(nums) - <span class="hljs-number">1</span><br>        <br>        <span class="hljs-keyword">while</span> left &lt;= right:<br>            mid = (left + right) // <span class="hljs-number">2</span><br>            <span class="hljs-keyword">if</span> target == nums[mid]:<br>                <span class="hljs-keyword">return</span> mid<br>            <span class="hljs-keyword">elif</span> target &lt; nums[mid]:<br>                right = mid - <span class="hljs-number">1</span><br>            <span class="hljs-keyword">elif</span> target &gt; nums[mid]:<br>                left = mid + <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> -<span class="hljs-number">1</span><br></code></pre></div></td></tr></table></figure><h2id="">34</h2><p><img src="/img/LeetCode//34.png" /></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">searchRange</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], target: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]:<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> nums:<br>            <span class="hljs-keyword">return</span> [-<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>]<br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">binarySearch</span>(<span class="hljs-params">nums, target</span>):<br>            left, right = <span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(nums) - <span class="hljs-number">1</span><br>            <span class="hljs-keyword">while</span> left &lt;= right:<br>                mid = (left + right) // <span class="hljs-number">2</span><br>                <span class="hljs-keyword">if</span> nums[mid] &gt;= target:<br>                    right = mid - <span class="hljs-number">1</span><br>                <span class="hljs-keyword">elif</span> nums[mid] &lt; target:<br>                    left = mid + <span class="hljs-number">1</span><br>            <span class="hljs-keyword">return</span> left<br>        a = binarySearch(nums, target)<br>        b = binarySearch(nums, target + <span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">if</span> a == <span class="hljs-built_in">len</span>(nums) <span class="hljs-keyword">or</span> nums[a] != target:<br>            <span class="hljs-keyword">return</span>[-<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>]<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">return</span>[a, b - <span class="hljs-number">1</span>]<br></code></pre></div></td></tr></table></figure><h2 id="powx-n">50Pow(x, n)</h2><p><img src="/img/LeetCode//50.png" /></p><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">myPow</span>(<span class="hljs-params">self, x: <span class="hljs-built_in">float</span>, n: <span class="hljs-built_in">int</span></span>) -&gt; <span class="hljs-built_in">float</span>:<br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">quickPow</span>(<span class="hljs-params">N</span>):<br>            <span class="hljs-keyword">if</span> N == <span class="hljs-number">0</span>:<br>                <span class="hljs-keyword">return</span> <span class="hljs-number">1.0</span><br>            y = quickPow(N // <span class="hljs-number">2</span>)<br>            <span class="hljs-keyword">return</span> y * y <span class="hljs-keyword">if</span> N % <span class="hljs-number">2</span> == <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> y * y * x<br>        <span class="hljs-keyword">return</span> quickPow(n) <span class="hljs-keyword">if</span> n &gt;= <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-number">1.0</span> / quickPow(-n)<br></code></pre></div></td></tr></table></figure><h2 id="">53</h2><p><img src="/img/LeetCode//53.png" /></p><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">maxSubArray</span>(<span class="hljs-params">self, nums: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-built_in">int</span>:<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(nums)):<br>            nums[i] += <span class="hljs-built_in">max</span>(nums[i - <span class="hljs-number">1</span>], <span class="hljs-number">0</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">max</span>(nums)<br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>LeetCode</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>pytorch</title>
    <link href="/2022/04/27/pytorch/"/>
    <url>/2022/04/27/pytorch/</url>
    
    <content type="html"><![CDATA[<h1 id="pytorch">PyTorch</h1><h2 id="dataset">1DataSet</h2><p>DataSetlabel</p><p>dataset/train/beesdataset/train/ants</p><p>DataSet</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">import</span> os<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyData</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, root_dir, label_dir</span>):<span class="hljs-comment"># read data &amp; preprocess</span><br>        self.root_dir = root_dir    <span class="hljs-comment"># </span><br>        self.label_dir = label_dir  <span class="hljs-comment"># </span><br>        self.path = os.path.join(self.root_dir, self.label_dir)     <span class="hljs-comment"># </span><br>        self.img_path = os.listdir(self.path)   <span class="hljs-comment"># </span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, index</span>):<span class="hljs-comment"># returns one sample at a time</span><br>        img_name = self.img_path[index]   <span class="hljs-comment"># </span><br>        img_item_path = os.path.join(self.root_dir, self.label_dir, img_name)<br>        img = Image.<span class="hljs-built_in">open</span>(img_item_path)<br>        label = self.label_dir<br>        <span class="hljs-keyword">return</span> img, label<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<span class="hljs-comment"># returns the size of the dataset</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.img_path)<br><br><br><span class="hljs-comment"># </span><br>root_dir = <span class="hljs-string">&quot;dataset/train&quot;</span><br>ants_label_dir = <span class="hljs-string">&quot;ants&quot;</span><br>bees_label_dir = <span class="hljs-string">&quot;bees&quot;</span><br>ants_dataset = MyData(root_dir, ants_label_dir)<br>bees_dataset = MyData(root_dir, bees_label_dir)<br><br><span class="hljs-comment"># </span><br>train_dataset = ants_dataset + bees_dataset<br></code></pre></div></td></tr></table></figure><h2 id="dataloader">2DataLoader</h2><p>DataSetDataLoader</p><p>torchvisionDataLoader</p><ul><li>datasetdataset</li><li>batch_size</li><li>shuffle</li><li>num_workersworker0batch1workerbatch</li><li>drop_last</li></ul><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><br><span class="hljs-comment"># </span><br><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br><br>test_data = torchvision.datasets.CIFAR10(<span class="hljs-string">&quot;./dataset&quot;</span>, train=<span class="hljs-literal">False</span>, transform=torchvision.transforms.ToTensor(), download=<span class="hljs-literal">True</span>)<br><br>test_loader = DataLoader(dataset=test_data, batch_size=<span class="hljs-number">64</span>, shuffle=<span class="hljs-literal">True</span>, num_workers=<span class="hljs-number">0</span>, drop_last=<span class="hljs-literal">False</span>)<br><br>writer = SummaryWriter(<span class="hljs-string">&quot;dataloader&quot;</span>)<br>step = <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> test_loader:<br>    imgs, targets = data<br>    writer.add_images(<span class="hljs-string">&quot;test_data&quot;</span>, imgs, step)<br>    step = step + <span class="hljs-number">1</span><br><br>writer.close()<br></code></pre></div></td></tr></table></figure><p></p><p><img src="/img/pytorch/1.png" /></p><h2 id="tensorboard">3TensorBoard</h2><p>TensorBoard</p><h3 id="">3.1</h3><p>TensorBoardy=xadd_scalar()yx</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br><br><span class="hljs-comment"># ,logs</span><br>writer = SummaryWriter(<span class="hljs-string">&quot;logs&quot;</span>)<br><br><span class="hljs-comment"># y = x</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>):<br>    writer.add_scalar(<span class="hljs-string">&quot;y=x&quot;</span>, i, i)<br><br>writer.close()<br></code></pre></div></td></tr></table></figure><p></p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">tensorboard --logdir=logs<br></code></pre></div></td></tr></table></figure><p>6006tensorboard6007</p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">tensorboard --logdir=logs --port=6007<br></code></pre></div></td></tr></table></figure><p><img src="/img/pytorch/2.png" /></p><p>y=x</p><p>y=2x</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># y = 2x</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>):<br>    writer.add_scalar(<span class="hljs-string">&quot;y=2x&quot;</span>, <span class="hljs-number">2</span>*i, i)<br></code></pre></div></td></tr></table></figure><h3 id="">3.2</h3><p>TensorBoardTensorBoardadd_image()tensornumpyglobal_step3HW(channel)3HW</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><br><span class="hljs-comment"># ,logs</span><br>writer = SummaryWriter(<span class="hljs-string">&quot;logs&quot;</span>)<br>image_path = <span class="hljs-string">&quot;dataset/train/ants/0013035.jpg&quot;</span><br>img_PIL = Image.<span class="hljs-built_in">open</span>(image_path)<br>img_array = np.array(img_PIL)<br><br>writer.add_image(<span class="hljs-string">&quot;test&quot;</span>, img_array, <span class="hljs-number">1</span>, dataformats=<span class="hljs-string">&#x27;HWC&#x27;</span>)<br><br>writer.close()<br></code></pre></div></td></tr></table></figure><h2 id="">4</h2><p>nn.Module</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyModel</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span></span>):<br>        output = <span class="hljs-built_in">input</span> + <span class="hljs-number">1</span><br>        <span class="hljs-keyword">return</span> output<br><br>res = MyModel()<br>x = torch.tensor(<span class="hljs-number">1.0</span>)<br>output = res(x)<span class="hljs-comment"># __call__xforward()</span><br><span class="hljs-built_in">print</span>(output)<br><br></code></pre></div></td></tr></table></figure><p></p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">tensor(2.)<br></code></pre></div></td></tr></table></figure><h2 id="">5</h2><p>torch.nn.functionaltorch.nnfunctionalconv2dstridestride</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F<br><br><span class="hljs-built_in">input</span> = torch.tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>],<br>                      [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>],<br>                      [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],<br>                      [<span class="hljs-number">5</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],<br>                      [<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]])<br><br>kernel = torch.tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>],<br>                       [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>],<br>                       [<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>]])<br><br><span class="hljs-built_in">input</span> = torch.reshape(<span class="hljs-built_in">input</span>, (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">5</span>, <span class="hljs-number">5</span>))<br>kernel = torch.reshape(kernel, (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>))<br><br>output = F.conv2d(<span class="hljs-built_in">input</span>, kernel, stride=<span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(output)<br><br>output2 = F.conv2d(<span class="hljs-built_in">input</span>, kernel, stride=<span class="hljs-number">2</span>)<br><span class="hljs-built_in">print</span>(output2)<br></code></pre></div></td></tr></table></figure><p></p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">tensor([[[[10, 12, 12],<br>          [18, 16, 16],<br>          [13,  9,  3]]]])<br>tensor([[[[10, 12],<br>          [13,  3]]]])<br></code></pre></div></td></tr></table></figure><p></p><p><img src="/img/pytorch/4.png" /></p><p>conv2dpadding</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">output3 = F.conv2d(<span class="hljs-built_in">input</span>, kernel, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>)<br><span class="hljs-built_in">print</span>(output3)<br></code></pre></div></td></tr></table></figure><p></p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">tensor([[[[ 1,  3,  4, 10,  8],<br>          [ 5, 10, 12, 12,  6],<br>          [ 7, 18, 16, 16,  8],<br>          [11, 13,  9,  3,  4],<br>          [14, 13,  9,  7,  4]]]])<br></code></pre></div></td></tr></table></figure><p></p><p><img src="/img/pytorch/5.png" /></p><p>torch.nnconv2d</p><ul><li><strong>in_channels</strong> (<ahref="https://docs.python.org/3/library/functions.html#int"><em>int</em></a>) Number of channels in the input image</li><li><strong>out_channels</strong> (<ahref="https://docs.python.org/3/library/functions.html#int"><em>int</em></a>) Number of channels produced by the convolution</li><li><strong>kernel_size</strong> (<ahref="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>or</em> <ahref="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a>) Size of the convolving kernel</li><li><strong>stride</strong> (<ahref="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>or</em> <ahref="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a><em>,</em><em>optional</em>)  Stride of the convolution. Default: 1</li><li><strong>padding</strong> (<ahref="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,</em><ahref="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a><em>or</em> <ahref="https://docs.python.org/3/library/stdtypes.html#str"><em>str</em></a><em>,</em><em>optional</em>)  Padding added to all four sides of the input.Default: 0</li><li><strong>padding_mode</strong> (*string**,* <em>optional</em>) <code>'zeros'</code>, <code>'reflect'</code>, <code>'replicate'</code>or <code>'circular'</code>. Default: <code>'zeros'</code></li><li><strong>dilation</strong> (<ahref="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>or</em> <ahref="https://docs.python.org/3/library/stdtypes.html#tuple"><em>tuple</em></a><em>,</em><em>optional</em>)  Spacing between kernel elements. Default: 1</li><li><strong>groups</strong> (<ahref="https://docs.python.org/3/library/functions.html#int"><em>int</em></a><em>,</em><em>optional</em>)  Number of blocked connections from input channelsto output channels. Default: 1</li><li><strong>bias</strong> (<ahref="https://docs.python.org/3/library/functions.html#bool"><em>bool</em></a><em>,</em><em>optional</em>)  If <code>True</code>, adds a learnable bias to theoutput. Default: <code>True</code></li></ul><p><img src="/img/pytorch/3.png" /></p><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> Conv2d<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br><br>test_data = torchvision.datasets.CIFAR10(<span class="hljs-string">&quot;./dataset&quot;</span>, train=<span class="hljs-literal">False</span>, transform=torchvision.transforms.ToTensor(),<br>                                         download=<span class="hljs-literal">True</span>)<br>dataloader = DataLoader(dataset=test_data, batch_size=<span class="hljs-number">64</span>)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyModel</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(MyModel, self).__init__()<br>        self.conv1 = Conv2d(in_channels=<span class="hljs-number">3</span>, out_channels=<span class="hljs-number">6</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">0</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.conv1(x)<br>        <span class="hljs-keyword">return</span> x<br><br><br>myModel = MyModel()<br><br>writer = SummaryWriter(<span class="hljs-string">&quot;logs&quot;</span>)<br>step = <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> dataloader:<br>    imgs, targets = data<br>    output = myModel(imgs)<br>    <span class="hljs-comment"># print(imgs.shape)</span><br>    <span class="hljs-comment"># print(output.shape)</span><br><br>    <span class="hljs-comment"># torch.Size([64, 3, 32, 32])</span><br>    writer.add_images(<span class="hljs-string">&quot;input&quot;</span>, imgs, step)<br>    <span class="hljs-comment"># torch.Size([64, 6, 32, 32]) -&gt; [xxx, 3, 32, 32]out_channels6add</span><br>    output = torch.reshape(output, (-<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">30</span>, <span class="hljs-number">30</span>))<br>    writer.add_images(<span class="hljs-string">&quot;output&quot;</span>, output, step)<br><br>    step = step + <span class="hljs-number">1</span><br></code></pre></div></td></tr></table></figure><p>tensorboard</p><p><img src="/img/pytorch/6.png" /></p><p><img src="/img/pytorch/7.png" /></p><h2 id="">6</h2><p>torch.nnMaxPool2d</p><ul><li><strong>kernel_size</strong>  the size of the window to take a maxover</li><li><strong>stride</strong>  the stride of the window. Default value is<code>kernel_size</code></li><li><strong>padding</strong>  implicit zero padding to be added on bothsides</li><li><strong>dilation</strong>  a parameter that controls the stride ofelements in the window</li><li><strong>return_indices</strong>  if <code>True</code>, will returnthe max indices along with the outputs. Useful for <ahref="https://pytorch.org/docs/stable/generated/torch.nn.MaxUnpool2d.html#torch.nn.MaxUnpool2d"><code>torch.nn.MaxUnpool2d</code></a>later</li><li><strong>ceil_mode</strong>  when True, will use ceil instead offloor to compute the output shape</li></ul><p>ceil_mode</p><p><img src="/img/pytorch/8.png" /></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> MaxPool2d<br><br><span class="hljs-built_in">input</span> = torch.tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>],<br>                      [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>],<br>                      [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],<br>                      [<span class="hljs-number">5</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],<br>                      [<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]], dtype=torch.float32)<br><span class="hljs-built_in">input</span> = torch.reshape(<span class="hljs-built_in">input</span>, (-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">5</span>, <span class="hljs-number">5</span>))<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyModel</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(MyModel, self).__init__()<br>        self.maxpool1 = MaxPool2d(kernel_size=<span class="hljs-number">3</span>, ceil_mode=<span class="hljs-literal">True</span>)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span></span>):<br>        output = self.maxpool1(<span class="hljs-built_in">input</span>)<br>        <span class="hljs-keyword">return</span> output<br><br><br>myModel = MyModel()<br>output = myModel(<span class="hljs-built_in">input</span>)<br><span class="hljs-built_in">print</span>(output)<br></code></pre></div></td></tr></table></figure><p></p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">tensor([[[[2., 3.],<br>          [5., 1.]]]])<br></code></pre></div></td></tr></table></figure><p>ceil_modeFalse</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">self.maxpool1 = MaxPool2d(kernel_size=<span class="hljs-number">3</span>, ceil_mode=<span class="hljs-literal">False</span>)<br></code></pre></div></td></tr></table></figure><p></p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">tensor([[[[2.]]]])<br></code></pre></div></td></tr></table></figure><p>tensorboard</p><p><img src="/img/pytorch/9.png" /></p><h2 id="">7</h2><p>torch.nnReLU</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> ReLU<br><br><span class="hljs-built_in">input</span> = torch.tensor([[<span class="hljs-number">1</span>, -<span class="hljs-number">0.5</span>],<br>                      [-<span class="hljs-number">1</span>, <span class="hljs-number">3</span>]])<br><br><span class="hljs-built_in">input</span> = torch.reshape(<span class="hljs-built_in">input</span>, (-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>))<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyModel</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(MyModel, self).__init__()<br>        self.relu1 = ReLU()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span></span>):<br>        output = self.relu1(<span class="hljs-built_in">input</span>)<br>        <span class="hljs-keyword">return</span> output<br><br><br>myModel = MyModel()<br>output = myModel(<span class="hljs-built_in">input</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">input</span>)<br><span class="hljs-built_in">print</span>(output)<br></code></pre></div></td></tr></table></figure><p></p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">tensor([[[[ 1.0000, -0.5000],<br>          [-1.0000,  3.0000]]]])<br>tensor([[[[1., 0.],<br>          [0., 3.]]]])<br></code></pre></div></td></tr></table></figure><p>torch.nnSigmoid</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.nn <span class="hljs-keyword">import</span> Sigmoid<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br><br>test_data = torchvision.datasets.CIFAR10(<span class="hljs-string">&quot;./dataset&quot;</span>, train=<span class="hljs-literal">False</span>, transform=torchvision.transforms.ToTensor(),<br>                                         download=<span class="hljs-literal">True</span>)<br>dataloader = DataLoader(dataset=test_data, batch_size=<span class="hljs-number">64</span>)<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyModel</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(MyModel, self).__init__()<br>        self.sigmoid1 = Sigmoid()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, <span class="hljs-built_in">input</span></span>):<br>        output = self.sigmoid1(<span class="hljs-built_in">input</span>)<br>        <span class="hljs-keyword">return</span> output<br><br>myModel = MyModel()<br>writer = SummaryWriter(<span class="hljs-string">&quot;logs_sigmoid&quot;</span>)<br>step = <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> dataloader:<br>    imgs, target = data<br>    output = myModel(imgs)<br>    writer.add_images(<span class="hljs-string">&quot;input&quot;</span>, imgs, step)<br>    writer.add_images(<span class="hljs-string">&quot;output&quot;</span>, output, step)<br>    step = step + <span class="hljs-number">1</span><br><br>writer.close()<br></code></pre></div></td></tr></table></figure><p>tensorboard</p><p><img src="/img/pytorch/10.png" /></p><h2 id="-">8 </h2><p></p><h2id="sequential">9Sequential</h2><p>cifar10</p><p><img src="/img/pytorch/11.png" /></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyModel</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(MyModel, self).__init__()<br>        self.conv1 = Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">32</span>, <span class="hljs-number">5</span>, padding=<span class="hljs-number">2</span>)<br>        self.maxpool1 = MaxPool2d(<span class="hljs-number">2</span>)<br>        self.conv2 = Conv2d(<span class="hljs-number">32</span>, <span class="hljs-number">32</span>, <span class="hljs-number">5</span>, padding=<span class="hljs-number">2</span>)<br>        self.maxpool2 = MaxPool2d(<span class="hljs-number">2</span>)<br>        self.conv3 = Conv2d(<span class="hljs-number">32</span>, <span class="hljs-number">64</span>, <span class="hljs-number">5</span>, padding=<span class="hljs-number">2</span>)<br>        self.maxpool3 = MaxPool2d(<span class="hljs-number">2</span>)<br>        self.flatten = Flatten()<br>        self.linear1 = Linear(<span class="hljs-number">1024</span>, <span class="hljs-number">64</span>)<br>        self.linear2 = Linear(<span class="hljs-number">64</span>, <span class="hljs-number">10</span>)<br><br>        self.model1 = Sequential(<br>            Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">32</span>, <span class="hljs-number">5</span>, padding=<span class="hljs-number">2</span>)<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.conv1(x)<br>        x = self.maxpool1(x)<br>        x = self.conv2(x)<br>        x = self.maxpool2(x)<br>        x = self.conv2(x)<br>        x = self.maxpool2(x)<br>        x = self.flatten(x)<br>        x = self.linear1(x)<br>        x = self.linear2(x)<br>        <span class="hljs-keyword">return</span> x<br></code></pre></div></td></tr></table></figure><p>Sequential</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyModel</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self.model1 = Sequential(<br>            Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">32</span>, <span class="hljs-number">5</span>, padding=<span class="hljs-number">2</span>),<br>            MaxPool2d(<span class="hljs-number">2</span>),<br>            Conv2d(<span class="hljs-number">32</span>, <span class="hljs-number">32</span>, <span class="hljs-number">5</span>, padding=<span class="hljs-number">2</span>),<br>            MaxPool2d(<span class="hljs-number">2</span>),<br>            Conv2d(<span class="hljs-number">32</span>, <span class="hljs-number">64</span>, <span class="hljs-number">5</span>, padding=<span class="hljs-number">2</span>),<br>            MaxPool2d(<span class="hljs-number">2</span>),<br>            Flatten(),<br>            Linear(<span class="hljs-number">1024</span>, <span class="hljs-number">64</span>),<br>            Linear(<span class="hljs-number">64</span>, <span class="hljs-number">10</span>)<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.model1(x)<br>        <span class="hljs-keyword">return</span> x<br></code></pre></div></td></tr></table></figure><h2 id="">10</h2><p>torch.nnL1LossMSELoss</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-built_in">input</span> = torch.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>], dtype=torch.float32)<br>target = torch.tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">5</span>], dtype=torch.float32)<br><br><span class="hljs-built_in">input</span> = torch.reshape(<span class="hljs-built_in">input</span>, (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>))<br>target = torch.reshape(target, (<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>))<br><br>loss = L1Loss(reduction=<span class="hljs-string">&#x27;sum&#x27;</span>)<br>result = loss(<span class="hljs-built_in">input</span>, target)<br><br>loss_mse = nn.MSELoss()<br>result_mse = loss_mse(<span class="hljs-built_in">input</span>, target)<br><br><span class="hljs-built_in">print</span>(result)<br><span class="hljs-built_in">print</span>(result_mse)<br></code></pre></div></td></tr></table></figure><p></p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">tensor(2.)<br>tensor(1.3333)<br></code></pre></div></td></tr></table></figure><p>backward</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">myModel = MyModel()<br>loss = nn.CrossEntropyLoss()<br><span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> dataloader:<br>    imgs, targets = data<br>    output = myModel(imgs)<br>    result_loss = loss(output, targets)<br>    result_loss.backward()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;ok&quot;</span>)<br></code></pre></div></td></tr></table></figure><h2 id="">11</h2><p>torch.optim:</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">myModel = MyModel()<br>loss = nn.CrossEntropyLoss()<br>optim = torch.optim.SGD(myModel.parameters(), lr=<span class="hljs-number">0.01</span>)<br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">20</span>):<br>    runing_loss = <span class="hljs-number">0.0</span><br>    <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> dataloader:<br>        imgs, targets = data<br>        output = myModel(imgs)<br>        result_loss = loss(output, targets)<br>        optim.zero_grad()<span class="hljs-comment"># 0</span><br>        result_loss.backward()<br>        optim.step()<span class="hljs-comment"># </span><br>        runing_loss = runing_loss + result_loss<br>    <span class="hljs-built_in">print</span>(runing_loss)<br></code></pre></div></td></tr></table></figure><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">tensor(<span class="hljs-number">18666.8984</span>, grad_fn=&lt;AddBackward0&gt;)<br>tensor(<span class="hljs-number">16161.6846</span>, grad_fn=&lt;AddBackward0&gt;)<br>tensor(<span class="hljs-number">15338.8057</span>, grad_fn=&lt;AddBackward0&gt;)<br>...<br></code></pre></div></td></tr></table></figure><p><code>torch.optim.lr_scheduler</code>epochlearningrateepoch</p><p><code>torch.optim.lr_scheduler.LambdaLR</code>epoch</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">torch</span>.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda, last_epoch=-<span class="hljs-number">1</span>)<br></code></pre></div></td></tr></table></figure><p> <span class="math display">\[new\_lr=\lambda \times initial\_lr\]</span> new_lrinitial_lr<spanclass="math inline">\(\lambda\)</span>lr_lambdaepoch</p><p></p><p>optimizer Optimizer lr_lambdafunctionor listepoch<spanclass="math inline">\(\lambda\)</span>listfunctionparametergroups<span class="math inline">\(\lambda\)</span>last_epochintepochindexepochepoch-1epoch=1</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">net_1 = model()<br><br>optimizer_1 = torch.optim.Adam(net_1.parameters(), lr = initial_lr)<br>scheduler_1 = LambdaLR(optimizer_1, lr_lambda=<span class="hljs-keyword">lambda</span> epoch: <span class="hljs-number">1</span>/(epoch+<span class="hljs-number">1</span>))<br></code></pre></div></td></tr></table></figure><h2 id="">12</h2><p>torchvisionvgg16</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">vgg16_true = torchvison.models.vgg16(pretrained=<span class="hljs-literal">True</span>)<br><span class="hljs-comment"># </span><br>vgg16_true.classifier.add_module(<span class="hljs-string">&#x27;add_linear&#x27;</span>, nn.Linear(<span class="hljs-number">1000</span>, <span class="hljs-number">10</span>))<br><span class="hljs-comment"># </span><br>vgg16_true.classifier[<span class="hljs-number">6</span>] = nn.Linear(<span class="hljs-number">4096</span>, <span class="hljs-number">10</span>)<br></code></pre></div></td></tr></table></figure><h2 id="">13</h2><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">vgg16 = torchvision.models.vgg16(pretrained=<span class="hljs-literal">False</span>)<br><span class="hljs-comment"># 1</span><br>torch.save(vgg16, <span class="hljs-string">&quot;vgg16_method1.pth&quot;</span>)<br><br><span class="hljs-comment"># </span><br>torch.save(vgg16.state_dict(), <span class="hljs-string">&quot;vgg16_method2.pth&quot;</span>)<br></code></pre></div></td></tr></table></figure><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># 1</span><br>model = torch.load(<span class="hljs-string">&quot;vgg16_method1.pth&quot;</span>)<br><br><span class="hljs-comment"># 2</span><br>vgg16 = vgg16 = torchvision.models.vgg16(pretrained=<span class="hljs-literal">False</span>)<br>vgg16.load_state_dict(torch.load(<span class="hljs-string">&quot;vgg16_method1.pth&quot;</span>))<br></code></pre></div></td></tr></table></figure><h2 id="">14</h2><p>model.py</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyModel</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(MyModel, self).__init__()<br>        self.model = nn.Sequential(<br>            nn.Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">32</span>, <span class="hljs-number">5</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>),<br>            nn.MaxPool2d(<span class="hljs-number">2</span>),<br>            nn.Conv2d(<span class="hljs-number">32</span>, <span class="hljs-number">32</span>, <span class="hljs-number">5</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>),<br>            nn.MaxPool2d(<span class="hljs-number">2</span>),<br>            nn.Conv2d(<span class="hljs-number">32</span>, <span class="hljs-number">64</span>, <span class="hljs-number">5</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>),<br>            nn.MaxPool2d(<span class="hljs-number">2</span>),<br>            nn.Flatten(),<br>            nn.Linear(<span class="hljs-number">64</span> * <span class="hljs-number">4</span> * <span class="hljs-number">4</span>, <span class="hljs-number">64</span>),<br>            nn.Linear(<span class="hljs-number">64</span>, <span class="hljs-number">10</span>)<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.model(x)<br>        <span class="hljs-keyword">return</span> x<br><br><br><span class="hljs-comment"># </span><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    myModel = MyModel()<br>    <span class="hljs-built_in">input</span> = torch.ones((<span class="hljs-number">64</span>, <span class="hljs-number">3</span>, <span class="hljs-number">32</span>, <span class="hljs-number">32</span>))<br>    output = myModel(<span class="hljs-built_in">input</span>)<br>    <span class="hljs-built_in">print</span>(output.shape)<br></code></pre></div></td></tr></table></figure><p>train.py</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torchvision<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> DataLoader<br><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br><br><span class="hljs-keyword">from</span> model <span class="hljs-keyword">import</span> *<br><br><span class="hljs-comment"># </span><br>train_data = torchvision.datasets.CIFAR10(<span class="hljs-string">&quot;./dataset&quot;</span>, train=<span class="hljs-literal">True</span>, transform=torchvision.transforms.ToTensor(),<br>                                         download=<span class="hljs-literal">True</span>)<br>test_data = torchvision.datasets.CIFAR10(<span class="hljs-string">&quot;./dataset&quot;</span>, train=<span class="hljs-literal">False</span>, transform=torchvision.transforms.ToTensor(),<br>                                         download=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># </span><br>train_data_length = <span class="hljs-built_in">len</span>(train_data)<br>test_data_length = <span class="hljs-built_in">len</span>(test_data)<br><br><span class="hljs-comment"># DataLoader</span><br>train_dataloader = DataLoader(train_data, batch_size=<span class="hljs-number">64</span>)<br>test_dataloader = DataLoader(test_data, batch_size=<span class="hljs-number">64</span>)<br><br><span class="hljs-comment"># </span><br>myModel = MyModel()<br><br><span class="hljs-comment"># </span><br>loss_fn = nn.CrossEntropyLoss()<br><br><span class="hljs-comment"># </span><br>learning_rate = <span class="hljs-number">0.01</span><br>optimizer = torch.optim.SGD(myModel.parameters(), lr=learning_rate)<br><br><span class="hljs-comment"># </span><br><span class="hljs-comment"># </span><br>total_train_step = <span class="hljs-number">0</span><br><span class="hljs-comment"># </span><br>total_test_step = <span class="hljs-number">0</span><br><span class="hljs-comment"># </span><br>epoch = <span class="hljs-number">10</span><br><br><span class="hljs-comment"># tensorboard</span><br>writer = SummaryWriter(<span class="hljs-string">&quot;logs_train&quot;</span>)<br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epoch):<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;------%d------&quot;</span> % (i+<span class="hljs-number">1</span>))<br><br>    <span class="hljs-comment"># </span><br>    myModel.train()<br>    <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> train_dataloader:<br>        imgs, targets = data<br>        outputs = myModel(imgs)<br>        loss = loss_fn(outputs, targets)<br><br>        <span class="hljs-comment"># </span><br>        <span class="hljs-comment"># </span><br>        optimizer.zero_grad()<br>        <span class="hljs-comment"># </span><br>        loss.backward()<br>        optimizer.step()<br><br>        total_train_step = total_train_step + <span class="hljs-number">1</span><br>        <span class="hljs-keyword">if</span> total_train_step % <span class="hljs-number">100</span> == <span class="hljs-number">0</span>:<br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&#123;&#125;loss&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(total_train_step, loss.item()))<br>            writer.add_scalar(<span class="hljs-string">&quot;train_loss&quot;</span>, loss.item(), total_train_step)<br><br>    <span class="hljs-comment"># </span><br>    myModel.<span class="hljs-built_in">eval</span>()<br>    total_test_loss = <span class="hljs-number">0</span><br>    total_accuracy = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        <span class="hljs-keyword">for</span> data <span class="hljs-keyword">in</span> test_dataloader:<br>            imgs, targets = data<br>            outputs = myModel(imgs)<br>            loss = loss_fn(outputs, targets)<br>            total_test_loss = total_test_loss + loss.item()<br>            accuracy = (outputs.argmax(<span class="hljs-number">1</span>) == targets).<span class="hljs-built_in">sum</span>()<br>            total_accuracy = total_accuracy + accuracy<br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Loss&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(total_test_loss))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(total_accuracy/test_data_length))<br>    writer.add_scalar(<span class="hljs-string">&quot;test_loss&quot;</span>, total_test_loss, total_test_step)<br>    writer.add_scalar(<span class="hljs-string">&quot;test_accuracy&quot;</span>, total_accuracy/test_data_length, total_test_step)<br>    total_test_step = total_test_step + <span class="hljs-number">1</span><br><br>    <span class="hljs-comment"># </span><br>    torch.save(myModel, <span class="hljs-string">&quot;myModel_&#123;&#125;.pth&quot;</span>.<span class="hljs-built_in">format</span>(i))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&quot;</span>)<br><br>writer.close()<br></code></pre></div></td></tr></table></figure><h2 id="gpu">15GPU</h2><h3 id=""></h3><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># </span><br>myModel = MyModel()<br><span class="hljs-keyword">if</span> torch.cuda.is_available():<br>    myModel = myModel.cuda()<br>    <br><span class="hljs-comment"># </span><br>loss_fn = nn.CrossEntropyLoss()<br><span class="hljs-keyword">if</span> torch.cuda.is_available():<br>    loss_fn = loss_fn.cuda()<br>    <br>imgs, targets = data<br><span class="hljs-keyword">if</span> torch.cuda.is_available():<br>imgs = imgs.cuda()<br>targets = targets.cuda()<br></code></pre></div></td></tr></table></figure><h3 id=""></h3><p></p><p>cpu</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># </span><br>device = torch.device(<span class="hljs-string">&quot;cpu&quot;</span>)<br><br><span class="hljs-comment"># </span><br>myModel = MyModel()<br>myModel.to(device)<span class="hljs-comment"># </span><br><br><span class="hljs-comment"># </span><br>loss_fn = nn.CrossEntropyLoss()<br>loss_fn.to(device)<br><br>imgs, targets = data<br>imgs = imgs.to(device)<span class="hljs-comment"># </span><br>targets = targets.to(device)<br></code></pre></div></td></tr></table></figure><p>gpu</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># </span><br>device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span>)<br></code></pre></div></td></tr></table></figure><p>gpu</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># </span><br>device = torch.device(<span class="hljs-string">&quot;cuda0&quot;</span>)<br></code></pre></div></td></tr></table></figure><h2 id="">16</h2><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">image_path = <span class="hljs-string">&quot;./img/dog.png&quot;</span><br><br>image = Image.<span class="hljs-built_in">open</span>(image_path)<br>image = image.convert(<span class="hljs-string">&#x27;RGB&#x27;</span>)<br><br>transform = torchvision.transforms.Compose([torchvision.transforms.Resize((<span class="hljs-number">32</span>, <span class="hljs-number">32</span>)),<br>                                            torchvision.transforms.ToTensor()])<br><br>image = transform(image)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyModel</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(MyModel, self).__init__()<br>        self.model = nn.Sequential(<br>            nn.Conv2d(<span class="hljs-number">3</span>, <span class="hljs-number">32</span>, <span class="hljs-number">5</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>),<br>            nn.MaxPool2d(<span class="hljs-number">2</span>),<br>            nn.Conv2d(<span class="hljs-number">32</span>, <span class="hljs-number">32</span>, <span class="hljs-number">5</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>),<br>            nn.MaxPool2d(<span class="hljs-number">2</span>),<br>            nn.Conv2d(<span class="hljs-number">32</span>, <span class="hljs-number">64</span>, <span class="hljs-number">5</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>),<br>            nn.MaxPool2d(<span class="hljs-number">2</span>),<br>            nn.Flatten(),<br>            nn.Linear(<span class="hljs-number">64</span> * <span class="hljs-number">4</span> * <span class="hljs-number">4</span>, <span class="hljs-number">64</span>),<br>            nn.Linear(<span class="hljs-number">64</span>, <span class="hljs-number">10</span>)<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.model(x)<br>        <span class="hljs-keyword">return</span> x<br><br><br>myModel = torch.load(<span class="hljs-string">&quot;myModel_0.pth&quot;</span>)<br><span class="hljs-built_in">print</span>(myModel)<br>image = torch.reshape(image, (<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">32</span>, <span class="hljs-number">32</span>))<br>myModel.<span class="hljs-built_in">eval</span>()<br><span class="hljs-keyword">with</span> torch.no_grad():<br>    output = myModel(image)<br><span class="hljs-built_in">print</span>(output)<br><span class="hljs-built_in">print</span>(output.argmax(<span class="hljs-number">1</span>))<br></code></pre></div></td></tr></table></figure><p></p><figure class="highlight shell"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs shell">tensor([[ 0.3308,  0.0307,  0.9064,  0.9474,  0.2715,  0.8123, -0.4077,  0.2044,<br>         -0.4149, -1.0106]])<br>tensor([3])<br></code></pre></div></td></tr></table></figure><p></p><h2 id="lstm">17LSTM</h2><p><strong>:</strong></p><ul><li>input_sizeembedding_dim()</li><li>hidden_sizeLSTM</li><li>num_layers</li><li>biasdefault=True</li><li>batch_firstshape=(batch_size,seq_length,embedding_dim),batch_firstFalse,LSTMbatch_sizeseq_length</li><li>dropout0dropout</li><li>bidirectionalfalseLSTM</li></ul><p><strong>input,(h_0,c_0):</strong></p><ul><li>inputshape=(seq_length,batch_size,input_size)</li><li>h_0shape=(num_layers*num_directions,batch_size,hidden_size)batch_sizenum_layersLSTMbidirectional=True,num_directions=2,</li><li>c_0h_0batch_sizeh_0,c_0</li></ul><p><strong>output,(h_n,c_n):</strong></p><ul><li>outputshape=(seq_length,batch_size,num_directions*hidden_size),LSTM(h_t),batch_size</li><li>h_n.shape==(num_directions * num_layers,batch,hidden_size)</li><li>h_nc_nseq_length</li><li>output[-1]h_noutput[-1]batch_sizeLSTMcellstateLSTM</li></ul><h2 id="lstmcell">18LSTMcell</h2><p>nn.LSTMLSTM,nnLSTMCellLSTMsequenceword</p><p>3LSTMcellcellLSTM</p><h2 id="pad_sequence">19pad_sequence</h2><p><strong>sequences</strong> list list tensor  tensor  size  L * F LF timestep F </p><p><strong>batch_first</strong> True  [batch_size, seq_len,feature]False [seq_len, batch_size,feature] True </p><p><strong>padding_value</strong> 0 </p><p><strong></strong></p><p> 0 mini-batch PyTorch  tensor mini-batch  tensor tensor mini-batch  mini-batch</p><p> PyTorch  DataLoader  mini-batch collate_fn</p><p><strong></strong></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset, DataLoader<br><span class="hljs-keyword">from</span> torch.nn.utils.rnn <span class="hljs-keyword">import</span> pad_sequence,pack_padded_sequence,pack_sequence,pad_packed_sequence<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyData</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, data</span>):<br>        self.data = data<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.data)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, idx</span>):<br>        <span class="hljs-keyword">return</span> self.data[idx]<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">collate_fn</span>(<span class="hljs-params">data</span>):<br>    data.sort(key=<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">len</span>(x), reverse=<span class="hljs-literal">True</span>)<br>    data = pad_sequence(data, batch_first=<span class="hljs-literal">True</span>, padding_value=<span class="hljs-number">0</span>)<br>    <span class="hljs-keyword">return</span> data<br><br>a = torch.tensor([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>])<br>b = torch.tensor([<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>])<br>c = torch.tensor([<span class="hljs-number">7</span>,<span class="hljs-number">8</span>])<br>d = torch.tensor([<span class="hljs-number">9</span>])<br>train_x = [a, b, c, d]<br><br>data = MyData(train_x)<br>data_loader = DataLoader(data, batch_size=<span class="hljs-number">2</span>, shuffle=<span class="hljs-literal">True</span>, collate_fn=collate_fn)<br><span class="hljs-comment">#  collate_fn </span><br><span class="hljs-comment">#data_loader = DataLoader(data, batch_size=2, shuffle=True) </span><br>batch_x = <span class="hljs-built_in">iter</span>(data_loader).<span class="hljs-built_in">next</span>()<br></code></pre></div></td></tr></table></figure><p> batch_x </p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># batch_x</span><br>tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>],<br>        [<span class="hljs-number">9</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]])<br></code></pre></div></td></tr></table></figure><p> batch_x  0</p><p> collate_fn collate_fn </p><h2 id="pack_padded_sequence">20pack_padded_sequence</h2><p><strong></strong></p><p><strong>input</strong> pad_sequence </p><p><strong>lengths</strong>mini-batch</p><p><strong>batch_first</strong>True  [batch_size, seq_len,feature] </p><p>False  [seq_len, batch_size, feature] </p><p><strong>enforce_sorted</strong> True False True </p><p><strong></strong></p><p> pack padding_value</p><p></p><p>RNN  time step mini-batch mini-batch  time step mini-batch</p><p></p><p><img src="/img/pytorch/12.png" /></p><p></p><p><img src="/img/pytorch/13.png" /></p><p>mini-batch  0  padding_value forward  padding_valueRNNpadding_value2  RNN </p><p><img src="/img/pytorch/14.png" /></p><p> 2 padding_value </p><p> RNN pad  pack_padded_sequence </p><p>pack_padded_sequence </p><p><strong></strong></p><p> collate_fn</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">collate_fn</span>(<span class="hljs-params">data</span>):<br>    data.sort(key=<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">len</span>(x), reverse=<span class="hljs-literal">True</span>)<br>    seq_len = [s.size(<span class="hljs-number">0</span>) <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> data] <span class="hljs-comment"># </span><br>    data = pad_sequence(data, batch_first=<span class="hljs-literal">True</span>)    <br>    data = pack_padded_sequence(data, seq_len, batch_first=<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">return</span> data<br></code></pre></div></td></tr></table></figure><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># batch_x</span><br>PackedSequence(data=tensor([<span class="hljs-number">1</span>, <span class="hljs-number">9</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>]), <br>               batch_sizes=tensor([<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]), <br>               sorted_indices=<span class="hljs-literal">None</span>, unsorted_indices=<span class="hljs-literal">None</span>)<br></code></pre></div></td></tr></table></figure><p> PackedSequence data batch_sizes </p><p><img src="/img/pytorch/15.png" /></p><p> 0 batch_size</p><p> PackedSequence sorted_indices unsorted_indices  pack_padded_sequence <strong>enforce_sorted</strong>  True False True pack_padded_sequence </p><p> enforce_sorted  False</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">data = [torch.tensor([<span class="hljs-number">9</span>]), <br>        torch.tensor([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>]),<br>        torch.tensor([<span class="hljs-number">5</span>,<span class="hljs-number">6</span>])]<br><br>seq_len = [s.size(<span class="hljs-number">0</span>) <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> data]<br>data = pad_sequence(data, batch_first=<span class="hljs-literal">True</span>)    <br>data = pack_padded_sequence(data, seq_len, batch_first=<span class="hljs-literal">True</span>, enforce_sorted=<span class="hljs-literal">False</span>)<br></code></pre></div></td></tr></table></figure><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">PackedSequence(data=tensor([<span class="hljs-number">1</span>, <span class="hljs-number">5</span>, <span class="hljs-number">9</span>, <span class="hljs-number">2</span>, <span class="hljs-number">6</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>]), <br>               batch_sizes=tensor([<span class="hljs-number">3</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]), <br>               sorted_indices=tensor([<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>]), <br>               unsorted_indices=tensor([<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>]))<br></code></pre></div></td></tr></table></figure><p>sorted_indices = tensor([1, 2, 0] data tensor 1  data   1 2  0 </p><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">sort_data = [torch.tensor([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>]),<br>             torch.tensor([<span class="hljs-number">5</span>,<span class="hljs-number">6</span>])<br>             torch.tensor([<span class="hljs-number">9</span>]), <br>             ]<br></code></pre></div></td></tr></table></figure><p>unsorted_indices = tensor([2, 0, 1]2 sort_data  2  data  0 0  sort_data  0 data  1 1  sort_data  1  data  2 </p><h2 id="pack_sequence">21pack_sequence</h2><p><strong></strong></p><p><strong>sequences</strong> list list tensor tensor  size  L * FL Ftime step F</p><p><strong>enforce_sorted</strong> True False True </p><p><strong></strong></p><p> PyTorch </p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">pack_sequence</span>(<span class="hljs-params">sequences, enforce_sorted=<span class="hljs-literal">True</span></span>): <br>lengths = torch.as_tensor([v.size(<span class="hljs-number">0</span>) <span class="hljs-keyword">for</span> v <span class="hljs-keyword">in</span> sequences]) <br><span class="hljs-keyword">return</span> pack_padded_sequence(pad_sequence(sequences),lengths,enforce_sorted=enforce_sorted)<br></code></pre></div></td></tr></table></figure><p> pack_sequence  pad_sequence pack_padded_sequence</p><p><strong></strong></p><p> collate_fn </p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">collate_fn</span>(<span class="hljs-params">data</span>):<br>    data.sort(key=<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">len</span>(x), reverse=<span class="hljs-literal">True</span>)<br>   <br>    data = pack_sequence(data)<br>    <span class="hljs-comment">#seq_len = [s.size(0) for s in data]</span><br>    <span class="hljs-comment">#data = pad_sequence(data, batch_first=True)    </span><br>    <span class="hljs-comment">#data = pack_padded_sequence(data, seq_len, batch_first=True)</span><br>    <span class="hljs-keyword">return</span> data<br></code></pre></div></td></tr></table></figure><p></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># batch_x</span><br>PackedSequence(data=tensor([<span class="hljs-number">1</span>, <span class="hljs-number">9</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>]), <br>               batch_sizes=tensor([<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]), <br>               sorted_indices=<span class="hljs-literal">None</span>, unsorted_indices=<span class="hljs-literal">None</span>)<br></code></pre></div></td></tr></table></figure><h2 id="pad_packed_sequence">22pad_packed_sequence</h2><p><strong></strong></p><p><strong>sequences</strong>PackedSequence  batch</p><p><strong>batch_first</strong> True[batch_size, seq_len, feature] </p><p><strong>padding_value</strong></p><p><strong>total_length</strong><code>None</code><code>total_length</code></p><p><strong></strong></p><p> pack_sequence pytorch  RNN out  PackedSequence </p><p> pack_padded_sequence</p><p> collate_fn pad_sequence  label RNN  label</p><p><strong></strong></p><p> LSTM  [batch_size,seq_len, feature]  unsqueeze batch_size <strong></strong>seq_len<strong></strong>feature <strong></strong></p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyData</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, data</span>):<br>        self.data = data<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.data)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, idx</span>):<br>        <span class="hljs-keyword">return</span> self.data[idx]<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">collate_fn</span>(<span class="hljs-params">data</span>):<br>    data.sort(key=<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">len</span>(x), reverse=<span class="hljs-literal">True</span>)<br>    seq_len = [s.size(<span class="hljs-number">0</span>) <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> data]<br>    data = pad_sequence(data, batch_first=<span class="hljs-literal">True</span>).<span class="hljs-built_in">float</span>()    <br>    data = data.unsqueeze(-<span class="hljs-number">1</span>)<br>    data = pack_padded_sequence(data, seq_len, batch_first=<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">return</span> data<br><br>a = torch.tensor([<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>])<br>b = torch.tensor([<span class="hljs-number">5</span>,<span class="hljs-number">6</span>,<span class="hljs-number">7</span>])<br>c = torch.tensor([<span class="hljs-number">7</span>,<span class="hljs-number">8</span>])<br>d = torch.tensor([<span class="hljs-number">9</span>])<br>train_x = [a, b, c, d]<br><br>data = MyData(train_x)<br>data_loader = DataLoader(data, batch_size=<span class="hljs-number">2</span>, shuffle=<span class="hljs-literal">True</span>, collate_fn=collate_fn)<br>batch_x = <span class="hljs-built_in">iter</span>(data_loader).<span class="hljs-built_in">next</span>()<br><br>rnn = nn.LSTM(<span class="hljs-number">1</span>, <span class="hljs-number">4</span>, <span class="hljs-number">1</span>, batch_first=<span class="hljs-literal">True</span>)<br>h0 = torch.rand(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>).<span class="hljs-built_in">float</span>()<br>c0 = torch.rand(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>).<span class="hljs-built_in">float</span>()<br>out, (h1, c1) = rnn(batch_x, (h0, c0))<br></code></pre></div></td></tr></table></figure><p> out  PackedSequence pack_padded_sequence </p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># out</span><br>PackedSequence(data=tensor([[-<span class="hljs-number">1.3302e-04</span>,  <span class="hljs-number">5.7754e-02</span>,  <span class="hljs-number">4.3181e-02</span>,  <span class="hljs-number">6.4226e-02</span>],<br>        [-<span class="hljs-number">2.8673e-02</span>,  <span class="hljs-number">3.9089e-02</span>, -<span class="hljs-number">2.6875e-03</span>,  <span class="hljs-number">4.2686e-03</span>],<br>        [-<span class="hljs-number">1.0216e-01</span>,  <span class="hljs-number">2.5236e-02</span>, -<span class="hljs-number">1.2230e-01</span>,  <span class="hljs-number">5.1524e-02</span>],<br>        [-<span class="hljs-number">1.6211e-01</span>,  <span class="hljs-number">2.1079e-02</span>, -<span class="hljs-number">1.5849e-01</span>,  <span class="hljs-number">5.2800e-02</span>],<br>        [-<span class="hljs-number">1.5774e-01</span>,  <span class="hljs-number">2.6749e-02</span>, -<span class="hljs-number">1.3333e-01</span>,  <span class="hljs-number">4.7894e-02</span>]],<br>       grad_fn=&lt;CatBackward&gt;), <br>       batch_sizes=tensor([<span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]), <br>       sorted_indices=<span class="hljs-literal">None</span>, unsorted_indices=<span class="hljs-literal">None</span>)<br></code></pre></div></td></tr></table></figure><p> out  pad_packed_sequence </p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">out_pad, out_len = pad_packed_sequence(out, batch_first=<span class="hljs-literal">True</span>)<br></code></pre></div></td></tr></table></figure><p>out_pad  out_len </p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># out_pad </span><br>tensor([[[-<span class="hljs-number">1.3302e-04</span>,  <span class="hljs-number">5.7754e-02</span>,  <span class="hljs-number">4.3181e-02</span>,  <span class="hljs-number">6.4226e-02</span>],<br>         [-<span class="hljs-number">1.0216e-01</span>,  <span class="hljs-number">2.5236e-02</span>, -<span class="hljs-number">1.2230e-01</span>,  <span class="hljs-number">5.1524e-02</span>],<br>         [-<span class="hljs-number">1.6211e-01</span>,  <span class="hljs-number">2.1079e-02</span>, -<span class="hljs-number">1.5849e-01</span>,  <span class="hljs-number">5.2800e-02</span>],<br>         [-<span class="hljs-number">1.5774e-01</span>,  <span class="hljs-number">2.6749e-02</span>, -<span class="hljs-number">1.3333e-01</span>,  <span class="hljs-number">4.7894e-02</span>]],<br><br>        [[-<span class="hljs-number">2.8673e-02</span>,  <span class="hljs-number">3.9089e-02</span>, -<span class="hljs-number">2.6875e-03</span>,  <span class="hljs-number">4.2686e-03</span>],<br>         [ <span class="hljs-number">0.0000e+00</span>,  <span class="hljs-number">0.0000e+00</span>,  <span class="hljs-number">0.0000e+00</span>,  <span class="hljs-number">0.0000e+00</span>],<br>         [ <span class="hljs-number">0.0000e+00</span>,  <span class="hljs-number">0.0000e+00</span>,  <span class="hljs-number">0.0000e+00</span>,  <span class="hljs-number">0.0000e+00</span>],<br>         [ <span class="hljs-number">0.0000e+00</span>,  <span class="hljs-number">0.0000e+00</span>,  <span class="hljs-number">0.0000e+00</span>,  <span class="hljs-number">0.0000e+00</span>]]],<br>       grad_fn=&lt;TransposeBackward0&gt;)<br><br><span class="hljs-comment"># out_len</span><br>tensor([<span class="hljs-number">4</span>, <span class="hljs-number">1</span>])<br></code></pre></div></td></tr></table></figure><p> pad_sequence </p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># batch_x</span><br>tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>],<br>        [<span class="hljs-number">9</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]])<br></code></pre></div></td></tr></table></figure><p> out_pad </p><h2 id="cat">22cat</h2><p>AB23432torch.cat01.</p><p>C=torch.cat((A,B),0)0ABAB13C002+4=6</p><p>C=torch.cat((A,B),1)1ABAB02C113+4=7</p><h2 id="torch.split">23torch.split</h2><p><code>torch.split(tensor, split_size_or_sections, dim=0)</code></p><p>torch.split()tensor</p><p></p><ul><li>tesnorinput</li><li>split_size_or_sections(int or list )</li><li>dim</li><li>output &lt;class 'tuple'&gt;</li><li>split_size_or_sections<strong>int</strong>tenorsplit_size_or_sectionsouputsplit_size_or_sectionstensor</li><li>split_size_or_sections<strong>list</strong>tensorlen(list)listlistsplit_size_or_sectionsint</li></ul><h2id="torch.squeezetorch.unsqueeze">24torch.squeezetorch.unsqueeze</h2><p>torch.squeeze()11,33</p><ul><li>1.squeeze(a)a11</li><li>2.a.squeeze(N) a</li><li>3.b=torch.squeeze(aN)aN</li></ul><p>torch.unsqueeze()</p><ul><li>1.301,3a.unsqueeze(N)aN1</li><li>2.b=torch.unsqueeze(aN)aaN1</li></ul><h2 id="nn.embedding">25nn.Embedding</h2><p><code>torch.nn.Embedding(num_embeddings, embedding_dim, padding_idx=None,max_norm=None,  norm_type=2.0,   scale_grad_by_freq=False, sparse=False,  _weight=None)</code></p><p></p><p></p><p><strong></strong></p><ul><li>num_embeddings (python:int) 50005000index0-4999</li><li>embedding_dim (python:int) </li><li>padding_idx (python:int, optional) id100id<strong>0</strong></li><li>max_norm (python:float, optional) </li><li>norm_type (python:float, optional) max_norm2</li><li>scale_grad_by_freq (boolean, optional) mini-batchFalse.</li><li>sparse (bool, optional) True,</li></ul><h2 id="torch.bmm">26torch.bmm</h2><p>torch</p><p></p><p><code>def bmm(self: Tensor,mat2: Tensor,*,out: Optional[Tensor] = None) -&gt; Tensor</code></p><p><ahref="https://so.csdn.net/so/search?q=&amp;spm=1001.2101.3001.7020"></a>shape</p><p><code>res = torch.bmm(ma, mb)</code></p><p><code>ma: [a, b, c]</code></p><p><code>mb: [a, c, d]</code></p>]]></content>
    
    
    <categories>
      
      <category>Deep Learning</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title></title>
    <link href="/2022/04/26/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/"/>
    <url>/2022/04/26/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<h1 id=""></h1><h2 id="">1</h2><p> <spanclass="math inline">\(47\)</span> </p><table><thead><tr class="header"><th style="text-align: center;"></th><th style="text-align: center;"></th></tr></thead><tbody><tr class="odd"><td style="text-align: center;"><spanclass="math inline">\(2104\)</span></td><td style="text-align: center;"><spanclass="math inline">\(400\)</span></td></tr><tr class="even"><td style="text-align: center;"><spanclass="math inline">\(1600\)</span></td><td style="text-align: center;"><spanclass="math inline">\(330\)</span></td></tr><tr class="odd"><td style="text-align: center;"><spanclass="math inline">\(2400\)</span></td><td style="text-align: center;"><spanclass="math inline">\(369\)</span></td></tr><tr class="even"><td style="text-align: center;"><spanclass="math inline">\(1416\)</span></td><td style="text-align: center;"><spanclass="math inline">\(232\)</span></td></tr><tr class="odd"><td style="text-align: center;"><spanclass="math inline">\(3000\)</span></td><td style="text-align: center;"><spanclass="math inline">\(540\)</span></td></tr><tr class="even"><td style="text-align: center;"></td><td style="text-align: center;"></td></tr></tbody></table><p><img src="/img//1.png" /></p><p></p><p></p><p></p><table><thead><tr class="header"><th style="text-align: center;"></th><th style="text-align: center;"></th><th style="text-align: center;"></th></tr></thead><tbody><tr class="odd"><td style="text-align: center;"><spanclass="math inline">\(2104\)</span></td><td style="text-align: center;"><spanclass="math inline">\(3\)</span></td><td style="text-align: center;"><spanclass="math inline">\(400\)</span></td></tr><tr class="even"><td style="text-align: center;"><spanclass="math inline">\(1600\)</span></td><td style="text-align: center;"><spanclass="math inline">\(3\)</span></td><td style="text-align: center;"><spanclass="math inline">\(330\)</span></td></tr><tr class="odd"><td style="text-align: center;"><spanclass="math inline">\(2400\)</span></td><td style="text-align: center;"><spanclass="math inline">\(3\)</span></td><td style="text-align: center;"><spanclass="math inline">\(369\)</span></td></tr><tr class="even"><td style="text-align: center;"><spanclass="math inline">\(1416\)</span></td><td style="text-align: center;"><spanclass="math inline">\(2\)</span></td><td style="text-align: center;"><spanclass="math inline">\(232\)</span></td></tr><tr class="odd"><td style="text-align: center;"><spanclass="math inline">\(3000\)</span></td><td style="text-align: center;"><spanclass="math inline">\(4\)</span></td><td style="text-align: center;"><spanclass="math inline">\(540\)</span></td></tr><tr class="even"><td style="text-align: center;"></td><td style="text-align: center;"></td><td style="text-align: center;"></td></tr></tbody></table><p></p><p></p><p><img src="/img//2.png" /></p><p></p><p><span class="math inline">\(x_1\)</span><spanclass="math inline">\(x_2\)</span>feature <spanclass="math inline">\(x_1\)</span>=<spanclass="math inline">\(x_2\)</span>=<span class="math display">\[h_\theta  (x) = \theta_0 + \theta_1 \times x_1 + \theta_2 \times x_2\]</span>  <span class="math display">\[h(x) = \sum^n_{i=0}  \theta_i x_i = \theta^T x\]</span> <spanclass="math inline">\(\theta\)</span><spanclass="math inline">\(h\)</span>loss function(errorfunction)<span class="math inline">\(h\)</span><spanclass="math inline">\(J\)</span> <span class="math display">\[J(\theta) = \frac 12 \sum^m_{i=1}(h_\theta(x^{(i)})-y^{(i)})^2\]</span> <span class="math inline">\(\theta\)</span><spanclass="math inline">\(J(\theta)\)</span>(leastsquares method)</p><h3 id="">1.1 </h3><p><strong>design matrix</strong> <spanclass="math inline">\(x\)</span>  <spanclass="math inline">\(m\times n\)</span> <spanclass="math inline">\(\theta_0\)</span>  <spanclass="math inline">\(m\times (n+1)\)</span></p><p><span class="math display">\[X =\begin{bmatrix}(x^{(1)}) ^T\\(x^{(2)}) ^T\\\vdots \\(x^{(m)}) ^T\\\end{bmatrix}\]</span></p><p> <span class="math inline">\(\vec{y}\)</span> <span class="math inline">\(m\)</span> m-dimensionalvector</p><p><span class="math display">\[Y =\begin{bmatrix}y^{(1)}\\y^{(2)}\\\vdots \\y^{(m)}\\\end{bmatrix}\]</span></p><p><span class="math inline">\(h_\theta(x_1,x_2,...,x_m)=\theta_0+\theta_1 \times x_1 + \theta_2 \times x_2 + ... +\theta \timesx_m\)</span>  <span class="math display">\[h_\theta(x)=X_\theta\]</span>  <span class="math display">\[\frac \partial {\partial\theta_j}J(\theta) = \frac12 (X_\theta - Y) ^ T(X_\theta - T)\]</span>  <spanclass="math inline">\(\theta\)</span> 0<span class="math display">\[\theta = (X^T X)^{-1} X^T Y\]</span></p><h3 id="">1.2 </h3><p> <span class="math inline">\(J(\theta)\)</span> <span class="math inline">\(\theta\)</span> <spanclass="math inline">\(\theta\)</span>  <spanclass="math inline">\(\theta\)</span>  <spanclass="math inline">\(J(\theta)\)</span> <spanclass="math inline">\(J(\theta)\)</span>  <spanclass="math inline">\(\theta\)</span>gradientdescent algorithm <spanclass="math inline">\(\theta\)</span></p><p><span class="math display">\[\theta_j := \theta_j - \alpha \frac \partial {\partial\theta_j}J(\theta)\]</span></p><p> <span class="math inline">\(0\)</span> <span class="math inline">\(n\)</span> <spanclass="math inline">\(j\)</span>  <spanclass="math inline">\(\alpha\)</span> <spanclass="math inline">\(J\)</span> </p><p><span class="math inline">\((x, y)\)</span> <spanclass="math inline">\(J\)</span> </p><p><span class="math display">\[\begin{aligned}\frac \partial {\partial\theta_j}J(\theta) &amp; = \frac \partial{\partial\theta_j} \frac  12(h_\theta(x)-y)^2\\&amp; = 2 \cdot\frac 12(h_\theta(x)-y)\cdot \frac \partial{\partial\theta_j}  (h_\theta(x)-y) \\&amp; = (h_\theta(x)-y)\cdot \frac \partial{\partial\theta_j}(\sum^n_{i=0} \theta_ix_i-y) \\&amp; = (h_\theta(x)-y) x_j\end{aligned}\]</span></p><p></p><p><span class="math display">\[\theta_j := \theta_j + \alpha (y^{(i)}-h_\theta (x^{(i)}))x_j^{(i)}\]</span></p><p></p>$<span class="math display">\[\begin{aligned}&amp;\qquad  \{ \\&amp;\qquad\qquad\theta_j := \theta_j + \alpha\sum^m_{i=1}(y^{(i)}-h_\theta (x^{(i)}))x_j^{(i)}\quad(j) \\&amp;\qquad\}\end{aligned}\]</span><p>$</p><p><spanclass="math inline">\(\frac {\partial J(\theta)}{\partial\theta_j}\)</span>  <span class="math inline">\(J\)</span><spanclass="math inline">\(J\)</span><strong>batchgradientdescent</strong><span class="math inline">\(\alpha\)</span> </p><p> <spanclass="math inline">\(\theta\)</span> <spanclass="math inline">\(\theta_0 = 71.27, \theta_1 =0.1345\)</span> <spanclass="math inline">\(h_{\theta}(x)\)</span>  <spanclass="math inline">\(x\)</span></p><p><img src="/img//3.png" /></p><p> <spanclass="math inline">\(\theta_0 = 89.60, \theta_1 = 0.1392, \theta_2 =8.738\)</span></p><p></p>$<span class="math display">\[\begin{aligned}&amp;\qquad\{ \\&amp;\qquad\qquad i1m,\{   \\&amp;\qquad\qquad\qquad\theta_j :=\theta_j  +\alpha(y^{(i)}-h_{\theta}(x^{(i)}))x_j^{(i)} \qquad( j)\\&amp;\qquad\qquad\}  \\&amp;\qquad\}\end{aligned}\]</span><p>$</p><p><strong>stochasticgradient descent</strong><strong>incrementalgradientdescent</strong><span class="math inline">\(m\)</span><span class="math inline">\(\theta\)</span>converge<span class="math inline">\(\theta\)</span>  <spanclass="math inline">\(J(\theta)\)</span></p>]]></content>
    
    
    <categories>
      
      <category>Machine Learning</category>
      
    </categories>
    
    
  </entry>
  
  
  
  
</search>
