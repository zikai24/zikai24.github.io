

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=dark>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" href="/img/favicon.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="肘子开">
  <meta name="keywords" content="">
  
    <meta name="description" content="论文：CoAtNet: Marrying Convolution and Attention for All Data Sizes   模型 融合convolution和self-attention 对于卷积，我们主要关注 MBConv 块 ，它采用深度卷积来捕获空间交互。 这种选择的一个关键原因是 Transformer 和 MBConv 中的 FFN 模块都采用了“反向瓶颈">
<meta property="og:type" content="article">
<meta property="og:title" content="CoAtNet">
<meta property="og:url" content="http://example.com/2022/11/06/CoAtNet/index.html">
<meta property="og:site_name" content="肘子开的博客">
<meta property="og:description" content="论文：CoAtNet: Marrying Convolution and Attention for All Data Sizes   模型 融合convolution和self-attention 对于卷积，我们主要关注 MBConv 块 ，它采用深度卷积来捕获空间交互。 这种选择的一个关键原因是 Transformer 和 MBConv 中的 FFN 模块都采用了“反向瓶颈">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/cv/image-20221114204217704.png">
<meta property="og:image" content="http://example.com/img/cv/image-20221106160427620.png">
<meta property="og:image" content="http://example.com/img/cv/image-20221106164733104.png">
<meta property="og:image" content="http://example.com/img/cv/image-20221106164712746.png">
<meta property="og:image" content="http://example.com/img/cv/image-20221106165751331.png">
<meta property="og:image" content="http://example.com/img/cv/image-20221106164949720.png">
<meta property="og:image" content="http://example.com/img/cv/image-20221106165319538.png">
<meta property="og:image" content="http://example.com/img/cv/image-20221106165448391.png">
<meta property="og:image" content="http://example.com/img/cv/image-20221106165504183.png">
<meta property="og:image" content="http://example.com/img/cv/image-20221106165537550.png">
<meta property="og:image" content="http://example.com/img/cv/image-20221106165549351.png">
<meta property="og:image" content="http://example.com/img/cv/image-20221106165643160.png">
<meta property="article:published_time" content="2022-11-06T07:42:36.000Z">
<meta property="article:modified_time" content="2022-11-15T08:16:55.513Z">
<meta property="article:author" content="肘子开">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://example.com/img/cv/image-20221114204217704.png">
  
  
  <title>CoAtNet - 肘子开的博客</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4/github-markdown.min.css" />
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hint.css@2/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10/styles/nnfx-dark.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.css" />
  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.8.14","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 6.1.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>肘子开的博客</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/img/bg/bg2.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="CoAtNet">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2022-11-06 15:42" pubdate>
        2022年11月6日 下午
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      12k 字
    </span>
  

  
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      101 分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">CoAtNet</h1>
            
            <div class="markdown-body">
              <ul>
<li>论文：CoAtNet: Marrying Convolution and Attention for All Data
Sizes</li>
</ul>
<p><img src="/img/cv/image-20221114204217704.png" srcset="/img/loading.gif" lazyload /></p>
<h1 id="模型">模型</h1>
<h2
id="融合convolution和self-attention">融合convolution和self-attention</h2>
<p>对于卷积，我们主要关注 MBConv 块 ，它采用深度卷积来捕获空间交互。
这种选择的一个关键原因是 Transformer 和 MBConv 中的 FFN
模块都采用了“反向瓶颈”(inverted
bottleneck)的设计，首先将输入的通道大小扩展了 4 倍，然后将 4
倍宽的隐藏状态投影回原始状态 通道大小以启用残差连接。</p>
<p>除了倒置瓶颈的相似性之外，我们还注意到深度卷积和自注意力都可以表示为预定义感受野中值的加权和。
具体来说，卷积依赖于一个固定的内核来从局部感受野收集信息。 <span
class="math display">\[
y_{i}=\sum_{j \in \mathcal{L}(i)} w_{i-j} \odot x_{j} \  (depthwise \
convolution), \ \ \ (1)
\]</span> 其中<span class="math inline">\(x_{i}, y_{i} \in
\mathbb{R}^{D}\)</span>分别是位置 <span class="math inline">\(i\)</span>
的输入和输出，<span class="math inline">\(\mathcal{L}(i)\)</span>表示
<span class="math inline">\(i\)</span> 的局部邻域，例如图像处理中以
<span class="math inline">\(i\)</span> 为中心的 3x3 网格。</p>
<p>相比之下，self-attention 允许感受野是整个空间位置，并根据<span
class="math inline">\((x_i,
x_j)\)</span>对之间重新归一化的成对相似度(re-normalized pairwise
similarity)计算权重： <span class="math display">\[
y_{i}=\sum_{j \in \mathcal{G}} \underbrace{\frac{\exp \left(x_{i}^{\top}
x_{j}\right)}{\sum_{k \in \mathcal{G}} \exp \left(x_{i}^{\top}
x_{k}\right)}}_{A_{i, j}} x_{j}\ \ \ \ (self-attention),\ \ \ (2)
\]</span> 其中 <span class="math inline">\(\mathcal{G}\)</span>
表示全局空间空间。在讨论如何最好地组合它们之前，值得比较它们的相对优势和劣势，这有助于找出我们希望保留的优良特性。</p>
<ul>
<li><p>首先，depthwise 卷积核 <span
class="math inline">\(w_{i-j}\)</span>
是一个静态值的输入独立参数，而注意力权重 <span
class="math inline">\(A_{i,j}\)</span>
动态地取决于输入的表示。因此，自注意力更容易捕捉不同空间位置之间复杂的关系交互，这是我们在处理高级概念时最想要的属性。然而，灵活性伴随着更容易过度拟合的风险，尤其是在数据有限的情况下。</p></li>
<li><p>其次，注意给定任何位置对(i; j)，对应的卷积权重 <span
class="math inline">\(w_{i-j}\)</span> 只关心它们之间的相对位移，即
<span class="math inline">\(i -j\)</span> ，而不是 <span
class="math inline">\(i\)</span> 或 <span
class="math inline">\(j\)</span>
的具体值。这个属性通常被称为平移等变性，已经发现它可以提高有限大小数据集下的泛化能力。由于使用绝对位置嵌入，标准
Transformer (ViT)
缺少此属性。这部分解释了为什么当数据集不是很大时，ConvNets 通常比
Transformers 更好。</p></li>
<li><p>最后，感受野的大小是自注意力和卷积之间最重要的区别之一。一般来说，更大的感受野提供更多的上下文信息，这可能导致更高的模型容量。因此，全局感受野一直是在视觉中使用自注意力的关键动机。然而，一个大的感受野需要更多的计算。在全局注意力的情况下，复杂性是二次方
w.r.t.空间大小，这是应用自注意力模型的基本权衡。</p></li>
</ul>
<p><img src="/img/cv/image-20221106160427620.png" srcset="/img/loading.gif" lazyload /></p>
<p>鉴于上述比较，理想模型应该能够结合表 1 中的 3 个理想属性。
可以实现这一点的一个简单的想法是简单地将全局静态卷积核与自适应注意矩阵相加，无论是在
Softmax 归一化之后还是之前，即 <span class="math display">\[
y_{i}^{\text {post }}=\sum_{j \in \mathcal{G}}\left(\frac{\exp
\left(x_{i}^{\top} x_{j}\right)}{\sum_{k \in \mathcal{G}} \exp
\left(x_{i}^{\top} x_{k}\right)}+w_{i-j}\right) x_{j} \text  { or }
y_{i}^{\text {pre }}=\sum_{j \in \mathcal{G}} \frac{\exp
\left(x_{i}^{\top} x_{j}+w_{i-j}\right)}{\sum_{k \in \mathcal{G}} \exp
\left(x_{i}^{\top} x_{k}+w_{i-k}\right)} x_{j} .\ \ \ (3)
\]</span> 有趣的是，虽然这个想法似乎过于简化，但预标准化版本 <span
class="math inline">\(y^{pre}\)</span>
对应的是相对自注意力的一个特定变体。在这种情况下，注意力权重 <span
class="math inline">\(A_{i,j}\)</span> 由平移等变性的 <span
class="math inline">\(w_{i-j}\)</span> 和输入自适应的 <span
class="math inline">\(x_{i}^{\top} x_{j}\)</span>
共同决定，根据它们的相对大小可以同时享受这两种效果。重要的是，注意到为了启用全局卷积核而不会造成参数爆炸，我们重新加载了
<span class="math inline">\(w_{i-j}\)</span> 的符号作为标量(即 <span
class="math inline">\(w \in \mathbb{R}^{O(|\mathcal{G}|)}\)</span>
)而不是Eqn(1)中的向量。<span class="math inline">\(w\)</span>
的标量形式的另一个优点是，对于所有的<span
class="math inline">\((i,j)\)</span>，检索 <span
class="math inline">\(w_{i-j}\)</span>
显然是通过计算成对点积注意力来包含的，从而产生最小的额外成本(见附录A.1)。考虑到好处，我们将使用Eqn(3)中带有预标准化相对注意力变量的Transformer块作为Co
At Net模型的关键组成部分。</p>
<h2 id="vertical-layout-design">Vertical Layout Design</h2>
<p>在找到了一种将卷积和注意力结合的好方法之后，我们接下来考虑如何利用它来堆叠整个网络。</p>
<p>正如我们在上面讨论的，全局上下文具有空间大小的二次复杂度。因此，如果直接套用Eqn(3)中的相对关注度，对于输入的原始图像，由于任意大小的图像中像素数量较多，计算会过于缓慢。因此，为了构建一个在实践中可行的网络，我们主要有三种选择：</p>
<ul>
<li><p><strong>A
执行一些下采样以减小空间大小，并在特征图达到可管理级别后使用全局相对注意力。</strong></p></li>
<li><p>B 加强局部注意力，将注意力中的全局感受野 <span
class="math inline">\(\mathcal{G}\)</span> 限制到一个局部领域 <span
class="math inline">\(\mathcal{L}\)</span> ，就像卷积中一样</p></li>
<li><p>C
将二次Softmax注意力替换为某些线性注意力变量，该变量仅具有空间大小的线性复杂度</p></li>
</ul>
<p>我们对选项( C )进行了简单的实验，但没有得到合理的结果。对于选项( B
)，我们发现实现本地注意力涉及许多需要密集内存访问的非平凡形状格式化操作。在我们的选择加速器(
TPU
)上，这样的操作被证明是极其缓慢的，这不仅挫败了加速全球注意力的最初目的，也伤害了模型的容量。因此，正如最近的一些工作研究了这个变体一样，<strong>我们将把重点放在选项(
A )上，并在我们的实证研究中比较我们的结果</strong>。</p>
<p>对于方案( A )，下采样可以通过( 1 )
ViT中具有激进步幅的卷积主干(例如,步幅16x16)或( 2
)卷积神经网络中具有渐进池化的多级网络来实现。通过这些选择，我们得到了5个变量的搜索空间，并在受控实验中进行了比较。</p>
<ul>
<li><p>当使用ViT Stem时，我们直接堆叠带有相对注意力的 <span
class="math inline">\(L\)</span> Transformer块，我们将其表示为 <span
class="math inline">\(ViT_{REL}\)</span>。</p></li>
<li><p>当使用多级布局时，我们模仿卷积神经网络来构建5级(
S0、S1、S2、S3和S4)的网络，空间分辨率从S0逐渐降低到S4。在每个阶段开始时，<strong>我们总是将空间大小减少2倍，并增加通道数</strong>(有关详细的下采样实现,请参见附录A.1)。</p>
<p>第一阶段S0是一个简单的2层卷积Stem，S1始终使用带有squeeze-excitation
(SE)操作和MBConv块，因为空间尺寸对于全局注意力来说太大了。从S2到S4，我们要么考虑MBConv，要么考虑Transformer块，约束卷积阶段必须出现在Transformer阶段之前。该约束基于这样的先验，<strong>即卷积在处理早期阶段更常见的局部模式方面更好</strong>。这导致了4种变体，其Transformer级数越来越多，C
- C - C - C、C - C - C - T、C - C - T - T和C - T - T -
T，其中C和T分别表示Convolution和Transformer。</p></li>
</ul>
<p>为了系统地研究设计选择，我们考虑两个基本方面的泛化能力和模型能力：对于泛化，我们感兴趣的是训练损失和评估精度之间的差距。如果两个模型具有相同的训练损失，那么具有较高评估精度的模型具有更好的泛化能力，因为它可以更好地泛化到看不见的评估数据集。当训练数据量有限时，泛化能力对数据效率尤为重要。对于模型容量，我们衡量了模型对大型训练数据集的拟合能力。当训练数据较为丰富且不存在过拟合问题时，容量较高的模型在经过合理的训练步骤后，最终更好的最终性能。值得注意的是，由于简单地增加模型大小可以导致更高的模型容量，为了进行有意义的比较，我们确保5个变体的模型大小具有可比性。</p>
<p>为了比较模型的泛化能力和模型容量，我们在ImageNet - 1K ( 1.3M )和JFT (
&gt; 300M
)数据集上分别训练了300和3个epoch的混合模型的不同变体，两者都没有任何正则化或增强。两个数据集上的训练损失和评估准确率总结如图1所示。</p>
<figure>
<img src="/img/cv/image-20221106164733104.png" srcset="/img/loading.gif" lazyload alt="图1" />
<figcaption aria-hidden="true">图1</figcaption>
</figure>
<ul>
<li>从ImageNet -
1K的结果中，一个关键的观察是，在泛化能力(即,培训和评价指标之间的差距)方面，我们有</li>
</ul>
<p><span class="math display">\[
\mathrm{C}-\mathrm{C}-\mathrm{C}-\mathrm{C} \approx
\mathrm{C}-\mathrm{C}-\mathrm{C}-\mathrm{T} \geq
\mathrm{C}-\mathrm{C}-\mathrm{T}-\mathrm{T}&gt;\mathrm{C}-\mathrm{T}-\mathrm{T}-\mathrm{T}
\gg \mathrm{VIT}_{\mathrm{REL}}
\]</span></p>
<p>特别是，<span
class="math inline">\(ViT_{REL}\)</span>比变种要差得多，我们猜想这与在其积极的下采样Stem中缺乏适当的低级信息处理有关。在多级变体中，总体趋势是模型的卷积级数越多，泛化差距越小。</p>
<ul>
<li>在模型能力方面，从JFT比较来看，训练结束时的训练指标和评价指标都显示出以下排序：</li>
</ul>
<p><span class="math display">\[
\mathrm{C}-\mathrm{C}-\mathrm{T}-\mathrm{T} \approx
\mathrm{C}-\mathrm{T}-\mathrm{T}-\mathrm{T}&gt;\mathrm{VIT}_{\mathrm{REL}}&gt;\mathrm{C}-\mathrm{C}-\mathrm{C}-\mathrm{T}&gt;\mathrm{C}-\mathrm{C}-\mathrm{C}-\mathrm{C}
\]</span></p>
<p>重要的是，<strong>这表明简单地拥有更多的Transformer块并不一定意味着更高的视觉处理能力</strong>。一方面，<span
class="math inline">\(ViT_{REL}\)</span>
在最初表现较差的情况下，最终赶上了MBConv级数较多的两个变体，体现了Transformer模块的容量优势。另一方面，C
- C - T - T和C - T - T - T的表现明显优于<span
class="math inline">\(ViT_{REL}\)</span> ，<strong>说明大步长的ViT
Stem可能丢失了过多的信息，从而限制了模型的容量</strong>。更有趣的是，C-C-T-T≈C-T-T-T表明，对于处理低级信息，像卷积这样的静态局部操作可以像自适应全局注意力机制一样有效，同时节省大量的计算和内存使用。</p>
<p>最后，为了决定C - C - T - T和C - T - T -
T之间的关系，我们进行了另一个可迁移性测试3 - -我们在ImageNet -
1K上对上述两个JFT预训练模型进行了30个epoch的微调，并比较了它们的迁移性能。从表2中可以看出，尽管预训练性能相同，C-C-T-T取得了明显优于C-T-T-T的传输精度。</p>
<p><img src="/img/cv/image-20221106164712746.png" srcset="/img/loading.gif" lazyload /></p>
<p>综合考虑模型的泛化性、模型容量、可移植性和效率等因素，<strong>我们采用C
- C - T - T的多级布局方式</strong>。附录A.1中包含了更多的模型细节。</p>
<p><img src="/img/cv/image-20221106165751331.png" srcset="/img/loading.gif" lazyload /></p>
<h1 id="附录">附录</h1>
<h2 id="a.1-模型细节">A.1 模型细节</h2>
<p>首先，CoAtNet概述如图所示</p>
<p><img src="/img/cv/image-20221106164949720.png" srcset="/img/loading.gif" lazyload /></p>
<p><img src="/img/cv/image-20221106165319538.png" srcset="/img/loading.gif" lazyload /></p>
<p><img src="/img/cv/image-20221106165448391.png" srcset="/img/loading.gif" lazyload /></p>
<p><img src="/img/cv/image-20221106165504183.png" srcset="/img/loading.gif" lazyload /></p>
<p><img src="/img/cv/image-20221106165537550.png" srcset="/img/loading.gif" lazyload /></p>
<p><img src="/img/cv/image-20221106165549351.png" srcset="/img/loading.gif" lazyload /></p>
<h2 id="a.2-超参数">A.2 超参数</h2>
<p><img src="/img/cv/image-20221106165643160.png" srcset="/img/loading.gif" lazyload /></p>
<h1 id="模型搭建">模型搭建</h1>
<h2 id="s0-stage">s0-stage</h2>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">conv_3x3_bn</span>(<span class="hljs-params">in_c, out_c, image_size, downsample=<span class="hljs-literal">False</span></span>):<br>	<span class="hljs-comment"># out_c = 64, imagesize = (112, 112)</span><br>    stride = <span class="hljs-number">2</span> <span class="hljs-keyword">if</span> downsample <span class="hljs-keyword">else</span> <span class="hljs-number">1</span><br>    layer = nn.Sequential(<br>        nn.Conv2d(in_c, out_c, <span class="hljs-number">3</span>, stride, <span class="hljs-number">1</span>, bias=<span class="hljs-literal">False</span>),<br>        nn.BatchNorm2d(out_c),<br>        nn.GELU()<br>    )<br>    <span class="hljs-keyword">return</span> layer<br></code></pre></div></td></tr></table></figure>
<h2 id="s1-mbconv">s1-MBConv</h2>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MBConv</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,</span><br><span class="hljs-params">                 in_c,</span><br><span class="hljs-params">                 out_c,</span><br><span class="hljs-params">                 image_size,</span><br><span class="hljs-params">                 downsample=<span class="hljs-literal">False</span>,</span><br><span class="hljs-params">                 expansion=<span class="hljs-number">4</span></span>):<br>        <span class="hljs-built_in">super</span>(MBConv, self).__init__()<br>        self.downsample = downsample<br>        stride = <span class="hljs-number">2</span> <span class="hljs-keyword">if</span> downsample <span class="hljs-keyword">else</span> <span class="hljs-number">1</span><br>        hidden_dim = <span class="hljs-built_in">int</span>(in_c * expansion)<br><br>        <span class="hljs-keyword">if</span> self.downsample:<br>            <span class="hljs-comment"># 只有第一层的时候，进行下采样</span><br>            <span class="hljs-comment"># self.pool = nn.MaxPool2d(kernel_size=2,stride=2)</span><br>            <span class="hljs-comment"># self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)</span><br>            <span class="hljs-comment"># self.proj = nn.Conv2d(in_c, out_c, 1, 1, 0, bias=False)</span><br><br>            self.downsample_layer = nn.Sequential(<br>                nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>),<br>                nn.Conv2d(in_c, out_c, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, bias=<span class="hljs-literal">False</span>)<br>            )<br><br>        layers = OrderedDict()<br>        <span class="hljs-comment"># expand</span><br>        expand_conv = nn.Sequential(<br>            nn.Conv2d(in_c, hidden_dim, <span class="hljs-number">1</span>, stride, <span class="hljs-number">0</span>, bias=<span class="hljs-literal">False</span>),<br>            nn.BatchNorm2d(hidden_dim),<br>            nn.GELU(),<br>        )<br>        layers.update(&#123;<span class="hljs-string">&quot;expand_conv&quot;</span>: expand_conv&#125;)<br><br>        <span class="hljs-comment"># Depwise Conv</span><br>        dw_conv = nn.Sequential(<br>            nn.Conv2d(hidden_dim, hidden_dim, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, groups=hidden_dim, bias=<span class="hljs-literal">False</span>),<br>            nn.BatchNorm2d(hidden_dim),<br>            nn.GELU(),<br>        )<br>        layers.update(&#123;<span class="hljs-string">&quot;dw_conv&quot;</span>: dw_conv&#125;)<br><br>        <span class="hljs-comment"># se</span><br>        layers.update(&#123;<span class="hljs-string">&quot;se&quot;</span>: SE(in_c, hidden_dim)&#125;)<br><br>        <span class="hljs-comment"># project</span><br>        pro_conv = nn.Sequential(<br>            nn.Conv2d(hidden_dim, out_c, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, bias=<span class="hljs-literal">False</span>),<br>            nn.BatchNorm2d(out_c)<br>        )<br>        layers.update(&#123;<span class="hljs-string">&quot;pro_conv&quot;</span>: pro_conv&#125;)<br>        self.block = nn.Sequential(layers)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">if</span> self.downsample:<br>            <span class="hljs-keyword">return</span> self.downsample_layer(x) + self.block(x)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">return</span> x + self.block(x)<br></code></pre></div></td></tr></table></figure>
<p>其中，Se模块代码为</p>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">SE</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, in_c, out_c, expansion=<span class="hljs-number">0.25</span></span>):<br>        <span class="hljs-built_in">super</span>(SE, self).__init__()<br>        self.avg_pool = nn.AdaptiveAvgPool2d(<span class="hljs-number">1</span>)<br>        self.fc = nn.Sequential(<br>            nn.Linear(out_c, <span class="hljs-built_in">int</span>(in_c * expansion), bias=<span class="hljs-literal">False</span>),<br>            nn.GELU(),<br>            nn.Linear(<span class="hljs-built_in">int</span>(in_c * expansion), out_c, bias=<span class="hljs-literal">False</span>),<br>            nn.Sigmoid()<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        b, c, _, _ = x.size()<br>        y = self.avg_pool(x).view(b, c)<br>        y = self.fc(y).view(b, c, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>)<br>        <span class="hljs-keyword">return</span> x * y<br></code></pre></div></td></tr></table></figure>
<h2 id="s3-tfm_rel">s3-TFM_rel</h2>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Transformer</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,</span><br><span class="hljs-params">                 in_c,</span><br><span class="hljs-params">                 out_c,</span><br><span class="hljs-params">                 image_size,</span><br><span class="hljs-params">                 heads=<span class="hljs-number">8</span>,</span><br><span class="hljs-params">                 dim_head=<span class="hljs-number">32</span>,</span><br><span class="hljs-params">                 downsample=<span class="hljs-literal">False</span>,</span><br><span class="hljs-params">                 dropout=<span class="hljs-number">0.</span>,</span><br><span class="hljs-params">                 expansion=<span class="hljs-number">4</span>,</span><br><span class="hljs-params">                 norm_layer=nn.LayerNorm</span>):<br>        <span class="hljs-built_in">super</span>(Transformer, self).__init__()<br>        self.downsample = downsample<br>        hidden_dim = <span class="hljs-built_in">int</span>(in_c * expansion)<br>        self.ih, self.iw = image_size<br><br>        <span class="hljs-keyword">if</span> self.downsample:<br>            <span class="hljs-comment"># 第一层进行下采样</span><br>            self.pool1 = nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>)<br>            self.pool2 = nn.MaxPool2d(kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">2</span>, padding=<span class="hljs-number">1</span>)<br>            self.proj = nn.Conv2d(in_c, out_c, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, bias=<span class="hljs-literal">False</span>)<br><br>        self.attn = Attention(in_c, out_c, image_size, heads, dim_head, dropout)<br>        self.ffn = FFN(out_c, hidden_dim)<br>        self.norm1 = norm_layer(in_c)<br>        self.norm2 = norm_layer(out_c)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x1 = self.pool1(x) <span class="hljs-keyword">if</span> self.downsample <span class="hljs-keyword">else</span> x<br>        x1 = rearrange(x1, <span class="hljs-string">&#x27;b c h w -&gt; b (h w) c&#x27;</span>)<br>        x1 = self.attn(self.norm1(x1))<br>        x1 = rearrange(x1, <span class="hljs-string">&#x27;b (h w) c -&gt; b c h w&#x27;</span>, h=self.ih, w=self.iw)<br>        x2 = self.proj((self.pool2(x))) <span class="hljs-keyword">if</span> self.downsample <span class="hljs-keyword">else</span> x<br><br>        x3 = x1 + x2<br>        x4 = rearrange(x3, <span class="hljs-string">&#x27;b c h w -&gt; b (h w) c&#x27;</span>)<br>        x4 = self.ffn(self.norm2(x4))<br>        x4 = rearrange(x4, <span class="hljs-string">&#x27;b (h w) c -&gt; b c h w&#x27;</span>, h=self.ih, w=self.iw)<br>        out = x3 + x4<br>        <span class="hljs-keyword">return</span> out<br></code></pre></div></td></tr></table></figure>
<h2 id="attention相对位置编码">attention(相对位置编码)</h2>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Attention</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,</span><br><span class="hljs-params">                 in_c,</span><br><span class="hljs-params">                 out_c,</span><br><span class="hljs-params">                 image_size,</span><br><span class="hljs-params">                 heads=<span class="hljs-number">8</span>,</span><br><span class="hljs-params">                 dim_head=<span class="hljs-number">32</span>,</span><br><span class="hljs-params">                 dropout=<span class="hljs-number">0.</span></span>):<br>        <span class="hljs-built_in">super</span>(Attention, self).__init__()<br>        inner_dim = dim_head * heads<br>        project_out = <span class="hljs-keyword">not</span> (heads == <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> dim_head == in_c)<br><br>        self.ih, self.iw = image_size <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(image_size) == <span class="hljs-number">2</span> <span class="hljs-keyword">else</span> (image_size, image_size)<br><br>        self.heads = heads<br>        self.scale = dim_head ** -<span class="hljs-number">0.5</span><br><br>        <span class="hljs-comment"># parameter table of relative position bias</span><br>        self.relative_bias_table = nn.Parameter(<br>            torch.zeros((<span class="hljs-number">2</span> * self.ih - <span class="hljs-number">1</span>) * (<span class="hljs-number">2</span> * self.iw - <span class="hljs-number">1</span>), heads)<br>        )<br><br>        coords = torch.meshgrid((torch.arange(self.ih), torch.arange(self.iw)))<br>        coords = torch.flatten(torch.stack(coords), <span class="hljs-number">1</span>)<br>        relative_coords = coords[:, :, <span class="hljs-literal">None</span>] - coords[:, <span class="hljs-literal">None</span>, :]<br><br>        relative_coords[<span class="hljs-number">0</span>] += self.ih - <span class="hljs-number">1</span><br>        relative_coords[<span class="hljs-number">1</span>] += self.iw - <span class="hljs-number">1</span><br>        relative_coords[<span class="hljs-number">0</span>] *= <span class="hljs-number">2</span> * self.iw - <span class="hljs-number">1</span><br>        relative_coords = rearrange(relative_coords, <span class="hljs-string">&#x27;c h w -&gt; h w c&#x27;</span>)<br>        relative_index = relative_coords.<span class="hljs-built_in">sum</span>(-<span class="hljs-number">1</span>).flatten().unsqueeze(<span class="hljs-number">1</span>)<br><br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        PyTorch中定义模型时，self.register_buffer(&#x27;name&#x27;, Tensor)，</span><br><span class="hljs-string">        该方法的作用是定义一组参数，该组参数的特别之处在于：</span><br><span class="hljs-string">        模型训练时不会更新（即调用 optimizer.step() 后该组参数不会变化，只可人为地改变它们的值），</span><br><span class="hljs-string">        但是保存模型时，该组参数又作为模型参数不可或缺的一部分被保存。</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        self.register_buffer(<span class="hljs-string">&quot;relative_index&quot;</span>, relative_index)<br><br>        self.attend = nn.Softmax(dim=-<span class="hljs-number">1</span>)<br>        self.qkv = nn.Linear(in_c, inner_dim * <span class="hljs-number">3</span>, bias=<span class="hljs-literal">False</span>)<br>        self.proj = nn.Sequential(<br>            nn.Linear(inner_dim, out_c),<br>            nn.Dropout(dropout)<br>        ) <span class="hljs-keyword">if</span> project_out <span class="hljs-keyword">else</span> nn.Identity()<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># [q,k,v]</span><br>        qkv = self.qkv(x).chunk(<span class="hljs-number">3</span>, dim=-<span class="hljs-number">1</span>)<br>        <span class="hljs-comment"># q,k,v:[batch_size, num_heads, num_patches, head_dim]</span><br>        q, k, v = <span class="hljs-built_in">map</span>(<span class="hljs-keyword">lambda</span> t: rearrange(<br>            t, <span class="hljs-string">&#x27;b n (h d) -&gt; b h n d&#x27;</span>, h=self.heads), qkv)<br><br>        <span class="hljs-comment"># [batch_size, num_heads, ih*iw, ih*iw]</span><br>        <span class="hljs-comment"># 时间复杂度：O(图片边长的平方)</span><br>        dots = torch.matmul(q, k.transpose(-<span class="hljs-number">1</span>, -<span class="hljs-number">2</span>)) * self.scale<br><br>        <span class="hljs-comment"># Use &quot;gather&quot; for more efficiency on GPUs</span><br>        relative_bias = self.relative_bias_table.gather(<br>            <span class="hljs-number">0</span>, self.relative_index.repeat(<span class="hljs-number">1</span>, self.heads)<br>        )<br>        relative_bias = rearrange(<br>            relative_bias, <span class="hljs-string">&#x27;(h w) c -&gt; 1 c h w&#x27;</span>, h=self.ih * self.iw, w=self.ih * self.iw<br>        )<br>        dots = dots + relative_bias<br><br>        attn = self.attend(dots)<br>        out = torch.matmul(attn, v)<br>        out = rearrange(out, <span class="hljs-string">&#x27;b h n d -&gt; b n (h d)&#x27;</span>)<br>        out = self.proj(out)<br>        <span class="hljs-keyword">return</span> out<br></code></pre></div></td></tr></table></figure>
<h2 id="ffnmlp">FFN（MLP）</h2>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">FFN</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, dim, hidden_dim, dropout=<span class="hljs-number">0.</span></span>):<br>        <span class="hljs-built_in">super</span>(FFN, self).__init__()<br>        self.ffn = nn.Sequential(<br>            nn.Linear(dim, hidden_dim),<br>            nn.GELU(),<br>            nn.Dropout(dropout),<br>            nn.Linear(hidden_dim, dim),<br>            nn.Dropout(dropout)<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">return</span> self.ffn(x)<br></code></pre></div></td></tr></table></figure>
<h2 id="coatnet">CoAtNet</h2>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">CoAtNet</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,</span><br><span class="hljs-params">                 image_size=(<span class="hljs-params"><span class="hljs-number">224</span>, <span class="hljs-number">224</span></span>),</span><br><span class="hljs-params">                 in_channels: <span class="hljs-built_in">int</span> = <span class="hljs-number">3</span>,</span><br><span class="hljs-params">                 num_blocks: <span class="hljs-built_in">list</span> = [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5</span>, <span class="hljs-number">2</span>],  <span class="hljs-comment"># L</span></span><br><span class="hljs-params">                 channels: <span class="hljs-built_in">list</span> = [<span class="hljs-number">64</span>, <span class="hljs-number">96</span>, <span class="hljs-number">192</span>, <span class="hljs-number">384</span>, <span class="hljs-number">768</span>],  <span class="hljs-comment"># D</span></span><br><span class="hljs-params">                 num_classes: <span class="hljs-built_in">int</span> = <span class="hljs-number">1000</span>,</span><br><span class="hljs-params">                 block_types=[<span class="hljs-string">&#x27;C&#x27;</span>, <span class="hljs-string">&#x27;C&#x27;</span>, <span class="hljs-string">&#x27;T&#x27;</span>, <span class="hljs-string">&#x27;T&#x27;</span>]</span>):<br>        <span class="hljs-built_in">super</span>(CoAtNet, self).__init__()<br><br>        <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(image_size) == <span class="hljs-number">2</span>, <span class="hljs-string">&quot;image size must be: &#123;H,W&#125;&quot;</span><br>        <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(channels) == <span class="hljs-number">5</span><br>        <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(block_types) == <span class="hljs-number">4</span><br><br>        ih, iw = image_size<br>        block = &#123;<span class="hljs-string">&#x27;C&#x27;</span>: MBConv, <span class="hljs-string">&#x27;T&#x27;</span>: Transformer&#125;<br><br>        self.s0 = self._make_layer(<br>            conv_3x3_bn, in_channels, channels[<span class="hljs-number">0</span>], num_blocks[<span class="hljs-number">0</span>], (ih // <span class="hljs-number">2</span>, iw // <span class="hljs-number">2</span>)<br>        )<br>        self.s1 = self._make_layer(<br>            block[block_types[<span class="hljs-number">0</span>]], channels[<span class="hljs-number">0</span>], channels[<span class="hljs-number">1</span>], num_blocks[<span class="hljs-number">1</span>], (ih // <span class="hljs-number">4</span>, iw // <span class="hljs-number">4</span>)<br>        )<br>        self.s2 = self._make_layer(<br>            block[block_types[<span class="hljs-number">1</span>]], channels[<span class="hljs-number">1</span>], channels[<span class="hljs-number">2</span>], num_blocks[<span class="hljs-number">2</span>], (ih // <span class="hljs-number">8</span>, iw // <span class="hljs-number">8</span>)<br>        )<br>        self.s3 = self._make_layer(<br>            block[block_types[<span class="hljs-number">2</span>]], channels[<span class="hljs-number">2</span>], channels[<span class="hljs-number">3</span>], num_blocks[<span class="hljs-number">3</span>], (ih // <span class="hljs-number">16</span>, iw // <span class="hljs-number">16</span>)<br>        )<br>        self.s4 = self._make_layer(<br>            block[block_types[<span class="hljs-number">3</span>]], channels[<span class="hljs-number">3</span>], channels[<span class="hljs-number">4</span>], num_blocks[<span class="hljs-number">4</span>], (ih // <span class="hljs-number">32</span>, iw // <span class="hljs-number">32</span>)<br>        )<br><br>        <span class="hljs-comment"># 总共下采样32倍 2^5=32</span><br>        self.pool = nn.AvgPool2d(ih // <span class="hljs-number">32</span>, <span class="hljs-number">1</span>)<br>        self.fc = nn.Linear(channels[-<span class="hljs-number">1</span>], num_classes, bias=<span class="hljs-literal">False</span>)<br><br>        <span class="hljs-keyword">for</span> m <span class="hljs-keyword">in</span> self.modules():<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(m, nn.Conv2d):<br>                nn.init.kaiming_normal_(m.weight, mode=<span class="hljs-string">&#x27;fan_out&#x27;</span>, nonlinearity=<span class="hljs-string">&#x27;relu&#x27;</span>)<br>            <span class="hljs-keyword">elif</span> <span class="hljs-built_in">isinstance</span>(m, (nn.BatchNorm2d, nn.GroupNorm, nn.LayerNorm)):<br>                nn.init.constant_(m.weight, <span class="hljs-number">1</span>)<br>                nn.init.constant_(m.bias, <span class="hljs-number">0</span>)<br><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = self.s0(x)<br>        x = self.s1(x)<br>        x = self.s2(x)<br>        x = self.s3(x)<br>        x = self.s4(x)<br><br>        x = self.pool(x)<br>        x = torch.flatten(x, <span class="hljs-number">1</span>)<br>        x = self.fc(x)<br>        <span class="hljs-keyword">return</span> x<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_make_layer</span>(<span class="hljs-params">self, block, in_c, out_c, depth, image_size</span>):<br>        layers = nn.ModuleList([])<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(depth):<br>            <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span>:<br>                layers.append(block(in_c, out_c, image_size, downsample=<span class="hljs-literal">True</span>))<br>            <span class="hljs-keyword">else</span>:<br>                layers.append(block(out_c, out_c, image_size, downsample=<span class="hljs-literal">False</span>))<br>        <span class="hljs-keyword">return</span> nn.Sequential(*layers)<br></code></pre></div></td></tr></table></figure>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/Deep-Learning/">Deep Learning</a>
                    
                      <a class="hover-with-bg" href="/categories/Deep-Learning/cv/">cv</a>
                    
                  </div>
                
                
              </div>
              
                <p class="note note-warning">
                  
                    本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2022/11/07/Mlp-mixer/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Mlp-mixer</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/11/05/Masked-Autoencoder-MAE/">
                        <span class="hidden-mobile">Masked_Autoencoder(MAE)</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
              <!-- Comments -->
              <article class="comments" id="comments" lazyload>
                
                  
                
                

              </article>
            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  

  

  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  <script  src="/js/local-search.js" ></script>



  
    <script  src="/js/img-lazyload.js" ></script>
  



  



  
    <script  src="https://cdn.jsdelivr.net/npm/tocbot@4/dist/tocbot.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4/anchor.min.js" ></script>
  
  
    <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js" ></script>
  






  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
        typing(title);
      
    })(window, document);
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        loader: {
          load: ['ui/lazy']
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js" ></script>

  











<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>


</body>
</html>
