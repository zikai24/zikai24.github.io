

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=dark>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" href="/img/favicon.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="肘子开">
  <meta name="keywords" content="">
  
    <meta name="description" content="Assignment4讲解 RNN和神经网络机器翻译 机器翻译是指，构建一个系统完成源语言到目标语言的变换映射，比如给定一个源句子（比如西班牙语），输出一个目标句子（比如英语）。本次作业中要实现的是一个带注意力机制的Seq2Seq神经模型，用于构建神经网络机器翻译（NMT）系统。首先我们来看NMT系统的训练过程，它用到了双向LSTM作为编码器（encoder）和单向LSTM作为解码器（deco">
<meta property="og:type" content="article">
<meta property="og:title" content="NLP-Assignment4">
<meta property="og:url" content="http://example.com/2022/05/15/NLP-Assignment4/index.html">
<meta property="og:site_name" content="肘子开的博客">
<meta property="og:description" content="Assignment4讲解 RNN和神经网络机器翻译 机器翻译是指，构建一个系统完成源语言到目标语言的变换映射，比如给定一个源句子（比如西班牙语），输出一个目标句子（比如英语）。本次作业中要实现的是一个带注意力机制的Seq2Seq神经模型，用于构建神经网络机器翻译（NMT）系统。首先我们来看NMT系统的训练过程，它用到了双向LSTM作为编码器（encoder）和单向LSTM作为解码器（deco">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/0060yMmAly1gsjzdzvwbaj30pv0hzjuy.jpg">
<meta property="article:published_time" content="2022-05-15T12:31:26.000Z">
<meta property="article:modified_time" content="2022-05-18T11:50:09.770Z">
<meta property="article:author" content="肘子开">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://ww1.sinaimg.cn/large/0060yMmAly1gsjzdzvwbaj30pv0hzjuy.jpg">
  
  
  <title>NLP-Assignment4 - 肘子开的博客</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4/github-markdown.min.css" />
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hint.css@2/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10/styles/nnfx-dark.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.css" />
  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.8.14","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 6.1.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>肘子开的博客</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/img/bg/bg2.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="NLP-Assignment4">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2022-05-15 20:31" pubdate>
        2022年5月15日 晚上
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      24k 字
    </span>
  

  
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      205 分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">NLP-Assignment4</h1>
            
            <div class="markdown-body">
              <h1 id="assignment4讲解">Assignment4讲解</h1>
<h2 id="rnn和神经网络机器翻译">RNN和神经网络机器翻译</h2>
<p>机器翻译是指，构建一个系统完成源语言到目标语言的变换映射，比如给定一个源句子（比如西班牙语），输出一个目标句子（比如英语）。本次作业中要实现的是一个带注意力机制的Seq2Seq神经模型，用于构建神经网络机器翻译（NMT）系统。首先我们来看NMT系统的训练过程，它用到了双向LSTM作为编码器（encoder）和单向LSTM作为解码器（decoder）。</p>
<p><img src="http://ww1.sinaimg.cn/large/0060yMmAly1gsjzdzvwbaj30pv0hzjuy.jpg" srcset="/img/loading.gif" lazyload referrerpolicy="no-referrer"/></p>
<p>给定长度为m的源语言句子（source），经过嵌入层，得到输入序列 <span
class="math inline">\(x_1, x_2, …, x_m \in R^{e \times
1}\)</span>，<span
class="math inline">\(e\)</span>是词向量大小。经过双向Encoder后，得到前向（→）和反向（←）LSTM的隐藏层和神经元状态，将两个方向的状态连接起来得到时间步
<span class="math inline">\(i\)</span> 的隐藏状态 <span
class="math inline">\(h_i^{enc}\)</span> 和 <span
class="math inline">\(c_i^{enc}\)</span> ： <span
class="math display">\[
\mathbf{h}_{i}^{\text {enc }}=\left[\overleftarrow{\mathbf{h}_{i}^{\text
{enc }}} ; \overrightarrow{\mathbf{h}_{i}^{\text {enc }}}\right] \text {
where } \mathbf{h}_{i}^{\text {enc }} \in \mathbb{R}^{2 h \times 1},
\overleftarrow{\mathbf{h}_{i}^{\text {enc }}},
\overrightarrow{\mathbf{h}_{i}^{\text {en }}} \in \mathbb{R}^{h \times
1} \quad 1 \leq i \leq m
\]</span></p>
<p><span class="math display">\[
\mathbf{c}_{i}^{\text {enc }}=\left[\overleftarrow{\mathbf{c}_{i}^{\text
{enc }}} ; \overrightarrow{\mathbf{c}_{i}^{\text {enc }}}\right] \text {
where } \mathbf{c}_{i}^{\text {enc }} \in \mathbb{R}^{2 h \times 1},
\overleftarrow{\mathbf{c}_{i}^{\text {enc }}},
\overrightarrow{\mathbf{c}_{i}^{\text {en }}} \in \mathbb{R}^{h \times
1} \quad 1 \leq i \leq m
\]</span></p>
<p>接着我们使用一个线性层来初始化Decoder的初始隐藏、神经元的状态： <span
class="math display">\[
\mathbf{h}_{0}^{\text {dec
}}=\mathbf{W}_{h}\left[\overleftarrow{\mathbf{h}_{1}^{\text {enc }}} ;
\overrightarrow{\mathbf{h}_{m}^{\text {enc }}}\right] \text { where }
\mathbf{h}_{0}^{\text {dec }} \in \mathbb{R}^{h \times 1},
\mathbf{W}_{h} \in \mathbb{R}^{h \times 2 h}
\]</span></p>
<p><span class="math display">\[
\mathbf{c}_{0}^{\text {dec
}}=\mathbf{W}_{c}\left[\overleftarrow{\mathbf{c}_{1}^{\text {enc }}} ;
\overrightarrow{\mathbf{c}_{m}^{\text {enc }}}\right] \text { where }
\mathbf{c}_{0}^{\text {dec }} \in \mathbb{R}^{h \times 1},
\mathbf{W}_{c} \in \mathbb{R}^{h \times 2 h}
\]</span></p>
<p>Decoder的时间步<span class="math inline">\(t\)</span> 的输入为 <span
class="math inline">\(\bar{y}_t\)</span> ，它由目标语言句子 <span
class="math inline">\(y_t\)</span>和上一神经元的输出和上一神经元的输出<span
class="math inline">\(o_{t-1}\)</span>经过连接得到，经过连接得到，<span
class="math inline">\(o_0\)</span>是0向量，所以 <span
class="math inline">\(\bar{y}_t \in R^{(e + h) \times 1}\)</span> <span
class="math display">\[
\mathbf{h}_{t}^{\mathrm{dec}},
\mathbf{c}_{t}^{\mathrm{dec}}=\operatorname{Decoder}\left(\overline{\mathbf{y}_{t}},
\mathbf{h}_{t-1}^{\mathrm{dec}}, \mathbf{c}_{t-1}^{\mathrm{dec}}\right)
\text { where } \mathbf{h}_{t}^{\mathrm{dec}} \in \mathbb{R}^{h \times
1}, \mathbf{c}_{t}^{\mathrm{dec}} \in \mathbb{R}^{h \times 1}
\]</span> 接着我们使用 <span class="math inline">\(h^{dec}_t\)</span>
来计算在 <span class="math inline">\(h^{enc}_0, h^{enc}_1, …,
h^{enc}_m\)</span> 的乘积注意力（multiplicative attention）： <span
class="math display">\[
\begin{array}{c}
\mathbf{e}_{t, i}=\left(\mathbf{h}_{t}^{\mathrm{dec}}\right)^{T}
\mathbf{W}_{\text {attProj }} \mathbf{h}_{i}^{\text {enc }} \text {
where } \mathbf{e}_{t} \in \mathbb{R}^{m \times 1}, \mathbf{W}_{\text
{attProj }} \in \mathbb{R}^{h \times 2 h} \quad 1 \leq i \leq m \\
\alpha_{t}=\operatorname{softmax}\left(\mathbf{e}_{t}\right) \text {
where } \alpha_{t} \in \mathbb{R}^{m \times 1} \\
\mathbf{a}_{t}=\sum_{i=1}^{m} \alpha_{t, i} \mathbf{h}_{i}^{\text {enc
}} \text { where } \mathbf{a}_{t} \in \mathbb{R}^{2 h \times 1}
\end{array}
\]</span> 然后将注意力 <span class="math inline">\(a_t\)</span>
和解码器的隐藏状态 <span class="math inline">\(h^{dec}_t\)</span>
连接，送入线性层，得到 <em>combined-output</em> 向量 <span
class="math inline">\(o_t\)</span> <span class="math display">\[
\begin{array}{r}
\mathbf{u}_{t}=\left[\mathbf{a}_{t} ;
\mathbf{h}_{t}^{\mathrm{dec}}\right] \text { where } \mathbf{u}_{t} \in
\mathbb{R}^{3 h \times 1} \\
\mathbf{v}_{t}=\mathbf{W}_{u} \mathbf{u}_{t} \text { where }
\mathbf{v}_{t} \in \mathbb{R}^{h \times 1}, \mathbf{W}_{u} \in
\mathbb{R}^{h \times 3 h} \\
\mathbf{o}_{t}=\operatorname{Dropout}\left(\tanh
\left(\mathbf{v}_{t}\right)\right) \text { where } \mathbf{o}_{t} \in
\mathbb{R}^{h \times 1}
\end{array}
\]</span> 这样以来，目标词的概率分布则为： <span class="math display">\[
\mathbf{P}_{t}=\operatorname{softmax}\left(\mathbf{W}_{\text {vocab }}
\mathbf{o}_{t}\right) \text { where } \mathbf{P}_{t} \in
\mathbb{R}^{V_{t} \times 1}, \mathbf{W}_{\text {vocab }} \in
\mathbb{R}^{V_{t} \times h}
\]</span> 使用交叉熵做目标函数即可 <span class="math display">\[
J_{t}(\theta)=\text { CrossEntropy }\left(\mathbf{P}_{t},
\mathbf{g}_{t}\right)
\]</span></p>
<p>代码实现部分，关键在于过程中的向量维度，向量维度匹配没有问题，整个过程的实现就比较清晰。</p>
<h2 id="part1-神经网络翻译系统代码实现">part1
神经网络翻译系统代码实现</h2>
<h3 id="a-pad_sents">(a) pad_sents</h3>
<p>In order to apply tensor operations, we must ensure that the
sentences in a given batch are of the same length. Thus, we must
identify the longest sentence in a batch and pad others to be the same
length. Implement the pad sents function in utils.py, which shall
produce these padded sentences.</p>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">pad_sents</span>(<span class="hljs-params">sents, pad_token</span>):<br>    <span class="hljs-string">&quot;&quot;&quot; Pad list of sentences according to the longest sentence in the batch.</span><br><span class="hljs-string">    @param sents (list[list[str]]): list of sentences, where each sentence</span><br><span class="hljs-string">                                    is represented as a list of words</span><br><span class="hljs-string">    @param pad_token (str): padding token</span><br><span class="hljs-string">    @returns sents_padded (list[list[str]]): list of sentences where sentences shorter</span><br><span class="hljs-string">        than the max length sentence are padded out with the pad_token, such that</span><br><span class="hljs-string">        each sentences in the batch now has equal length.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    sents_padded = []<br><br>    <span class="hljs-comment"># YOUR CODE HERE (~6 Lines)</span><br>    corpus_size = <span class="hljs-built_in">len</span>(sents)<br>    lens = [<span class="hljs-built_in">len</span>(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> sents]  <span class="hljs-comment"># every sentence&#x27;s length</span><br>    max_lens = <span class="hljs-built_in">max</span>(lens)<br>    sents_padded = [sents[i] + [pad_token] * (max_lens - lens[i]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(corpus_size)]      <span class="hljs-comment"># shape N x max_lens</span><br>    <span class="hljs-comment"># END YOUR CODE</span><br><br>    <span class="hljs-keyword">return</span> sents_padded<br></code></pre></div></td></tr></table></figure>
<h3 id="b-modelembeddings">(b) ModelEmbeddings</h3>
<p>Implement the <code>__init__</code> function in model embeddings.py
to initialize the necessary source and target embeddings.</p>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ModelEmbeddings</span>(nn.Module): <br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    Class that converts input words to their embeddings.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, embed_size, vocab</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">        Init the Embedding layers.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        @param embed_size (int): Embedding size (dimensionality)</span><br><span class="hljs-string">        @param vocab (Vocab): Vocabulary object containing src and tgt languages</span><br><span class="hljs-string">                              See vocab.py for documentation.</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>(ModelEmbeddings, self).__init__()<br>        self.embed_size = embed_size<br><br>        <span class="hljs-comment"># default values</span><br>        self.source = <span class="hljs-literal">None</span><br>        self.target = <span class="hljs-literal">None</span><br><br>        src_pad_token_idx = vocab.src[<span class="hljs-string">&#x27;&lt;pad&gt;&#x27;</span>]<br>        tgt_pad_token_idx = vocab.tgt[<span class="hljs-string">&#x27;&lt;pad&gt;&#x27;</span>]<br><br>        <span class="hljs-comment"># YOUR CODE HERE (~2 Lines)</span><br>        <span class="hljs-comment"># TODO - Initialize the following variables:</span><br>        <span class="hljs-comment">#     self.source (Embedding Layer for source language)</span><br>        <span class="hljs-comment">#     self.target (Embedding Layer for target langauge)</span><br>        <span class="hljs-comment">#</span><br>        <span class="hljs-comment"># Note:</span><br>        <span class="hljs-comment">#     1. `vocab` object contains two vocabularies:</span><br>        <span class="hljs-comment">#            `vocab.src` for source</span><br>        <span class="hljs-comment">#            `vocab.tgt` for target</span><br>        <span class="hljs-comment">#     2. You can get the length of a specific vocabulary by running:</span><br>        <span class="hljs-comment">#             `len(vocab.&lt;specific_vocabulary&gt;)`</span><br>        <span class="hljs-comment">#     3. Remember to include the padding token for the specific vocabulary</span><br>        <span class="hljs-comment">#        when creating your Embedding.</span><br>        <span class="hljs-comment">#</span><br>        <span class="hljs-comment"># Use the following docs to properly initialize these variables:</span><br>        <span class="hljs-comment">#     Embedding Layer:</span><br>        <span class="hljs-comment">#         https://pytorch.org/docs/stable/nn.html#torch.nn.Embedding</span><br><br>        self.source = nn.Embedding(<span class="hljs-built_in">len</span>(vocab.src), embed_size, padding_idx=src_pad_token_idx)<br>        self.target = nn.Embedding(<span class="hljs-built_in">len</span>(vocab.tgt), embed_size, padding_idx=tgt_pad_token_idx)<br><br>        <span class="hljs-comment"># END YOUR CODE</span><br></code></pre></div></td></tr></table></figure>
<h3 id="c-nmt">(c) NMT</h3>
<p>Implement the <code>__init__</code> function in nmt model.py to
initialize the necessary model embeddings (using the ModelEmbeddings
class from model embeddings.py) and layers (LSTM, projection, and
dropout) for the NMT system</p>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">NMT</span>(nn.Module):<br>    <span class="hljs-string">&quot;&quot;&quot; Simple Neural Machine Translation Model:</span><br><span class="hljs-string">        - Bidrectional LSTM Encoder</span><br><span class="hljs-string">        - Unidirection LSTM Decoder</span><br><span class="hljs-string">        - Global Attention Model (Luong, et al. 2015)</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, embed_size, hidden_size, vocab, dropout_rate=<span class="hljs-number">0.2</span></span>):<br>        <span class="hljs-string">&quot;&quot;&quot; Init NMT Model.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        @param embed_size (int): Embedding size (dimensionality)</span><br><span class="hljs-string">        @param hidden_size (int): Hidden Size (dimensionality)</span><br><span class="hljs-string">        @param vocab (Vocab): Vocabulary object containing src and tgt languages</span><br><span class="hljs-string">                              See vocab.py for documentation.</span><br><span class="hljs-string">        @param dropout_rate (float): Dropout probability, for attention</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-built_in">super</span>(NMT, self).__init__()<br>        self.model_embeddings = ModelEmbeddings(embed_size, vocab)<br>        self.hidden_size = hidden_size<br>        self.dropout_rate = dropout_rate<br>        self.vocab = vocab<br><br>        <span class="hljs-comment"># default values</span><br>        self.encoder = <span class="hljs-literal">None</span> <br>        self.decoder = <span class="hljs-literal">None</span><br>        self.h_projection = <span class="hljs-literal">None</span><br>        self.c_projection = <span class="hljs-literal">None</span><br>        self.att_projection = <span class="hljs-literal">None</span><br>        self.combined_output_projection = <span class="hljs-literal">None</span><br>        self.target_vocab_projection = <span class="hljs-literal">None</span><br>        self.dropout = <span class="hljs-literal">None</span><br><br>        <span class="hljs-comment"># YOUR CODE HERE (~8 Lines)</span><br>        <span class="hljs-comment"># TODO - Initialize the following variables:</span><br>        <span class="hljs-comment">#     self.encoder (Bidirectional LSTM with bias)</span><br>        <span class="hljs-comment">#     self.decoder (LSTM Cell with bias)</span><br>        <span class="hljs-comment">#     self.h_projection (Linear Layer with no bias), called W_&#123;h&#125; in the PDF.</span><br>        <span class="hljs-comment">#     self.c_projection (Linear Layer with no bias), called W_&#123;c&#125; in the PDF.</span><br>        <span class="hljs-comment">#     self.att_projection (Linear Layer with no bias), called W_&#123;attProj&#125; in the PDF.</span><br>        <span class="hljs-comment">#     self.combined_output_projection (Linear Layer with no bias), called W_&#123;u&#125; in the PDF.</span><br>        <span class="hljs-comment">#     self.target_vocab_projection (Linear Layer with no bias), called W_&#123;vocab&#125; in the PDF.</span><br>        <span class="hljs-comment">#     self.dropout (Dropout Layer)</span><br>        <span class="hljs-comment">#</span><br>        <span class="hljs-comment"># Use the following docs to properly initialize these variables:</span><br>        <span class="hljs-comment">#     LSTM:</span><br>        <span class="hljs-comment">#         https://pytorch.org/docs/stable/nn.html#torch.nn.LSTM</span><br>        <span class="hljs-comment">#     LSTM Cell:</span><br>        <span class="hljs-comment">#         https://pytorch.org/docs/stable/nn.html#torch.nn.LSTMCell</span><br>        <span class="hljs-comment">#     Linear Layer:</span><br>        <span class="hljs-comment">#         https://pytorch.org/docs/stable/nn.html#torch.nn.Linear</span><br>        <span class="hljs-comment">#     Dropout Layer:</span><br>        <span class="hljs-comment">#         https://pytorch.org/docs/stable/nn.html#torch.nn.Dropout</span><br><br>        self.encoder = nn.LSTM(embed_size, hidden_size, bias=<span class="hljs-literal">True</span>, bidirectional=<span class="hljs-literal">True</span>)<br>        self.decoder = nn.LSTMCell(embed_size + hidden_size, hidden_size, bias=<span class="hljs-literal">True</span>)<br>        self.h_projection = nn.Linear(hidden_size * <span class="hljs-number">2</span>, hidden_size, bias=<span class="hljs-literal">False</span>) <span class="hljs-comment"># prj output of last h_state of encode (R^2h) to R^h</span><br>        self.c_projection = nn.Linear(hidden_size * <span class="hljs-number">2</span>, hidden_size, bias=<span class="hljs-literal">False</span>)<br>        self.att_projection = nn.Linear(hidden_size * <span class="hljs-number">2</span>, hidden_size, bias=<span class="hljs-literal">False</span>) <span class="hljs-comment"># 1 x 2h (h_encode_i) * 2h x h (W) * h * 1 (h_decode_t) = 1 x 1 = e_t,i</span><br>        self.combined_output_projection = nn.Linear(hidden_size * <span class="hljs-number">3</span>, hidden_size, bias=<span class="hljs-literal">False</span>) <span class="hljs-comment"># use after combined attention output and h_decode</span><br>        self.target_vocab_projection    = nn.Linear(hidden_size, <span class="hljs-built_in">len</span>(vocab.tgt), bias=<span class="hljs-literal">False</span>) <span class="hljs-comment"># for softmax of last</span><br>        self.dropout = nn.Dropout(self.dropout_rate)<br>        <span class="hljs-comment"># END YOUR CODE</span><br><br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, source: <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]], target: <span class="hljs-type">List</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]]</span>) -&gt; torch.Tensor:<br>        <span class="hljs-string">&quot;&quot;&quot; Take a mini-batch of source and target sentences, compute the log-likelihood of</span><br><span class="hljs-string">        target sentences under the language models learned by the NMT system.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        @param source (List[List[str]]): list of source sentence tokens</span><br><span class="hljs-string">        @param target (List[List[str]]): list of target sentence tokens, wrapped by `&lt;s&gt;` and `&lt;/s&gt;`</span><br><span class="hljs-string"></span><br><span class="hljs-string">        @returns scores (Tensor): a variable/tensor of shape (b, ) representing the</span><br><span class="hljs-string">                                    log-likelihood of generating the gold-standard target sentence for</span><br><span class="hljs-string">                                    each example in the input batch. Here b = batch size.</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-comment"># Compute sentence lengths</span><br>        source_lengths = [<span class="hljs-built_in">len</span>(s) <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> source]<br><br>        <span class="hljs-comment"># Convert list of lists into tensors</span><br>        source_padded = self.vocab.src.to_input_tensor(source, device=self.device)   <span class="hljs-comment"># Tensor: (src_len, b)</span><br>        target_padded = self.vocab.tgt.to_input_tensor(target, device=self.device)   <span class="hljs-comment"># Tensor: (tgt_len, b)</span><br><br>        <span class="hljs-comment">#     Run the network forward:</span><br>        <span class="hljs-comment">#     1. Apply the encoder to `source_padded` by calling `self.encode()`</span><br>        <span class="hljs-comment">#     2. Generate sentence masks for `source_padded` by calling `self.generate_sent_masks()`</span><br>        <span class="hljs-comment">#     3. Apply the decoder to compute combined-output by calling `self.decode()`</span><br>        <span class="hljs-comment">#     4. Compute log probability distribution over the target vocabulary using the</span><br>        <span class="hljs-comment">#        combined_outputs returned by the `self.decode()` function.</span><br><br>        enc_hiddens, dec_init_state = self.encode(source_padded, source_lengths)<br>        enc_masks = self.generate_sent_masks(enc_hiddens, source_lengths)<br>        combined_outputs = self.decode(enc_hiddens, enc_masks, dec_init_state, target_padded)<br>        P = F.log_softmax(self.target_vocab_projection(combined_outputs), dim=-<span class="hljs-number">1</span>)<br><br>        <span class="hljs-comment"># Zero out, probabilities for which we have nothing in the target text</span><br>        target_masks = (target_padded != self.vocab.tgt[<span class="hljs-string">&#x27;&lt;pad&gt;&#x27;</span>]).<span class="hljs-built_in">float</span>()<br>        <br>        <span class="hljs-comment"># Compute log probability of generating true target words</span><br>        target_gold_words_log_prob = torch.gather(P, index=target_padded[<span class="hljs-number">1</span>:].unsqueeze(-<span class="hljs-number">1</span>), dim=-<span class="hljs-number">1</span>).squeeze(-<span class="hljs-number">1</span>) * target_masks[<span class="hljs-number">1</span>:]<br>        scores = target_gold_words_log_prob.<span class="hljs-built_in">sum</span>(dim=<span class="hljs-number">0</span>)<br>        <span class="hljs-keyword">return</span> scores<br></code></pre></div></td></tr></table></figure>
<h3 id="d-encode">(d) encode</h3>
<p>Implement the <code>encode</code> function in nmt model.py. This
function converts the padded source sentences into the tensor<span
class="math inline">\(X\)</span>, generates<span
class="math inline">\(h^{enc}_1,...,h^{enc}_m\)</span> , and computes
the initial state<span class="math inline">\(\ h^{dec}_0\)</span>and
initial cell<span class="math inline">\(\ c^{dec}_0\)</span>for the
Decoder. You can run a non-comprehensive sanity check by
executing:<code>python sanity_check.py 1d</code></p>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">encode</span>(<span class="hljs-params">self, source_padded: torch.Tensor, source_lengths: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; <span class="hljs-type">Tuple</span>[torch.Tensor, <span class="hljs-type">Tuple</span>[torch.Tensor, torch.Tensor]]:<br>   <span class="hljs-string">&quot;&quot;&quot; Apply the encoder to source sentences to obtain encoder hidden states.</span><br><span class="hljs-string">       Additionally, take the final states of the encoder and project them to obtain initial states for decoder.</span><br><span class="hljs-string"></span><br><span class="hljs-string">   @param source_padded (Tensor): Tensor of padded source sentences with shape (src_len, b), where</span><br><span class="hljs-string">                                   b = batch_size, src_len = maximum source sentence length. Note that </span><br><span class="hljs-string">                                  these have already been sorted in order of longest to shortest sentence.</span><br><span class="hljs-string">   @param source_lengths (List[int]): List of actual lengths for each of the source sentences in the batch</span><br><span class="hljs-string">   @returns enc_hiddens (Tensor): Tensor of hidden units with shape (b, src_len, h*2), where</span><br><span class="hljs-string">                                   b = batch size, src_len = maximum source sentence length, h = hidden size.</span><br><span class="hljs-string">   @returns dec_init_state (tuple(Tensor, Tensor)): Tuple of tensors representing the decoder&#x27;s initial</span><br><span class="hljs-string">                                           hidden state and cell.</span><br><span class="hljs-string">   &quot;&quot;&quot;</span><br>   enc_hiddens, dec_init_state = <span class="hljs-literal">None</span>, <span class="hljs-literal">None</span><br><br>   <span class="hljs-comment"># YOUR CODE HERE (~ 8 Lines)</span><br>   <span class="hljs-comment"># <span class="hljs-doctag">TODO:</span></span><br>   <span class="hljs-comment">#     1. Construct Tensor `X` of source sentences with shape (src_len, b, e) using the source model embeddings.</span><br>   <span class="hljs-comment">#         src_len = maximum source sentence length, b = batch size, e = embedding size. Note</span><br>   <span class="hljs-comment">#         that there is no initial hidden state or cell for the decoder.</span><br>   <span class="hljs-comment">#     2. Compute `enc_hiddens`, `last_hidden`, `last_cell` by applying the encoder to `X`.</span><br>   <span class="hljs-comment">#         - Before you can apply the encoder, you need to apply the `pack_padded_sequence` function to X.</span><br>   <span class="hljs-comment">#         - After you apply the encoder, you need to apply the `pad_packed_sequence` function to enc_hiddens.</span><br>   <span class="hljs-comment">#         - Note that the shape of the tensor returned by the encoder is (src_len b, h*2) and we want to</span><br>   <span class="hljs-comment">#           return a tensor of shape (b, src_len, h*2) as `enc_hiddens`.</span><br>   <span class="hljs-comment">#     3. Compute `dec_init_state` = (init_decoder_hidden, init_decoder_cell):</span><br>   <span class="hljs-comment">#         - `init_decoder_hidden`:</span><br>   <span class="hljs-comment">#             `last_hidden` is a tensor shape (2, b, h). The first dimension corresponds to forwards and backwards.</span><br>   <span class="hljs-comment">#             Concatenate the forwards and backwards tensors to obtain a tensor shape (b, 2*h).</span><br>   <span class="hljs-comment">#             Apply the h_projection layer to this in order to compute init_decoder_hidden.</span><br>   <span class="hljs-comment">#             This is h_0^&#123;dec&#125; in the PDF. Here b = batch size, h = hidden size</span><br>   <span class="hljs-comment">#         - `init_decoder_cell`:</span><br>   <span class="hljs-comment">#             `last_cell` is a tensor shape (2, b, h). The first dimension corresponds to forwards and backwards.</span><br>   <span class="hljs-comment">#             Concatenate the forwards and backwards tensors to obtain a tensor shape (b, 2*h).</span><br>   <span class="hljs-comment">#             Apply the c_projection layer to this in order to compute init_decoder_cell.</span><br>   <span class="hljs-comment">#             This is c_0^&#123;dec&#125; in the PDF. Here b = batch size, h = hidden size</span><br>   <span class="hljs-comment">#</span><br>   <span class="hljs-comment"># See the following docs, as you may need to use some of the following functions in your implementation:</span><br>   <span class="hljs-comment">#     Pack the padded sequence X before passing to the encoder:</span><br>   <span class="hljs-comment">#         https://pytorch.org/docs/stable/nn.html#torch.nn.utils.rnn.pack_padded_sequence</span><br>   <span class="hljs-comment">#     Pad the packed sequence, enc_hiddens, returned by the encoder:</span><br>   <span class="hljs-comment">#         https://pytorch.org/docs/stable/nn.html#torch.nn.utils.rnn.pad_packed_sequence</span><br>   <span class="hljs-comment">#     Tensor Concatenation:</span><br>   <span class="hljs-comment">#         https://pytorch.org/docs/stable/torch.html#torch.cat</span><br>   <span class="hljs-comment">#     Tensor Permute:</span><br>   <span class="hljs-comment">#         https://pytorch.org/docs/stable/tensors.html#torch.Tensor.permute</span><br>   X = self.model_embeddings.source(source_padded) <span class="hljs-comment"># (src_len, b, e)</span><br>   X = pack_padded_sequence(X, lengths=source_lengths) <span class="hljs-comment"># if feed pack to RNN, it will not calculate output for pad element</span><br>   <span class="hljs-comment"># pack_padded_sequence and pad_packed_sequence example:</span><br>   <span class="hljs-comment"># https://github.com/HarshTrivedi/packing-unpacking-pytorch-minimal-tutorial</span><br>   <span class="hljs-comment"># PackedSequence: Named Tuple with 2 attribute data &amp; batch_size</span><br>   <span class="hljs-comment"># data: shape (batch_sum_len x embed_dim)</span><br>   <span class="hljs-comment"># batch_size: each columns when feed to lstm (max = batch_size (start word of all sentence), min = 1 (only one word in this column))</span><br><br>   <span class="hljs-comment"># After feed PackedSequence to LSTM, return PackedSequence with the same attributes : data &amp; batch_size</span><br>   enc_hiddens, (last_hidden, last_cell) = self.encoder(X)<br>   <span class="hljs-comment"># pad_packed_sequence will unpack PackedSequence, which transform (data &amp; batch_size) -&gt; (max_len, b, h * 2)</span><br>   <span class="hljs-comment"># padded indice will be 0s</span><br>   enc_hiddens, _ = pad_packed_sequence(enc_hiddens)<br>   enc_hiddens = enc_hiddens.transpose(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>)	<span class="hljs-comment"># (b, max_len, h* 2) 维度互换</span><br><br>   last_hidden = torch.cat((last_hidden[<span class="hljs-number">0</span>], last_hidden[<span class="hljs-number">1</span>]), <span class="hljs-number">1</span>)	<span class="hljs-comment"># (2, b, h) -&gt; (b, h * 2)</span><br>   init_decoder_hidden = self.h_projection(last_hidden)<br><br>   last_cell = torch.cat((last_cell[<span class="hljs-number">0</span>], last_cell[<span class="hljs-number">1</span>]), <span class="hljs-number">1</span>)<br>   init_decoder_cell = self.c_projection(last_cell)<br><br>   dec_init_state = (init_decoder_hidden, init_decoder_cell)<br>   <span class="hljs-comment"># END YOUR CODE</span><br><br>   <span class="hljs-keyword">return</span> enc_hiddens, dec_init_state<br></code></pre></div></td></tr></table></figure>
<h3 id="e-decode">(e) decode</h3>
<p>Implement the <code>decode</code> function in nmt model.py. This
function constructs y¯ and runs the step function over every timestep
for the input. You can run a non-comprehensive sanity check by
executing:<code>python sanity_check.py 1e</code></p>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">decode</span>(<span class="hljs-params">self, enc_hiddens: torch.Tensor, enc_masks: torch.Tensor,</span><br><span class="hljs-params">            dec_init_state: <span class="hljs-type">Tuple</span>[torch.Tensor, torch.Tensor], target_padded: torch.Tensor</span>) -&gt; torch.Tensor:<br>    <span class="hljs-string">&quot;&quot;&quot;Compute combined output vectors for a batch.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    @param enc_hiddens (Tensor): Hidden states (b, src_len, h*2), where</span><br><span class="hljs-string">                                 b = batch size, src_len = maximum source sentence length, h = hidden size.</span><br><span class="hljs-string">    @param enc_masks (Tensor): Tensor of sentence masks (b, src_len), where</span><br><span class="hljs-string">                                 b = batch size, src_len = maximum source sentence length.</span><br><span class="hljs-string">    @param dec_init_state (tuple(Tensor, Tensor)): Initial state and cell for decoder</span><br><span class="hljs-string">    @param target_padded (Tensor): Gold-standard padded target sentences (tgt_len, b), where</span><br><span class="hljs-string">                                   tgt_len = maximum target sentence length, b = batch size. </span><br><span class="hljs-string"></span><br><span class="hljs-string">    @returns combined_outputs (Tensor): combined output tensor  (tgt_len, b,  h), where</span><br><span class="hljs-string">                                    tgt_len = maximum target sentence length, b = batch_size,  h = hidden size</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># Chop of the &lt;END&gt; token for max length sentences.</span><br>    target_padded = target_padded[:-<span class="hljs-number">1</span>]<br><br>    <span class="hljs-comment"># Initialize the decoder state (hidden and cell)</span><br>    dec_state = dec_init_state<br><br>    <span class="hljs-comment"># Initialize previous combined output vector o_&#123;t-1&#125; as zero</span><br>    batch_size = enc_hiddens.size(<span class="hljs-number">0</span>)<br>    o_prev = torch.zeros(batch_size, self.hidden_size, device=self.device)<br><br>    <span class="hljs-comment"># Initialize a list we will use to collect the combined output o_t on each step</span><br>    combined_outputs = []<br><br>    <span class="hljs-comment"># YOUR CODE HERE (~9 Lines)</span><br>    <span class="hljs-comment"># <span class="hljs-doctag">TODO:</span></span><br>    <span class="hljs-comment">#     1. Apply the attention projection layer to `enc_hiddens` to obtain `enc_hiddens_proj`,</span><br>    <span class="hljs-comment">#         which should be shape (b, src_len, h),</span><br>    <span class="hljs-comment">#         where b = batch size, src_len = maximum source length, h = hidden size.</span><br>    <span class="hljs-comment">#         This is applying W_&#123;attProj&#125; to h^enc, as described in the PDF.</span><br>    <span class="hljs-comment">#     2. Construct tensor `Y` of target sentences with shape (tgt_len, b, e) using the target model embeddings.</span><br>    <span class="hljs-comment">#         where tgt_len = maximum target sentence length, b = batch size, e = embedding size.</span><br>    <span class="hljs-comment">#     3. Use the torch.split function to iterate over the time dimension of Y.</span><br>    <span class="hljs-comment">#         Within the loop, this will give you Y_t of shape (1, b, e) where b = batch size, e = embedding size.</span><br>    <span class="hljs-comment">#             - Squeeze Y_t into a tensor of dimension (b, e).</span><br>    <span class="hljs-comment">#             - Construct Ybar_t by concatenating Y_t with o_prev.</span><br>    <span class="hljs-comment">#             - Use the step function to compute the the Decoder&#x27;s next (cell, state) values</span><br>    <span class="hljs-comment">#               as well as the new combined output o_t.</span><br>    <span class="hljs-comment">#             - Append o_t to combined_outputs</span><br>    <span class="hljs-comment">#             - Update o_prev to the new o_t.</span><br>    <span class="hljs-comment">#     4. Use torch.stack to convert combined_outputs from a list length tgt_len of</span><br>    <span class="hljs-comment">#         tensors shape (b, h), to a single tensor shape (tgt_len, b, h)</span><br>    <span class="hljs-comment">#         where tgt_len = maximum target sentence length, b = batch size, h = hidden size.</span><br>    <span class="hljs-comment">#</span><br>    <span class="hljs-comment"># Note:</span><br>    <span class="hljs-comment">#    - When using the squeeze() function make sure to specify the dimension you want to squeeze</span><br>    <span class="hljs-comment">#      over. Otherwise, you will remove the batch dimension accidentally, if batch_size = 1.</span><br>    <span class="hljs-comment">#</span><br>    <span class="hljs-comment"># Use the following docs to implement this functionality:</span><br>    <span class="hljs-comment">#     Zeros Tensor:</span><br>    <span class="hljs-comment">#         https://pytorch.org/docs/stable/torch.html#torch.zeros</span><br>    <span class="hljs-comment">#     Tensor Splitting (iteration):</span><br>    <span class="hljs-comment">#         https://pytorch.org/docs/stable/torch.html#torch.split</span><br>    <span class="hljs-comment">#     Tensor Dimension Squeezing:</span><br>    <span class="hljs-comment">#         https://pytorch.org/docs/stable/torch.html#torch.squeeze</span><br>    <span class="hljs-comment">#     Tensor Concatenation:</span><br>    <span class="hljs-comment">#         https://pytorch.org/docs/stable/torch.html#torch.cat</span><br>    <span class="hljs-comment">#     Tensor Stacking:</span><br>    <span class="hljs-comment">#         https://pytorch.org/docs/stable/torch.html#torch.stack</span><br><br>    <span class="hljs-comment"># 1,</span><br>    enc_hiddens_proj = self.att_projection(enc_hiddens) <span class="hljs-comment"># enc_hiddens: (b, l, h * 2)  dot (h * 2, h) -&gt; b, l, h</span><br>    <span class="hljs-comment"># 2,</span><br>    Y = self.model_embeddings.target(target_padded) <span class="hljs-comment"># (tgt_len, b, h)</span><br>    <span class="hljs-comment"># 3,</span><br>    <span class="hljs-keyword">for</span> Y_t <span class="hljs-keyword">in</span> torch.split(Y, <span class="hljs-number">1</span>, dim=<span class="hljs-number">0</span>):<br>        squeezed = torch.squeeze(Y_t) <span class="hljs-comment"># shape (b, e)</span><br>        Ybar_t = torch.cat((squeezed, o_prev), dim=<span class="hljs-number">1</span>) <span class="hljs-comment"># shape (b, e + h)</span><br>        dec_state, o_t, _ = self.step(Ybar_t, dec_state, enc_hiddens, enc_hiddens_proj, enc_masks)<br>        combined_outputs.append(o_t)<br>        o_prev = o_t<br>    <span class="hljs-comment"># 4,</span><br>    combined_outputs = torch.stack(combined_outputs, dim=<span class="hljs-number">0</span>)<br>    <span class="hljs-comment"># END YOUR CODE</span><br><br>    <span class="hljs-keyword">return</span> combined_outputs<br></code></pre></div></td></tr></table></figure>
<h3 id="f-step">(f) step</h3>
<p>Implement the <code>step</code> function in nmt model.py. This
function applies the Decoder’s LSTM cell for a single timestep,
computing the encoding of the target word h dec t , the attention scores
et, attention distribution αt, the attention output at, and finally the
combined output ot. You can run a non-comprehensive sanity check by
executing:<code>python sanity_check.py 1f</code></p>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">step</span>(<span class="hljs-params">self, Ybar_t: torch.Tensor,</span><br><span class="hljs-params">        dec_state: <span class="hljs-type">Tuple</span>[torch.Tensor, torch.Tensor],</span><br><span class="hljs-params">        enc_hiddens: torch.Tensor,</span><br><span class="hljs-params">        enc_hiddens_proj: torch.Tensor,</span><br><span class="hljs-params">        enc_masks: torch.Tensor</span>) -&gt; <span class="hljs-type">Tuple</span>[<span class="hljs-type">Tuple</span>, torch.Tensor, torch.Tensor]:<br>    <span class="hljs-string">&quot;&quot;&quot; Compute one forward step of the LSTM decoder, including the attention computation.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    @param Ybar_t (Tensor): Concatenated Tensor of [Y_t o_prev], with shape (b, e + h). The input for the decoder,</span><br><span class="hljs-string">                            where b = batch size, e = embedding size, h = hidden size.</span><br><span class="hljs-string">    @param dec_state (tuple(Tensor, Tensor)): Tuple of tensors both with shape (b, h), where b = batch size, h = hidden size.</span><br><span class="hljs-string">            First tensor is decoder&#x27;s prev hidden state, second tensor is decoder&#x27;s prev cell.</span><br><span class="hljs-string">    @param enc_hiddens (Tensor): Encoder hidden states Tensor, with shape (b, src_len, h * 2), where b = batch size,</span><br><span class="hljs-string">                                src_len = maximum source length, h = hidden size.</span><br><span class="hljs-string">    @param enc_hiddens_proj (Tensor): Encoder hidden states Tensor, projected from (h * 2) to h. Tensor is with shape (b, src_len, h),</span><br><span class="hljs-string">                                where b = batch size, src_len = maximum source length, h = hidden size.</span><br><span class="hljs-string">    @param enc_masks (Tensor): Tensor of sentence masks shape (b, src_len),</span><br><span class="hljs-string">                                where b = batch size, src_len is maximum source length. </span><br><span class="hljs-string"></span><br><span class="hljs-string">    @returns dec_state (tuple (Tensor, Tensor)): Tuple of tensors both shape (b, h), where b = batch size, h = hidden size.</span><br><span class="hljs-string">            First tensor is decoder&#x27;s new hidden state, second tensor is decoder&#x27;s new cell.</span><br><span class="hljs-string">    @returns combined_output (Tensor): Combined output Tensor at timestep t, shape (b, h), where b = batch size, h = hidden size.</span><br><span class="hljs-string">    @returns e_t (Tensor): Tensor of shape (b, src_len). It is attention scores distribution.</span><br><span class="hljs-string">                            Note: You will not use this outside of this function.</span><br><span class="hljs-string">                                  We are simply returning this value so that we can sanity check</span><br><span class="hljs-string">                                  your implementation.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    combined_output = <span class="hljs-literal">None</span><br><br>    <span class="hljs-comment"># YOUR CODE HERE (~3 Lines)</span><br>    <span class="hljs-comment"># <span class="hljs-doctag">TODO:</span></span><br>    <span class="hljs-comment">#     1. Apply the decoder to `Ybar_t` and `dec_state`to obtain the new dec_state.</span><br>    <span class="hljs-comment">#     2. Split dec_state into its two parts (dec_hidden, dec_cell)</span><br>    <span class="hljs-comment">#     3. Compute the attention scores e_t, a Tensor shape (b, src_len).</span><br>    <span class="hljs-comment">#        Note: b = batch_size, src_len = maximum source length, h = hidden size.</span><br>    <span class="hljs-comment">#</span><br>    <span class="hljs-comment">#       Hints:</span><br>    <span class="hljs-comment">#         - dec_hidden is shape (b, h) and corresponds to h^dec_t in the PDF (batched)</span><br>    <span class="hljs-comment">#         - enc_hiddens_proj is shape (b, src_len, h) and corresponds to W_&#123;attProj&#125; h^enc (batched).</span><br>    <span class="hljs-comment">#         - Use batched matrix multiplication (torch.bmm) to compute e_t.</span><br>    <span class="hljs-comment">#         - To get the tensors into the right shapes for bmm, you will need to do some squeezing and unsqueezing.</span><br>    <span class="hljs-comment">#         - When using the squeeze() function make sure to specify the dimension you want to squeeze</span><br>    <span class="hljs-comment">#             over. Otherwise, you will remove the batch dimension accidentally, if batch_size = 1.</span><br>    <span class="hljs-comment">#</span><br>    <span class="hljs-comment"># Use the following docs to implement this functionality:</span><br>    <span class="hljs-comment">#     Batch Multiplication:</span><br>    <span class="hljs-comment">#        https://pytorch.org/docs/stable/torch.html#torch.bmm</span><br>    <span class="hljs-comment">#     Tensor Unsqueeze:</span><br>    <span class="hljs-comment">#         https://pytorch.org/docs/stable/torch.html#torch.unsqueeze</span><br>    <span class="hljs-comment">#     Tensor Squeeze:</span><br>    <span class="hljs-comment">#         https://pytorch.org/docs/stable/torch.html#torch.squeeze</span><br><br>    <span class="hljs-comment"># 1,</span><br>    dec_state = self.decoder(Ybar_t, dec_state)<br>    (dec_hidden, dec_cell) = dec_state<br>    <span class="hljs-comment"># 3, (b, src_len, h) .dot(b, h, 1) -&gt; (b, src_len, 1) -&gt; (b, src_len)</span><br>    e_t = enc_hiddens_proj.bmm(dec_hidden.unsqueeze(<span class="hljs-number">2</span>)).squeeze(<span class="hljs-number">2</span>)<br>    <span class="hljs-comment">### END YOUR CODE</span><br><br>    <span class="hljs-comment"># Set e_t to -inf where enc_masks has 1</span><br>    <span class="hljs-keyword">if</span> enc_masks <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        e_t.data.masked_fill_(enc_masks.byte(), -<span class="hljs-built_in">float</span>(<span class="hljs-string">&#x27;inf&#x27;</span>)) <span class="hljs-comment"># mask the 0s with -inf, so e^x = 0</span><br><br>    <span class="hljs-comment"># YOUR CODE HERE (~6 Lines)</span><br>    <span class="hljs-comment"># <span class="hljs-doctag">TODO:</span></span><br>    <span class="hljs-comment">#     1. Apply softmax to e_t to yield alpha_t</span><br>    <span class="hljs-comment">#     2. Use batched matrix multiplication between alpha_t and enc_hiddens to obtain the</span><br>    <span class="hljs-comment">#         attention output vector, a_t.</span><br>    <span class="hljs-comment">#     Hints:</span><br>    <span class="hljs-comment">#           - alpha_t is shape (b, src_len)</span><br>    <span class="hljs-comment">#           - enc_hiddens is shape (b, src_len, 2h)</span><br>    <span class="hljs-comment">#           - a_t should be shape (b, 2h)</span><br>    <span class="hljs-comment">#           - You will need to do some squeezing and unsqueezing.</span><br>    <span class="hljs-comment">#     Note: b = batch size, src_len = maximum source length, h = hidden size.</span><br>    <span class="hljs-comment">#</span><br>    <span class="hljs-comment">#     3. Concatenate dec_hidden with a_t to compute tensor U_t</span><br>    <span class="hljs-comment">#     4. Apply the combined output projection layer to U_t to compute tensor V_t</span><br>    <span class="hljs-comment">#     5. Compute tensor O_t by first applying the Tanh function and then the dropout layer.</span><br>    <span class="hljs-comment">#</span><br>    <span class="hljs-comment"># Use the following docs to implement this functionality:</span><br>    <span class="hljs-comment">#     Softmax:</span><br>    <span class="hljs-comment">#         https://pytorch.org/docs/stable/nn.html#torch.nn.functional.softmax</span><br>    <span class="hljs-comment">#     Batch Multiplication:</span><br>    <span class="hljs-comment">#        https://pytorch.org/docs/stable/torch.html#torch.bmm</span><br>    <span class="hljs-comment">#     Tensor View:</span><br>    <span class="hljs-comment">#         https://pytorch.org/docs/stable/tensors.html#torch.Tensor.view</span><br>    <span class="hljs-comment">#     Tensor Concatenation:</span><br>    <span class="hljs-comment">#         https://pytorch.org/docs/stable/torch.html#torch.cat</span><br>    <span class="hljs-comment">#     Tanh:</span><br>    <span class="hljs-comment">#         https://pytorch.org/docs/stable/torch.html#torch.tanh</span><br><br>    <span class="hljs-comment"># 1, apply softmax to e_t</span><br>    alpha_t = F.softmax(e_t, dim=<span class="hljs-number">1</span>) <span class="hljs-comment"># (b, src_len)</span><br>    <span class="hljs-comment"># 2, (b, 1, src_len) x (b, src_len, 2h) = (b, 1, 2h) -&gt; (b, 2h)</span><br>    <span class="hljs-comment"># a_t = e_t.unsqueeze(1).bmm(enc_hiddens).squeeze(1)</span><br>    att_view = (alpha_t.size(<span class="hljs-number">0</span>), <span class="hljs-number">1</span>, alpha_t.size(<span class="hljs-number">1</span>))<br>    a_t = torch.bmm(alpha_t.view(*att_view), enc_hiddens).squeeze(<span class="hljs-number">1</span>)<br><br>    <span class="hljs-comment"># 3, concate a_t (b, 2h) and dec_hidden (b, h) to U_t (b, 3h)</span><br>    U_t = torch.cat((a_t, dec_hidden), dim=<span class="hljs-number">1</span>)<br>    <span class="hljs-comment"># 4, apply combined output to U_T -&gt; V_t, shape (b, h)</span><br>    V_t = self.combined_output_projection(U_t)<br>    O_t = self.dropout(torch.tanh(V_t))<br><br>    <span class="hljs-comment"># END YOUR CODE</span><br><br>    combined_output = O_t<br>    <span class="hljs-keyword">return</span> dec_state, combined_output, e_t<br></code></pre></div></td></tr></table></figure>
<h3 id="g-generate_sent_masks">(g) generate_sent_masks</h3>
<p>The generate sent masks() function in nmt model.py produces a tensor
called enc masks. It has shape (batch size, max source sentence length)
and contains 1s in positions corresponding to ‘pad’ tokens in the input,
and 0s for non-pad tokens. Look at how the masks are used during the
attention computation in the step() function (lines 295-296). First
explain (in around three sentences) what effect the masks have on the
entire attention computation. Then explain (in one or two sentences) why
it is necessary to use the masks in this way.</p>
<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_sent_masks</span>(<span class="hljs-params">self, enc_hiddens: torch.Tensor, source_lengths: <span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>]</span>) -&gt; torch.Tensor:<br>    <span class="hljs-string">&quot;&quot;&quot; Generate sentence masks for encoder hidden states.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    @param enc_hiddens (Tensor): encodings of shape (b, src_len, 2*h), where b = batch size,</span><br><span class="hljs-string">                                 src_len = max source length, h = hidden size. </span><br><span class="hljs-string">    @param source_lengths (List[int]): List of actual lengths for each of the sentences in the batch.</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    @returns enc_masks (Tensor): Tensor of sentence masks of shape (b, src_len),</span><br><span class="hljs-string">                                where src_len = max source length, h = hidden size.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    enc_masks = torch.zeros(enc_hiddens.size(<span class="hljs-number">0</span>), enc_hiddens.size(<span class="hljs-number">1</span>), dtype=torch.<span class="hljs-built_in">float</span>)<br>    <span class="hljs-keyword">for</span> e_id, src_len <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(source_lengths):<br>        enc_masks[e_id, src_len:] = <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> enc_masks.to(self.device)<br></code></pre></div></td></tr></table></figure>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/Deep-Learning/">Deep Learning</a>
                    
                      <a class="hover-with-bg" href="/categories/Deep-Learning/NLP/">NLP</a>
                    
                  </div>
                
                
              </div>
              
                <p class="note note-warning">
                  
                    本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2022/05/14/%E7%AC%AC%E5%85%AB%E8%AE%B2-%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E3%80%81seq2seq%E4%B8%8E%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/">
                        <span class="hidden-mobile">第八讲-机器翻译、seq2seq与注意力机制</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
              <!-- Comments -->
              <article class="comments" id="comments" lazyload>
                
                  
                
                

              </article>
            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  

  

  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  <script  src="/js/local-search.js" ></script>



  
    <script  src="/js/img-lazyload.js" ></script>
  



  



  
    <script  src="https://cdn.jsdelivr.net/npm/tocbot@4/dist/tocbot.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4/anchor.min.js" ></script>
  
  
    <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js" ></script>
  






  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
        typing(title);
      
    })(window, document);
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        loader: {
          load: ['ui/lazy']
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js" ></script>

  











<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>


</body>
</html>
