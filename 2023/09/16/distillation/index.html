

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=dark>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" href="/img/favicon.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="肘子开">
  <meta name="keywords" content="">
  
    <meta name="description" content="Classification FitNet FITNETS: HINTS FOR THIN DEEP NETS (ICLR 2015) Knowledge Distillation via the Target-aware Transformer (CVPR 2022) 目前不足：  感受野对模型表征能力影响十分重要，这种差异是目前一对一匹配蒸馏法导致次优结果的潜在原因。  改进">
<meta property="og:type" content="article">
<meta property="og:title" content="distillation">
<meta property="og:url" content="http://example.com/2023/09/16/distillation/index.html">
<meta property="og:site_name" content="肘子开的博客">
<meta property="og:description" content="Classification FitNet FITNETS: HINTS FOR THIN DEEP NETS (ICLR 2015) Knowledge Distillation via the Target-aware Transformer (CVPR 2022) 目前不足：  感受野对模型表征能力影响十分重要，这种差异是目前一对一匹配蒸馏法导致次优结果的潜在原因。  改进">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/cv/image-20230916163256829.png">
<meta property="og:image" content="http://example.com/img/cv/image-20230916170214352.png">
<meta property="og:image" content="http://example.com/img/cv/image-20230916172809521.png">
<meta property="og:image" content="http://example.com/img/cv/image-20230916173404192.png">
<meta property="og:image" content="http://example.com/img/cv/image-20230916173923018.png">
<meta property="og:image" content="http://example.com/img/cv/image-20230918105121610.png">
<meta property="og:image" content="http://example.com/img/cv/image-20230918172153838.png">
<meta property="og:image" content="http://example.com/img/cv/image-20230918174811736.png">
<meta property="og:image" content="http://example.com/img/cv/image-20230918175405238.png">
<meta property="article:published_time" content="2023-09-16T08:27:59.000Z">
<meta property="article:modified_time" content="2023-09-18T10:24:46.437Z">
<meta property="article:author" content="肘子开">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://example.com/img/cv/image-20230916163256829.png">
  
  
  <title>distillation - 肘子开的博客</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4/github-markdown.min.css" />
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hint.css@2/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10/styles/nnfx-dark.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.css" />
  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.8.14","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 6.1.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>肘子开的博客</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/img/bg/bg2.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="distillation">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2023-09-16 16:27" pubdate>
        2023年9月16日 下午
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      11k 字
    </span>
  

  
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      91 分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">distillation</h1>
            
            <div class="markdown-body">
              <h1 id="classification">Classification</h1>
<h2 id="fitnet">FitNet</h2>
<p>FITNETS: HINTS FOR THIN DEEP NETS (ICLR 2015)</p>
<h2
id="knowledge-distillation-via-the-target-aware-transformer-cvpr-2022">Knowledge
Distillation via the Target-aware Transformer (CVPR 2022)</h2>
<p>目前不足：</p>
<ul>
<li>感受野对模型表征能力影响十分重要，这种差异是目前一对一匹配蒸馏法导致次优结果的潜在原因。</li>
</ul>
<p>改进：</p>
<ul>
<li>我们提出通过<em>target-aware
transformer</em>（TaT）进行知识提炼，使全体学生分别模仿教师的各个空间组件（one-to-all）。这样，我们就能提高匹配能力，从而改善知识提炼的性能。</li>
<li>我们提出了分层蒸馏法，以转移局部特征和全局依赖性，而不是原始特征图。这样，我们就能将提出的方法应用于因特征图规模庞大而计算负担沉重的应用中。</li>
</ul>
<p><img src="/img/cv/image-20230916163256829.png" srcset="/img/loading.gif" lazyload /></p>
<p>由于教师网络的特征图通常包含更多的层和更大的特征通道，与学生网络相比，同一像素位置的空间信息包含更丰富的语义信息。为此，我们提出了一个一对一的空间匹配知识提炼管道，让教师的每个特征位置都能以动态的方式教授整个学生的特征。
<span class="math display">\[
\begin{aligned}
W^{i} &amp; =\sigma\left(\left\langle f_{1}^{s},
f_{i}^{t}\right\rangle,\left\langle f_{2}^{s}, f_{i}^{t}\right\rangle,
\ldots,\left\langle f_{N}^{s}, f_{i}^{t}\right\rangle\right) \\
&amp; =\left[w_{1}^{i}, w_{2}^{i}, \ldots, w_{N}^{i}\right]
\end{aligned}
\]</span> 将这些相关语义汇总到所有组件中，我们就得到了结果： <span
class="math display">\[
f_{i}^{s^{\prime}}=w_{1}^{i} \times f_{1}^{s}+w_{2}^{i} \times
f_{2}^{s}+\cdots+w_{N}^{i} \times f_{N}^{s}
\]</span> 两个公式可以合为一个矩阵乘法：<span
class="math inline">\(f^{s^{&#39;}}_i=\sigma(f^s\cdot f^t_i)\cdot
f^s\)</span></p>
<p>为了方便训练，我们引入了参数方法，对学生特征和教师特征进行了额外的线性变换。我们发现，在消融研究中，参数版本比非参数版本表现更好。
<span class="math display">\[
f^{s^{\prime}}=\sigma\left(\gamma\left(f^s\right) \cdot
\theta\left(f^t\right)^{\top}\right) \cdot \phi\left(f^s\right)
\]</span> 最后TaT的损失函数就为： <span class="math display">\[
\mathcal{L}_{\mathrm{TaT}}=\left\|f^{s^{\prime}}-f^t\right\|_2
\]</span> 但是TaT的计算量还是很大，所以通过Patch-group
Distillation和Anchor-point Distillation减少计算量。</p>
<ul>
<li>Patch-group
Distillation通过将特征图分割成Patch然后n个Patch为一组，在各组之间计算TaT损失</li>
<li>上述算法对于远距离的感知性较差。Anchor-point
Distillation将特征图进行池化采样成小特征图进行计算TaT损失</li>
</ul>
<p>最后总的Loss为： <span class="math display">\[
\mathcal{L}_{\mathrm{Seg}}=\alpha \mathcal{L}_{\mathrm{CE}}+\delta
\mathcal{L}_{\mathrm{TaT}}^{\mathcal{P}}+\zeta
\mathcal{L}_{\mathrm{TaT}}^{\mathcal{A}}
\]</span></p>
<h1 id="object-detection">Object Detection</h1>
<h2
id="improve-object-detection-with-feature-based-knowledge-distillation-towards-accurate-and-efficient-detectors-iclr-2021"><strong>IMPROVE
OBJECT DETECTION WITH FEATURE-BASED KNOWLEDGE DISTILLATION: TOWARDS
ACCURATE AND EFFICIENT DETECTORS (ICLR 2021)</strong></h2>
<p>KD在目标检测方向的应用受限主要是因为如下两个原因</p>
<ul>
<li>前后背景的像素点数量不平衡</li>
<li>像素间的关联性缺少一定的蒸馏</li>
</ul>
<p>对应的解决策略如下：</p>
<ul>
<li>既然存在不平衡关系，那我直接只针对这些bbox的区域做不就好了吗。有些是直接二值mask过滤、有的是将二值soft成高斯分布的形式</li>
<li>采用Non-Local算子产生attention map，针对attention
map计算L2损失回归</li>
</ul>
<p><img src="/img/cv/image-20230916170214352.png" srcset="/img/loading.gif" lazyload /></p>
<h3 id="attention-guided-distillation">ATTENTION-GUIDED
DISTILLATION</h3>
<p>那么，空间注意力图和通道注意力图的生成就等同于找到映射函数$^s: ^{C,
H, W} ^{H, W} <span class="math inline">\(和\)</span>^c: ^{C, H, W}
^C$。由于特征中每个元素的绝对值都意味着其重要性，因此我们通过对通道维度的绝对值求和来构建
<span
class="math inline">\(\mathcal{G}^s\)</span>，并通过对宽度和高度维度的绝对值求和来构建
<span class="math inline">\(\mathcal{G}^c\)</span>，具体公式为<span
class="math inline">\(\mathcal{G}^c(A)=\frac{1}{H W} \sum_H^{i=1}
\sum_W^{j=1}\left|A_{\cdot, i, j}\right|\)</span>和<span
class="math inline">\(\mathcal{G}^s(A)=\frac{1}{C}
\sum_C^{k=1}\left|A_{k,,
\cdot}\right|\)</span>。然后，将教师和学生Detector的注意力图相加，就可以得到注意力引导蒸馏法中使用的空间注意力掩码
<span class="math inline">\(M^s\)</span> 和通道注意力掩码 <span
class="math inline">\(M^c\)</span>，公式为<span
class="math inline">\(M^s=H W \cdot
\operatorname{softmax}\left(\left(\mathcal{G}^s\left(A^{\mathcal{S}}\right)+\mathcal{G}^s\left(A^{\mathcal{T}}\right)\right)
/ T\right)\)</span>和<span
class="math inline">\(M^c=C\cdot\text{softmax}(\mathcal{G}^c(A^{\mathcal{S}})+\mathcal{G}^c(A^{\mathcal{T}}))/T)\)</span>。注意力引导蒸馏损失
<span class="math inline">\(\mathcal{L}_{AGD}\)</span>
由两部分组成--注意力转移损失 <span
class="math inline">\(\mathcal{L}_{AT}\)</span> 和注意力屏蔽损失 <span
class="math inline">\(\mathcal{L}_{AM}\)</span>。 <span
class="math inline">\(\mathcal{L}_{AT}\)</span>
鼓励学生模型模拟教师模型的空间和通道注意力: <span
class="math display">\[
\mathcal{L}_{AT}=\mathcal{L}_2(\mathcal{G}^s(A^{\mathcal{S}}),\mathcal{G}^s(A^{\mathcal{T}}))+\mathcal{L}_2(\mathcal{G}^c(A^{\mathcal{S}}),\mathcal{G}^c(A^{\mathcal{T}}))
\]</span> <span
class="math inline">\(\mathcal{L}_{AM}\)</span>鼓励学生模仿教师模型的特征:
<span class="math display">\[
\begin{aligned}\mathcal{L}_{AM}&amp;=\left(\sum_{k=1}^C\sum_{i=1}^H\sum_{j=1}^W(A_{k,i,j}^T-A_{k,i,j}^\mathcal{S})^2\cdot
M_{i,j}^s\cdot M_k^c\right)^{\frac{1}{2}}\end{aligned}
\]</span></p>
<h3 id="non-local-distillation">NON-LOCAL DISTILLATION</h3>
<p>使用NON-LOCAL模块来提取全局信息，最后Loss： <span
class="math display">\[
\mathcal{L}_{NLD}=\mathcal{L}_{2}(r^{\mathcal{S}},r^{\mathcal{T}})
\]</span></p>
<h3 id="overall-loss-function">OVERALL LOSS FUNCTION</h3>
<p><span class="math display">\[
\mathcal{L}_{Distill}(A^\mathcal{T},A^\mathcal{S})=\underbrace{\alpha\cdot\mathcal{L}_{AT}+\beta\cdot\mathcal{L}_{AM}}_{\text{Attention-guided
distillation}}+\underbrace{\gamma\cdot\mathcal{L}_{NLD}.}_{\text{Non-local
distillation}}
\]</span></p>
<h2
id="localization-distillation-for-object-detection-tpami"><strong>Localization
Distillation for Object Detection</strong> (TPAMI)</h2>
<p><img src="/img/cv/image-20230916172809521.png" srcset="/img/loading.gif" lazyload /></p>
<p>还没看懂，后面再看</p>
<h2
id="general-instance-distillation-for-object-detection-cvpr-2021"><strong>General
Instance Distillation for Object Detection (</strong>CVPR
2021<strong>)</strong></h2>
<p>不足：</p>
<ul>
<li>此外，目前的检测蒸馏方法不能同时在多个检测框架中很好地发挥作用，例如两阶段、一阶段、无锚方法。</li>
</ul>
<p>贡献：</p>
<ul>
<li>将General
Instance（GI）定义为蒸馏目标，可有效提高检测模型的蒸馏效果。</li>
<li>在 GI
的基础上，我们首先引入基于关系的知识，对检测任务进行提炼，并将其与基于反应和特征的知识进行整合，从而使学生超越教师。</li>
<li>我们的方法对各种检测框架具有稳健的泛化性</li>
</ul>
<p><img src="/img/cv/image-20230916173404192.png" srcset="/img/loading.gif" lazyload /></p>
<h3 id="general-instance-selection-module">General Instance Selection
Module</h3>
<p><img src="/img/cv/image-20230916173923018.png" srcset="/img/loading.gif" lazyload /></p>
<p>为了量化每个实例的差异以及选择用于蒸馏的判别实例，提出了两个指标：GI
score和GI box。为了节省训练时的计算资源，我们只需计算分类得分的 L1
距离作为 GI score，并选择得分较高的方框作为 GI
box(针对每一个回归框，作者通过比较tea与stu回归框的所有分类得分差异最大的那个作为当前框的差异分数)。上图展示了生成
GI 的过程，每个预测实例 r 的得分和方框定义如下： <span
class="math display">\[
\begin{aligned}
P_{GI}^{r}&amp; =\max_{0&lt;c\leq C}\left|P_t^{rc}-P_s^{rc}\right|,  \\
B_{GI}^r&amp; =\left\{\begin{array}{cc}B_t^r,&amp;\max_{0&lt;c\leq
C}P_t^{rc}&gt;\max_{0&lt;c\leq C}P_s^{rc}\\B_s^r,&amp;\max_{0&lt;c\leq
C}P_t^{rc}\leq\max_{0&lt;c\leq C}P_s^{rc}\end{array}\right.,  \\
\text{GI}&amp; =NMS(P_{GI},B_{GI}),
\end{aligned}
\]</span> 其中<span class="math inline">\(P_{GI}\)</span>和<span
class="math inline">\(B_{GI}\)</span>分别为GI score和GI
box。对与one-stage来说<span class="math inline">\(P_t\)</span>和<span
class="math inline">\(P_s\)</span>就是教师和学生模型的预测分类得分，对于two-stage来说<span
class="math inline">\(P\)</span>就是RPN预测的目标得分。同时，<span
class="math inline">\(B_t\)</span>和<span
class="math inline">\(B_s\)</span>就是预测的目标框了。R
是预测框的数量，C 是类别的数量。r、c 是 R、C
维度中的索引。最后使用NMS来消除冗余的重叠实例。此外，在每幅图像中，我们只选择得分最高的
K 个实例作为蒸馏的最终 GI。</p>
<h3 id="feature-based-distillation">Feature-based Distillation</h3>
<p>由于 FPN 结合了多个骨干层的特点，我们直观地选择 FPN
进行蒸馏。具体来说，我们根据每个 GI 方框的不同大小，对匹配 FPN
层的特征进行裁剪。鉴于检测任务中目标大小的差异很大，直接进行像素化提炼会使模型更倾向于学习大型目标。因此，我们采用
ROIAlign 算法，将不同大小的 GI
特征调整为相同大小，然后进行蒸馏，对每个目标一视同仁。基于特征的蒸馏损失如下：
<span class="math display">\[
\begin{gathered}L_{Feature}=\frac1K\sum_{i=1}^K\left\|t_i-s_i^{\prime}\right\|_2^2,\\s^{\prime}=f_{adapt}(s),\end{gathered}
\]</span>
K是第一部分GISM挑选出来的GI数量。第二个公式是线性适应方法令学生特征图映射到和教师相同维度。</p>
<h3 id="relation-based-distillation">Relation-based Distillation</h3>
<p>在这里，我们使用欧氏距离来衡量实例的相关性，并使用 L1
距离来传递知识。我们还利用 GI
之间的相关性信息来提炼从教师到学生的知识。损失表达式如下： <span
class="math display">\[
\begin{aligned}
L_{Relation}&amp;
\begin{aligned}=\sum_{(i,j)\in\mathbb{K}^2}l(\frac{1}{\phi(t)}\|t_i-t_j\|_2,\frac{1}{\phi(s)}\|s&#39;_i-s&#39;_j\|_2),\end{aligned}  \\
\phi(x)&amp;
=\frac1{|\mathbb{K}^2|}\sum_{(i,j)\in\mathbb{K}^2}\|x_i-x_j\|_2,
\end{aligned}
\]</span> <span
class="math inline">\(\phi(\cdot)\)</span>是归一化因子。<span
class="math inline">\(l\)</span> 是 L1 loss。</p>
<h3 id="response-based-distillation">Response-based Distillation</h3>
<p>对检测头的整个输出进行提炼会损害学生模型的性能。
这可能是由于检测任务中正负样本的不平衡以及过多的负样本带来的噪声造成的。最近，一些检测蒸馏方法只对检测头的正样本进行蒸馏，而忽略了具有判别能力的负样本的正则化效应。因此，我们根据选定的
GI 为分类分支和回归分支设计了蒸馏掩码，事实证明这比仅使用 GT
标签作为蒸馏掩码更有效。</p>
<p>然而，由于不同模型对探测头输出的定义不同，我们提出了一个针对不同模型对探测头进行蒸馏的通用框架。首先，基于
GI 的蒸馏掩码计算如下： <span class="math display">\[
M=F_{Assign}(GIs),
\]</span> F是标签分配算法。例如，对于 RetinaNet，我们使用锚点和 GI
之间的 IoU 来确定是否屏蔽。对于 FCOS，GI
以外的所有输出都是屏蔽的。于是Loss为： <span class="math display">\[
\begin{aligned}L_{Response}=\frac{1}{N_m}\sum_{i=1}^{R}M_i\left(\alpha
L_{cls}\left(y_t^i,y_s^i\right)+\beta
L_{reg}\left(r_t^i,r_s^i\right)\right)\\
N_m=\sum_{i=1}^RM_i
\end{aligned}
\]</span> 其中y是分类头输出，r是回归头输出。</p>
<h3 id="overall-loss-function-1">Overall loss function</h3>
<p><span class="math display">\[
\begin{aligned}L&amp;=L_{GT}+\lambda_1L_{Feature}+\lambda_2L_{Relation}+\lambda_3L_{Response}\end{aligned}
\]</span></p>
<h2
id="distilling-object-detectors-via-decoupled-features-cvpr-2021">Distilling
Object Detectors via Decoupled Features (CVPR 2021)</h2>
<p>不足：</p>
<ul>
<li>以往的paper都没有使用背景区域进行蒸馏学习，只使用了目标区域</li>
</ul>
<p>创新点：</p>
<ul>
<li>使用解耦的目标区域和背景区域进行蒸馏学习</li>
</ul>
<p><img src="/img/cv/image-20230918105121610.png" srcset="/img/loading.gif" lazyload /></p>
<h3 id="decouple-intermediate-features-in-distillation">Decouple
Intermediate Features in Distillation</h3>
<p>我们得出的结论是，中间特征中的背景区域可以补充目标区域，进一步帮助学生检测器的训练。利用ground-truth来生成二值化的掩码，随后使用二值化的掩码来区分前景和背景，然后解耦的进行损失值的计算。
<span class="math display">\[
\begin{aligned}&amp;\mathcal{L}_{fea}=\frac{\alpha_{obj}}{2N_{obj}}\sum_{h=1}^{H}\sum_{w=1}^{W}\sum_{c=1}^{C}M_{h,w}(\phi(\mathcal{S}_{h,w,c})-\mathcal{T}_{h,w,c})^2\\&amp;+\frac{\alpha_{bg}}{2N_{bg}}\sum_{h=1}^{H}\sum_{w=1}^{W}\sum_{c=1}^{C}(1-M_{h,w})(\phi(\mathcal{S}_{h,w,c})-\mathcal{T}_{h,w,c})^2,\end{aligned}
\]</span></p>
<h3 id="decouple-region-proposals-in-distillation">Decouple Region
Proposals in Distillation</h3>
<p>在蒸馏检测头时将区域建议分为positive建议和negative建议，所以还是对教师和学生的预测结果进行软化：
<span class="math display">\[
\begin{aligned}p^{s,T_{obj}}(c\mid\theta^s)&amp;=\frac{exp(z_c^s/T_{obj})}{\sum_{j=1}^Cexp(z_j^s/T_{obj})},c\in
Y\\p^{t,T_{obj}}(c\mid\theta^t)&amp;=\frac{exp(z_c^t/T_{obj})}{\sum_{j=1}^Cexp(z_j^t/T_{obj})},c\in
Y\end{aligned}
\]</span> 最后就进行positive和negative的损失计算： <span
class="math display">\[
\begin{gathered}
\begin{aligned}\mathcal{L}_{cls}&amp;=\frac{\beta_{obj}}{K_{obj}}\sum_{i=1}^{K}b_i\mathcal{L}_{KL}(p_i^{s,T_{obj}},p_i^{t,T_{obj}})\end{aligned}
\\
+\frac{\beta_{\boldsymbol{b}g}}{K_{\boldsymbol{b}g}}\sum_{i=1}^K{(1-b_i)\mathcal{L}_{KL}(p_i^{s,T_{\boldsymbol{b}g}},p_i^{t,T_{\boldsymbol{b}g}})}
\\
\begin{aligned}\mathcal{L}_{KL}(p^{s,T},p^{t,T})&amp;=T^2\sum_{c=1}^Cp^{t,T}(c|\theta^t)\log\frac{p^{t,T}(c|\theta^t)}{p^{s,T}(c|\theta^s)}\end{aligned}
\end{gathered}
\]</span></p>
<h2
id="instance-conditional-knowledge-distillation-for-object-detection-nips2021"><strong>Instance-Conditional
Knowledge Distillation for Object Detection</strong> (NIPS2021)</h2>
<p>不足：</p>
<ul>
<li>许多方法会忽略信息量大的上下文区域，或涉及缜密的决策</li>
<li>虽然注意力能为辨别区域提供固有提示，但激活与检测知识之间的关系仍不明确。</li>
</ul>
<p>创新点：</p>
<ul>
<li>我们设计了一个条件解码模块来定位知识，每个实例之间的相关性由实例感知注意力来计算</li>
</ul>
<p><img src="/img/cv/image-20230918172153838.png" srcset="/img/loading.gif" lazyload /></p>
<h3 id="overview">Overview</h3>
<p>为了促进KD，作者提出在教师和学生之间传输实例条件知识，Loss为： <span
class="math display">\[
\mathcal{L}_{distill}=\sum_{i=1}^N\mathcal{L}_d(\kappa_i^\mathcal{S},\kappa_i^\mathcal{T})
\]</span> 其中<span
class="math inline">\(\kappa_i^{\mathcal{T}}=\mathcal{G}(\mathcal{T},
y_i)\)</span>，<span
class="math inline">\(\mathcal{G}\)</span>是实例条件解码模块，由辅助loss进行优化。</p>
<h3 id="instance-conditional-knowledge">Instance-conditional
Knowledge</h3>
<p>实例条件知识由两部分计算得出(1) 无条件知识 (2) 实例条件</p>
<ul>
<li><p>无条件知识 <span class="math inline">\(\mathcal{T}\)</span> ,
表示教师探测器提供的所有信息。将多尺度特征表示为 <span
class="math inline">\(\mathcal{T}=\{X_p \in \mathbb{R}^{D\times
H_p\times W_p}\}_{p\in \mathcal{P}}\)</span> ，其中 <span
class="math inline">\(\mathcal{P}\)</span> 是空间上的分辨率，D
是维度。沿着空间维度方向对不同尺度的表征进行concat，我们就会获得 <span
class="math inline">\(A^T\in \mathbb{R}^{L \times D}\)</span> ，其中
<span class="math inline">\(L=\sum_{p \in \mathcal{P}}H_pW_p\)</span>
是各尺度像素总数之和</p></li>
<li><p>实例条件最初描述的是人类观察到的物体，用 <span
class="math inline">\(\mathcal{Y} = \{y_i\}^N_{i=1}\)</span> 表示，其中
N 是物体编号，<span class="math inline">\(y_i = (c_i, b_i)\)</span> 是第
i 个实例的注释，包括类别 <span class="math inline">\(c_i\)</span>
和框位置 <span class="math inline">\(b_i = (x_i, y_i, w_i,
h_i)\)</span>，其中指定了定位和尺寸信息。</p>
<p>为了为每个实例生成可学习的嵌入，注释被映射到隐藏空间中的查询特征向量
<span
class="math inline">\(q_i\)</span>，该向量指定了收集所需知识的条件：
<span class="math display">\[
\mathbf{q}_i=\mathcal{F}_q(\mathcal{E}(\mathrm{y}_i)),\mathrm{~}\mathbf{q}_i\in\mathbb{R}^D
\]</span> 其中 <span class="math inline">\(\mathcal{E} (\cdot)\)</span>
是一个编码方法，以及 <span class="math inline">\(\mathcal{F}_q\)</span>
是一个MLP</p>
<p>我们通过测量相关反应，从给定 <span
class="math inline">\(q_i\)</span>的 <span
class="math inline">\(\mathcal{T}\)</span>
中检索知识。通过多头注意力机制进行计算得出。 <span
class="math display">\[
\begin{aligned}
&amp;\mathrm{K}_{j}^{\mathcal{T}}&amp;&amp;
=\mathcal{F}_j^k(\mathrm{A}^{\mathcal{T}}+\mathcal{F}_{pe}(\mathrm{P})),\text{
K}_j^{\mathcal{T}}\in\mathbb{R}^{L\times d}  \\
&amp;\mathrm{V}_j^{\mathcal{T}}&amp;&amp;
=\mathcal{F}_j^v(\mathrm{A}^{\mathcal{T}}),\text{
V}_j^{\mathcal{T}}\in\mathbb{R}^{L\times d}  \\
&amp;\mathbf{q}_{ij}&amp;&amp;
=\mathcal{F}_j^q(\mathbf{q}_i),\mathbf{q}_{ij}\in\mathbb{R}^d  \\
&amp;\mathbf{m}_{ij}&amp;&amp;
=softmax(\frac{\mathrm{K}_j^T\mathbf{q}_{ij}}{\sqrt{d}}),\mathbf{m}_{ij}\in\mathbb{R}^L
\end{aligned}
\]</span></p></li>
</ul>
<h3 id="auxiliary-task">Auxiliary Task</h3>
<p>等下次再看，不太懂</p>
<h2
id="focal-and-global-knowledge-distillation-for-detectors-cvpr2022">Focal
and Global Knowledge Distillation for Detectors (CVPR2022)</h2>
<p>不足：</p>
<ul>
<li>将前景和背景不进行解耦一起进行蒸馏结果是最差的，这一现象表明，特征图的不均匀差异会对蒸馏产生负面影响。</li>
<li>再往深处想，不仅前景和背景之间存在负面影响，像素和通道之间也存在负面影响。</li>
<li>缺乏对全局信息的提取。</li>
</ul>
<p>创新点：</p>
<ul>
<li>提出focal蒸馏。在分离前景和背景的同时，焦点提炼还能计算出教师特征中不同像素和通道的关注度，让学生关注教师的关键像素和通道。</li>
<li>提出global蒸馏。我们利用 GcBlock
提取不同像素之间的关系，然后将其从教师提炼到学生。</li>
</ul>
<p><img src="/img/cv/image-20230918174811736.png" srcset="/img/loading.gif" lazyload /></p>
<h3 id="focal-distillation">Focal Distillation</h3>
<p>针对前景和背景不平衡的问题，我们提出了焦点蒸馏法来分离图像，引导学生关注关键像素和通道。对于蒸馏区域的对比如下图所示:</p>
<p><img src="/img/cv/image-20230918175405238.png" srcset="/img/loading.gif" lazyload /></p>
<p>首先还是利用ground-truth来得到二值化掩码M。在不同的图像中，像素数量和前景与背景的比例差异很大。因此，为了对不同目标一视同仁，平衡前景和背景的损失，我们将比例掩码
S 设置为： <span class="math display">\[
\begin{aligned}S_{i,j}&amp;=\begin{cases}\frac1{H_rW_r},&amp;\mathrm{if~}\left(i,j\right)\in
r\\\frac1{N_{bg}},&amp;\mathrm{Otherwise}&amp;\end{cases}\\\\N_{bg}&amp;=\sum_{i=1}^H\sum_{j=1}^W(1-M_{i,j})\end{aligned}
\]</span>
其中r就是ground-truth。如果一个像素属于不同的目标，我们会选择最小的方框来计算
S。</p>
<p>随后先选择焦点像素和通道，然后得到相应的注意力掩码。我们分别计算不同像素和不同通道的绝对平均值：
<span class="math display">\[
\begin{aligned}G^S(F)&amp;=\frac1C\cdot\sum_{c=1}^C|F_c|\\\\G^C(F)&amp;=\frac1{HW}\cdot\sum_{i=1}^H\sum_{j=1}^W|F_{i,j}|\end{aligned}
\]</span> 然后得到注意力机制掩码： <span class="math display">\[
\begin{aligned}A^S(F)&amp;=H\cdot W\cdot
softmax\big(G^S(F)/T\big)\\\\A^C(F)&amp;=C\cdot
softmax\big(G^C(F)/T\big)\end{aligned}
\]</span> 得到特征损失函数： <span class="math display">\[
\begin{aligned}L_{fea}&amp;=\alpha\sum_{k=1}^C\sum_{i=1}^H\sum_{j=1}^WM_{i,j}S_{i,j}A_{i,j}^SA_k^C\left(F_{k,i,j}^T-f(F_{k,i,j}^S)\right)^2\\&amp;+\beta\sum_{k=1}^C\sum_{i=1}^H\sum_{j=1}^W(1-M_{i,j})S_{i,j}A_{i,j}^SA_k^C\left(F_{k,i,j}^T-f(F_{k,i,j}^S)\right)^2\end{aligned}
\]</span>
此外，我们还利用注意力损失使学生检测器模仿教师检测器的空间和通道注意力掩码，其公式为：
<span class="math display">\[
    L_{at}=\gamma\cdot\left(l(A_t^S,A_S^S)+l(A_t^C,A_S^C)\right)
\]</span> 最后的Focal loss为： <span class="math display">\[
L_{focal}=L_{fea}+L_{at}
\]</span></p>
<h3 id="global-distillation">Global Distillation</h3>
<p>利用 GcBlock
在单幅图像中捕捉全局关系信息，并迫使学生探测器从教师那里学习关系。全局Loss为：
<span class="math display">\[
\begin{aligned}
L_{global}=&amp;
\lambda\cdot\sum\left(\mathcal{R}(F^T)-\mathcal{R}(F^S)\right)^2  \\
\mathcal{R}(F)=&amp; \begin{aligned}F+W_{v2}(ReLU(LN(W_{v1}\end{aligned}
\begin{aligned}(\sum_{j=1}^{N_p}\frac{e^{W_kF_j}}{\sum_{m=1}^{N_p}e^{W_kF_M}}F_j))))\end{aligned}
\end{aligned}
\]</span></p>
<h3 id="overall-loss">Overall loss</h3>
<p>于是总的Loss为： <span class="math display">\[
L=L_{original}+L_{focal}+L_{global}
\]</span></p>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/Deep-Learning/">Deep Learning</a>
                    
                      <a class="hover-with-bg" href="/categories/Deep-Learning/cv/">cv</a>
                    
                  </div>
                
                
              </div>
              
                <p class="note note-warning">
                  
                    本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2023/05/22/math/">
                        <span class="hidden-mobile">math</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
              <!-- Comments -->
              <article class="comments" id="comments" lazyload>
                
                  
                
                

              </article>
            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  

  

  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  <script  src="/js/local-search.js" ></script>



  
    <script  src="/js/img-lazyload.js" ></script>
  



  



  
    <script  src="https://cdn.jsdelivr.net/npm/tocbot@4/dist/tocbot.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3/dist/jquery.fancybox.min.js" ></script>
  
  
    <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4/anchor.min.js" ></script>
  
  
    <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2/dist/clipboard.min.js" ></script>
  






  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
        typing(title);
      
    })(window, document);
  </script>





  

  
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        loader: {
          load: ['ui/lazy']
        },
        options: {
          renderActions: {
            findScript: [10, doc => {
              document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
                const display = !!node.type.match(/; *mode=display/);
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                const text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = { node: text, delim: '', n: 0 };
                math.end = { node: text, delim: '', n: 0 };
                doc.math.push(math);
              });
            }, '', false],
            insertedScript: [200, () => {
              document.querySelectorAll('mjx-container').forEach(node => {
                let target = node.parentNode;
                if (target.nodeName.toLowerCase() === 'li') {
                  target.parentNode.classList.add('has-jax');
                }
              });
            }, '', false]
          }
        }
      };
    </script>

    <script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js" ></script>

  











<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>


</body>
</html>
